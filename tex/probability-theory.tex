%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Probability Theory}\label{part:probability_theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\fist Measure Theory (Part \ref{part:measure_theory})

\fist Probabilistic Logic (\S\ref{sec:probabilistic_logic}) --
2013 - \emph{Logic and Probability} -
\url{https://plato.stanford.edu/entries/logic-probability/} (Stanford
Encyclopedia of Philosophy)

\fist cf. Inductive Logic (\S\ref{sec:inductive_logic}) -- makes extensive use
of Probabilistic notions

\emph{Bayesian Epistemology}: Probability as a formal representation of Belief
(cf. Bayesian Inference \S\ref{sec:bayesian_inference})

\emph{Knowledge Representation}: Probability in Artificial Intelligence

\fist cf. Fuzzy Logic (\S\ref{sec:fuzzy_logic})

\fist cf. Quantum Logic (\S\ref{sec:quantum_logic}) --
\emph{Quantum Logic and Probability Theory} (2002) -
\url{https://plato.stanford.edu/entries/qt-quantlog/}

\fist Decision Theory (\S\ref{sec:decision_theory}) --
(wiki): Probabilistic Decision Theory is Sensitive
(\S\ref{sec:sensitivity_analysis}) to \emph{Assumptions} about Probabilities of
Events; Non-probabilistic Decision Rules (\S\ref{sec:decision_rule}), such as
Minimax (\S\ref{sec:minimax}), are \emph{Robust} (\S\ref{sec:robust_statistics})
in that they don't make such Assumptions (FIXME: clarify)

2018 - \emph{A Categorical Look at Random Variables} -
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html} (article):

$\cat{Prob}$ -- Category with Objects as Probability Spaces
(\S\ref{sec:probability_space}) and Morphisms are ``Almost-everywhere-equality
Equivalence Classes'' of Measure-preserving Maps

``Probability Theory is \emph{not} about the Category $\cat{Prob}$, in the sense
that Group Theory or Topology might be said (however incompletely) to be about
the Categories $\cat{Grp}$ or $\cat{Top}$''

\emph{Isomorphic Objects} in $\cat{Prob}$ are \emph{not} the same from the point
of view of \emph{Probability Theory}

example: the Distributions (\S\ref{sec:probability_distribution}) of a Uniform
Random Variable in an Interval, an Infinite Sequence of independent ``coin
flips'', and Brownian Motion $\{B_t : t \geq 0\}$ are \emph{different} things in
Probability Theory, but are Isomorphic in $\cat{Prob}$

the fundamental ``objects'' in Probability Theory are the Morphisms of
$\cat{Prob}$ and those Morphisms are \emph{Random Variables}
(\S\ref{sec:random_variable})

\fist Giry Monads (Probability Monads \S\ref{sec:probability_monad})

\asterism

1933 - Kolmogorov - \emph{Foundations of the Theory of Probability}

\emph{Field of Probabilities} (\emph{$\sigma$-algebra}
(\S\ref{sec:sigma_algebra})



% ==============================================================================
\section{Experiment}\label{sec:experiment}
% ==============================================================================

(wiki): any ``procedure'' that can be infinitely repeated and has a well-defined
Set of possible \emph{Outcomes} (\S\ref{sec:outcome})

when an Experiment is ``performed'' (or ``conducted'') one and only one possible
Outcome ``results'', and any Events (\S\ref{sec:probability_event}), i.e.
Subsets of the Sample Space, containing that Outcome are said to have
``occurred''

a \emph{Random Experiment} has more than one possible Outcome; a Random
Experiment with exactly two possible (Mutually Exclusive) outcomes is called a
\emph{Binomial (Bernoulli) Trial} (\S\ref{sec:bernoulli_trial})

a \emph{Deterministic Experiment} has only a single possible Outcome

a number of repetitions of an Experiment is called a \emph{Composed Experiment},
and the individual repetitions are called ``\emph{Trials}'' (\S\ref{sec:trial})

after conducting many Trials of the same Experiment, the \emph{Relative
  Frequency} (Empirical Probability \S\ref{sec:relative_frequency}) of the
various Outcomes and Events can be assessed

\fist cf. Experimental Unit (Unit of Observation \S\ref{sec:observational_unit})
-- one Member of a Set of objects that are initially equivalent until each
object is subjected to an ``Exprimental Treatment''

\fist cf. Data Collection (Data Generating Process
\S\ref{sec:data_generating_process})

\fist cf. Replication (Sampling \S\ref{sec:replication})



% ------------------------------------------------------------------------------
\subsection{Trial}\label{sec:trial}
% ------------------------------------------------------------------------------

an individual repetition of a Composed Experiment



\subsubsection{Binomial Trial}\label{sec:binomial_trial}

or \emph{Bernoulli Trial}

Binomial Distribution (\S\ref{sec:binomial_distribution}); special case:
Bernoulli Distribution (\S\ref{sec:bernoulli_distribution})

Mathematical Formalization: Bernoulli Process (\S\ref{sec:bernoulli_process})

\begin{enumerate}
  \item repeated Trials
  \item each Trial results in an Outcome
  \item Probability of Success is Constant
  \item each Trial is Independent
\end{enumerate}

Number of Successes in $n$ Bernoulli Trials is a \emph{Binomial Random
  Variable} (\S\ref{sec:binomial_variable})

\fist Statistical Odds (\S\ref{sec:odds}) -- Ratio of the Probability that an
Event will occur versus the Probability that it will not occur, i.e. a Binomial
Trial



% ------------------------------------------------------------------------------
\subsection{Outcome}\label{sec:outcome}
% ------------------------------------------------------------------------------

a possible result of an Experiment (or Trial)

a Subset of Outcomes in a Sample Space is called an \emph{Event}
(\S\ref{sec:probability_event})

if an actual Outcome is inside an Event, the Event is said to have
``\emph{occurred}''

\fist cf. \emph{Observation} (or \emph{Realization} \S\ref{src:observation}):
the ``Outcome'' of a \emph{Random Variable} (\S\ref{sec:random_variable}), i.e.
the Member of the Random Variable's State Space corresponding to an Outcome
which occurred in the Sample Space of a performed Experiment

\fist note sometimes ``\emph{Outcome}'' is used to refer to a Response Variable
(Regressor \S\ref{sec:regression_analysis}) or Classification Category
(\S\ref{sec:classification}) to be Predicted



% ------------------------------------------------------------------------------
\subsection{Sample Space}\label{sec:sample_space}
% ------------------------------------------------------------------------------

a.k.a. \emph{Possibility Space} or \emph{Event Space}

Set of all possible Outcomes of Statistical \emph{Experiment}
(\S\ref{sec:experiment})

$S$

an \emph{Event} (\S\ref{sec:probability_event}) is a Subset of a Sample Space

the Probability (\S\ref{sec:probability}) $P$ of an Event $E$ is usually defined
such that $P$ satisfies the Kolmogorov Axioms (\S\ref{sec:probability_axioms})
\fist \emph{Unit Measure Axiom}: the total Probability of the Sample Space is
$1 = P(S)$

Random Variable (\S\ref{sec:random_variable}): Function on a Sample Space to a
Measurable \emph{State Space}

a Statistical Model (\S\ref{sec:statistical_model}) $(S,\mathcal{P})$ is a
Sample Space $S$ together with a Set of Probability Distributions
(\S\ref{sec:probability_distribution}) $\mathcal{P}$ on $S$

\fist cf. \emph{Sample} (\S\ref{sec:sample}) -- a Subset of a Population
(\S\ref{sec:population})



% ------------------------------------------------------------------------------
\subsection{Event}\label{sec:probability_event}
% ------------------------------------------------------------------------------

Subset of a Sample Space (\S\ref{sec:sample_space})

if an actual Outcome is inside an Event (Subset), the Event is said to have
``\emph{occurred}''

\emph{Probability} (\S\ref{sec:probability})

(Kolmogorov33) analogy between the \emph{Measure} (\S\ref{sec:measure}) of a Set
and the Probability of an Event

(FIXME: cf. Observation \S\ref{sec:observation})

The \emph{Information Content} (\emph{Self-information} or \emph{Surprisal}
\S\ref{sec:information_content}) of a Sampled (\S\ref{sec:sample}) Random
Variable or Signal (\S\ref{sec:signal}) is the amount of Information
(\S\ref{sec:information}) ``gained'' by the Sample; this Information Content is
a Random Variable defined for any Event as the Negative Log-probability
(\S\ref{sec:log_probability}) of the Vent, regardless of whether a Random
Variable is being measured or not. (wiki)



\subsubsection{Elementary Event}\label{sec:elementary_event}

or \emph{Atomic Event} or \emph{Simple Event} is an Event which contains only a
\emph{single Outcome} in the Sample Space, i.e. it is a Singleton Subset of the
Sample Space

the Unitarity Axiom (\S\ref{sec:probability_axioms}) states that the
Probability that at least one of the Elementary Events in the Entire Sample
Space will Occur is $1$



\subsubsection{Mutually Exclusive Event}\label{sec:mutually_exclusive}

$\sigma$-additivity Axiom (\S\ref{sec:probability_axioms}): the Probability of
a Countable Sequence of Disjoint Sets is equal to the Sum of the individual
Probabilities

a Quasiprobability Distribution (\S\ref{sec:quasiprobability_distribution})
violates the $\sigma$-additivity Axiom by not representing Probabilities of
Mutually Exclusive States



\subsubsection{Independent Event}\label{sec:independent_event}

\fist cf. Independence (\S\ref{sec:independence})

Independent if and only if $P(A \cap B) = P(A) P(B)$, or in terms of Conditional
Probability (\S\ref{sec:conditional_probability}), $A$ and $B$ are Independent
if and only if $P(A|B) = P(A)$ or $P(B|A) = P(B)$

\fist two Events are Independent if and only if their Odds Ratio
(\S\ref{sec:odds_ratio}) equals $1$

an Event is Self-independent if and only if $P(A) = 0$ or $P(A) = 1$

$n$ Events are Independent if:
\[
  P(A_i \cap A_j \cap \cdots \cap A_g) = P(A_i)P(A_j) \cdots P(A_g)
\]
for any distinct Events $i,j,\ldots,g$

Pairwise Independence does not imply $n$-way Independence

$P(A \cap B | C) = P(A|C)P(B|C)$

\fist Conditional Independence (\S\ref{sec:conditional_independence})

note that two Events may be Independent, but not \emph{Conditionally}
Independent, i.e. the Intersection of each Independent Event $A$ and $B$ with
the Conditioning Event $C$ may be Disjoint, making them \emph{Dependent}



% ==============================================================================
\section{Probability}\label{sec:probability}
% ==============================================================================

Probability of an Event (\S\ref{sec:probability_event}) $A$, $P(A)$ is the Sum
of Weights of all Sample Points in $A$

the Probability $P$ of an Event $E$ is usually defined such that $P$ satisfies
the Kolmogorov Axioms (\S\ref{sec:probability_axioms})

(Kolmogorov33) analogy between the \emph{Measure} (\S\ref{sec:measure}) of a Set
and the Probability of an Event

cf. Uncertainty (\S\ref{sec:uncertainty})

cf. \emph{Likelihood} (\S\ref{sec:likelihood}) -- a Probability refers to
variable ``Sample Data'' (\S\ref{sec:sample}) for a fixed Hypothesis
(\S\ref{sec:hypothesis_testing}), while a Likelihood refers to variable
Hypotheses for fixed Data

$\frac{|A|}{|S|}$

$P(A \cup B) = P(A) + P(B) - P(A \cap B)$

$P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) -
P(B \cap C) + P(A \cap B \cap C)$

Corollary: for Disjoint $A_1, A_2, \ldots$:
\[
  P(A_1 \cup A_2 \cup \ldots) = P(A_1) + P(A_2) + \ldots
\]

$P(A_1 \cap A_2 \cap \ldots \cap A_k) = P(A_1) P(A_2 | A_1) P(A_3 |
A_1 \cap A_2) \ldots P(A_k | A_1 \cap A_2 \cap \ldots \cap A_{k-1})$

\textbf{(Thm.) Continuity of Probabilities} \emph{If $A_n \rightarrow A$, then:}
\[
  P(A_n) \rightarrow P(A)
\]
\emph{as $n \rightarrow \infty$}.

cf. \emph{Probability Measure} (\S\ref{sec:probability_measure}),
\emph{Probability Measure Function} (\S\ref{sec:probability_measure_function})

\fist Algorithmic Probability (\S\ref{sec:algorithmic_probability})

(wiki):

two broad categories of \emph{Probability Interpretations}:
\begin{enumerate}
  \item \emph{Physical Probabilities} -- ``Objective'' or \emph{Frequency
    Probabilities} associated with ``Random'' Physical Systems
    \begin{enumerate}
      \item \emph{Frequentist Probability} (``Long-run Probability'') -- defines
        an Event's (\S\ref{sec:probability_event}) Probability as the Limit of
        its Relative Frequency (Empirical Probability
        \S\ref{sec:relative_frequency}) in a large number of Trials
        (\S\ref{sec:trial}); cf. Frequentist Inference
        (\S\ref{sec:frequentist_inference})
      \item \emph{Propensity Probability} (``Single-case Probability'') -- a
        Propensity (\S\ref{sec:propensity}) is not a Relative Frequency but a
        purported ``\emph{cause}'' or explanation of the observed stable
        Relative Frequencies; invokes the Law of Large Numbers
        (\S\ref{sec:large_numbers}) to explain stable \emph{long-run}
        Frequencies as a manifestation of invariant \emph{single-case}
        Probabilities
    \end{enumerate}
  \item \emph{Evidential Probabilities} -- \emph{Bayesian Probability};
    interpretation of Probability as ``reasonable'' \emph{Expectation}
    (\S\ref{sec:expected_value}) or ``degree of belief''; assigns Probability to
    Statements even when no Random Process (\S\ref{sec:stochastic_process}) is
    involved; assigns Probability to Hypotheses (\S\ref{sec:hypothesis}), unlike
    Frequentist Inference which Tests Hypotheses without assigning Probability
    \begin{enumerate}
      \item \emph{Classical Interpretation}
      \item \emph{Subjective Interpretation}
      \item \emph{Inductive (Epistemic) Interpretation}
      \item \emph{Logical Interpretation}
      \item \emph{Intersubjective Interpretation}
    \end{enumerate}
\end{enumerate}

2011 - \emph{Interpretations of Probability} -
\url{https://plato.stanford.edu/entries/probability-interpret/}:
\begin{itemize}
  \item \emph{Classical Probability} (Laplace) -- Probability shared equally
    among ``possible outcomes'' (cf. Keynes ``Principle of Indifference'');
    issues include Infinite Probability Spaces and the elimination of
    Irrational-valued Probabilities; extension to Countable Infinities by
    generalizing the Principle of Indifference to the ``Principle of Maximum
    Entropy'' (Jaynes)-- select from the family of all Probability Functions
    consistent with evidence the Function that maximizes Entropy; for
    difficulties with Uncountable Infinities cf. the \emph{Bertrand Paradox}--
    Probabilities may not be Well-defined if the method that produces the Random
    Variable is not Well-defined, cf. \emph{Invariance Condition} (Jaynes): two
    problems with the same evidence should assign the same Probabilities
  \item \emph{Logical Probability} (``Non-deductive Logic''
    \S\ref{sec:probabilistic_logic}) -- generalizes Classical Interpretation to
    assigning unequal weights to possibilities, and Probabilities may be
    computed from asymmetric evidence; generalizes Deductive Logic and its
    notion of Implication to a complete theory of Inference with a notion of
    ``\emph{Degree of Implication}'' that relates Evidence to Hypotheses;
    Deductive Logic is the case where the Confirmation Function takes values 0
    and 1; Carnap-- choice of Language and Confirmation Function are in a sense
    arbitrary
  \item \emph{Subjective Probability} (``Subjective Bayesianism'', cf.
    Subjective Logic \S\ref{sec:subjective_logic}) --
    Probability as a \emph{degree of ``belief''}, cf. Doxastic Logic
    (\S\ref{sec:doxastic_logic}); betting analysis (de Finetti): ``operational''
    definition of Probability as a measurement of belief as a basis of action
    (Ramsey); Utilities (``desirabilities'') of outcomes, Probabilities of
    outcomes, and ``rational Preferences'' can be derived from one another in
    different ways-- (Ramsey26) derives Utilities and Probabilities from
    Preferences alone (``Logic of Partial Belief''); see also ``Expected Utility
    Representation'' (Savage54, Jeffrey66) ``Decision Theory''
    (\S\ref{sec:decision_theory}) in which ``rational choice'' maximizes
    Expected Utility;
    these accounts presuppose a connection between ``desire-like states'' and
    ``belief-like states'' rendered explicit in the connections between
    Preferences and Probabilities;
    \emph{Orthodox Bayesianism}, Conditioning (\S\ref{sec:conditioning});
    compare also Probabilistic Coherence (Regularity)--only \emph{a priori}
    falsehoods are assigned Probability 0--to Consistency in ordinary Doxastic
    Logic; cf. Moore's Paradox
  \item \emph{Frequency Interpretations} -- Relative Frequency (Empirical
    Probability \S\ref{sec:relative_frequency}); identifies the Probability of
    an Outcome with the Frequency of the Outcome in a suitable Sequence of
    ``trials''; differs from the Classical Interpretation in counting only the
    \emph{actual} Outcomes instead of the \emph{possible} Outcomes; Finite
    Frequentism (Venn)-- dominant view in Statistics; problems handling
    single-cases and ``unrepeatable'' events; Hypothetical Frequentism:
    extension of Relative Frequencies of an actual Sequence of ``Trials'' to
    counterfactual, limiting Relative Frequencies in case of an Infinite number
    of Trials; Reference Class Problem: Relative Frequencies must be
    ``Relativised'' to a ``Reference Class'' (this problem may exist for other
    interpretations as well)-- solutions restrict to certain Sequences of
    Outcomes, e.g. (Infinite) ``\emph{Collectives}'' (Von Mises57)--cf. Infinite
    Bernoulli Sequences (\S\ref{sec:bernoulli_sequence})--where a
    \emph{Place-selection} is an effective method of selecting indices of
    Members of a Sequence such that the selection or not of Index $i$ depends
    \emph{at most} on the first $i-1$ Outcomes (``attributes''), with the Axioms
    of Convergence (the limiting Relative Frequency of any Outcome exists) and
    Randomness (the limiting Relative Frequency of each Outcome in a Collective
    $\omega$ is the same in any Infinite Subsequence of $\omega$ determined by
    Place-selection; note that trivial Sequences such as $H,H,H,\ldots$ satisfy
    this ``Randomness'' Axiom; cf. the Principle of Maximum Entropy in Classical
    Probability), Algorithmic Randomness (\S\ref{sec:algorithmic_randomness});
    issues with limiting Relative Frequencies are that they violate Countable
    Additivity and the Domain of Definition is not a Set-field or a
    $\sigma$-algebra (de Finetti72)
  \item \emph{Propensity Interpretations} (Pierce10, Popper57) -- Probability as
    a ``physical'' tendency or disposition of a given ``physical situation'' to
    yield an Outcome of a certain kind, or to yield long-run Relative Frequency
    of such an Outcome; motivated by ``single-case'' Probability attributions
    (e.g. radioactive decay); distinction between \emph{long-run} and
    \emph{single-case} Propensities (Gillies00); \emph{Humphreys' Paradox}:
    Propensities as measures of ``causal tendencies'' violates Bayes' Theorem
    which allows the reversal of a Conditional Probability-- cf. alternative
    ``Probabilistic Causal Calculus'' (Fetzer81)
  \item \emph{Best-system Interpretations} (Lewis94) -- a Theory of the
    ``Physical Laws'' of the Universe ``optimally balances'' simplicity,
    strength, and ``fit'' (assigning a higher Probability to the ``actual''
    history of the Universe
\end{itemize}

(\url{https://plato.stanford.edu/entries/logic-probability/}):

Probabilistic Semantics (\S\ref{sec:probabilistic_semantics}) for Logical
Consequence Relation yields \emph{Probability Preserving} (dually,
\emph{Uncertainty Propagating}) Deductive Validity (\S\ref{sec:validity}),
rather than Truth Preserving (\S\ref{sec:truth_preservation})

\emph{Probability, Knowledge, and Meta-probability}:
\url{https://www.lesswrong.com/posts/2xmKZu73gZLDEQw7c/probability-knowledge-and-meta-probability}



% ------------------------------------------------------------------------------
\subsection{Probability Axioms}\label{sec:probability_axioms}
% ------------------------------------------------------------------------------

\emph{Kolmogorov Axioms}

the Probability $P$ of an Event $E$ is usually defined such that $P$ satisfies
the Kolmogorov Axioms

\begin{enumerate}
  \item (\emph{Non-negativity}) The Probability of an Event is a Non-negative
    (Finite) Real Number
  \item (\emph{Unit Measure}) The Probability that at least one of the
    Elementary Events in the entire Sample Space will Occur is $1$
  \item (Countable \emph{$\sigma$-additivity}) Any Countable Sequence of
    Disjoint Sets (Mutually Exclusive Events) $E_1, E_2, \ldots$ satisfies:
    \[
      P (\bigcup_{i=1}^\infty = \sum_{i=1}^\infty P(E_i)
    \]
\end{enumerate}

\fist Unit Measure: cf. \emph{Unitarity} in Physics is used as a synonym for
``Consistency'', esp. the condition that the Hamiltonian is bounded from below,
i.e. there is a State of Minimal Energy (the \emph{Ground State} or
\emph{Vacuum State}), which is needed for the Third Law of Thermodynamics to
hold

the Third Axiom is relaxed in Quasiprobability Distributions
(\S\ref{sec:quasiprobability_distribution}); to compensate sometimes they are
allowed to have regions of Negative Probability
(\S\ref{sec:negative_probability}) Density

\fist cf. Probabilistic Logic (\S\ref{sec:probabilistic_logic})

(wiki): note that Axiomatic Probability Theory avoids definition of a
\emph{Random Sequence} (\S\ref{sec:random_sequence})



% ------------------------------------------------------------------------------
\subsection{Law of Total Probability}\label{sec:total_probability}
% ------------------------------------------------------------------------------

For a Countably Inifinite Partition of a Sample Space
(\S\ref{sec:sample_space}), $\{ B_n : n = 1,2,3,\ldots \}$, with each Event
$B_n$ being Measurable (\S\ref{sec:measure}), then for any Event $A$ in the same
Probability Space (\S\ref{sec:probability_space}):
\[
  P(A) = \sum_n P(A \cap B_n)
\]
or equivalently:
\[
  P(A) = \sum_n P(A|B_n) P(B_n)
\]
where terms such that $P(B_n) = 0$ are omitted from the summation.



% ------------------------------------------------------------------------------
\subsection{Log-probability}\label{sec:log_probability}
% ------------------------------------------------------------------------------

the \emph{Negative} of the Log Probability is the \emph{Information Content}
(\S\ref{sec:information_content}) of an Event (\S\ref{sec:probability_event})

cf. Log-likelihood (\S\ref{sec:log_likelihood})

(wiki): viewing Data as ``evidence'', Log-likelihood is the ``weight'' of
evidence or providing ``\emph{support}'' for a particular Model; the support of
a Model given an Event is the Negative of the Surprisal (Information Content),
i.e. the Log-probability, of the Event given the Model: a Model is supported by
an Event to the extent that the Event is ``\emph{unsurprising}'' given the Model



% ------------------------------------------------------------------------------
\subsection{Conditional Probability}\label{sec:conditional_probability}
% ------------------------------------------------------------------------------

where Event $A$ is known to have occurred:

$P(B|A) = \frac{P(A \cap B)}{P(A)}$ when $P(A) > 0$

$P(A \cap B) = P(A) P(B|A)$ when $P(A) > 0$

$P(A|A) = 1$

note that Conditional Probability is only defined when the Conditioning Event
has a Non-zero (Positive) Probability

$A$ and $B$ are Independent (\S\ref{sec:independent_event}) if and only if
$P(A|B) = P(A)$

\fist Conditional Independence (\S\ref{sec:conditional_independence})

\fist Discriminative Models (Classification \S\ref{sec:discriminative_model})

\fist Negative Probability (\S\ref{sec:negative_probability})

(Witten18): Quantum Information Theory doesn't have a good analog to defining a
Conditional Probability Distribution as in Classical Information Theory, but
does have an analog of \emph{Strong Subadditivity of Entropy}
(\S\ref{sec:entropy})



% ------------------------------------------------------------------------------
\subsection{Baye's Theorem}\label{sec:bayes_theorem}
% ------------------------------------------------------------------------------

or \emph{Bayes Rule}

\fist Bayes Classifier (\S\ref{sec:bayes_classifier})

\url{https://arbital.com/p/bayes_rule/?l=1zq}

\emph{Bayesian Inference} (\S\ref{sec:bayesian_inference})

\[
  P(A|B) = \frac{P(A)P(B|A)}{P(B)}
\]

for a Partition $A_1, \ldots, A_k$ of $\Omega$ such that $P(A_i) > 0$ for all
$i$, if $P(B) > 0$ then for $i \in \{1, \ldots, k\}$:
\[
  P(A_i|B) = \frac{
    P(B|A_i)P(A_i)
  }{
    \sum_j P(B|A_j)P(A_j)
  }
\]
where $A_i$ is the \emph{Prior Probability} of $A$ and $P(A_i|B)$ is the
\emph{Posterior Probability} of $A$ (FIXME: what is $A$ here ???)

\fist Relative Entropy (Kullback-Leibler Divergence
\S\ref{sec:relative_entropy})



% ------------------------------------------------------------------------------
\subsection{Independence}\label{sec:independence}
% ------------------------------------------------------------------------------

\emph{Property of Probabilistic Independence}

$P(A \cap B) = P(A)P(B)$

for Dependent Events, $P(A) \neq P(A|B)$

two Random Variables (\S\ref{sec:random_varible}) are \emph{Dependent}
(\S\ref{sec:dependence}) if they do not Satisfy the Property of
Probabilistic Independence:
\[
  P(X \in A, Y \in B) = P(X \in A) P(Y \in B)
\]

\fist cf. Independent Event (\S\ref{sec:independent_event}) --
two Events are Independent if and only if their Odds Ratio
(\S\ref{sec:odds_ratio}) equals $1$

if $X$ and $Y$ are Independent and have Finite Second Moments, then they are
Uncorrelated (\S\ref{sec:statistical_correlation}); not all Uncorrelated
Variables are Independent

for Independent Random Variables, $Var(X + Y) = Var(X) + Var(Y)$ and
$Var(X - Y) = Var(X) + Var(Y)$

cf. Binomial Distribution (\S\ref{sec:binomial_distribution}) -- Sum of
Independent Trials; Sampling 10\% Rule (TODO)

Tests for Independence (Wasserman04, Ch.15) %TODO



\subsubsection{Conditional Independence}\label{sec:conditional_independence}

$P(A \cap B | C) = P(A|C)P(B|C)$

note that two Events may be Independent, but not \emph{Conditionally}
Independent, i.e. the Intersection of each Independent Event $A$ and $B$ with
the Conditioning Event $C$ may be Disjoint, making them \emph{Dependent}

\fist cf. Conditional Probability (\S\ref{sec:conditional_probability})

\fist Bayesian Networks (\S\ref{sec:bayes_network});
Markov Condition (\S\ref{sec:markov_condition}) -- every Node is Conditionally
Independent (\S\ref{sec:conditional_independence}) of its Non-descendents, given
its Parents

\fist Pairwise Markov Graph (\S\ref{sec:pairwise_markov}) -- encodes a Set
of Pairwise Conditional Independence Relations

\url{http://lesswrong.com/lw/pi/classical_configuration_spaces/}
-- ``Conditional Independence happens when the Joint Probability Distribution
is the Product of the individual Probability Distributions''



% ------------------------------------------------------------------------------
\subsection{Odds}\label{sec:odds}
% ------------------------------------------------------------------------------

for Probability $p$, the Odds are:
\[
  \frac{p}{1-p}
\]

the Odds can range in $[0, \infty)$

\fist Logit (Log-odds \S\ref{sec:logit}):
\[
  ln \frac{p}{1-p}
\]
is the Inverse of the Logistic Function (\S\ref{sec:logistic_function}); the
Logistic Function can be used to convert a Log-odds into a Probability

an expression of Relative Probabilities: the Odds \emph{in favor} of an Event or
Proposition is the Ratio of the Probability that the Event will occur to the
Probability that it will not occur, i.e. a \emph{Binomial Trial}
(Bernoulli Trial \S\ref{sec:binomial_trial})



\subsubsection{Odds Ratio}\label{sec:odds_ratio}

Statistic (\S\ref{sec:statistic})

quantifies strength of Association (Dependence \S\ref{sec:dependence}) between
two Events

\fist cf. Risk Ratio (\S\ref{sec:risk_ratio}), Risk Difference
(\S\ref{sec:risk_difference})

two Events are Independent if and only if their Odds Ratio equals $1$

\url{https://www.youtube.com/watch?v=ckkiG-SDuV8}:

in Logistic Regression (\S\ref{sec:logistic_regression}), the Odds Ratio for an
Independent Variable represents how the Odds change with a 1 unit increase in
the Independent Variable, holding all other variables constant



\subsubsection{Log-odds}\label{sec:log_odds}

Logit (Log-odds \S\ref{sec:logit})

\[
  \ln \Big(\frac{p}{1 - p}\Big)
\]

(wiki) --
the difference between the Log-odds of two Probabilities is the Logarithm
of the Odds Ratio (\S\ref{sec:odds_ratio}), $R$:
\[
  logit(p_1) - logit(p_2) = \ln\Big(\frac{p_1/(1 - p_1)}{p_2/(1 - p_2)}\Big)
    = \ln R
\]



% ------------------------------------------------------------------------------
\subsection{Negative Probability}\label{sec:negative_probability}
% ------------------------------------------------------------------------------

or \emph{Quasiprobability}

may apply to \emph{Unobservable Events} or \emph{Conditional Probability}
(\S\ref{sec:conditional_probability})

forbidden by the First Kolmogorov Axiom (\S\ref{sec:probability_axioms})

the Third Axiom ($\sigma$-additivity) is relaxed in Quasiprobability
Distributions (\S\ref{sec:quasiprobability_distribution}); to compensate
sometimes they are allowed to have regions of Negative Probability Density,
violating the First Law

Wigner Distribution in Phase Space (Quantum Corrections)



% ==============================================================================
\section{Probability Space}\label{sec:probability_space}
% ==============================================================================

$(\Omega, \Sigma, P)$

A \emph{Probability Space} is a Measure Space (\S\ref{sec:measure_space}) with a
\emph{Probability Measure} (\S\ref{sec:probability_measure}).

\fist cf. Measure-preserving Dynamical Systems
(\S\ref{sec:measure_preserving_system})

$\cat{Prob}$ -- Category with Objects as Probability Spaces and Morphisms are
``Almost-everywhere-equality Equivalence Classes'' of Measure-preserving Maps
--
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html}:
``Probability Theory is not about the Category $\cat{Prob}$''

$\cat{Prob}$ -- Category with Objects as Probability Spaces and Morphisms are
``Almost-everywhere-equality Equivalence Classes'' of Measure-preserving Maps
(\S\ref{sec:measure_preserving_map})

the fundamental ``objects'' of Probability Theory are the \emph{Morphisms} of
$\cat{Prob}$ and these Morphisms are \emph{Random Variables}
(\S\ref{sec:random_variable})



% ------------------------------------------------------------------------------
\subsection{Probability Measure}\label{sec:probability_measure}
% ------------------------------------------------------------------------------

A \emph{Probability Measure} is a Measure (\S\ref{sec:measure}) that assigns the
Value $1$ to the entire Measure Space (making it a Probability Space).

cf. \emph{Probability} (\S\ref{sec:probability})

\fist a \emph{Probability Distribution} (\S\ref{sec:probability_distribution})
is the Pushforward Measure (\S\ref{sec:pushforward_measure}) of a Random
Variable (\S\ref{sec:random_variable})

\emph{Choquet Simplex} (\S\ref{sec:choquet_theory}) -- any Point in a Choquet
Simplex is represented by a unique Probability Measure



\subsubsection{Probability Measure Function}
\label{sec:probability_measure_function}

\subsubsection{Kullback-Leibler Divergence}\label{sec:kullback_leibler}

can be used to characterize Relative Entropy (\S\ref{sec:relative_entropy}),
Randomness (\S\ref{sec:statistical_randomness})

defined between PDFs (\S\ref{sec:pdf})

can be used to show Consistency of MLE (\S\ref{sec:mle})



% ==============================================================================
\section{Random Variable}\label{sec:random_variable}
% ==============================================================================

A general \emph{Random Element} is a Measurable Function
(\S\ref{sec:measurable_function}) on a Sample Space (\S\ref{sec:sample_space})
mapping Outcomes (\S\ref{sec:outcome}) in the Sample Space to some other Set of
Values called the \emph{State Space}:
\[
  X : \Omega \rightarrow E
\]
The Type (\S\ref{sec:datatype}) of a State Space is called a \emph{Statistical
  Data Type} (\S\ref{sec:statistical_data_type}).

A Realization of a Random Element resulting from a specific Outcome is called an
\emph{Observation} (\S\ref{sec:observation}).

A \emph{Random Variable} is a Random Element where $E = \reals$ is the Real Line
(\S\ref{sec:real_line}).

other types of Random Elements:
\begin{itemize}
  \item Random Measure (\S\ref{sec:random_measure})
  \item ...
\end{itemize}

The \emph{Information Content} (\emph{Self-information} or \emph{Surprisal}
\S\ref{sec:information_content}) of a Sampled (\S\ref{sec:sample}) Random
Variable or Signal (\S\ref{sec:signal}) is the amount of Information
(\S\ref{sec:information}) ``gained'' by the Sample; this Information Content is
a Random Variable defined for any Event (\S\ref{sec:probability_event}) as the
Negative Log-probability (\S\ref{sec:log_probability}) of the Event,
regardless of whether a Random Variable is being measured or not. (wiki)

the Entropy of a Random Variable is the Expected Value of its Information
Content

\fist cf. \emph{Statistical Unit} (\S\ref{sec:statistical_unit}) -- one Member
of a Set of entities being analyzed, providing the ``material source'' for an
abstract Random Variable (wiki)

\fist a \emph{Statistic} (\S\ref{sec:statistic}) is an Observable Random
Variable defined as a Function of a Random Variable constituting a Random Sample
(IID \S\ref{sec:random_sample})

Discrete Random Variable (\S\ref{sec:discrete_random_variable})

Continuous Random Variable (\S\ref{sec:continuous_random_variable})

a \emph{Probability Distribution} (\S\ref{sec:probability_distribution})
is the Pushforward Measure (\S\ref{sec:pushforward_measure}) of $X$

such a distribution records all the individual Probabilities $P(X = x)$,
sometimes written $p_X(x)$

a \emph{Dependence} (Association \S\ref{sec:association}) between two Random
Variables (``Bivariate Data'' \S\ref{sec:bivariate_distribution}) is any
``Statistical Relationship'' (which may or may not be Causal)

Wasserman04 Ch.2

two Random Variables $X$ and $Y$ are \emph{Independent}, sometimes denoted
$X \coprod Y$, if they Satisfy the Property of \emph{Probabilistic Independence}
(\S\ref{sec:independence}):
\[
  P(X \in A, Y \in B) = P(X \in A) P(Y \in B)
\]
that is, for every $x$ and $y$, the Events $\{X \leq x\}$ and $\{Y \leq y\}$ are
Independent Events (\S\ref{sec:independent_event}); in terms of CDFs:
\[
  \forall x,y\ F_{X,Y}(x,y) = F_X(x)F_Y(y)
\]
or in terms of Probability Mass or Density Functions (if they exist):
\[
  \forall x,y\ f_{X,Y}(x,y) = f_X(x)f_Y(y)
\]

\textbf{Thm.} \emph{If the Range of Random Variables $X$ and $Y$ is a (possibly
  Infinite) Rectangle and $f_{X,Y}(x,y) = g(x)h(y)$ for arbitrary Functions $g$
  and $h$, then $X$ and $Y$ are Independent.}

\fist Relative Entropy (\S\ref{sec:relative_entropy}), Mutual Information
(\S\ref{sec:mutual_information})

cf. \emph{Statistical Randomness} (\S\ref{sec:statistical_randomness}),
\emph{Algorithmic Randomness} (\S\ref{sec:algorithmic_randomness})

a Discrete Random Variable $Y = r(X)$ that is a Transformation of a Discrete
Random Variable $X$, the Probability Mass Function is given by:
\[
  f_Y(y) = P(Y = y) = P(r(X) = y) = P(X \in r^{-1}(y))
\]
for Continuous Random Variables, the CDF is defined as the Integral of the PDF
$f_X(x)$ over the Set $A_y = \{x : r(x) \leq y\}$:
\[
  F_Y(y) = \int_{A_y} f_X(x) dx
\]
and the PDF can be defined as $f_Y(y) = F_Y'(y)$

for Continuous $X$ with CDF $F_X$, $Y = F_X(X)$ is called a \emph{Probability
  Integral Transform} (\S\ref{sec:probability_integral_transform}) and has a
Standard Uniform Distribution

\asterism

\emph{A Categorical Look at Random Variables} -
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html}:

$\cat{Prob}$ -- Category with Objects as Probability Spaces
(\S\ref{sec:probability_space}) and Morphisms are ``Almost-everywhere-equality
Equivalence Classes'' of Measure-preserving Maps
(\S\ref{sec:measure_preserving_map})

the fundamental ``objects'' of Probability Theory are the \emph{Morphisms} of
$\cat{Prob}$ and these Morphisms are \emph{Random Variables}

a Random Variable is defined as a Measurable Map
(\S\ref{sec:measurable_function}):
\[
  X : \Omega \rightarrow E
\]
where $(\Omega,\mathbb{P})$ is a Probability Space and $E$ is an arbitrary
Measurable Space

\asterism

MIT 6.041SC Lec. 5 - \url{https://www.youtube.com/watch?v=3MOahpLxj6A}:

Functions of Random Variables are also Random Variables

Probability Mass Function (\S\ref{sec:pmf}) $p_X$ assigns
Probabilities to Elements of $x \in E$:
\[
  p_X(x) = P(X = x)
\]

$p_X(x) \geq 1$

$\sum_x p_X(x) = 1$

Expected Value (\S\ref{sec:expected_value}) of a Random Variable is a kind of
``average'' where Probabilities are treated like ``frequencies'':
\[
  E[X] = \sum_x xp_X(x)
\]
for a Function of a Random Variable $Y = g(X)$:
\[
  E[Y] = \sum_x g(x)p_X(x)
\]

for a PMF that is Symmetric around a certain point, that point is the Expected
Value



% ------------------------------------------------------------------------------
\subsection{Observation}\label{sec:observation}
% ------------------------------------------------------------------------------

An \emph{Observation} (\emph{Observed Value}, \emph{Measurement},
\emph{Realization}, or \emph{Random Variate}) is the Element of a Random
Variable's State Space corresponding to the actual Outcome (\S\ref{sec:outcome})
resulting from performing an Experiment (\S\ref{sec:experiment}).

in Statistics, it is commonly assumed that Observations are \emph{Independent
  and Identifcally Distributed} (\emph{IID} \S\ref{sec:iid})

\fist A \emph{Data Generating Process} (\S\ref{sec:data_generating_process})
is a possibly unspecified \emph{Probabilistic (Statistical) Model}
(\S\ref{sec:statistical_model}) governing the ``Generation'' of Observed Data.
The \emph{Level of Measurement} (\S\ref{sec:measurement_level}) is a
classification of the \emph{Statistical Data Type}
(\S\ref{sec:statistical_data_type}) of a State Space.

\fist A \emph{(Statistical) Population} (\S\ref{sec:population}) is a totality
of Observations. A \emph{Statistical Sample} (\S\ref{sec:sample}) is
a Subset of a Population selected by a definite \emph{Sampling Procedure}
(\S\ref{sec:sampling}). A \emph{``Data Point''} is an Observation of a
\emph{Statistical Unit} (\S\ref{sec:statistical_unit}) in the Statistical
Sample. A \emph{Statistic} (\S\ref{sec:statistic}) is an Observable Random
Variable defined as a Function of a Random Variable constituting a Random
Sample.

\fist \emph{Statistical Inference} (\S\ref{sec:inferential_statistics}) is the
use of Sample Data to \emph{Infer} (cf. Logical Inference
\S\ref{sec:logical_inference}, Inference Rules \S\ref{sec:inference_rule}) the
Distribution (\S\ref{sec:probability_distribution}) that \emph{Generated}
(\S\ref{sec:data_generating_process}) the Data.

\fist \emph{Observational Error} (\emph{Measurement Error}
\S\ref{sec:observational_error}) is the
difference between an Observed Value (Random Variate) and the ``true'' Value;
a \emph{Statistical Error} (\S\ref{sec:error}) is the difference between an
Observed Value and its \emph{Expected Value};
the \emph{Residual} (\S\ref{sec:residual}) of an Observed Value is the
difference between the Observed Value and the \emph{Estimated}
(\S\ref{sec:estimation_theory}) Value

\fist Multivariate Statistics (\S\ref{sec:multivariate_statistics}) --
\emph{simultaneous} Observation and Analysis of more than one Outcome Variable
(Random Vector \S\ref{sec:random_vector})

\fist Curve Fitting (\S\ref{sec:curve_fitting}), Regression Analysis
(\S\ref{sec:regression_analysis}): the process of constructing a Curve (or
Function) that has the ``best Fit'' to a Series of Data Points (Observations),
possibly subject to constraints

\fist cf. \emph{Observable} (\S\ref{sec:observable})



\subsubsection{Deviation}\label{sec:deviation}

A \emph{Deviation} is a Signed Difference (\S\ref{sec:subtraction}) between an
Observation and some other value, usually the Observed Random Variable's Mean
(Expected Value \S\ref{sec:expected_value}).

\begin{itemize}
  \item an \emph{Error} (\S\ref{sec:error}) is a Deviation of an Observed value
    and an ideal (possibly theoretical) ``true'' value, e.g. Deviation from a
    Population Mean
  \item a \emph{Residual} (\S\ref{sec:residual}) is a Deviation of an Observed
    value from an \emph{Estimate} (\S\ref{sec:estimation_theory}) of a ``true''
    value, e.g. Deviation from a Sample Mean
\end{itemize}

\emph{Statistical Dispersion} (or ``Variability'' \S\ref{sec:dispersion}) is
measured by Population Parameters or Sample Statistics defined on the
\emph{Distribution of Deviations}:
\begin{itemize}
  \item Variation Ratio (Qualitative Variation, Deviation from the Mode
    \S\ref{sec:variation_ratio}) -- proportion of cases that are \emph{not} in
    the Mode (\S\ref{sec:mode})
  \item Mean Absolute Deviation (MAD \S\ref{sec:mad}) -- average of Absolute
    Deviations (\S\ref{sec:absolute_deviation}); the Median (\S\ref{sec:median})
    minimizes the MAD
  \item Standard Deviation (\S\ref{sec:standard_deviation}) -- average of
    Squared Deviations (\S\ref{sec:squared_deviation}); the Mean
    (\S\ref{sec:mean}) minimizes the Standard Deviation
  \item Maximum Absolute Deviation (\S\ref{sec:maximum_absolute_deviation}) --
    maximum of Absolute Deviations around a point; the Mid-range
    (\S\ref{sec:midrange}) minimizes the Maximum Absolute Deviation
\end{itemize}

see also:
\begin{itemize}
  \item Regression Error (\S\ref{sec:regression_error}) -- Deviation of a value
    Predicted by an Estimated Regression Function from the value Predicted by
    the ``true'' Prediction Function
  \item Regression Residual (\S\ref{sec:regression_residual}) -- Deviation of an
    Observed value from the value Predicted by an Estimated Regression Function
  \item Mean Signed Deviation (\S\ref{sec:mean_signed_deviation}) -- Average
    of Signed Error of the Estimated value (produced by an Estimator) from the
    ``true''  value
  \item Mean Squared Deviation (MSD \S\ref{sec:msd}) -- Average of the Squared
    Error of the Estimated value (produced by an Estimator) from the ``true''
    value; MSD is the Second Moment of the Error; for an Unbiased Estimator the
    MSD is the Variance of the Estimator
  \item Root-Mean-Square Deviation (RMSD \S\ref{sec:rmsd}) -- Square Root of the
    MSD (cf. Standard Deviation)
  \item Standard Error (\S\ref{sec:standard_error}) -- the Standard Deviation of
    a Sampling Distribution
  \item Mean Absolute Difference (\S\ref{sec:mean_absolute_difference}) --
    Average Absolute Difference of two IID Random Variables
  \item Mean Absolute Error (MAE \S\ref{sec:mae}) -- Average Absolute Difference
    between two Continuous Random Variables, i.e. the Average Vertical or
    Horizontal Difference between each Point (Pair) and the Identity Line
\end{itemize}



\paragraph{Absolute Deviation}\label{sec:absolute_deviation}\hfill

Absolute Error, Absolute Residual

\fist Mean Absolute Deviation (MAD \S\ref{sec:mad}) -- measure of Dispersion
(\S\ref{sec:dispersion}) associated with the $L^1$ Metric (Taxicab Norm
\S\ref{sec:p_norm}); corresponding Central Tendency
(\S\ref{sec:central_tendency}) is the Median (\S\ref{sec:median})

\fist Maximum Absolute Deviation (\S\ref{sec:maximum_absolute_deviation}) --
measure of Dispersion associated with the $L^{\infty}$ Metric (Max Norm
\S\ref{sec:p_norm}); corresponding Central Tendency is the Midrange
(\S\ref{sec:midrange})



\paragraph{Squared Deviation}\label{sec:squared_deviation}\hfill

\fist Variance (\S\ref{sec:variance}) is the Expected Value of the Squared
Deviation from the Mean (SDM \S\ref{sec:sdm})

\fist Loss Function for Regression (\S\ref{sec:regression_analysis}); cf.
Categorical Cross-entropy Loss Function for Classification

\begin{itemize}
  \item Sum of Squared Deviations (\S\ref{sec:sum_squared_deviation})
    \begin{itemize}
      \item Total Sum of Squares (\S\ref{sec:tss})
      \item Sum of Squared Residuals (\S\ref{sec:ssr})
      \item Explained Sum of Squares (\S\ref{sec:ess})
    \end{itemize}
  \item Mean Squared Deviation (MSD \S\ref{sec:msd})
  \item Squared Deviation from the Mean (\S\ref{sec:sdm})
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Expected Value}\label{sec:expected_value}
% ------------------------------------------------------------------------------

The \emph{Expected Value}, \emph{Expectation}, or \emph{Mean} (First Raw Moment
\S\ref{sec:moment}/Cumulant \S\ref{sec:cumulant}) of a Random Variable is a kind
of ``average'' where Probabilities are treated like ``frequencies''. (FIXME:
clarify)

\fist Mean (\S\ref{sec:mean}) -- Central Tendency (\S\ref{sec:central_tendency})
for Interval Measurement (\S\ref{sec:measurement_level}); associated with
minimizing the Standard Deviation (\S\ref{sec:standard_deviation}); cf. the
Median minimizes Absolute Deviation (\S\ref{sec:absolute_deviation})

as an Estimate (\S\ref{sec:estimation_theory}) of $X$, the Expected Value $E[X]$
minimizes Squared Error (\S\ref{sec:error})

note that $E(X + Y) = E(X) + E(Y)$, but not for $m(X+Y)$

\fist Sample Mean (Estimator \S\ref{sec:sample_mean}) -- minimizes Squares of
the Residuals;
by the Law of Large Numbers (\S\ref{sec:large_numbers}), the Arithmetic Mean
Converges to the Expected Value as the Sample Size gets larger

(Kolmogorov33) analogy between the \emph{Expectation} of a Random Variable, and
\emph{Lebesgue Integration} (\S\ref{sec:lebesgue_integral})

For a Random Variable $X$ defined on Probability Space $(\Omega,\Sigma,P)$, the
Expected Value $\mu_X = E[X]$ of $X$ is defined as the Lebesgue Integral:
\[
  \mu_X = E[X] = \int_\Omega X(\omega) dP(\omega)
\]

In terms of the Cumulative Distribution Function (\S\ref{sec:cdf}) $F_X$ of $X$
and a Radon Integral (\S\ref{sec:radon_integral}):
\[
  \mu_X = E[X] = \int\limits_{-\infty}^{\infty} x dF_X(x)
\]

For Discrete Random Variable $X$ with Probability Mass Function
(\S\ref{sec:pmf}) $f_X(x)$, the Expected Value of $X$ is:
\[
  E[X] = \sum_x x f_X(x)
\]
For a PMF that is Symmetric around a certain point, that point is the Expected
Value.

For a Continuous Random Variable $X$ with Probability Density Function
(\S\ref{sec:pdf}) $f_X(x)$, the Expected Value of $X$ is:
\[
  E[X] = \int x f(x) dx
\]

note that some Distributions have no Expected Value, e.g. the Cauchy
Distribution (\S\ref{sec:cauchy_distribution})

for Linear Function $g$:
\[
  E[g(X)] = g(E[X])
\]

Expectations of Constants (i.e. as ``degenerate'' Random Variables) are just
the Constants themselves: $E[a] = a$

Expectations of Random Variables multiplied by Constant is the Constant
multiplied by the Expectation of the Random Variable:
\[
  E[aX] = aE[X]
\]

Expectation of a Random Variable with the addition of a Constant is the
Constant added to the Expectation of the Random Variable:
\[
  E[X + b] = E[X] + b
\]

for a Function of a Random Variable $Y = g(X)$:
\[
  E[Y] = \sum_x g(x) p_X(x)
\]
%FIXME: is this only for discrete random variables ???

For Random Variable $X$ with Probability Density Function $f(x)$, the
Expected Value of a Measurable Function
(\S\ref{sec:measurable_function}) of $X$, $g(X)$, is:
\[
  \mu_{g(X)} = E[g(X)] = \int\limits_{-\infty}^{\infty} g(x) f(x) dx
\]

For Joint Probability Density Function:
\[
  E[X Y] = \int\int x y j(x,y) dx dy
\]
\fist Note that $E[X Y]$ is not necessarily equal to $E[X] E[Y]$, see Covariance
(\S\ref{sec:covariance}).

For $X$ and $Y$ Independent (\S\ref{sec:independence}), $E[X,Y] = E[X] E[Y]$

If $a$ and $b$ are Constants, then $E[aX + b] = a E[X] + b$

$E [g(X) \pm h(X)] = E[g(X)] \pm E[h(X)]$

$E [g(X,Y) \pm h(X,Y)] = E[g(X,Y)] \pm E[h(X,Y)]$

Wasserman04 Ch.3

\textbf{Thm.} for $X_1, \ldots, X_n$ Random Variables and $a_1, \ldots, a_n$
Constants:
\[
  E\Big(\sum_i a_i X_i\Big) = \sum_i a_i E(X_i)
\]

\textbf{Thm.} for $X_1, \ldots, X_n$ Independent Random Variables:
\[
  E\Big(\prod_{i=1}^n X_i\Big) = \prod_i E(X_i)
\]

\emph{Conditional Expectation} -- $E(X|Y)$ is a Random Variable whose Value is
$E(X|Y = y)$ when $Y = y$

\textbf{Thm.} (Rule of Iterated Expectations) \emph{
  For Random Variables $X$ and $Y$, assuming Expectations exist, then:
  \[
    E(E(Y|X)) = E(Y) \quad\quad E(E(X|Y)) = E(X)
  \]
  or generally for any Function $r(x,y)$:
  \[
    E(E(r(X,Y)|X)) = E(r(X,Y))
  \]
}

Moment-generating Function (\S\ref{sec:moment_generating_function}):
$M_X(t) := E(e^{tX})$ for $t \in \reals$

the Variance (Expected Value of the Squared Deviation \S\ref{sec:deviation}) of
a Random Variable $X$ is equal to:
\begin{align*}
  \sigma^2 = V(X) & = E(X - E(X))^2   \\
                  & = E(X^2) - E(X)^2 \\
                  & = \int(x - E(X))^2 dF(x) \\
\end{align*}
assuming the Expectation exists

$V(Y) = E(V(Y|X)) + V(E(Y|X))$

\textbf{Thm.} \emph{Covariance (\S\ref{sec:covariance}) Satisfies:
  \[
    Cov(X,Y) = E(XY) - E(X)E(Y)
  \]
}

example of Probability as a special case of Expectation (Wasserman Ch. 3): for
Event $A$ with Indicator Function $I_A(x)$:
\[
  E(I_A(X)) = \int I_A(x)f_X(x)dx = \int_A f_X(x) dx = P(X \in A)
\]

the \emph{$k^{th}$ Moment} (\S\ref{sec:moment}) of $X$ is defined as $E(X^k)$
assuming that $E(|X|^k) < \infty$

\emph{Cauchy-Schwarz Inequality} (\S\ref{sec:cauchy_schwarz}):
\[
  E|XY|^2 \leq \sqrt{E(X^2)E(Y^2)}
\]
where $X$ and $Y$ have Finite Variances

\textbf{Thm.} (Jensen's Inequality) \emph{
  If $g$ is a Convex Function, then:
  \[
    E(g(X)) \geq g(E(X))
  \]
  and if $g$ is Concave, then:
  \[
    E(g(X)) \leq g(E(X))
  \]
}
examples: $E(X^2) \geq E(X)^2$; if $X$ is Positive, then $E(1/X) \geq 1/E(X)$;
since $\log$ is Concave $E(\log X) \leq \log E(X)$



\subsubsection{Law of Large Numbers}\label{sec:large_numbers}

the Sample Mean (\S\ref{sec:sample_mean})
$\overline{X}_n = \frac{1}{n}\sum_i X_i$ of a Sequence of Random Variables
$X_1, \ldots, X_n$ \emph{Converges in Probability}
(\S\ref{sec:stochastic_convergence}) to the Expectation
(\S\ref{sec:expected_value}) $\mu = E(X_i)$ as $n \rightarrow \infty$, i.e.
$\overline{X}_n$ is close to $\mu$ with high Probability

\textbf{Thm.} (Weak Law of Large Numbers) \emph{If $X_1, \ldots, X_n$ are IID
  (\S\ref{sec:iid}), then:
  \[
    \overline{X}_n \xrightarrow{P} \mu = E(X_1)
  \]
}
(note that since $X_i$ are IID, $\mu$ is identical for all $X_i$)

\textbf{Thm.} (Strong Law of Large Numbers) \emph{If $X_1, \ldots, X_n$ are IID,
  and $\mu = E(|X_1|) < \infty$, then $\overline{X}_n \xrightarrow{as} \mu$}

\fist cf. Law of Iterated Logarithm (\S\ref{sec:iterated_logarithm})

\fist \emph{Propensity Probability} (``Single-case Probability''
\S\ref{sec:propensity}) -- invokes the Law of Large Numbers to explain stable
\emph{long-run} Relative Frequencies (\S\ref{sec:relative_frequency}) as a
manifestation of invariant \emph{single-case} Probabilities

\fist cf. Asymptotic Theory (Large Sample Theory \S\ref{sec:asymptotic_theory})



\subsubsection{Markov's Inequality}\label{sec:markovs_inequality}

\textbf{Thm.} (Markov's Inequality) \emph{
  Given a Random Variable $X$ with Expectation $E(X)$, for any $t > 0$:
  \[
    P(X > t) \leq \frac{E(X)}{t}
  \]
}



\subsubsection{Conditional Expectation}\label{sec:conditional_expectation}

or \emph{Conditional Mean}

\fist Regression Analysis (\S\ref{sec:regression_analysis}) commonly Estimates
the Conditional Expectation of a Dependent Variable given an Independent
Variable

\fist Probability Monads (\S\ref{sec:probability_monad}): Partial Evaluations
(\S\ref{sec:partial_evaluation}) as Conditional Expectations
(\url{https://golem.ph.utexas.edu/category/2019/05/partial_evaluations.html},
Perrone 2018)



\paragraph{Law of Total Expectation}\label{sec:total_expectation}\hfill

$E(X) = E(E(X | Y))$

MIT 6.041SC, Lec. 6



\subsubsection{Risk}\label{sec:risk}

the Expected Value of an ``undesirable'' Outcome (\emph{Absolute Risk}) or Loss
Function (\S\ref{sec:objective_function})

\emph{Risk Function}

\begin{itemize}
  \item Mean Integrated Squared Error (MISE \S\ref{sec:mise}) -- $L^2$ Risk
    Function \fist Density Estimation (\S\ref{sec:density_estimation}):
    $Risk = Bias^2 + Variance$
  \item ...
\end{itemize}



\paragraph{Risk Ratio}\label{sec:risk_ratio}\hfill

or \emph{Relative Risk}

cf. Odds Ratio (\S\ref{sec:odds_ratio})



\paragraph{Risk Difference}\label{sec:risk_difference}\hfill

cf. Odds Ratio (\S\ref{sec:odds_ratio})



\paragraph{Empirical Risk Minimization (ERM)}\label{sec:erm}\hfill

Probability Inequalities (Classification Error \S\ref{sec:classification_error})



% ------------------------------------------------------------------------------
\subsection{Moment-generating Function}\label{sec:moment_generating_function}
% ------------------------------------------------------------------------------

$M_X(t) = E(e^{tX}) = \int e^{tx} dF(x)$ for $t \in \reals$

the Cauchy Distribution (\S\ref{sec:cauchy_distribution}) has no
Moment-generating Function

the Cumulant-generating Function (\S\ref{sec:cumulant_generating_function}) is
the Natural Logarithm of the Moment-generating Function

\fist Laplace Transform (\S\ref{sec:laplace_transform})
%FIXME: explain relation

cf. Characteristic Function (\S\ref{sec:characteristic_function}) --
if a Random Variable has a Moment-generating Function then the Characteristic
Function can be extended to the Complex Plane

every Distribution with a Moment-generating Function is a member of a Natural
Exponential Family (\S\ref{sec:nautral_exponential_family})



% ------------------------------------------------------------------------------
\subsection{Cumulant-generating Function}
\label{sec:cumulant_generating_function}
% ------------------------------------------------------------------------------

Natural Logarithm of the Moment-generating Function



% ------------------------------------------------------------------------------
\subsection{Characteristic Function}\label{sec:characteristic_function}
% ------------------------------------------------------------------------------

for a Scalar Random Variable $X$, the \emph{Characteristic Function} is the
Expected Value of $e^{itX}$ where $i$ is the Imaginary Unit and $t \in \reals$
is the Argument of the ``Characteristic Function'' $\varphi_X : \reals
\rightarrow \comps$:
\[
  \varphi_X(t) = E[e^{itX}] = \int_\reals e^{itx} dF_X(x)
\]
where $F_X$ is the Cumulative Distribution Function (\S\ref{sec:cdf}) of $X$ and
the Integral is a Riemann-Sieltjes Integral (TODO: xref)

like the Cumulative Distribution Function, completely determines the behavior
and properties of the Probability Distribution

cf. Moment-generating Function (\S\ref{sec:moment_generating_function}) --
the Characteristic Function always exists even when the Moment-generating
Function and Probability Density Function (\S\ref{sec:pdf}) do not exist;
if a Random Variable has a Moment-generating Function then the Characteristic
Function can be extended to the Complex Plane

if the Random Variable admits a Probability Density Function then the
Characteristic Function is the Fourier Transform (\S\ref{sec:fourier_transform})
of the Probability Density Function and vice versa

\fist cf. Indicator Functions (\S\ref{sec:indicator_function})



% ------------------------------------------------------------------------------
\subsection{Discrete Random Variable}\label{sec:discrete_random_variable}
% ------------------------------------------------------------------------------

State Space is a Countable Set

has a Cumulative Distribution Function (\S\ref{sec:cdf}) that is Piecewise
Constant (\S\ref{sec:step_function})

\fist Discrete Probability Distributions (\S\ref{sec:discrete_probability})



\subsubsection{Probability Mass Function (PMF)}\label{sec:pmf}

for a Discrete Random Variable $X$, the \emph{Probability Mass Function} is
defined as:
\[
  p_X(x) = P(X = x)
\]
and has the Properties:
\begin{enumerate}
  \item $p_X(x) \geq 0$
  \item $\sum_x p_X(x) = 1$
\end{enumerate}

characterizes a Discrete Probability Distribution
(\S\ref{sec:discrete_probability})

related to the CDF (\S\ref{sec:cdf}) $F_X$ of $X$ by:
\[
  F_X(x) = P(X \leq x) = \sum_{x_i \leq x} p_X(x_i)
\]

for a Probability Mass Function that is Symmetric around a certain point, that
point is the Expected Value (\S\ref{sec:expected_value})

\fist each Row in the Transition Matrix of a Markov Process
(\S\ref{sec:markov_process}) represents a Probability Mass Function



\paragraph{Probability Generating Function}
\label{sec:probability_generating_function}\hfill

(Ordinary) Generating Function (\S\ref{sec:generating_function})--i.e. Formal
Power Series representation--of the Probability Mass Function of a Discrete
Random Variable



\subsubsection{Binomial Random Variable}\label{sec:binomial_variable}

number of ``Successes'' in $n$ Independent Trials with Constant Success
Probability $p$

can be viewed as a Sum of a ``Bernoulli'' Random Variables, i.e. the Sum of $n$
Binomial Variables with $n = 1$

Binomial (Bernoulli) Trial (\S\ref{sec:binomial_trial})

Binomial Distribution (\S\ref{sec:binomial_distribution})

cf. Binomial Coefficients (\S\ref{sec:binomial_coefficient})

\fist cf. Geometric Distribution (\S\ref{sec:geometric_distribution}) -- number
of Trials until first Success

$X \sim B(n,p)$

Expected Value $E(X) = np$

Variance $\sigma^2 = np(1-p)$

Probability Mass Function:
\[
  f(k,n,p) = P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}
\]
for $k = 0,1,2, \ldots, n$



% ------------------------------------------------------------------------------
\subsection{Continuous Random Variable}\label{sec:continuous_random_variable}
% ------------------------------------------------------------------------------

has Probability $0$ of assuming a particular Value

\fist Continuous Probability Distributions (\S\ref{sec:continuous_probability})



\subsubsection{Probability Density Function (PDF)}\label{sec:pdf}

\emph{Probability Density Function} $f_X(x)$ of a Continuous Random Variable $X$
has the Properties:
\begin{enumerate}
  \item $\forall x \in \reals, f_X(x) \geq 0$
  \item $\int\limits_{-\infty}^{\infty} f_X(x) dx = 1$
  \item $\forall a \leq b, P (a < X < b) = \int\limits_a^b f(x) dx$
\end{enumerate}
the CDF (\S\ref{sec:cdf}) $F_X$ of $X$ can be defined in terms of $f_X$ as:
\[
  F_X(x) = \int_{-\infty}^x f_X(t)dt
\]
i.e. the CDF of a Continuous Random Variable gives the Area under the PDF from
$-\infty$ to $x$, and $f_X(x) = F'_X(x)$ at all Points $x$ at which $F_X$ is
Differentiable

\emph{Probability Densities} represent \emph{rates} at which Probabilities
``accumulate'' (cf. Discrete \emph{Probability Masses} (\S\ref{sec:pmf}) which
are actual Probabilities); cf. \emph{Likelihood} (\S\ref{sec:likelihood})

characterizes a Continuous Probability Distribution
(\S\ref{sec:continuous_probability})

for a Random Variable that admits a Probability Density Function, the
Characteristic Function (\S\ref{sec:characteristic_function}) of the Random
Variable is the Fourier Transform (\S\ref{sec:fourier_transform}) of its
Probability Density Function and vice versa

\fist Probability Amplitude (Quantum Systems \S\ref{sec:probability_amplitude}):
Complex Number with Modulus Squared representing a Probability Density

\fist Kullback-Leibler Divergence (\S\ref{sec:kullback_leibler})



\paragraph{Normalizing Constant}\label{sec:normalizing_constant}\hfill

used to reduce any Probability Function to a Probability Density Function with
total Probability $1$

%FIXME: same concept as Normalizing Constant for bayesian inference ?



\subsubsection{Mean Absolute Error (MAE)}\label{sec:mae}

Average Absolute Difference between two Continous Random Variables, e.g.:
\begin{itemize}
  \item between \emph{Predicted} and \emph{Observed} (cf. Residual
    \S\ref{sec:residual})
  \item between \emph{Initial} and \emph{Subsequent Observations}
  \item between \emph{measurement techniques}
\end{itemize}

Expected Value of the Absolute Difference of two Continuous Random Variables

measures the Vertical or Horizontal Distance from the Identity Line

\fist not to be confused with \emph{Mean Absolute Deviation} (MAD
\S\ref{sec:mad})-- Average of Deviations around a central point, or \emph{Mean
  Absolute Difference} (\S\ref{sec:mean_absolute_difference})-- Average Absolute
Difference of two IID Random Variables



% ------------------------------------------------------------------------------
\subsection{Mixed Random Variable}\label{sec:mixed_random_variable}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Random Sequence}\label{sec:random_sequence}
% ------------------------------------------------------------------------------

(wiki):

a Random Sequence is a special case of \emph{Stochastic Process}
(\S\ref{sec:stochastic_process}) where the Index Set is some Subset of the
Integers

Stochastic Processes: Sequences of possibly \emph{Dependent}
(\S\ref{sec:dependence}) Random Variables; cf. IID (\S\ref{sec:iid}) Sequences

cf. Random Vector (\S\ref{sec:random_vector})

note that Axiomatic Probability Theory (\S\ref{sec:probability_axioms})
avoids definition of a \emph{Random Sequence}

paradigms:
\begin{itemize}
  \item \emph{Frequency / Measure-theoretic} approach -- (Mises-Church); the
    Sets ``Coding'' Frequency-based Stochastic properties are special kinds of
    Null Sets (\S\ref{sec:null_set}) (Martin-L\"of)
  \item \emph{Complexity / Compressibility} approach -- (Kolmogorov-Chatin)
    Algorithmic (Kolmogorov) Complexity (\S\ref{sec:algorithmic_complexity})
  \item \emph{Predictability} approach -- (Schnorr) Constructive Martingales
    (\S\ref{sec:martingale})
\end{itemize}

Bernoulli Sequence (\S\ref{sec:bernoulli_sequence})

\emph{Subsequence Selection Criterion} -- \emph{Mises-Church Randomness}: any
Recursive Function which having read the first $N$ elements of the Sequence
decides if it wants to select element $N+1$; cf. Algorithmic Randomness
(\S\ref{sec:algorithmic_randomness})

\emph{Reference Class Problem}: Relative Frequencies must be ``Relativised'' to
a ``Reference Class'' (other interpretations of Probability may have this
problem as well)--

solutions restrict to certain Sequences of Outcomes, e.g. (Infinite)
``\emph{Collectives}'' (Von Mises57)--cf. Infinite Bernoulli Sequences --where a
\emph{Place-selection} is an effective method of selecting indices of Members of
a Sequence such that the selection or not of Index $i$ depends \emph{at most} on
the first $i-1$ Outcomes (``attributes''), with the Axioms of \emph{Convergence}
(the limiting Relative Frequency of any Outcome exists) and \emph{Randomness}
(the limiting Relative Frequency of each Outcome in a Collective $\omega$ is the
same in any Infinite Subsequence of $\omega$ determined by Place-selection; note
that trivial Sequences such as $H,H,H,\ldots$ satisfy this ``Randomness'' Axiom;
cf. the Principle of Maximum Entropy in Classical Probability), Algorithmic
Randomness (\S\ref{sec:algorithmic_randomness});
issues with limiting Relative Frequencies are that they violate Countable
Additivity and the Domain of Definition is not a Set-field or a $\sigma$-algebra
(de Finetti72)



% ------------------------------------------------------------------------------
\subsection{Multivariate Random Variable}\label{sec:random_vector}
% ------------------------------------------------------------------------------

or \emph{Random Vector}

$X = (X_1, \ldots, X_n)$

cf. Random Sequences (\S\ref{sec:random_sequence})

\fist cf. Stochastic Processes (\S\ref{sec:stochastic_process}) -- Sequences of
not necessarily IID (\S\ref{sec:iid}) Random Variables

\fist Multivariate Statistics (\S\ref{sec:multivariate_statistics}) --
\emph{simultaneous} Observation and Analysis of more than one Outcome Variable

Multinomial Distribution (\S\ref{sec:multinomial_distribution})

Multivariate Normal Distribution (\S\ref{sec:multivariate_normal})



\subsubsection{Independent and Identically Distributed (IID)}\label{sec:iid}

if $X_1, \ldots, X_n$ are Independent and each has the same Marginal
Distribution (\S\ref{sec:marginal_distribution}) with CDF $F$, then $X_1,
\ldots, X_n$ are said to be \emph{Independent and Identically Distributed
  (IID)}, writing:
\[
  X_1, \ldots, X_n \sim F
\]
and if $F$ has Density $f$, then:
\[
  X_1, \ldots, X_n \sim f
\]
$X_1, \ldots, X_n$ are then called a \emph{Random Sample of Size $n$ from $F$}
(\S\ref{sec:random_sample})

in Statistics it is commonly assumed that Observations (\S\ref{sec:observation})
are IID



\subsubsection{Homoscedasticity}\label{sec:homoscedasticity}

an Assumption in Regression Analysis (\S\ref{sec:regression_analysis}): Error is
Constant accross Observations



\subsubsection{Heteroscedasticity}\label{sec:heteroscedasticity}

Weighted Least Squares (WLS \S\ref{sec:wls})



% ==============================================================================
\section{Probability Distribution}\label{sec:probability_distribution}
% ==============================================================================

the Pushforward Measure (\S\ref{sec:pushforward_measure}) of a Random Variable
(\S\ref{sec:random_variable})

cf. Probability Measure (\S\ref{sec:probability_measure})

\emph{Probability Distribution Function} of a Random Variable $X$ often means
the Cumulative Distribution Function (\S\ref{sec:cdf}) $F_X$, but can also refer
to:
\begin{itemize}
  \item Probability Mass Function (\S\ref{sec:pmf}) -- Discrete Probability
    Distributions (\S\ref{sec:discrete_probability})
  \item Probability Density Function (\S\ref{sec:pdf}) -- Continuous Probability
    Distributions (\S\ref{sec:continuous_probability})
\end{itemize}

\fist cf. Probability Measure Function
(\S\ref{sec:probability_measure_function}), Distribution Function (Measure
Theory \S\ref{sec:distribution_function}), Distribution (Analysis
\S\ref{sec:distribution}), Frequency Distribution
(\S\ref{sec:frequency_distribution})

\fist \emph{Statistical Inference} (\S\ref{sec:inferential_statistics}) -- using
Sample Data (\S\ref{sec:sample_sample}) to \emph{Infer} the Distribution
that \emph{Generated} (\S\ref{sec:data_generating_process}) the Data; a
Statistical Model (\S\ref{sec:statistical_model}) $(S,\mathcal{P})$ is a Sample
Space (\S\ref{sec:sample_space}) $S$ together with a Set of Probability
Distributions $\mathcal{P}$ on $S$

\fist Random Graphs (\S\ref{sec:random_graph}) -- Probability Distribution over
a Graph

collapsing a Probability Distribution (Measure) of Probability Distrubtions to a
Probability Distribution is called the ``Giry Monad'' (TODO)

(wiki): a Statistical (or Population) Parameter
(\S\ref{sec:population_parameter}) is a ``quantity'' that indexes a Family of
Probability Distributions

the Entropy (\S\ref{sec:entropy}) of a Distribution is the Mean number
of Bits-per-symbols in an Optimal Encoding (\S\ref{sec:encoding}) --
\url{https://golem.ph.utexas.edu/category/2017/02/functional_equations_iii_expla.html}

Cross Entropy (\S\ref{sec:cross_entropy}) measures the average number of Bits
needed to identify an Event drawn from an underlying Set of Events under two
Probability Distributions $p$ and $q$, if the ``coding scheme'' is optimized for
an ``unnatural'' Distribution $q$ rather than a ``true'' Distribution $p$
%FIXME: clarify

\emph{Principle of Maximum Entropy}; cf. Axiom of Randomness in Frequentist
Probability (Von Mises57)

(Witten18): Quantum Information Theory doesn't have a good analog to defining a
Conditional Probability Distribution (\S\ref{sec:conditional_probability}) as in
Classical Information Theory, but does have an analog of \emph{Strong
  Subadditivity of Entropy}

the Quantum analog of a Classical Probability Distribution is a \emph{Density
  Matrix} (\S\ref{sec:density_matrix}), a representation of the Linear
\emph{Density Operator} \S\ref{sec:density_operator})-- a Self-adjoint
(Hermitian), Positive Semi-definite, Trace One, and may be Infinite-dimensional
Matrix; every Matrix with these properties can be ``Purified'', meaning that it
is the Density Matrix of \emph{some} Pure State on some ``Bipartite'' System
$AB$; there is no ``classical analog'' for Purification, i.e. there is no way to
make Probability Distribution ``pure'' (one outcome with Probability $1$) by
adding more Variables



% ------------------------------------------------------------------------------
\subsection{Moment}\label{sec:moment}
% ------------------------------------------------------------------------------

the \emph{$k^{th}$ Moment} of $X$ is defined as $E(X^k) = \int x^k dF(x)$
assuming that $E(|X|^k) < \infty$, where $F$ is the CDF (\S\ref{sec:cdf}) of $X$

the \emph{$k^{th}$ Sample Moment} of a Sample (\S\ref{sec:sample}) $X_1, \ldots,
X_n$ is:
\[
  \frac{1}{n}\sum_{i=1}^n X^k_{i}
\]

\fist Cumulants (\S\ref{sec:cumulant}) -- Moments determine Cumulants and vice
versa

\textbf{Thm.} \emph{If $j < k$ and the $k$th Moment Exists, then the $j$th
  moment exists.}

Mean (Expected Value \S\ref{sec:expected_value}) -- First Raw Moment; Sample
Mean (\S\ref{sec:sample_mean})

Variance (\S\ref{sec:variance}) -- Second Central Moment

Skewness (\S\ref{sec:skewness}) -- Third Central Moment; ``lopsided-ness''

Kurtosis (\S\ref{sec:kurtosis}) -- Fourth Central Moment; Measure of the
``heaviness'' of the tail of a Distribution

Fourth and higher-order Cumulants are not equal to Central Moments

\fist Moment-generating Function (\S\ref{sec:moment_generating_function})

\fist Method of Moments (\S\ref{sec:moments_method}) -- Estimator of Statistical
Model Parameters

\fist Mean Squared Deviation or Mean Squared Error (MSE \S\ref{sec:msd}) of an
Estimator (\S\ref{sec:estimator}) is the Average of the Squared Error of the
Estimated value (produced by an Estimator) from the ``true'' value; MSD is
the Second Moment of the Error; for an Unbiased Estimator the MSD is the
Variance of the Estimator



% ------------------------------------------------------------------------------
\subsection{Cumulant}\label{sec:cumulant}
% ------------------------------------------------------------------------------

\fist Moments (\S\ref{sec:moment}) -- Cumulants determine Moments and vice
versa

Mean (Expected Value \S\ref{sec:expected_value}) -- First Cumulant

Variance (\S\ref{sec:variance}) -- Second Cumulant

Skewness (\S\ref{sec:skewness}) -- Third Cumulant; ``lopsided-ness''

Fourth and higher-order Cumulants are not equal to Central Moments

\fist Cumulant-generating Function (\S\ref{sec:cumulant_generating_function})



% ------------------------------------------------------------------------------
\subsection{Cumulative Distribution Function (CDF)}\label{sec:cdf}
% ------------------------------------------------------------------------------

MIT 6.041SC, Lec.8

CDF applies equally well to Discrete and Continuous Random Variables

(wiki):

the \emph{Cumulative Distribution Function (CDF)} of a Real-valued Random
Variable $X$ evaluated at $x$ is equal to the Probability that $X$ will take a
value less than or equal to $x$:
\[
  \forall x \in \reals, F_X(x) = P(X \leq x)
\]
every CDF is Non-decreasing and Right-continuous

special case of Distribution Function (Measure Theory
\S\ref{sec:distribution_function}) with the boundary conditions
$\lim_t\rightarrow\infty F_X(t) = 0$ and $\lim_{t\rightarrow\infty}F_X(t) = 1$

every Function with these four Properties is a CDF, i.e. for every such Function
a Random Variable can be defined such that the Function is a CDF of that Random
Variable

a Random Variable $X$ with CDF $F$ is indicated by the notation $X \sim F$, but
note that this does not mean ``apprximate equality''

the CDF $F_X$ of a Discrete Random Variable can be related to its Probability
Mass Function (\S\ref{sec:pmf}) $f_X$ by:
\[
  F_X(x) = P(X \leq x) = \sum_{x_i \leq x} f_X(x_i)
\]

the CDF of a Continuous Random Variable can be expressed as the Integral of its
Probability Density Function (\S\ref{sec:pdf}) $f_X$:
\[
  F_X(x) = \int\limits_{-\infty}^x f_X(t) dt
\]
i.e. the CDF of a Continuous Random Variable gives the Area under the PDF from
$-\infty$ to $x$

if $F_X$ is Absolutely Continuous (\S\ref{sec:absolute_continuity}), then there
exists a Lebesgue-integrable Function $f_X(x)$ such that:
\[
  F_X(b) - F_X(a) = P(a < X \leq b) = \int_a^b f_X(x) dx
\]
for all Real Numbers $a, b$ and $f_X$ is the PDF of the Distribution of $X$
and equals the Derivative of $F_X$ almost everywhere

\fist \emph{Empirical Distribution Function}
(\S\ref{sec:empirical_distribution}) -- an Unbiased Estimator for $F$ defined as
the CDF of the Empirical Measure (\S\ref{sec:empirical_measure}) of a Sample
(\S\ref{sec:sample})



\subsubsection{Quantile Function}\label{sec:quantile_function}

\emph{Inverse CDF} $F^{-1}$

$F^{-1}(0.25)$ -- \emph{First Quartile}

$F^{-1}(0.5)$ -- \emph{Median} (or \emph{Second Quartile})

$F^{-1}(0.75)$ -- \emph{Third Quartile}

Location Parameter



\paragraph{Probit}\label{sec:probit}\hfill

Quantile Function of the Normal Distribution



\subsubsection{Statistical Functional}\label{sec:statistical_functional}

(Wasserman04 Example 6.05):

a Function of a CDF is called a \emph{Statistical Functional}

can be used to compute various Summary Statistics
(\S\ref{sec:summary_statistic}):
\begin{itemize}
  \item $\mu = T(F) = \int x dF(x)$
    -- Mean (Expectation \S\ref{sec:expected_value})
  \item $\sigma^2 = T(F) = \int (x - \mu)^2 dF(x)$
    -- Variance (\S\ref{sec:variance})
  \item $m = T(F) = F^{-1}(0.5)$
    -- Median (\S\ref{sec:median})
\end{itemize}

Non-parametric Inference (\S\ref{sec:nonparametric_model})

the \emph{Plug-in Estimator} (\S\ref{sec:plugin_principle}) for a Functional
$\theta = T(F)$ is:
\[
  \hat{\theta} = T(\hat{F}_n)
\]
where $\hat{F}_n$ is the Empirical Distribution Function
(\S\ref{sec:empirical_distribution})



\paragraph{Linear Functional}\label{sec:linear_functional}\hfill

a Functional of the form:
\[
  T(F) = \int r(x) dF(x)
\]
for some Function $r(x)$

called ``Linear'' because in this case $T$ satisfies
$T(aF + bG) = aT(F) + bT(G)$, i.e. $T$ is Linear in all arguments

the Plug-in Estimator (\S\ref{sec:plugin_principle}) for a Linear Functional:
\[
  T(\hat{F}_n) = \frac{1}{n}\sum_{i=1}^n r(X_i)
\]
where $\hat{F}_n$ is the Empirical Distribution Function
(\S\ref{sec:empirical_distribution})



% ------------------------------------------------------------------------------
\subsection{Discrete Probability Distribution}
\label{sec:discrete_probability}
% ------------------------------------------------------------------------------

Probability Distribution of a Discrete Random Variable
(\S\ref{sec:discrete_random_variable})

characterized by a Probability Mass Function (\S\ref{sec:pmf})

Cumulative Distribution Function (\S\ref{sec:cdf}) increases only by Jump
Discontinuities

\begin{itemize}
  \item \emph{Point Mass Distribution} -- $X \sim \delta_a$ has CDF:
    \[
      F_X(x) = \begin{cases}
        0 & x <    a \\
        1 & x \geq a \\
      \end{cases}
    \]
    and PMF:
    \[
      f_X(x) = \begin{cases}
        1 & x = a \\
        0 & \text{otherwise} \\
      \end{cases}
    \]
  \item \emph{Discrete Uniform Distribution} (\S\ref{sec:uniform_distribution})
  \item \emph{Multinomial Distribution} (\S\ref{sec:multinomial_distribution})
    -- $X \sim Multinomial_k(n,p)$
  \begin{itemize}
    \item \emph{Bernoulli Distribution} (\S\ref{sec:bernoulli_distribution}) --
      $X \sim Bernoulli(p)$
    \item \emph{Binomial Distribution} (\S\ref{sec:binomial_distribution}) --
      $X \sim Binomial(n,p)$
    \item \emph{Categorical Distribution} (\S\ref{sec:categorical_distribution})
      -- $X \sim Categorical(k,p)$
  \end{itemize}
  \item \emph{Geometric Distribution} (\S\ref{Sec:geometric_distribution}) --
    $X \sim Geom(p)$
  \item \emph{Poisson Distribution} (\S\ref{Sec:poisson_distribution}) --
    $X \sim Poisson(\lambda)$
\end{itemize}



\subsubsection{Multinomial Distribution}\label{sec:multinomial_distribution}

$n$ Trials

$k$ Outcomes or ``\emph{Categories}''

$k$ Outcomes $E_1, E_2, \ldots, E_k$

Probabilities $p_1, p_2, \ldots, p_k$

Probability Distribution of $x_1, x_2, \ldots, x_k$ number of
Occurences for $E_1, E_2, \ldots, E_k$ in $n$ Independent Trials:
\[
  f(x_1, x_2, \ldots, x_k) = \binom{n}{x_1, x_2, \ldots, x_k} =
    p_1^{x_1} p_2^{x_2} \cdots p_k^{x_k}
\]
and $\sum_{i=1}^k x_i = n$ and $\sum_{i=1}^k {p_i} = 1$

for $X = (X_1, \ldots, X_k) \sim Multinomial_k(n, p)$ and
$p = (p_1, \ldots, p_k)$, the Marginal Distribution
(\S\ref{sec:marginal_distribution}) of $X_j$ is $Binomial (n, p_j)$

\begin{itemize}
  \item Bernoulli Distribution (\S\ref{sec:bernoulli_distribution}) -- $k = 2$,
    $n = 1$
  \item Binomial Distribution (\S\ref{sec:binomial_distribution}) -- $k = 2$,
    $n > 1$
  \item Categorical Distribution (\S\ref{sec:categorical_distribution}) --
    $k > 2$, $n = 1$
\end{itemize}



\paragraph{Bernoulli Distribution}\label{sec:bernoulli_distribution}\hfill

$k = 2$, $n = 1$

for a Random Variable $X$ representing a Binary Outcome:
\begin{itemize}
  \item $P(X=1) = p$
  \item $P(X=0) = 1-p$
\end{itemize}
for some $p \in [0,1]$

Mean:
\[
  \mu = p
\]
Variance:
\[
  \sigma^2 = p(1-p)
\]
PMF:
\[
  f(x) = p^x(1-p)^{1-x}
\]
or equivalently:
\[
  f(x) = \begin{cases}
    p   & x = 1 \\
    1-p & x = 0 \\
  \end{cases}
\]
for $x \in \{0, 1\}$

\fist cf. Logistic Regression (\S\ref{sec:logistic_regression}) -- Model with
Binary Data $Y_i$, the Conditional Distribution $y | x$ is Bernoulli
Distributed:
\[
  Y_i | X_i = x_i \sim Bernoulli(p_i)
\]
(cf. Linear Regression where the Conditional Distribution is Normally
Distributed)

generalization: Categorical Distribution (\S\ref{sec:categorical_distribution})



\paragraph{Binomial Distribution}\label{sec:binomial_distribution}\hfill

Sum of Independent Trials; cf. Normal Distribution
(\S\ref{sec:normal_distribution})

Binomial (Bernoulli) Trial (\S\ref{sec:binomial_trial})

Binomial Random Variable (\S\ref{sec:binomial_variable})

$k = 2$ , $n > 1$

cf. Binomial Coefficients (\S\ref{sec:binomial_coefficient})

\fist cf. Geometric Distribution (\S\ref{sec:geometric_distribution}) -- number
of Trials until first Success

Random Variable $X$ with Binomial Distribution where $n \in \nats$ and
$p \in [0,1]$:
\[
  X \sim B(n,p)
\]
describes the Probability of getting exactly $x$ ``Successes'' in $n$ Trials
where the Probability of Success is $p$:
\[
  P(x,n,p) = \binom{n}{x}p^x(1-p)^{n-x}
\]

\fist Poisson Distribution (\S\ref{sec:poisson_distribution}) -- Limit of the
Binomial Distribution as number of Trials $n \rightarrow \infty$

Expected Value $E(X) = np$

Mean $\mu = n p$

Variance $\sigma^2 = n p (1-p)$

Sample Proportion %FIXME



\subparagraph{Negative Binomial Distribution}\label{sec:negative_binomial}\hfill

$b^*(x; k,p) = \binom{x-1}{k-1} p^k 2^{k-k}$



\subparagraph{Normal Approximation}\label{sec:normal_approximation}\hfill

For Binomial Random Variable $X$ with Mean $\mu = np$ and Variance
$\sigma^2 = npq$, then:
\[
  Z = \frac{X - np}{\sqrt{npq}}
\]
as $n \rightarrow \infty$ is the Standard Normal Distribution
(\S\ref{sec:normal_distribution}) $n(Z;0,1)$



\paragraph{Categorical Distribution}\label{sec:categorical_distribution}
\hfill

$k > 2$, $n = 1$



\paragraph{Softmax Function}\label{sec:softmax}
\hfill

or \emph{Normalized Exponential Function}

generalization of Logistic Function (\S\ref{sec:logistic_function}); the
Logistic Function is the Derivative of Softplus --TODO

output can be used to represent a Categorical Distribution

often used as final layer of a Neural Network-based Classifier



\subsubsection{Poisson Distribution}\label{sec:poisson_distribution}

$P(x; \lambda t) = \frac{e^{-\lambda t} (\lambda t)^x}{x!}$
where $\lambda$ is the average number of outcomes per unit time

Expected Value is the Limit of the Binomial Distribution as number of Trials
$n \rightarrow \infty$:
\begin{flalign*}
  E(X) & = \lambda \\
  V(X) & = \lambda \\
  P(X = k) & = \lim_{n\rightarrow\infty}
               \binom{n}{k}(\frac{\lambda}{n})^k(1-\frac{\lambda}{n})^{n-k} \\
           & = \frac{\lambda^k e^{-\lambda}}{k!} \\
\end{flalign*}

models counts of rare events, e.g. radioactive decay, traffic accidents (cf.
Propensity Interpretation of Probability)

cf. Poisson Processes (\S\ref{sec:poisson_process})

\fist Poisson Noise (Shot Noise): Statistical Fluctuations
(\S\ref{sec:statistical_fluctuation})

for Independent Random Variables $X \sim Poisson(\lambda)$ and
$Y \sim Poisson(\nu)$:
\[
  X + Y \sim Poisson(\lambda + \nu)
\]

if $N \sim Poisson(\lambda)$ and $Y | N = n \sim Binomial(n,p)$, then the
Marginal Distribution of $Y$ is $Y \sim Poisson(\lambda p)$
(Wasserman04 \S 23.3)



\subsubsection{Geometric Distribution}\label{sec:geometric_distribution}

$P(X = k) = p(1-p)^{k-1}$ for $k \in \{1, 2, 3, \ldots\}$

where $X$ is the number of Independent Trials with Constant Probability of
``Success'' until the first Success

cf. Binomial Distribution (\S\ref{sec:binomial_distribution}) -- number of
Successes after $n$ Trials

cf. Geometric Series (\S\ref{sec:geometric_series})

Expected Value $E(X) = 1 + (1-p) + (1-p)^2 + \cdots = \frac{1}{p}$



\subsubsection{Hypergeometric Distribution}
\label{sec:hypergeometric_distribution}

$h(x; N, n, k) = \frac{\binom{k}{x} \binom{N-k}{n-x}}{\binom{N}{n}}$

Mean $\mu = \frac{nk}{N}$

Variance $\sigma^2 = \frac{N-n}{N-1} n \frac{k}{N}(1 - \frac{k}{N})$



\paragraph{Multivariate Hypergeometric Distribution}
\label{sec:multivariate_hypergeometric}\hfill



\subsubsection{Parabolic Fractal Distribution}
\label{sec:parabolic_fractal_distribution}

\subsubsection{Discrete Power Law Distribution}
\label{sec:discrete_power_law_distribution}

\fist Continuous Power Law Distributions
(\S\ref{sec:continuous_power_law_distribution})



\paragraph{Zipf Distribution}\label{sec:zipf_distribution}\hfill

\paragraph{Zeta Distribution}\label{sec:zeta_distribution}\hfill

Normalization of the Zipf Distribution

\paragraph{Yule-Simon Distribution}
\label{sec:yule_simon_distribution}\hfill



% ------------------------------------------------------------------------------
\subsection{Continuous Probability Distribution}
\label{sec:continuous_probability}
% ------------------------------------------------------------------------------

Probability Distribution of a Continuous Random Variable
(\S\ref{sec:continuous_random_variable})

characterized by a Probability Density Function
(\S\ref{sec:probability_density})

has a Continuous Cumulative Distribution Function (\S\ref{sec:cdf})

\fist Discrete Power Law Distributions
(\S\ref{sec:discrete_power_law_distribution})

\begin{itemize}
  \item \emph{Uniform Distribution} (\S\ref{sec:uniform_distribution}) --
    $X \sim Uniform(a,b)$
  \item \emph{Normal (Gaussian) Distribution} (\S\ref{sec:normal_distribution})
    -- $X \sim N(\mu, \sigma^2)$
  \item \emph{Exponential Distribution} (\S\ref{sec:exponential_distribution})
    -- $X \sim Exp(\beta) = Gamma(1, \beta)$
  \item \emph{Gamma Distribution} (\S\ref{sec:gamma_distribution})
    -- $X \sim Gamma(\alpha, \beta)$
  \item \emph{Beta Distribution} (\S\ref{sec:beta_distribution})
    -- $X \sim Beta(\alpha, \beta)$
  \item \emph{$t$-distribution} (\S\ref{sec:t_distribution})
    -- $X \sim t_\nu$
  \item \emph{Cauchy-Lorenz Distribution} (\S\ref{sec:cauchy_distribution})
    -- $X \sim t_\nu=1$
  \item \emph{$\chi^2$-distribution} (\S\ref{sec:chi_squared})
    -- $X \sim \chi^2_p$
\end{itemize}



\subsubsection{Normal Distribution}\label{sec:normal_distribution}

(or \emph{Gaussian Distribution})

member of the family of Tweedie (\S\ref{sec:tweedie_distribution}) Exponential
Dispersion Models (\S\ref{sec:exponential_dispersion})

\[
  n (x; \mu, \sigma) =
  \frac{1}{\sqrt{2\pi \sigma}} e^{-\frac{1}{2 \sigma^2}(x - \mu)^2}
\]

cf. Binomial Distribution (Discrete \S\ref{sec:binomial_distribution})
-- Sum of Independent Trials

a Normal Distribution corresponds to a $t$-distribution
(\S\ref{sec:t_distribution}) with $\nu = \infty$ Degrees of Freedom

the Ratio $X_1/X_2$ of two Normally Distributed Independent Random Variables
$X_1, X_2 \sim N(0,1)$ is a Cauchy Distribution

\emph{Central Limit Thoerem} (\S\ref{sec:central_limit_theorem}) -- ``the
Distribution of a Sum of Independent Random Variables can be approximated by a
Normal Distribution'';
for a Sequence of Random Variables (\S\ref{sec:random_variable})
$X_i, \ldots, X_n$ with Sample Mean (\S\ref{sec:sample_mean})
$\overline{X}_n$, $\sqrt{n}(\overline{X}_n - \mu)$
\emph{Converges in Distribution} to a Normal Distribution
(\S\ref{sec:normal_distribution}) as $n \rightarrow \infty$, i.e. the Sample
Mean has approximately a Normal Distribution for large $n$

as a consequence of the Central Limit Theorem, Random Errors
(\S\ref{sec:random_error}) tend to be Normally Distributed

\fist Gaussian Processes (\S\ref{sec:gaussian_process}) can be seen as
Infinite-dimensional generalizations of Multivariate Normal Distributions

\emph{Empirical Rule} 68-95-99.7 Rule -- 68\% within 1 Standard Deviation of the
Mean, 95\% within 2 Standard Deviations, 99.7\% within 3 Standard Deviations

MIT 6.041SC, Lec.8

Linear Functions of Normal Variables are Normal--
for $X \sim N(\mu, \sigma^2)$ and $Y = aX + b$:
\[
  Y \sim N(a \mu + b, a^2 \sigma^2)
\]

\emph{Standardizing} -- for $X \sim N(\mu, \sigma^2)$:
\[
  \frac{X - \mu}{\sigma} \sim N(0, 1)
\]
where $(X - \mu)/\sigma$ is the \emph{Standard Score}
($z$-score \S\ref{sec:standard_score})

2018 - Eric Jang
- \emph{Normalizing Flows Tutorial}
- \url{https://blog.evjang.com/2018/01/nf1.html}



\paragraph{Mill's Inequality}\label{sec:mills_inequality}\hfill

\textbf{Thm.} (Mill's Inequality) \emph{
  For $Z \sim N(0,1)$:
  \[
    P(|Z| > t) \leq \sqrt{\frac{2}{\pi}}\frac{e^{-t^2/2}}{t}
  \]
}



\paragraph{Standard Normal Distribution}\label{sec:standard_normal}\hfill

Mean $\mu = 0$

Variance $\sigma^2 = 1$

by convention Standard Normal Random Variables are denoted by $Z$, PDF by
$\phi(z)$ and CDF by $\Phi(z)$

there is no Closed-form Expression (\S\ref{sec:closed_form_expression}) for
$\Phi$ (requires use of the Error Function \S\ref{sec:error_function})



\paragraph{Multivariate Normal Distribution}\label{sec:multivariate_normal}
\hfill

Multivariate Random Variable (\S\ref{sec:random_vector})



\subsubsection{$t$-distribution}\label{sec:t_distribution}

(or \emph{Student's $t$-distribution})

$\nu$ -- Degrees of Freedom

a Normal Distribution (\S\ref{sec:normal_distribution}) corresponds to a
$t$-distribution with $\nu = \infty$ Degrees of Freedom

Sampling Distribution (\S\ref{sec:sampling_distribution}) for low Sample Size

$t$-statistic (\S\ref{sec:t_statistic})

$t$-test (\S\ref{sec:t_test})



\paragraph{Cauchy Distribution}\label{sec:cauchy_distribution}\hfill

or \emph{Cauchy-Lorentz Distribution}

$\nu = 1$

Expected Value (\S\ref{sec:expected_value}) and Variance (\S\ref{sec:variance})
are undefined; the ``average'' of $n$ Independent Cauchy Random Variables with
$x_0 = 0$ \emph{does not} Converge to $0$ as $n \rightarrow \infty$ with
Probability $1$-- ``it'' stays a Cauchy Distribution of the same size; however
$0$ is the Median and Mode (FIXME: clarify)
--\url{https://stats.stackexchange.com/questions/36027/why-does-the-cauchy-distribution-have-no-mean}

\url{https://stats.stackexchange.com/questions/232967/what-makes-the-mean-of-some-distributions-undefined/233950#233950}:
the Cauchy Distribution is a ``disguised'' form of the Uniform Distribution on a
Circle

has no Moment-generating Function (\S\ref{sec:moment_generating_function})

the Ratio $X_1/X_2$ of two Normally Distributed Independent Random Variables
$X_1, X_2 \sim N(0,1)$ is a Cauchy Distribution



\subsubsection{Inverse Gaussian Distribution}\label{sec:inverse_gaussian}

\subsubsection{Log-normal Distribution}\label{sec:lognormal_distribution}

\subsubsection{Gamma Distribution}\label{sec:gamma_distribution}

Gamma Function (\S\ref{sec:gamma_function})

Continuous Random Variable $X$ with parameters $\alpha > 0$ and $\beta
> 0$:
\[
  f(x; \alpha, \beta) =
  \begin{cases}
    \frac{1}{\beta^\alpha \Gamma(\alpha)} x^{\alpha-1} e^{\sfrac{-x}{\beta}}
      & \quad x > 0 \\
    0 & \quad\text{else} \\
  \end{cases}
\]

Mean $\mu = \alpha \beta$

Variance $\sigma^2 = \alpha \beta^2$



\paragraph{Exponential Distribution}\label{sec:exponential_distribution}\hfill

a $Gamma(1,\beta)$ Distribution

Continuous Random Variable $X$ with parameter $\beta > 0$:
\[
  f(x; \beta) =
  \begin{cases}
  \frac{1}{\beta} e^{\sfrac{-x}{\beta}}     & \quad x > 0 \\
  0     & \quad\text{else} \\
  \end{cases}
\]

models lifetimes of electronic components, wait times between rare events



\subparagraph{Double Exponential Distribution}
\label{sec:double_exponential}\hfill

or \emph{Laplace Distribution}



\paragraph{$\chi^2$ Distribution}\label{sec:chi_squared}\hfill

Non-symmetric

Sums of Squared IID Normally-distributed Random Variables, where the number of
Variables is the ``Degrees of Freedom''

\[
  f(x; v) =
  \begin{cases}
    \frac{1}{2^{\sfrac{v}{2}}\Gamma(\sfrac{v}{2})}
      x^{\sfrac{v}{2-1}} e^{\sfrac{-x}{2}}
          & \quad x > 0 \\
    0     & \quad\text{else} \\
  \end{cases}
\]

Goodness-of-fit (\S\ref{sec:model_fit})

Chi-squared Statistic -- Randomness Condition, Large Counts Condition ($>5$
expected), Independence Condition

\fist Chi-squared Test (\S\ref{sec:chi_squared_test})

Logistic Regression



\subparagraph{$F$-distribution}\label{sec:f_distribution}\hfill

(Fisher)

can be seen as a Ratio of Chi-squared Distributions with not necessarily the
same DoFs

$F$-statistic (\S\ref{sec:f_statistic})

$F$-test (\S\ref{sec:f_test})

$F = \frac{\text{between-group variability}}{\text{within-group variability}}$

$F = \frac{\frac{SSB}{DoF_B}}{\frac{SSW}{DoF_W}}$

ANOVA (\S\ref{sec:variance_analysis}), Linear Regression



\paragraph{Wishart Distribution}\label{sec:wishart_distribution}\hfill



\subsubsection{Beta Distribution}\label{sec:beta_distribution}

Gamma Function (\S\ref{sec:gamma_function})



\subsubsection{Continuous Power Law Distribution}
\label{sec:continuous_power_law_distribution}

Scale Invariance (\S\ref{sec:scale_invariance})



\paragraph{Pareto Distribution}\label{sec:pareto_distribution}\hfill

prototypical Power Law Distribution



\subsubsection{Phse-type Distribution}\label{sec:phasetype_distribution}

\begin{itemize}
  \item Degenerate Distribution (TODO) -- 0
    Phases
  \item Exponential Distribution (\S\ref{sec:exponential_distribution}) -- 1
    Phase
  \item Erlang Distribution (TODO) -- 2 or more identical Phases in sequence
  \item ...
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Symmetric Probability Distribution}
\label{sec:symmetric_probability}
% ------------------------------------------------------------------------------

\subsubsection{Uniform Distribution}\label{sec:uniform_distribution}

for a Finite Sample Space $\Omega$:
\[
  P(A) = \frac{\|A\|}{\|\Omega\|}
\]

a Uniform Distribution is defined by a rectangle formed on the interval Interval
$[min,max]$ such that the area is $1$

$Uniform(0,1)$ -- \emph{Standard Uniform Distribution}

\url{https://stats.stackexchange.com/questions/232967/what-makes-the-mean-of-some-distributions-undefined/233950#233950}:
the Cauchy Distribution (\S\ref{sec:cauchy_distribution}) is a ``disguised''
form of the Uniform Distribution on a Circle



\paragraph{Probability Integral Transform}
\label{sec:probability_integral_transform}\hfill

for Continuous $X$ with CDF $F_X$, $Y = F_X(X)$ is called a \emph{Probability
  Integral Transform} and has a Standard Uniform Distribution

\emph{Universal Random Number Generator} (Wasserman04 Ch.2 Exercise 15) -- TODO



% ------------------------------------------------------------------------------
\subsection{Joint Probability Distribution}\label{sec:joint_probability}
% ------------------------------------------------------------------------------

$f(x,y,\ldots)$ for two or more Random Variables $X,Y,\ldots$

\fist Generative Models (Classification \S\ref{sec:generative_model})

Discrete Random Variables:
\begin{enumerate}
  \item $f(x,y) \geq 0$
  \item $\sum_x \sum_y f(x,y) = 1$
  \item $P(X = x, Y = y) = f(x,y)$
\end{enumerate}

Continuous Random Variables:
\begin{enumerate}
  \item $\forall (x,y) \in X \times Y, f(x,y) \geq 0$
  \item $\int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty}
    f(x,y) dx dy = 1$
  \item $P[(X,Y) \in B] = \iint\limits_B f(x,y) dA$
\end{enumerate}

(Wasserman04, \S23.1):

for Random Variables $X_1, \ldots, X_n$, the Joint Density $f(x_1, \ldots, x_n)$
is:
\begin{flalign*}
  f(x_1, \ldots, x_n)
    & = f(x_1) f(x_2 | x_1) \cdots f(x_n | x_1, \ldots, x_{n-1}) \\
    & = \prod_{i=1}^n f(x_i | x_1, \ldots, x_{i-1}) \\
\end{flalign*}
for a Markov Process (\S\ref{sec:markov_process}), this simplifies to:
\[
  f(x_0, \ldots, x_t) = f(x_1)f(x_2|x_1)f(x_3|x_2) \cdots f(x_t|x_{t-1})
\]

\asterism

\fist \emph{Cross-variation Assumptions} -- Model-based Statistical Assumptions
(\S\ref{sec:statistical_assumption}) involving Joint Probability Distributions
of either Observations or Random Errors in a Model; simple Models may Assume
that Observations or Errors are Statistically Independent
(\S\ref{sec:independence})

Conditional Independence (\S\ref{sec:conditional_independence}) happens when
the Joint Probability Distribution is the Product of the individual Probability
Distributions
--\url{http://lesswrong.com/lw/pi/classical_configuration_spaces/}

\fist a Stationary Process (\S\ref{sec:stationary_process}) is a Stochastic
Process whose Unconditional Joint Probability Distribution is unchanged in Time



\subsubsection{Bivariate Distribution}\label{sec:bivariate_distribution}

$P(X = x, Y = y)$



\subsubsection{Kalman Filter}\label{sec:kalman_filter}

a series of papers on ``Kalman Folding'':
\url{http://vixra.org/author/brian_beckman}



% ------------------------------------------------------------------------------
\subsection{Conditional Distribution}
\label{sec:conditional_distribution}
% ------------------------------------------------------------------------------

for Discrete Random Variables $X$, $Y$:

\[
  P(X = x | Y = y) = P(X = x, Y = y)/P(Y = y)
\]
the Conditional Probability Mass Function, assuming $f_Y(y) > 0$:
\[
  f_{X|Y}(x|y) = P(X = x|Y = y) =
    \frac{P(X = x, Y = y)}{P(Y = y)} =
    \frac{f_{X,Y}(x,y)}{f_Y(y)}
\]

for Continuous Random Variables $X$, $Y$, the Conditional Probability Density
Function:
\[
  f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}
\]
and:
\[
  P(X \in A| Y = y) = \int_A f_{X|Y}(x|y) dx
\]

cf. \emph{Borel-Kolmogorov Paradox} -- the concept of a Conditional Probability
with regard to an isolated given Hypothesis whose Probability equals $0$ is
inadmissable (Kolmogorov33); Conditional Probability Density Functions need not
be Invariant under Coordinate Transformations



% ------------------------------------------------------------------------------
\subsection{Marginal Distribution}\label{sec:marginal_distribution}
% ------------------------------------------------------------------------------

Marginal Probability Mass Functions:

$f_X(x) = P(X = x) = \sum_y P(X = x, Y = y) = \sum_y P(X = x | Y = y) P(Y = y)$

$f_Y(y) = P(Y = y) = \sum_x P(X = x, Y = y) = \sum_x P(Y = y | X = x) P(X = x)$

Marginal Probability Density Functions:

$f_X(x) = \int f_{X,Y}(x,y) dy$

$f_Y(y) = \int f_{X,Y}(x,y) dx$



% ------------------------------------------------------------------------------
\subsection{Asymptotic Distribution}\label{sec:asymptotic_distribution}
% ------------------------------------------------------------------------------

\fist cf. Asymptotic Theory (Large Sample Theory \S\ref{sec:asymptotic_theory})



\subsubsection{Central Limit Theorem}\label{sec:central_limit}

``the Distribution of a Sum of Independent Random Variables can be approximated
by a Normal Distribution''

\fist Sampling Distribution (\S\ref{sec:sampling_distribution})

for a Sequence of Random Variables (\S\ref{sec:random_variable})
$X_i, \ldots, X_n$ with Sample Mean (\S\ref{sec:sample_mean})
$\overline{X}_n$, $\sqrt{n}(\overline{X}_n - \mu)$
\emph{Converges in Distribution} to a Normal Distribution
(\S\ref{sec:normal_distribution}) as $n \rightarrow \infty$, i.e. the Sample
Mean has approximately a Normal Distribution for large $n$

\textbf{Thm.} (Central Limit Theorem) \emph{For IID (\S\ref{sec:iid}) Random
  Variables $X_1, \ldots, X_n$ with Mean $\mu$ and Variance $\sigma^2$, then:
  \[
    Z_n \equiv \frac{\overline{X}_n - \mu}{\sqrt{V(\overline{X}_n)}} =
      \frac{\sqrt{n}(\overline{X}_n - \mu)}{\sigma} \rightarrow Z \sim N(0,1)
  \]
  i.e:
  \[
    \lim_{n\rightarrow\infty} P(Z_n \leq z) = \Phi(z) =
      \int_{-\infty}^z \frac{1}{\sqrt{2\pi}}e^{-x^2/2} dx
  \]
}

\emph{Berry-Ess\'een Inequality}

\emph{Multivariate Central Limit Theorem}

generalization: \emph{Local Asymptotic Normality}

as a consequence of the Central Limit Theorem, Random Errors
(\S\ref{sec:random_error}) tend to be Normally Distributed

\fist an instance of \emph{Renormalization} (\S\ref{sec:renormalization})

\fist origin of ``Multifractality'' (\S\ref{sec:multifractal_system}) in
Sequential (Time Series) data attributed to ``convergence effects'' related to
the Central Limit Theorem that have Foci of Convergence in the family of Tweedie
Exponential Dispersion Models (Probability Distributions
\S\ref{sec:tweedie_distribution})



% ------------------------------------------------------------------------------
\subsection{Tweedie Distribution}\label{sec:tweedie_distribution}
% ------------------------------------------------------------------------------

(wiki): \emph{Tweedie Convergence Theorem}: describes the Convergence of certain
Statistical Processes towards the Family of Statistical Models known as
\emph{Tweedie Distributions}; Variance-to-Mean Power Law (TODO: xref); cf.
Taylor's Power Law, \emph{Fluctuation Scaling}; alternative paradigm to explain
Power Law manifestations attributed to ``Self-organized Criticality''
(SOC \S\ref{sec:soc})

Pink ($1/f$) Noise

Normal Distribution (\S\ref{sec:normal_distribution}) is a member of the family
of Tweedie Exponential Dispersion Models (\S\ref{sec:exponential_dispersion})

\fist origin of ``Multifractality'' (\S\ref{sec:multifractal_system}) in
Sequential (Time Series) data attributed to ``convergence effects'' related to
the Central Limit Theorem (\S\ref{sec:central_limit}) that have Foci of
Convergence in the family of Tweedie Exponential Dispersion Models



% ------------------------------------------------------------------------------
\subsection{Quasiprobability Distribution}
\label{sec:quasiprobability_distribution}
% ------------------------------------------------------------------------------

relaxation of the Third Kolmogorov Axiom ($\sigma$-additivity
\S\ref{sec:probability_axioms})

to compensate some Quasiprobability Distributions have regions of Negative
Probability (\S\ref{sec:negative_probability}) Density, contradicting the First
Axiom

regions Integrated under them do not represent Probabilities of Mutually
Exclusive States (\S\ref{sec:mutually_exclusive})

cf. Phase Space (\S\ref{sec:phase_space}) Formulation of Quantum Mechanics:
Position and Momentum Variables on equal footing in Phase Space (cf.
Schr\"odinger formulation uses Position \emph{or} Momentum representations)

\fist Time-Frequency Analysis (\S\ref{sec:time_frequency_analysis}): analysis
of Signals with Time-varying Statistics (cf. Entropy \S\ref{sec:entropy}), e.g.
Transient Signals (\S\ref{sec:transient})



% ==============================================================================
\section{Statistical Analysis}\label{sec:statistical_analysis}
% ==============================================================================

Statistical Theory -- FIXME

Statistical Population (\S\ref{sec:population})

Statistical Sample (\S\ref{sec:sample})

Statistic (\S\ref{sec:statistic}) -- a Function of a Random Variable
(\S\ref{sec:random_variable}) constituting a Random Sample

Descriptive Statistics (\S\ref{sec:descriptive_statistics})

Statistical Parameter (\S\ref{sec:population_parameter})

Statistical Model (\S\ref{sec:statistical_model})

Statistical Inference (\S\ref{sec:inferential_statistics})

Statistical Learning Theory (\S\ref{sec:statistical_learning_theory})

\emph{Statistical Studies}:
\begin{itemize}
  \item Sample Study -- Population Parameter Estimate (Statistic)
  \item Observational Study -- Explanatory, Explained Variables (Correlation)
  \item Experimental Study -- Control, Treatment (Causality)
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Population}\label{sec:population}
% ------------------------------------------------------------------------------

\emph{Statistical Population}

totality of Observations (\S\ref{sec:observation})

Value of a Random Variable $X$ having some Probability Distribution $f(x)$

Paired Observation (Dependent) (???)

(wiki):

\emph{Statistical Population} -- a Set of ``similar items'' or Events
(\S\ref{sec:probability_event}) of interest

\fist cf. Data Generating Process (\S\ref{sec:data_generating_process}), Data
Collection (\S\ref{sec:data_collection})

A Subset of the Population is a \emph{Statistical Sample} (\S\ref{sec:sample}).
A \emph{Statistical Model} (\S\ref{sec:statistical_model}) is a Set of
Statistical Assumptions (\S\ref{sec:statistical_assumption}) concerning the
Generation (\S\ref{sec:data_generating_process}) of Sample Data.

A \emph{Statistical Hypothesis} is a Conjecture (\S\ref{sec:conjecture})
concerning one or more Populations.



% ------------------------------------------------------------------------------
\subsection{Data Generating Process}\label{sec:data_generating_process}
% ------------------------------------------------------------------------------

(wiki):

\begin{itemize}
  \item \emph{Data Collection} (\S\ref{sec:data_collection})
  \item a ``notional'', \emph{non-specific} Probabilistic Model
    that would include all of the ``Random influences'' that lead to individual
    Observations (\S\ref{sec:observation})
  \item a \emph{specific} \emph{Statistical Model}
    (\S\ref{sec:statistical_model}) used to represent Random Variations in
    Observations
\end{itemize}

\fist \emph{Model Validation} (\S\ref{sec:model_validation}) is the process of
confirming that the ``outputs'' of a Statistical Model are ``acceptable'' with
respect to the ``real'' Data Generating Process

\fist cf. Sample Data (Statistical Sample \S\ref{sec:sample})

\fist cf. Stochastic Process (\S\ref{sec:stochastic_process})



% ------------------------------------------------------------------------------
\subsection{Level of Measurement}\label{sec:measurement_level}
% ------------------------------------------------------------------------------

\begin{itemize}
  \item \emph{Nominal} -- Dispersion: Variation Ratio
    (\S\ref{sec:variation_ratio}); Central Tendency: Mode (\S\ref{sec:mode})
  \item \emph{Ordinal} -- Central Tendency: Median (\S\ref{sec:median})
  \item \emph{Interval} -- Central Tendency: Mean (\S\ref{sec:arithmetic_mean}),
    Deviation (\S\ref{sec:deviation})
  \item \emph{Ratio} -- Central Tendency: Geometric Mean
    (\S\ref{sec:geometric_mean}), Variation Coefficient (TODO)
\end{itemize}



\subsubsection{Statistical Data Type}\label{sec:statistical_data_type}

\fist cf. \emph{Datatype}

cf. Statistical Unit (\S\ref{sec:statistical_unit})

\emph{Simple Data Types}:
\begin{itemize}
  \item Binary
  \item Categorical
    \fist Statistical Classification (\S\ref{sec:classification})
  \item Ordinal
  \item Binomial
  \item Count
  \item Real
  \item Positive Real
  \item ...
\end{itemize}

\emph{Multivariate Data Types}:
\begin{itemize}
  \item Random Vector
  \item Random Sequence
  \item Bayes Networks
  \item Random Process
  \item Random Field
  \item ...
\end{itemize}

(TODO: xrefs)



% ------------------------------------------------------------------------------
\subsection{Population Parameter}\label{sec:population_parameter}
% ------------------------------------------------------------------------------

or \emph{Statistical Parameter}

(wiki): a ``quantity'' that indexes a Family of Probability Distributions
(\S\ref{sec:probability_distribution}), i.e. a ``numerical characteristic'' of a
\emph{Statistical Model} (\S\ref{sec:statistical_model})

Parametric Models (\S\ref{sec:parametric_model}) have a Finite Set of Parameters

example: the Family of Normal Distributions (\S\ref{sec:normal_distribution})
are Parameterized by the Mean and Standard Deviation

Non-parametric models (\S\ref{sec:nonparametric_model}) have an Infinite Set of
Parameters

a \emph{Parameter} is to a \emph{Population} as a \emph{Statistic}
(\S\ref{sec:statistic}) is to a \emph{Sample} (\S\ref{sec:sample})

\fist an \emph{Estimator} (\S\ref{sec:estimator}) is a Statistic used to
Estimate a Population Parameter:
\begin{itemize}
  \item Maximum Likelihood Estimation (MLE \S\ref{sec:mle})
  \item Method of Moments (\S\ref{sec:moments_method})
  \item ...
\end{itemize}

\fist Hyperparameters (Learning Algorithms \S\ref{sec:hyperparameter})

$\mu$, $\sigma$

\begin{itemize}
  \item Location Parameter -- Quantile
  \item Dispersion Parameter
  \item Scale Parameter
  \item Shape Parameter
  \item Concentration Parameter
  \item Regression Coefficient
\end{itemize}
(TODO: xrefs



\subsubsection{Population Proportion}\label{sec:proportion}

Population Parameter $p$ describing a percentage value associated with a
Population

\fist Confidence Interval (\S\ref{sec:confidence_interval})



\paragraph{Lexis Ratio}\label{sec:lexis_ratio}\hfill



% ------------------------------------------------------------------------------
\subsection{Statistical Sample}\label{sec:sample}
% ------------------------------------------------------------------------------

A \emph{Statistical Sample} (or \emph{Data Sample}) is a Subset of a Statistical
Population, selected by a definite procedure (\emph{Sampling Procedure}
\S\ref{sec:sampling}).

A \emph{Data Point} is an Observation (Random Variate \S\ref{sec:observation})
of a Statistical Unit (\S\ref{sec:statistical_unit}) in a Statistical Sample.

The \emph{Information Content} (\emph{Self-information} or \emph{Surprisal}
\S\ref{sec:information_content}) of a Sampled Random Variable or Signal
(\S\ref{sec:signal}) is the amount of Information (\S\ref{sec:information})
``gained'' by the Sample; this Information Content is a Random Variable defined
for any Event (\S\ref{sec:probability_event}) as the Negative Log-probability
(\S\ref{sec:log_probability}), regardless of whether a Random Variable is being
measured or not. (wiki)

\fist cf. \emph{Data} (\S\ref{sec:data}), \emph{Data Generating Process}
(\S\ref{sec:data_generating_process}), \emph{Dataset} (\S\ref{sec:dataset}),
\emph{Training Set} (\S\ref{sec:training_dataset})

\fist cf. Frequency Distribution (\S\ref{sec:frequency_distribution})

\fist a Statistical Model (\S\ref{sec:statistical_model}) ``embodies'' the Set
of Statistical Assumptions that concern the \emph{Generation}
(\S\ref{sec:data_generating_process}) of Sample Data

Binomial Distribution (\S\ref{sec:binomial_distribution}) -- Independence
Assumption: Sampling 10\% Rule (TODO)



% ------------------------------------------------------------------------------
\subsection{Statistical Unit}\label{sec:statistical_unit}
% ------------------------------------------------------------------------------

one of a Member of a Set of entities being analyzed, providing the ``material
source'' for abstract Random Variables (\S\ref{sec:random_variable})

cf. Statistical Data Type (\S\ref{sec:statistical_data_type})



\subsubsection{Unit of Observation}\label{sec:observational_unit}

\emph{Unit of Observation} or \emph{Unit of Collection}

\begin{itemize}
  \item \emph{Experimental Unit} -- a Member of a Set of objects that are
    initially equivalent until each object is subjected to an ``Experimental
    Treatment'' (\S\ref{sec:experiment})
  \item \emph{Sampling Unit} -- an object that has been Sampled
    (\S\ref{sec:sample}) from a Statistical Population (\S\ref{sec:population})
\end{itemize}

\fist Observation (Random Variate \S\ref{sec:observation})



\subsubsection{Unit of Analysis}\label{sec:analysis_unit}

the entity that frames what is being ``analyzed'' in a ``study'' (cf. Experiment
\S\ref{sec:experiment})



% ------------------------------------------------------------------------------
\subsection{Sampling}\label{sec:sampling}
% ------------------------------------------------------------------------------

\emph{Sampling} is the \emph{selection} of a Subset (Statistical Sample) from
within a Statistical Population

\fist cf. \emph{Data Collection} (\S\ref{sec:data_collection})

\fist \emph{Sampling Unit} (Unit of Observation \S\ref{sec:observational_unit})
-- an object that has been Sampled from a Population

\fist \emph{Sampling Error} (\S\ref{sec:sampling_error}) -- Statistical Error
arising from the Estimation of Statistical characteristics of a Population from
a Subset (Sample)

\fist \emph{Design-based Assumptions} -- Statistical Assumptions
(\S\ref{sec:statistical_assumption}) of the way Observations have been made,
e.g. Assumption of Randomization during Sampling (\S\ref{sec:random_sample})

\emph{Empirical Distribution Function} (\S\ref{sec:empirical_distribution}) --
an Unbiased Estimator for the CDF (\S\ref{sec:cdf}) associated with the
Empirical Measure (\S\ref{sec:empirical_measure}) of a Sample



\subsubsection{Data Collection}\label{sec:data_collection}

%FIXME: cf. measurement, observation ?



\subsubsection{Sample Size}\label{sec:sample_size}

\emph{Sample Size Determination} -- choosing the number of Observations
(\S\ref{sec:observation}) or Replicates (\S\ref{sec:replication}) to include in
a Statistical Sample

\fist Asymptotic Theory (Large Sample Theory \S\ref{sec:asymptotic_theory}):
evaluates properties of Estimators (\S\ref{sec:estimator}) and Statistical Tests
(\S\ref{sec:hypothesis_testing}) as Sample Size $n \rightarrow \infty$



\subsubsection{Replication}\label{sec:replication}

cf. Experiment (\S\ref{sec:experiment})



\subsubsection{Observational Error}\label{sec:observational_error}

\emph{Observational Error} (or \emph{Measurement Error}) is the difference
between an Observed Value (Random Variate \S\ref{sec:observation}) of a
``quantity'' and its ``true'' Value

cf. \emph{Statistical Error} (\S\ref{sec:error})



\paragraph{Random Error}\label{sec:random_error}\hfill

or \emph{Random Variation}

inconsistency of repeated Observations (Measurements) of a Constant attribute or
quantity

usually Normally Distributed due to the Central Limit Theorem
(\S\ref{sec:central_limit})

\fist a \emph{Distributional Assumption} is a Model-baesd Statistical Assumption
(\S\ref{sec:statistical_assumption}) about the Probability Distribution of
Random Errors



\subparagraph{Precision}\label{sec:precision}\hfill

cf. Accuracy (Systematic Errors \S\ref{sec:accuracy})



\paragraph{Systematic Error}\label{sec:systmatic_error}\hfill

or \emph{Statistical Bias}

cf. \emph{Sampling Bias} (\S\ref{sec:nonrandom_sample})

inaccuracy inherent to Observation (Measurement) process



\subparagraph{Accuracy}\label{sec:accuracy}\hfill

cf. Precision (Random Errors \S\ref{sec:precision})

\fist Root-Mean-Square Deviation (RMSD \S\ref{sec:rmsd})



% ------------------------------------------------------------------------------
\subsection{Random Sample}\label{sec:random_sample}
% ------------------------------------------------------------------------------

A \emph{Random Sample} (or \emph{Probability Sample}) is a Sample where each
individual Member of the Population has a known Non-zero Probability of being
selected as part of the Sample.

A Random Vector (Multivariate Random Variable \S\ref{sec:random_vector}) of IID
(\S\ref{sec:iid}) Random Variables $X_1, \ldots, X_n \sim F$ is called a
\emph{Random Sample of Size $n$ from $F$} -- in Statistics it is commonly
assumed that Observations are IID

 a Random Sequence (\S\ref{sec:random_sequence}) of IID Observations is a
 special case of a Stochastic Process (\S\ref{sec:stochastic_process})

\fist cf. \emph{Statistical Randomness} (\S\ref{sec:statistical_randomness}),
\emph{Algorithmic Randomness} (\S\ref{sec:algorithmic_randomness})

\fist Monte Carlo Simulation (\S\ref{sec:monte_carlo})

\fist Random Assignment (Counterfactual Causal Inference
\S\ref{sec:counterfactual_model})



\subsubsection{Simple Random Sample}\label{sec:simple_random_sample}

\subsubsection{Systematic Sample}\label{sec:systematic_sample}

\subsubsection{Stratified Random Sample}\label{sec:stratified_random_sample}

cf. Benchmarking (``\emph{Post-stratification}'' \S\ref{sec:benchmarking})

Horvitz-Thompson Estimator (\S\ref{sec:horvitz_thompson})



\subsubsection{Cluster Sample}\label{sec:cluster_sample}



% ------------------------------------------------------------------------------
\subsection{Non-random Sample}\label{sec:nonrandom_sample}
% ------------------------------------------------------------------------------

(or \emph{Non-probability Sample} or \emph{Biased Sample})

cf. Statistical Bias (\S\ref{sec:statistical_bias})

Voluntary Sampling, Response Bias

\emph{Accidental Sample} (\emph{Convenience Sample})

\emph{Consecutive Sample}

\emph{Snowball Sample}

\emph{Purposive Sample} (\emph{Judgemental Sample})

\emph{Quota Sample}

\emph{Quadrature Nodes} (Quasi-Monte Carlo Methods) %FIXME: xref



% ------------------------------------------------------------------------------
\subsection{Statistic}\label{sec:statistic}
% ------------------------------------------------------------------------------

cf. Sample Study

(wiki):

or \emph{Sample Statistic}

Computed by applying a Function (Statistical Algorithm) to Sample Data, i.e. a
Statistic is a Function of the Random Variable (\S\ref{sec:random_variable})
constituting a Random Sample, therefore a Statistic itself is an
\emph{Observable} Random Variable:
\[
  T_n = g(X_1, \ldots, X_n)
\]

the term \emph{Statistic} may be used both for the Function and for the value of
the Function on a given Sample

the Probability Distribution (\S\ref{sec:probability_distribution}) of a
Statistic is a \emph{Sampling Distribution} (\S\ref{sec:sampling_distribution})

a \emph{Statistic} is to a \emph{Sample} as a \emph{Parameter}
(\S\ref{sec:population_parameter}) is to a Population (\S\ref{sec:population})

Confidence Interval (\S\ref{sec:confidence_interval})

\fist an \emph{Estimator} (\S\ref{sec:estimator}) is a Statistic used to
Estimate a Population Parameter

\fist Resampling (\S\ref{sec:resampling}) is a method of Estimating the
precision of a Sample Statistic

$\overline{x}$, $\sigma^2$

\begin{itemize}
  \item Descriptive Statistics (\S\ref{sec:descriptive_statistics}) --
    Descriptive (Summary) Statistic (\S\ref{sec:summary_statistic}) used to
    describe Data
  \item Estimation Theory (\S\ref{sec:estimation_theory}) -- Estimator used to
    describe Population Parameter
  \item Hypothesis Testing (\S\ref{sec:hypothesis_testing}) -- Test Statistic
    (\S\ref{sec:test_statistic}) used to Test a Hypothesis
\end{itemize}

\asterism

\begin{itemize}
  \item $z$-score (Standard Score or $z$-statistic \S\ref{sec:z_statistic})
    -- Estimation of Population Proportion (\S\ref{sec:proportion})
  \item $t$-statistic (\S\ref{sec:t_statistic}) -- Estimation of Population Mean
    (\S\ref{sec:expected_value}) from a Sampling Distribution where the Sample
    Means of the Population Standard Deviation is unknown, or for other
    Parameters or when $n$ is too small
\end{itemize}

\asterism

\begin{itemize}
  \item Signal Coherence (\S\ref{sec:signal_coherence})
  \item ...
\end{itemize}

\asterism

(Wasserman04 \S9.13.2) a Statistic induces a \emph{Partition} on the Set of
Outcomes (FIXME: clarify)



\subsubsection{Sampling Distribution}\label{sec:sampling_distribution}

Probability Distribution of a Statistic (\S\ref{sec:statistic})

\fist Central Limit Theorem (\S\ref{sec:central_limit_theorem})

Conditions for Normal (\S\ref{sec:sampling_distribution}) Sampling Distribution:
\begin{enumerate}
  \item Randomness Condition
  \item Normality Condition
  \item Independence Condition
\end{enumerate}

Statistical Inference (\S\ref{sec:inferential_statistics})

the Standard Deviation (\S\ref{sec:standard_deviation}) of a Sampling
Distribution is called the \emph{Standard Error} (\S\ref{sec:standard_error})

$t$-distribution (\S\ref{sec:t_distribution}) -- Sampling Distribution for small
Sample Size

(Wasserman04 \S6.3.1):
the Distribution of a Point Estimator (\S\ref{sec:point_estimator})
$\hat{\theta}_n = g(X_1,\ldots,X_n)$



\subsubsection{Robust Statistic}\label{sec:robust_statistic}

\fist Info-gap Decision Theory (\S\ref{sec:info_gap}) -- Non-probabilistic
Decision Theory seeking to optimize Robustness to ``failure'' under severe
Uncertainty (\S\ref{sec:uncertainty_analysis})



\subsubsection{Sufficient Statistic}\label{sec:sufficient_statistic}

a \emph{Sufficient Statistic} is a Statistic that contains all the
Information (\S\ref{sec:information}) in the Data

(Wasserman04 \S9.13.2):

a Statistic if Sufficient if the Likelihood Function (\S\ref{sec:likelihood})
can be computed knowing only $T(X^n)$,
\emph{or}: a Statistic is Sufficient if the Distribution of $X^n$ given
$T(X^n) = t$ does not depend on Model Paramters $\theta$

a Statistic is \emph{Minimal Sufficient} if it is Sufficient and is a Function
of every other Sufficient Statistic

\emph{Factorization Theorem}

\emph{Rao-Blackwell Theorem} -- an Estimator (\S\ref{sec:estimator}) that does
not depend on a Sufficient Statistic is sub-optimal

for Exponential Family Distributions (\S\ref{sec:exponential_family}) which have
PDFs of the form:
\[
  f(x; \theta) = h(x) e^{\eta(\theta)T(x) - B(\theta)}
\]
$T$ is called the \emph{Natural Sufficient Statistic}



\subsubsection{Degrees of Freedom}\label{sec:statistical_freedom}

\subsubsection{$z$-statistic}\label{sec:z_statistic}

Standard Score ($z$-score \S\ref{sec:standard_score})

cf. $t$-statistic (\S\ref{sec:t_statistic})



\subsubsection{$t$-statistic}\label{sec:t_statistic}

$t$-distribution (\S\ref{sec:t_distribution})

$t$-test (\S\ref{sec:t_test})

cf. $z$-statistic (\S\ref{sec:z_statistic})

can be used for small $n$ ($t$-distribution has fatter tails)

conditions:
\begin{itemize}
  \item Sample is Random
  \item Normal Condition -- $n \geq 30$, or else original Distribution is Normal
    or Symmetric around Mean
  \item Observations are Independent
\end{itemize}

Margin of Error (\S\ref{sec:margin_of_error})

Degree of Freedom (\S\ref{sec:statistical_freedom}) -- Sample Size minus $1$;
different $t$-distribution depending on the Sample Size



\subsubsection{$F$-statistic}\label{sec:f_statistic}

(Fisher)

$F$-distribution (\S\ref{sec:f_distribution}) -- can be seen as a Ratio of
$\chi^2$-distributions with differing DoF

$F$-test (\S\ref{sec:f_test})

ANOVA (\S\ref{sec:variance_analysis})

$F = \frac{\text{between-group variability}}{\text{within-group variability}}$

Linear Regression



% ------------------------------------------------------------------------------
\subsection{Error}\label{sec:error}
% ------------------------------------------------------------------------------

\emph{Statistical Error} or \emph{Disturbance}

Deviation (Signed Difference \S\ref{sec:deviation}) of an Observation
(\S\ref{sec:observation}) \emph{or} of an Estimate
(\S\ref{sec:estimation_theory}) from an ideal (possibly theoretical) ``true''
value, usually the Observed (Estimated) Random Variable's Expected Value
(\S\ref{sec:expected_value})

\fist cf. \emph{Observational Error} (Measurement Error
\S\ref{sec:observational_error}), \emph{Standard Error}
  (\S\ref{sec:standard_error})

Absolute Error -- Median minimizes Absolute Error

Squared Error -- Mean (Expected Value) minimizes Squared Error

cf. \emph{Variance} (\S\ref{sec:variance}) -- Expected Squared Error

\fist Mean Squared Deviation or Mean Squared Error (MSE \S\ref{sec:msd}) of an
Estimator (\S\ref{sec:estimator}) is the Average of the Squared Error of the
Estimated value (produced by an Estimator) from the ``true'' value; MSD is
the Second Moment of the Error; for an Unbiased Estimator the MSD is the
Variance of the Estimator

cf. Residual (\S\ref{sec:residual}) -- Deviation of an Observed Value from an
\emph{Estimated} (\S\ref{sec:estimation_theory}) Expected Value

\fist Regression Error (\S\ref{sec:regression_error})

\fist Classification Error (\S\ref{sec:classification_error})

(wiki):

example for Sample (\S\ref{sec:sample}) of IID Normally Distributed Random
Variables, $X_1, \ldots, X_n \sim N(\mu, \sigma^2)$, the Sample Mean
(\S\ref{sec:sample_mean}):
\[
  \overline{X} = \frac{X_1 + \cdots + X_n}{n}
\]
is a Random Variable with Normal Distribution:
\[
  \overline{X} = N(\mu, \frac{\sigma^2}{n})
\]
and the \emph{Statistical Errors} are:
\[
  e_i = X_i - \mu
\]
and the \emph{Residuals} (\S\ref{sec:residual}) are:
\[
  r_i = X_i - \overline{X}
\]



\subsubsection{Sampling Error}\label{sec:sampling_error}

\subsubsection{Non-sampling Error}\label{sec:nonsampling_error}

Coverage Errors

Response Errors



% ------------------------------------------------------------------------------
\subsection{Variance Analysis}\label{sec:variance_analysis}
% ------------------------------------------------------------------------------

ANalysis Of VAriance (ANOVA)

repeated Measures (Observations \S\ref{sec:observation})

General Linear (Multivariate) Regression (\S\ref{sec:multivariate_regression})

cf. Mixed Models (\S\ref{sec:mixed_model})

Analysis of the the differences among ``group means'' (FIXME: clarify) in a
Sample (\S\ref{sec:sample})

$F$-statistic (\S\ref{sec:f_statistic}):
$F = \frac{\text{between-group variability}}{\text{within-group variability}}$

generalizes $t$-test (\S\ref{sec:t_test}) to more than two groups

compare three or more ``group means'' for Significance
(\S\ref{sec:statistical_significance})

\fist Multivariate Analysis of Variance (MANOVA \S\ref{sec:manova})



\subsubsection{Squared Deviation from Mean (SDM)}\label{sec:sdm}

\fist Squared Deviation (\S\ref{sec:squared_deviation})

cf. Mean Squared Deviation (MSD \S\ref{sec:msd}), Sum of Squared
Deviations (\S\ref{sec:sum_squared_deviation})

\emph{Variance} (\S\ref{sec:variance}) is defined as either:
\begin{itemize}
  \item the \emph{Expected Value of the SDM} when considering a
    \emph{theoretical Distribution}
\end{itemize}
or:
\begin{itemize}
  \item the Sample Mean (\S\ref{sec:sample_mean}) of some Data
    (\S\ref{sec:sample})
\end{itemize}

cf. Least Squares (\S\ref{sec:least_squares}), Regression
(\S\ref{sec:regression_analysis})



\subsubsection{Sum of Squared Deviation}\label{sec:sum_squared_deviation}

\fist Squared Deviation (\S\ref{sec:squared_deviation})

cf. Mean Squared Deviation (MSD \S\ref{sec:msd}), Sum of Squared
Deviations (\S\ref{sec:sum_squared_deviation})

\fist cf. Least Squares (\S\ref{sec:least_squares})

unscaled measure of \emph{Dispersion} (Variability \S\ref{sec:dispersion})

Estimates the Variance (\S\ref{sec:variance}) when scaled for the number of
\emph{Degrees of Freedom} (\S\ref{sec:statistical_freedom})



\paragraph{Total Sum of Squares (TSS)}\label{sec:tss}\hfill

or \emph{SST}

\[
  TSS = \sum_{i=1}^n (y_i - \overline{y})^2
\]

the numerator when calculating the Variance

equal to SSR + ESS

SSW -- Sum of Squares \emph{Within} a Sample

SSB -- Sum of Squares \emph{Between} Samples

$SST = SSW + SSB$

ANOVA (\S\ref{sec:variance_analysis}) --
$F$-statistic (\S\ref{sec:f_statistic}):
$F = \frac{\text{between-group variability}}{\text{within-group variability}}$

$F = \frac{\frac{SSB}{DoF_B}}{\frac{SSW}{DoF_W}}$

Determination Coefficient (\S\ref{sec:determination_coefficient}):
\[
  r^2 = 1 - \frac{
    ESS_{\hat{y}}
  }{
    TSS_{\overline{y}}
  }
\]



\paragraph{Sum of Squared Residuals (SSR)}\label{sec:ssr}\hfill

or \emph{SSE} or \emph{SSR}

$SSE = \sum(Y_i - \hat{Y_i})^2$

Residuals (\S\ref{sec:residual})

\fist a \emph{Least Square Estimate} (\S\ref{sec:least_squares}) is an
approximate solution of an Overdetermined System that minimizes the Sum of
Squared Residuals (SSR)

the SSR is a measure of how well an Estimated Regression Function
(\S\ref{sec:regression_analysis}) $\hat{r}(x)$ ``Fits'' the Data; Regression
Parameters that minimize SSR are called \emph{Least Squares Estimates}

\[
  \sum_{i=1}^n \hat{\epsilon}_i^2
\]



\paragraph{Explained Sum of Squares (ESS)}\label{sec:ess}\hfill

Expected Deviation from Mean: $SSR = \sum(\hat{Y}_i - \overline{Y})^2$

Determination Coefficient (\S\ref{sec:determination_coefficient}):
\[
  r^2 = 1 - \frac{
    ESS_{\hat{y}}
  }{
    TSS_{\overline{y}}
  }
\]



\subsubsection{Partition of Sum of Squares}\label{sec:partition_squares}

TODO



% ==============================================================================
\section{Descriptive Statistics}\label{sec:descriptive_statistics}
% ==============================================================================

\emph{Descriptive Measures}

Summary of Data: Mean, Median, Mode, Standard Deviation

cf. Test Statistics (\S\ref{sec:test_statistic})

Descriptive Statistics are often Non-parametric
(\S\ref{sec:nonparametric_model})



% ------------------------------------------------------------------------------
\subsection{Summary Statistics}\label{sec:summary_statistics}
% ------------------------------------------------------------------------------

% FIXME: many of the below concepts apply to *population parameters* as well as
% *sample statistics*; can they be distinguished/moved elsewhere ???

\begin{itemize}
  \item Dispersion (\S\ref{sec:dispersion})
  \item Central Tendency (\S\ref{sec:central_tendency})
  \item Shape (\S\ref{sec:distribution_shape})
  \item Dependence (\S\ref{sec:dependence})
\end{itemize}

various Summary Statistics can be computed by Statistical Functionals
(\S\ref{sec:statistical_functional}), i.e. Functions of the CDF
(\S\ref{sec:cdf}):
\begin{itemize}
  \item $\mu = T(F) = \int x dF(x)$
    -- Mean (Expectation \S\ref{sec:expected_value})
  \item $\sigma^2 = T(F) = \int (x - \mu)^2 dF(x)$
    -- Variance (\S\ref{sec:variance})
  \item $m = T(F) = F^{-1}(0.5)$
    -- Median (\S\ref{sec:median})
\end{itemize}



\subsubsection{Statistical Dispersion}\label{sec:dispersion}

\emph{Variability} or \emph{Spread}

Estimated by Statistics on the Distribution of Deviations
(\S\ref{sec:deviation})

quantified by Standard Deviation (\S\ref{sec:standard_deviation})

\fist Scale Parameter (\S\ref{sec:scale_parameter})

\begin{itemize}
  \item Range (\S\ref{sec:range}) -- difference between largest and smallest
    values
  \item InterQuartile Range (IQR \S\ref{sec:iqr}) -- difference between 75th and
    25th Percentiles
  \item ... TODO
\end{itemize}

(wiki): ``Dispersion precedes Location'' --

given a measure of Statistical Dispersion, measures of Central Tendency
(\S\ref{sec:central_tendency}) can be characterized as \emph{Minimizing
  Variation} (\S\ref{sec:calculus_of_variations}) such that the Center is
minimal among all possible choices of Center (may or may not be unique); in the
sense of $L^p$-norms (\S\ref{sec:p_norm}):
\begin{tabular}{l l l}
  $L^p$ & Dispersion & Central Tendency
  $L^0$ & Variation Ratio (Qualitative Variation \S\ref{sec:variation_ratio})
    & Mode (\S\ref{sec:mode}) \\
  $L^1$ & Mean Absolute Deviation (\S\ref{sec:mad})
    & Median (\S\ref{sec:median}),
      Geometric Median (\S\ref{sec:geometric_median}) \\
  $L^2$ & Standard Deviation (\S\ref{sec:standard_deviation})
    & Mean (\S\ref{sec:mean}) \\
  $L^\infty$ & Maximum Deviation (\S\ref{sec:maximum_deviation})
    & Mid-range (\S\ref{sec:midrange})
\end{tabular}

\fist Sum of Squared Deviations (\S\ref{sec:sum_squared_deviation}) -- unscaled
measure of Dispersion

cf. \emph{Uncertainty}

2018 - \emph{Uncertainty: a Tutorial} -
\url{https://blog.evjang.com/2018/12/uncertainty.html}



\paragraph{Range}\label{sec:range}\hfill

\subparagraph{InterQuartile Range (IQR)}\label{sec:iqr}\hfill

Outliers:  $Q1 - 1.5 \times IQR$, $Q3 + 1.5 \times IQR$



\paragraph{Qualitative Variation}\label{sec:qualitative_variation}\hfill

measure of Statistical Dispersion for {Nominal Distributions} (Measurement Level
\S\ref{sec:measurement_level})

Deviation from the Mode (\S\ref{sec:mode})



\subparagraph{Variation Ratio}\label{sec:variation_ratio}\hfill

Dispersion associated with the $L^0$ Metric (Counting ``Norm''-- not really a
Norm \S\ref{sec:p_norm}); the corresponding Central Tendency is the \emph{Mode}
(\S\ref{sec:mode})

equal to the overall proportion of cases that are \emph{not} in the Mode:
\[
  v \defeq 1 - \frac{n_{\text{mode}}}{N}
\]
where $n_{\text{mode}}$ are the number of cases in the Mode and $N$ is the total
number of cases



\paragraph{Mean Absolute Deviation (MAD)}\label{sec:mad}\hfill

or \emph{Average of Absolute Deviations} (\S\ref{sec:absolute_deviation}), i.e.
Errors or Residuals, to a central point

Dispersion measure associated with the $L^1$ Metric (Taxicab Norm
\S\ref{sec:p_norm}); the corresponding Central Tendency which minimizes the MAD
is the \emph{Median} (\S\ref{sec:median}) or \emph{Geometric Median}
(\S\ref{sec:geometric_median})

\fist not to be confused with \emph{Mean Absolute Error} (MAE \S\ref{sec:mae})
-- Average difference between two Continuous Random Variables,
or \emph{Mean Absolute Difference} (\S\ref{sec:mean_absolute_difference}) --
Average Absolute Difference between two IID Random Variables

cf. Mean Squared Deviation (MSD \S\ref{sec:msd})



\subparagraph{Mean Absolute Difference}
\label{sec:mean_absolute_difference}\hfill

\emph{Absolute Mean Difference} or \emph{Gini Mean Difference (GMD)}

$MD$

Average Absolute Difference (\S\ref{sec:absolute_difference}) between two IID
Random Variables, i.e. the Expected Value of the Absolute Difference of two IID
Random Variables



\subparagraph{Relative Mean Absolute Difference}
\label{sec:relative_mean_absolute_difference}\hfill

Mean Absolute Difference divided by the Arithmetic Mean
(\S\ref{sec:arithmetic_mean})



\paragraph{Standard Deviation}\label{sec:standard_deviation}\hfill

$\sigma$

Dispersion measure associated with the $L^2$ Metric (Euclidean Norm
\S\ref{sec:p_norm}); the corresponding Central Tendency which minimizes the
Standard Deviation is the \emph{Mean} (\S\ref{sec:mean})

Deviation (\S\ref{sec:deviation})

Square Root of the Variance (\S\ref{sec:variance}) $\sqrt{V(X)}$

cf. Root Mean Squared Deviation (RMSD \S\ref{sec:rmsd}) -- Square Root of the
Mean Squared Deviation (MSD \S\ref{sec:msd})

the Standard Deviation of a Sampling Distribution
(\S\ref{sec:sampling_distribution}) is called the \emph{Standard Error}
(\S\ref{sec:standard_error})

the Standard Error equals the Standard Deviation divided by the square root of
the Sample Size, i.e. the Standard Error of the Mean is a measure of
``Dispersion'' of Sample Means around the Population Mean

cf. Confidence Interval (\S\ref{sec:confidence_interval})

$S$ -- Standard Deviation of Regression Residuals
(\S\ref{sec:regression_residual})

\emph{Uncorrected Standard Deviation}:
\[
  s_n = \sqrt{\frac{1}{n}\sum_{i=1}^n (x_i - \overline{x})^2}
\]

\emph{Corrected Standard Deviation}

\emph{Unbiased Standard Deviation}



\subparagraph{Standard Score}\label{sec:standard_score}\hfill

or \emph{$z$-score}

$z$-statistic (\S\ref{sec:z_statistic}) -- used for Estimating Population
Proportion (\S\ref{sec:population_proportion})

cf. $t$-statistic (\S\ref{sec:t_statistic}) -- used for Estimating Population
Mean and other Parameters, and for small $n$

(wiki): signed fractional number of Standard Deviations by which an Observation
or Data Point is \emph{above} the Mean:
\[
  z = \frac{x - \mu}{\sigma}
\]

$z$-statistic for a Proportion Statistic $\hat{p}$ with Sample Size $n$:
\[
  z = \frac{\hat{p} - p}{\sqrt{\frac{p(1-p)}{n}}}
\]
where the Denominator is the Standard Deviation of the Sampling Distribution of
the Sample Proportion (i.e. the Standard Error of the Statistic
\S\ref{sec:standard_error})

MIT 6.041SC, Lec.8

\emph{Standardizing} a Normal Random Variable (\S\ref{sec:normal_distribution})
-- for $X \sim N(\mu, \sigma^2)$:
\[
  \frac{X - \mu}{\sigma} \sim N(0, 1)
\]
where $(X - \mu)/\sigma$ is the Standard Score



\subparagraph{Mahalanobis Distance}\label{sec:mahalanobis_distance}\hfill

Multi-dimensional generalization of Standard Deviation

Generalized Least Squares (GLS \S\ref{sec:gls})



\subparagraph{Variance}\label{sec:variance}\hfill

the \emph{Variance} is the Expected Value of the Squared Deviation
(\S\ref{sec:sdm}) of a Random Variable

$\sigma_X^2 = Cov(X,X)$ (\S\ref{sec:covariance})

this is either equal to the Expected Value of the Square Deviation from the
Mean of a theoretical Distribution, or as the Squared Deviations from the Sample
Mean (Sample Variance \S\ref{sec:sample_variance})

the \emph{Sum of Squared Deviations} (\S\ref{sec:sum_squared_deviation})
Estimates (\S\ref{sec:estimation_theory}) the Variance when scaled for the
number of \emph{Degrees of Freedom} (\S\ref{sec:statistical_freedom})

\fist Mean Squared Deviation or Mean Squared Error (MSE \S\ref{sec:msd}) of an
Estimator (\S\ref{sec:estimator}) is the Average of the Squared Error of the
Estimated value (produced by an Estimator) from the ``true'' value; MSD is
the Second Moment of the Error; for an Unbiased Estimator the MSD is the
Variance of the Estimator

\emph{Overfitting} (Multiple Regression \S\ref{sec:multiple_regression}) -- too
many Covariates, high Variance

\fist ANalaysis Of VAriance (ANOVA \S\ref{sec:variance_analysis}) --
Variance is defined as either the Expected Value of the
Squared Deviation from the Mean (SDM \S\ref{sec:sdm}), considering a theoretical
Distribution, or its Sample Mean (\S\ref{sec:sample_mean})

Second Central Moment (\S\ref{sec:moment})/Second Cumulant
(\S\ref{sec:cumulant})

Variances are always Non-negative

the Variance of a Random Variable $X$ is equal to:
\begin{align*}
  \sigma^2 = V(X) & = E(X - E(X))^2   \\
                  & = E(X^2) - E(X)^2 \\
                  & = \int(x - E(X))^2 dF(x) \\
\end{align*}
assuming the Expected Value (\S\ref{sec:expected_value}) $E(\cdot)$ exists

Discrete Random Variable $X$:
\[
  Var(X) = \sigma_X^2 = \sum_{i=1}^n f(x_i) (x_i - \mu)^2 = \sum_{i=1}^n
  f(x_i) x_i^2 - \mu^2
\]
where $\mu = \sum_{i=1}^n f(x_i) x_i$

Continuous Random Variable $X$:
\[
  Var(X) = \sigma_X^2 = \int (x - \mu)^2 f(x) dx = \int x^2 f(x) dx -
  \mu^2
\]
where $\mu = \int x f(x) dx$

For Random Variables $X$, $Y$ with Joint Probability Distribution
$f(x,y)$ and $a$, $b$, $c$ are Constants, then:
\[
  \sigma^2_{a X + b Y + c} = a^2 \sigma^2_X + b^2 \sigma^2_Y + 2ab
  \sigma_{X Y}
\]

\fist Estimator: Sample Variance (\S\ref{sec:sample_variance})

for Independent Random Variables, $Var(X + Y) = Var(X) + Var(Y)$ and
$Var(X - Y) = Var(X) + Var(Y)$

\emph{Conditional Variance} $V(X|Y)$

$V(Y) = E(V(Y|X)) + V(E(Y|X))$

Variance reduction methods:
\begin{itemize}
  \item Bootstrap Aggregation (Bagging \S\ref{sec:bootstrap_aggregation})
\end{itemize}



\subparagraph{Sample Variance}\label{sec:sample_variance}\hfill

$s^2$

Degrees of Freedom, Linear Independence, Biased/Unbiased Estimator
(\S\ref{sec:unbiased_estimate})

Unbiased Sample Variance:
\[
  s^2 = \frac{n}{n-1}\sigma^2_y =
  \frac{1}{n-1} \sum_{i=1}^n (y_i - \overline{y})^2
\]



\subparagraph{Chebyshev's Inequality}\label{sec:chebyshevs_inequality}\hfill

Probability that a Random Variable $X$ will assume Value within $k$ Standard
Deviations

Random Variable $X$ with Finite Expected Value (\S\ref{sec:expected_value})
$\mu$ and Finite Non-zero Variance $\sigma^2$, for any $k \in \reals : k > 0$:
\[
  P(k\sigma \leq |X - \mu|) \leq \frac{1}{k^2}
\]



\paragraph{Maximum Absolute Deviation}
\label{sec:maximum_absolute_deviation}\hfill

Dispersion measure associated with the $L^\infty$ Metric (Max Norm
\S\ref{sec:p_norm}); the corresponding Central Tendency which minimizes the
Maximum Absolute Deviation is the \emph{Midpoint} (\S\ref{sec:midpoint})



\subsubsection{Central Tendency}\label{sec:central_tendency}

or \emph{Location} or ``\emph{Average}''

(wiki): ``Dispersion precedes Location'' --

given a measure of Statistical Dispersion (\S\ref{sec:dispersion}), measures of
Central Tendency can be characterized as \emph{Minimizing Variation}
(\S\ref{sec:calculus_of_variations}) such that the Center is minimal among all
possible choices of Center (may or may not be unique); in the sense of
$L^p$-norms (\S\ref{sec:p_norm}):
\begin{tabular}{l l l}
  $L^p$ & Dispersion & Central Tendency
  $L^0$ & Variation Ratio (Qualitative Variation \S\ref{sec:variation_ratio})
    & Mode (\S\ref{sec:mode}) \\
  $L^1$ & Mean Absolute Deviation (\S\ref{sec:mad})
    & Median (\S\ref{sec:median}),
      Geometric Median (\S\ref{sec:geometric_median}) \\
  $L^2$ & Standard Deviation (\S\ref{sec:standard_deviation})
    & Mean (\S\ref{sec:mean}) \\
  $L^\infty$ & Maximum Deviation (\S\ref{sec:maximum_deviation})
    & Mid-range (\S\ref{sec:midrange})
\end{tabular}



\paragraph{Mode}\label{sec:mode}\hfill

Central Tendency for Nominal Measurement (\S\ref{sec:measurement_level})

\fist Variation Ratio (Qualitative Variation, Deviation from the Mode
\S\ref{sec:variation_ratio}) -- the Dispersion measure associated with the $L^0$
Metric (Counting ``Norm''-- not really a Norm \S\ref{sec:p_norm}) for which the
Mode is the corresponding Central Tendency

cf. \emph{Unimodality}, \emph{Multimodality} -- Global/Local Maxima



\paragraph{Median}\label{sec:median}\hfill

Central Tendency for Ordinal Measurement (\S\ref{sec:measurement_level})

\fist Mean Absolute Deviation (MAD \S\ref{sec:mad}) -- Dispersion measure
associated with the $L^1$ Metric (Taxicab Norm \S\ref{sec:p_norm}) for which the
Median is the corresponding measure of Central Tendency

i.e. as an Estimate (\S\ref{sec:estimation_theory}) for $X$, the Median $m[X]$
minimizes Absolute Deviation (Absolute Errors or Absolute Residuals)

cf. the \emph{Mean} (Expected Value \S\ref{sec:mean}) minimizes Squared Error

note that $E(X + Y) = E(X) + E(Y)$, but not for $m(X+Y)$



\subparagraph{Geometric Median}\label{sec:geometric_median}\hfill

\subparagraph{Sample Median}\label{sec:sample_median}\hfill



\paragraph{Mean}\label{sec:mean}\hfill

Central Tendency for Interval Measurement (\S\ref{sec:measurement_level})

\fist Expected Value (\S\ref{sec:expected_value})



\subparagraph{Arithmetic Mean}\label{sec:arithmetic_mean}\hfill

\emph{Arithmetic Mean} $\overline{x} = \frac{1}{n}\sum_{i=1}^n x_i$

by the Law of Large Numbers (\S\ref{sec:large_numbers}), the Arithmetic Mean
Converges to the Mean (Expected Value \S\ref{sec:expected_value}) as the Sample
Size gets larger

Central Tendency for Interval Measurement (\S\ref{sec:measurement_level})

\begin{itemize}
  \item Relative Mean Absolute Difference
    (\S\ref{sec:relative_mean_absolute_difference}) -- Mean Absolute Difference
    divided by the Arithmetic Mean
\end{itemize}



\subparagraph{Weighted Arithmetic Mean}\label{sec:weighted_mean}\hfill

\emph{Weight Function}

\emph{Weighted Sum} or \emph{Weighted Average}

\fist Benchmarking (\S\ref{sec:benchmarking})

Simpson's Paradox



\subparagraph{Geometric Mean}\label{sec:geometric_mean}\hfill

using the Product of Values instead of Sum as in Arithmetic Mean

Central Tendency for Ratio Measurement (\S\ref{sec:measurement_level})



\paragraph{Trimmed Mean}\label{sec:trimmed_mean}\hfill



\paragraph{Midrange}\label{sec:midrange}\hfill

Average of Max and Min (Range \S\ref{sec:range})

Central Tendency minimizing the Maximum Absolute Deviation
(\S\ref{sec:maximum_absolute_deviation})



\subparagraph{Midhinge}\label{sec:midhinge}\hfill

Average of First and Third Quartiles; minimizes Median Absolute Deviation and
Maximum Absolute Deviation of the Distribution of the 2nd and 3rd Quartiles

Trimmed $L^\infty$ Norm Statistic



\subsubsection{Shape}\label{sec:distribution_shape}

\paragraph{Skewness}\label{sec:skewness}\hfill

Asymmetry %FiXME

``lopsided-ness''

Third Central Moment (\S\ref{sec:moment})/Third Cumulant (\S\ref{sec:cumulant})



\paragraph{Kurtosis}\label{sec:kurtosis}\hfill

Fourth Central Moment (\S\ref{sec:moment})

Measure of the ``heaviness'' of the tail of a Distribution



\subsubsection{Dependence}\label{sec:dependence}

or \emph{Association}

any ``\emph{Statistical Relationship}'' between two Random Variables
(``Bivariate Data'')

may or may not be Causal -- (wiki): the main difference between
\emph{Causal Inference} (\S\ref{sec:causal_inference}) and an Inference of
\emph{Association} is that the former analyzes the ``response'' of the ``effect
variable'' when the Cause is changed

Random Variables are \emph{Dependent} if they do not Satisfy the Property of
\emph{Probabilistic Independence} (\S\ref{sec:independence})

Stochastic Processes (\S\ref{sec:stochastic_process}): Sequences of Dependent
Random Variables

\fist Regression Analysis (\S\ref{sec:regression_analysis}) -- Estimation
(\S\ref{sec:estimation_theory}) of Relations in Multivariate Data
(\S\ref{sec:random_vector})

\fist a \emph{Structural Assumption} is a Model-baesd Statistical Assumption
(\S\ref{sec:statistical_assumption}) about the Functional Dependence between
Variables in a Statistical Model



\paragraph{Covariance}\label{sec:covariance}\hfill

a measure of the ``Joint Variability'' of two Random Variables; the sign of the
Covariance shows the tendency of a Linear Relation between the Variables, and
the Normalized version of the Covariance is the \emph{Correlation Coefficient}
(\S\ref{sec:correlation_coefficient}) which gives the magnitude of the Linear
Relation

$Cov(X,Y) = E [(X - \mu_X)(Y - \mu_Y)]$

$Cov(X,X)$ -- Variance (\S\ref{sec:variance})

\fist cf. Causation (\S\ref{sec:causation})

$n$ Discrete Samples:
\[
  \sigma_{X,Y} = Cov(X,Y) = E [(X - \mu_X)(Y - \mu_Y)] =
    \frac{1}{n} \sum_{i=1}^n (x_i - \mu_X) (y_i - \mu_Y)
\]

Continuous:
\[
  Cov(X,Y) = E [(X - \mu_X)(Y - \mu_Y)] =
  \int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty}
  (x - \mu_X) (y - \mu_Y) f(x,y) dx dy
\]
where $f(x,y)$ is the Joint Probability Distribution
(\S\ref{sec:joint_probability}) of $X$, $Y$

\fist Sample Covariance (\S\ref{sec:sample_covariance})

\textbf{Thm.} \emph{Covariance Satisfies:
  \[
    Cov(X,Y) = E(XY) - E(X)E(Y)
  \]
}

the Correlation (\S\ref{sec:statistical_correlation}) is defined in terms of the
Covariance:
\[
  \rho_{X,Y} = \frac{Cov(X,Y)}{\sigma_X \sigma_Y}
\]
if $X$ and $Y$ are Independent (\S\ref{sec:dependence}), then
$Cov(X,Y) = \rho = 0$



\subsubsection{Correlation}\label{sec:statistical_correlation}

$\rho$

measure of how close two Random Variables are to having a \emph{Linear
  Relationship}

Normalized Covariance (\S\ref{sec:covariance})

\fist cf. Linear Regression (\S\ref{sec:linear_regression})

cf. Observational Studies

\[
  \rho_{X,Y} = \frac{Cov(X,Y)}{\sigma_X \sigma_Y}
\]
where $Cov(X,Y)$ is the Covariance (\S\ref{sec:covariance})

if $X$ and $Y$ are Independent (\S\ref{sec:dependence}) and have Finite Second
Moments, then they are Uncorrelated; not all Uncorrelated Variables are
Independent

if $X$ and $Y$ are Independent, then $Cov(X,Y) = \rho = 0$



\paragraph{Correlation Coefficient}\label{sec:correlation_coefficient}\hfill

\emph{Pearson Product-moment Correlation Coefficient}

$\rho_{xy} = \frac{\sigma_{xy}}{\sigma_x \sigma_y}$

Sample Correlation Coefficient $-1 \leq r \leq 1$:
\[
  r = \frac{1}{n-1} \sum_{i=1}^n
    \Big(\frac{x_i - \overline{x}}{s_x}\Big)
    \Big(\frac{y_i - \overline{y}}{s_y}\Big)
\]
where $s_x$ and $s_y$ are the Sample Standard Deviations of $x$ and $y$

\fist cf. $r^2$ -- Coefficient of
Determination (\S\ref{sec:determination_coefficient})



\subsubsection{Covariance Matrix}\label{sec:covariance_matrix}

\emph{Variance-Covariance Matrix} or \emph{Dispersion Matrix}

Symmetric Matrix (\S\ref{sec:symmetric_matrix}) where the $i,j$th entry is the
Covariance between the $i$th and $j$th entries of a Random Vector

Positive Semi-definite (\S\ref{sec:positive_semidefinite})

the Inverse of the Covariance Matrix is called the \emph{Precision Matrix}



% ------------------------------------------------------------------------------
\subsection{Earthmover Distance}\label{sec:earthmover_distance}
% ------------------------------------------------------------------------------

%FIXME: does this section belong here?

a measure of ``nearness'' for Probability Distributions

\url{https://jeremykun.com/2018/03/05/earthmover-distance/}



% ==============================================================================
\section{Inferential Statistics}\label{sec:inferential_statistics}
% ==============================================================================

\emph{Statistical Inference} (or ``\emph{Learning}'' in Computer Science) --
using \emph{Sample Data} (\S\ref{sec:sample}) to \emph{Infer} (cf. Logical
Inference \S\ref{sec:logical_inference}, Inference Rules
\S\ref{sec:inference_rule}) the Distribution
(\S\ref{sec:probability_distribution}) that ``generated'' the Data

\fist cf. Statistical Learning Theory (\S\ref{sec:statistical_learning_theory})

\fist cf. Probabilistic Inference
(\S\ref{sec:probabilistic_inference}), Inductive Inference
(\S\ref{sec:inductive_inference})

\fist Probabilistic Classification (\S\ref{sec:probabilistic_classification}) --
use of Statistical Inference to solve a Statistical Classification
(\S\ref{sec:classification}) problem

(wiki)

two approaches to Statistical Inference, both relying on some \emph{Statistical
  Model} (\S\ref{sec:statistical_model}) to represent a ``Data-generating
Process'' (cf. Stochastic Process \S\ref{sec:stochastic_process}):
\begin{enumerate}
  \item \emph{Model-based Inference} -- the Model is taken to be initially
    unknown and the goal is to \emph{Select} (\S\ref{sec:model_selection}) a
    Model for Inference
  \item \emph{Design-based Inference} -- the Model is taken to be known and the
    goal is to ensure Sample Data is selected \emph{Randomly}
    (\S\ref{sec:random_sample}) enough for Inference
\end{enumerate}
the Statistical Assumptions (\S\ref{sec:statistical_assumption}) made by a
Statistical Model depends on the approach taken

Wasserman04 - \emph{All of Statistics}, Part II \emph{Models, Statistical
  Inference and Learning}



% ------------------------------------------------------------------------------
\subsection{Statistical Assumption}\label{sec:statistical_assumption}
% ------------------------------------------------------------------------------

(wiki):

\emph{Informally}, a Statistical Model (\S\ref{sec:statistical_model}) can be
thought of as a Set of Statistical Assumptions that allow the calculation of the
Probability of any Event (\S\ref{sec:event}), i.e. the Statistical Model
``embodies'' the Set of Statistical Assumptions that concern the
\emph{Generation} (\S\ref{sec:data_generating_process}) of Sample Data
(\S\ref{sec:sample}).

\emph{Classes of Assumptions} depend on which approach to Statistical Inference
is used (Model-based Inference or Design-based Inference):
\begin{enumerate}
  \item \emph{Model-based Assumptions}:
    \begin{itemize}
      \item \emph{Distributional Assumptions} -- Assumptions about the
        Probability Distribution of Random Errors (\S\ref{sec:random_error})
      \item \emph{Structural Assumptions} -- Assumptions about the form of a
        Statistical Relationship (Dependence \S\ref{sec:dependence}) between
        Variables, e.g. as in Linear Regression (\S\ref{sec:linear_regression})
      \item \emph{Cross-variation Assumptions} -- Assumptions involving Joint
        Probability Distributions (\S\ref{sec:joint_probability}) of either
        Observations or Random Errors in a Model; simple Models may Assume that
        Observations or Errors are Statistically Independent
        (\S\ref{sec:independence})
    \end{itemize}
  \item \emph{Design-based Assumptions} -- Assumptions of the way Observations
    have been made, e.g. Assumption of Randomization during Sampling
    (\S\ref{sec:random_sample})
\end{enumerate}

cf. Statistical Hypothesis (\S\ref{sec:hypothesis})

\fist Assumption (Proof Theory \S\ref{sec:antecedent})



% ------------------------------------------------------------------------------
\subsection{Statistical Model}\label{sec:statistical_model}
% ------------------------------------------------------------------------------

A \emph{Statistical Model} (or \emph{Probabilistic Model})
$\mathfrak{F} = (S,\mathcal{P})$ is a Sample Space (\S\ref{sec:sample_space}),
$S$, together with a Set of Probability Distributions
(\S\ref{sec:probability_distribution}) $\mathcal{P}$ on $S$

(wiki): \emph{Informally}, a Statistical Model can be thought of as a Set of
Statistical Assumptions (\S\ref{sec:statistical_assumption}) that allow the
calculation of the Probability of any Event (\S\ref{sec:event}), i.e. the
Statistical Model ``embodies'' the Set of Statistical Assumptions that concern
the \emph{Generation} (\S\ref{sec:data_generating_process}) of Sample Data
(\S\ref{sec:sample}).

\begin{itemize}
  \item \emph{Parametric Models} (\S\ref{sec:parametric_model}) -- Distributions
    are Parameterized by a Finite number of \emph{Statistical Parameters}
    (Population Parameters \S\ref{sec:population_parameter})
  \item \emph{Non-parametric Models} (\S\ref{sec:nonparametric_model})
    -- has an Infinite-dimensional Parameter Space
  \item \emph{Semi-parametric Models} (\S\ref{sec:semiparametric_model}) -- has
    Finite-dimensional Parameters and Infinite-dimensional
    ``Nuisance Parameters''
  \item \emph{Semi-nonparametric Models} (\S\ref{sec:seminonparametric_model})
    -- has both Finite-dimensional and Infinite-dimensional unknown Parameters
    of interest
\end{itemize}

\emph{Parameter Estimation} (\S\ref{sec:estimation_theory}): Data $\rightarrow$
Parameters

\emph{Prediction} (\S\ref{sec:prediction})

\emph{Hypothesis Testing} (\S\ref{sec:hypothesis_testing})

\fist a \emph{Regression Model} (\S\ref{sec:regression_model}) makes some
assumption about the Relations (Dependences \S\ref{sec:dependence}) among
Multivariate Data (\S\ref{sec:random_vector})

\fist \emph{Classification Model} (\S\ref{sec:classification_model})

VC Dimension (Model Complexity \S\ref{sec:vc_dimension})

(wiki):

$\mathfrak{F} = (S, \mathcal{P})$

$S$ -- ``Sample Space''

$\mathcal{P}$ -- Set of Probability Distributions
(\S\ref{sec:probability_distribution}) on $S$

Wasserman04, Ch.6

\asterism

MIT 6.041SC - \emph{Probabilistic Systems Analysis and Applied Probability}

Probability Laws -- describes ``beliefs'' about which outcomes are more likely
than others; should obey Probability Axioms (\S\ref{sec:probability_axioms})

Sample Space $\Omega$ -- description of possible outcomes

a ``list'' of Events should be Mutually Exclusive
(\S\ref{sec:mutually_exclusive}, for $\sigma$-additivity Axiom) and exhaustive
(for Unitarity Axiom)

\emph{Discrete Uniform Law} (\S\ref{sec:discrete_uniform_law}): all Outcomes are
equally likely

\emph{Continuous Uniform Law} (\S\ref{sec:continuous_uniform_law}): equal Areas
have equal Probabilities

Discrete Models

Continuous Models -- any individual outcome has Zero Probability (TODO: explain)

Models based on Conditional Probabilities (\S\ref{sec:conditional_probability})



\subsubsection{Model Validation}\label{sec:model_validation}

(wiki):

confirming that the ``outputs'' of a Statistical Model are ``acceptable'' with
respect to the ``real'' Data Generating Process
(\S\ref{sec:data_generating_process})

can be based on two types of Sample Data (\S\ref{sec:sample}):
\begin{enumerate}
  \item Data that was used in the \emph{construction} of the Model -- usually
    involves analyzing the \emph{Fit} (\S\ref{sec:model_fit}) or \emph{Residual
      Diagnostics} (\S\ref{sec:residual})
  \item Data that was \emph{not} used in the construction of the Model --
    usually involves analyzing whether the Model's ``\emph{Predictive
      Performance}'' (\S\ref{sec:prediction_interval}) holds up when applied to
    new Data
\end{enumerate}



\paragraph{Fit}\label{sec:model_fit}\hfill

\emph{Goodness-of-Fit}

measures the discrepancy between Observed (\S\ref{sec:observation}) values and
Predicted (\S\ref{sec:prediction}) values under the Statistical Model

$\chi^2$ Distributions (\S\ref{sec:chi_squared});
Chi Squared Test (\S\ref{sec:chi_squared_test})

\fist analysis of Residuals (Fitting Deviation \S\ref{sec:residual})

cf. Regression Analysis (\S\ref{sec:regression_analysis}), Curve Fitting
(\S\ref{sec:curve_fitting})

\fist cf. Learning Algorithms (\S\ref{sec:learning_algorithm});
Parameter Estimation (\S\ref{sec:estimation_theory}), Feature Selection
(\S\ref{sec:feature_selection})

Likelihood-Ratio (LR) Test (\S\ref{sec:lr_test})



\paragraph{Cross-validation}\label{sec:cross_validation}\hfill

or \emph{Rotation Estimation} or \emph{Out-of-sample Testing}

Predictive Models (\S\ref{sec:predictive_model})

Cross-validation Estimation of Fit

Cross-validation Estimator of Risk (Density Estimation
\S\ref{sec:density_estimation})



\subsubsection{Parametric Model}\label{sec:parametric_model}

\emph{Parametric Statistics}

A \emph{Parametric Model} or \emph{Finite-dimensional Model} assumes that Sample
Data (\S\ref{sec:sample}) comes from a Population that follows a Probability
Distribution based on a fixed Finite Set of \emph{Statistical Parameters}
(Population Parameters \S\ref{sec:population_parameter}).

A Parametric Model is defined by a collection of Probability Distributions,
$\mathfrak{F} = \{ F_\theta \ |\ \theta \in \Theta \}$, Indexed by a Finite Set
$\Theta$ called the \emph{Parameter Space}. For a Parametric Model with
Real-valued Parameters, $\Theta \subseteq \reals^k$ for some Positive Integer
$k$.

A Parametric Model consisting of Absolutely Continuous Distributions
can be specified in terms of corresponding Probability Density Functions:
\[
  \mathfrak{F} = \{ f(x; \theta) \ |\ \theta \in \Theta \}
\]

\emph{example}:
\begin{itemize}
  \item the Family of Normal Distributions (\S\ref{sec:normal_distribution}) are
    Parameterized by the Mean and Standard Deviation:
    \[
      \mathfrak{F} = \Big\{
        f(x; \mu, \sigma) =
          \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
        \ \Big|\ \mu \in \reals, \sigma > 0
      \Big\}
    \]
    where $f(x; \mu, \sigma)$ is the PDF of each Normal Distribution
    %FIXME: the above example is from wasserman04, 6.2; the pdf given differs
    % from that on wikipedia for a normal distribution
\end{itemize}

Parameter Estimation:
\begin{itemize}
  \item Method of Moments
  \item Maximum Likelihood Estimation (MLE \S\ref{sec:mle})
  \item ...
\end{itemize}
(TODO: xrefs)

``Parameters of Interest'', ``Nuisance Parameters''

\emph{Estimating Parameters in Chaotic Systems} -
\url{http://idontgetoutmuch.org/estimating-chaotic.htm} \fist Chaotic Systems
(\S\ref{sec:chaos_theory})



\paragraph{Exponential Family}\label{sec:exponential_family}\hfill

has PDFs of the form:
\[
  f(x; \theta) = h(x) e^{\eta(\theta)T(x) - B(\theta)}
\]
where $T$ is called the \emph{Natural Sufficient Statistic}
(\S\ref{sec:sufficient_statistic}) and $\eta$ is called the \emph{Natural
  Parameter}

includes:
\begin{itemize}
  \item Normal Distribution
  \item Exponential Distribution
  \item Gamma Distribution
  \item Wishart Distribution
  \item Chi-squared Distribution
  \item Beta Distribution
  \item Dirichlet Distribution
  \item Bernoulli Distribution
  \item Poisson Distribution
  \item Categorical Distribution
  \item Geometric Distribution
\end{itemize}
(TODO: xrefs)

when Observations come from an Exponential Family, under mild conditions the
Least-squares Estimates (\S\ref{sec:least_squares}) and Maximum-Likelihood
Estimates (\S\ref{sec:mle}) are identical



\subparagraph{Natural Exponential Family}
\label{sec:natural_exponential_family}\hfill

every Distribution with a Moment-generating Function
(\S\ref{sec:moment_generating_function}) is a member of a Natural
Exponential Family

Generalized Linear Models (\S\ref{sec:glm})



\subparagraph{Exponential Dispersion Model}
\label{sec:exponential_dispersion}\hfill

generalization of Natural Exponential Family

includes:
\begin{itemize}
  \item Tweedie Distribution (\S\ref{sec:tweedie_distribution})
\end{itemize}

Generalized Linear Models (\S\ref{sec:glm})



\paragraph{Scale Parameter}\label{sec:scale_parameter}\hfill

Parameter determining the Dispersion (\S\ref{sec:dispersion}) of a Parametric
Family



\paragraph{Fixed Effects Model}\label{sec:fixed_effect}\hfill

\paragraph{Random Effects Model}\label{sec:random_effect}\hfill

\paragraph{Mixed Model}\label{sec:mixed_model}\hfill

both Fixed Effects and Random Effects

useful in settings where repeated Measurements (Observations
\S\ref{sec:observation}) are made ont he same Statistical Units
(\S\ref{sec:statistical_units}), i.e. a ``Longitudinal Study'', or where
Measurements are made on \emph{clusters} of related Statistical Units

cf. ANOVA (Variance Analysis \S\ref{sec:variance_analysis})

BLUP (\S\ref{sec:blup})



\subsubsection{Non-parametric Model}\label{sec:nonparametric_model}

a Model that cannot be Parameterized by a Finite Parameter Set

e.g. the Model of \emph{all} Cumulative Distribution Functions (CDFs
\S\ref{sec:cdf}) is Non-parametric

Parameter Set (or \emph{Feature Set} in Machine Learning) is not fixed, i.e. it
may increase or decrease as new relevant information is collected

Descriptive Statistics (\S\ref{sec:descriptive_statistics}) are often
Non-parametric

\fist Non-parametric Inference: Statistical Functionals
(\S\ref{sec:statistical_functional}), Resampling Methods
(\S\ref{sec:resampling}), Non-parametric Regression
(\S\ref{sec:nonparametric_regression})

\emph{Stein's Paradox} -- when three or more Parameters are Estimated
simultaneously, there exist combined Estimators more accurate on average (having
lower Expected MSE) than any method handling the Parameters Separately



\paragraph{Order Statistic}\label{sec:order_statistic}

\paragraph{Rank Statistic}\label{sec:rank_statistic}



\subsubsection{Semi-parametric Model}\label{sec:semiparametric_model}

\subsubsection{Semi-nonparametric Model}\label{sec:seminonparametric_model}

\subsubsection{Discrete Choice Model}\label{sec:discrete_choice_model}

\paragraph{Binary Choice Model}\label{sec:binary_choice}\hfill

essentially the same as Binomial Regression
(\S\ref{sec:binomial_regression}) Models



\subsubsection{Logistic Model}\label{sec:discrete_uniform_law}

or \emph{Logit Model}

Non-linear Model using a Logistic Function (\S\ref{sec:logistic_function}) to
Model a Binary Dependent Variable

Logit (\S\ref{sec:logit}) -- inverse of Logistic Function

Logistic Regression (\S\ref{sec:logistic_regression})



\subsubsection{Graphical Model}\label{sec:graphical_model}

(Whittaker 1990 - \emph{Graphical Models in Applied Multivariate Statistics}

\fist \emph{Log-linear Model} (Poisson Regression \S\ref{sec:log_linear}) --
Fitting a Graphical Model to Discrete Data \fist Pairwise Markov Graph
(Undirected Graph \S\ref{sec:pairwise_markov})



\paragraph{Markov Blanket}\label{sec:markov_blanket}\hfill

\paragraph{Bayes Network}\label{sec:bayes_network}\hfill

or \emph{Probabilistic Directed Acyclic Graphical Model}

DAG (\S\ref{sec:dag}) -- Dependency structure

representation of Probability Distributions based on \emph{Causal Dependencies}
(\S\ref{sec:causal_graph})

\emph{Causality} (Pearl 2009) -- counterfactual reasoning

\url{https://golem.ph.utexas.edu/category/2018/07/bayesian_networks.html}



\subparagraph{Markov Condition}\label{sec:markov_condition}\hfill

every Node is Conditionally Independent (\S\ref{sec:conditional_independence})
of its Non-descendents, given its Parents

\emph{Causal Markov Condition}
--
Causal Graphs (\S\ref{sec:causal_graph})



\subparagraph{Directional Separation}\label{sec:directional_separation}\hfill

Directed Separation or $d$-separation



\subparagraph{Multilevel Model}\label{sec:multilevel_model}\hfill

or \emph{Hierarchical Linear Models}

Gibbs Sampling (\S\ref{sec:mcmc})



\subparagraph{Random Tree}\label{sec:random_tree}\hfill



\subsubsection{Latent Variable Model}\label{sec:latent_variable_model}

\emph{Observable Variable} (\emph{Manifest Variable})

\emph{Latent Variable} (\emph{Hidden Variable})



\subsubsection{Discrete Uniform Law}\label{sec:discrete_uniform_law}

MIT 6.041SC Lec. 4 - \url{https://www.youtube.com/watch?v=6oV3pKLgW2I}

every possible Outcome has the same Probability of Occurring

Sample Space $\Omega$

the Probability of an Event $A$:
\[
  P(A) = \frac{|A|}{|\Omega|}
\]

for $|\Omega| = N$, every Element of $\Omega$ has Probability $\frac{1}{N}$

for a Subset $A$ with Cardinality $|A| = n$:
\[
  P(A) = n \frac{1}{N}
\]


Basic Counting Principles

for a Set with Cardinality $n$:
\begin{itemize}
  \item $n^\ell$ -- Possible Sequences of Length $\ell$ (with repetitions)
  \item $2^n$ -- Possible Subsets
  \item $\binom{n}{k}$ -- Possible Subsets of $k$ Elements
  \item $n!$ -- Possible Permutations (Orderings with no repetitions)
  \item $\frac{n!}{(n-k)!}$ -- Possible Permutations of $k$ Elements
  \item $n^2$ -- Possible Ordered Pairs
  \item $\frac{n(n-1)}{2}$ -- Possible Unique Pairings (Handshake problem)
\end{itemize}


Binomial Probabilities \fist Binomial Distribution
(\S\ref{sec:binomial_distribution}) -- Probability of getting exactly $k$
``successes'' in $n$ Trials where the Probability of ``success'' is $p$:
\[
  P(k,n,p) = \binom{n}{k}p^k(1-p)^{n-k}
\]
(FIXME: clarify)



\subsubsection{Continuous Uniform Law}\label{sec:continuous_uniform_law}

\subsubsection{Variational Bayesian Method}
\label{sec:variational_bayesian_method}

Free Energy Principle -- implicit Minimization of Variational Free Energy;
Active Inference (Friston)



\subsubsection{Model Selection}\label{sec:model_selection}

\paragraph{Features Selection}\label{sec:feature_selection}\hfill

\paragraph{Optimality Criterion}\label{sec:optimality_criterion}\hfill

\fist Decision Rules (Decision Theory \S\ref{sec:decision_rule}): makes a
Choice using an Optimality Critereon



\paragraph{Akaike Information Criterion (AIC)}\label{sec:aic}\hfill

Likelihood minus number of Parameters

Mallows's $C_p$

\fist Information Theory (Part \ref{part:information_theory})



\paragraph{Bayesian Information Criterion (BIC)}\label{sec:bic}\hfill

Likelihood minus number of Parameters divided by two times the Log of Sample
Size



\paragraph{WAIC}\label{sec:waic}\hfill



% ------------------------------------------------------------------------------
\subsection{Estimation Theory}\label{sec:estimation_theory}
% ------------------------------------------------------------------------------

deals with ``\emph{Estimating}'' the values of Statistical Parameters
(\S\ref{sec:population_parameter}) based on data that has a ``\emph{random
  component}'' (FIXME: clarify)

an \emph{Estimator} (\S\ref{sec:estimator}) attempts to approximate unknown
Statistical Parameters using ``measured data''

\fist cf. Decision Theory (\S\ref{sec:decision_theory}) -- choosing Estimators

\fist \emph{Supervised Learning}:
\begin{itemize}
  \item \emph{Classification} (\S\ref{sec:classification})
  \item \emph{Regression} (\S\ref{sec:regression_analysis}) is the Estimation of
    Dependencies (\S\ref{sec:dependency}) in Multivariate Data
    (\S\ref{sec:random_vector}), i.e. the Estimation of the \emph{Regression
      Function} (\S\ref{sec:regression_function}); commonly this is the Estimate
    of the Conditional Expectation (\S\ref{sec:conditional_expectation}) of a
    Dependent Variable given an Independent Variable
\end{itemize}

approaches:
\begin{itemize}
  \item \emph{Probabilistic} -- assume the Sample Data is Random with a
    Probability Distribution (\S\ref{sec:probability_distribution}) dependent on
    the Statistical Parameters of interest
  \item \emph{Set-membership} (\S\ref{sec:set_estimation}) -- assumes the
    Sample Data belongs to a Set that depends on the Parameters
\end{itemize}

\fist cf. Approximation Theory (\S\ref{sec:approximation_theory})

Sample Distribution (\S\ref{sec:sample_distribution})

Confidence Interval (\S\ref{sec:confidence_interval}), Margin of Error
(\S\ref{sec:margin_of_error})

Estimating:
\begin{itemize}
  \item Population Proportion (\S\ref{sec:proportion}) -- $z$-score (Standard
    Score \S\ref{sec:standard_score})
  \item Population Mean (\S\ref{sec:expected_value})
  \item ...
\end{itemize}

\emph{Estimating Parameters in Chaotic Systems} -
\url{http://idontgetoutmuch.org/estimating-chaotic.htm} \fist Chaotic Systems
(\S\ref{sec:chaos_theory})

\asterism

\emph{Optimizer's Curse} -
\url{https://confusopoly.com/2019/04/03/the-optimizers-curse-wrong-way-reductions/}
-- TODO



\subsubsection{Estimator}\label{sec:estimator}

\fist Decision Rule (Decision Theory \S\ref{sec:decision_rule})

(wiki):

an \emph{Estimator} attempts to approximate unknown Statistical Parameters
(\S\ref{sec:statistical_paramaeter}) using ``measured data''

when the Data consists of ``multiple variables'' (cf. Multivariate Statistics
\S\ref{sec:multivariate_statistics}), Estimating the ``relation'' between them
is \emph{Regression Analysis} (\S\ref{sec:regression_analysis})
--FIXME: clarify

\emph{Rao-Blackwell Theorem} -- an Estimator that does not depend on a
Sufficient Statistic (\S\ref{sec:sufficient_statistic}) is sub-optimal



\paragraph{Delta Method}\label{sec:delta_method}\hfill

(wiki): concerns the approximate Probability Distribution for a Function of an
Asymptotically Normal Estimator (e.g. MLE \S\ref{sec:mle}) from knowledge of the
limiting \emph{Variance} of the Estimator

\fist cf. Propagation of Error (\S\ref{sec:error_propagation})

\emph{Multivariate Delta Method}



\paragraph{Point Estimator}\label{sec:point_estimator}\hfill

\emph{Point Estimation} -- use of Sample Data to calculate a single value
(\emph{Point Estimate} or \emph{Statistic} \S\ref{sec:statistic}) to serve as an
Estimate of an unknown Population Parameter (\S\ref{sec:population_parameter})

\[
  \hat{\theta}_n = g(X_1, \ldots, X_n)
\]
where $X_1, \ldots, X_n$ are IID (\S\ref{sec:iid})

the Distribution of $\hat{\theta}_n$ is called a \emph{Sampling Distribution}
(\S\ref{sec:sampling_distribution}) and the Standard Deviation
(\S\ref{sec:standard_deviation}) of $\hat{\theta}_n$ is called the
\emph{Standard Error} (\S\ref{sec:standard_error})

\begin{itemize}
  \item Minimum-Variance Mean-Unbiased Estimator (MVUE)
  \item Best Linear Unbiased Estimator (BLUE)
  \item Minimum Mean Squared Error (MMSE)
  \item Median-Unbiased Estimator
  \item Maximum Likelihood Estimator (MLE \S\ref{sec:mle})
  \item Method of Moments (\S\ref{sec:moments_method})
\end{itemize}

Bayesian Point Estimation:
\begin{itemize}
  \item Posterior Mean
  \item Posterior Median
  \item Maximum A Posteriori (MAP)
\end{itemize}

(TODO: xrefs)



\subparagraph{Sample Mean}\label{sec:sample_mean}

Estimates the Population Mean (Expectation \S\ref{sec:expected_value})

for Random Variables (\S\ref{sec:random_variable}) $X_1, \ldots, X_n$:
\[
  \overline{X}_n = \frac{1}{n}\sum_i X_i
\]

\emph{Law of Large Numbers} (\S\ref{sec:large_numbers}): the Sample Mean
$\overline{X}_n = \frac{1}{n}\sum_i X_i$ \emph{Converges in Probability}
(\S\ref{sec:stochastic_convergence}) to the Expectation
(\S\ref{sec:expected_value}) $\mu = E(X_i)$ as $n \rightarrow \infty$, i.e.
$\overline{X}_n$ is close to $\mu$ with high Probability

\emph{Central Limit Theorem} (\S\ref{sec:central_limit}):
$\sqrt{n}(\overline{X}_n - \mu)$ \emph{Converges in Distribution} to a Normal
Distribution (\S\ref{sec:normal_distribution}) as $n \rightarrow \infty$, i.e.
the Sample Mean has approximately a Normal Distribution for large $n$

the \emph{Grand Mean} is the Mean of multiple Sample Means



\subparagraph{Sample Variance}\label{sec:sample_variance}\hfill

Estimates the Population Variance

$s^2_{n-1}$ -- Unbiased Sample Variance



\subparagraph{Sample Covariance}\label{sec:sample_covariance}\hfill

Estimates the Population Covariance



\subparagraph{Sample Standard Deviation}
\label{sec:sample_standard_deviation}\hfill

$\sqrt{s^2_{n-1}}$ -- Biased

\fist Root-Mean-Square Deviation (RMSD \S\ref{sec:rmsd}) -- Sample Standard
Deviation of Regression Residuals



\subparagraph{Sample Bias}\label{sec:sample_bias}\hfill

\subparagraph{Maximum Likelihood Estimation}\label{sec:mle}\hfill

method of Estimating Population Parameters (\S\ref{sec:population_parameter})

$\hat{\theta}$ -- the value of $\theta$ that maximizes the Likilihood
(\S\ref{sec:likelihood}) $\mathcal{L}(\theta)$

under \emph{Regularity Conditions} (essentially Smoothness Conditions on
$f(x; \theta)$), MLE is Consistent, Equivariant, Asymptotically Normal, and
Asymptotically Optimal (or ``Efficient'' \S\ref{sec:efficiency})

\fist Delta Method (\S\ref{sec:delta_method})

cf. Backpropagation (\S\ref{sec:backpropagation}): the process of ``Training'' a
Regression Model (\S\ref{sec:regression_analysis})

when Observations come from an Exponential Family
(\S\ref{sec:exponential_family}), under mild conditions the Least-squares
Estimates (\S\ref{sec:least_squares}) and Maximum-Likelihood Estimates are
identical

whereas Least-squares is used to measure Fit of Linear Regression, MLE is used
to measure Fit in Logistic Regression (\S\ref{sec:logistic_regression}) \fist
Iteratively Re-weighted Least Squares (IRLS \S\ref{sec:irls})

the MLE Approximates (\S\ref{sec:approximation_theory}) the Bayes Estimator
(\S\ref{sec:bayes_estimator})

for Distributions satisfying ``Regularity Conditions'', e.g. Bernoulli and
Normal Distributions, Posterior Mean (\S\ref{sec:posterior_distribution}) is
generally close to the MLE

for Parametric Models satisfying ``Regularity Conditions'', MLE is approximately
Minimax (\S\ref{sec:minimax})

note that MLE is \emph{not} an optimal Estimator for high-dimensional problems,
e.g. when there are as many Parameters as there are Observations

$\hat{\theta} \pm 2\hat{S_E}$ is an approximate 95\% Confidence Interval, where
$S_E$ is the Standard Error

(Wasserman04 \S9.13.4) Numerical Approximations -- Iterative Method:
\begin{itemize}
  \item Newton-Raphson (Newton's Method \S\ref{sec:newtons_method})
  \item Expectation-Maximization (EM) Algorithm
\end{itemize}
produce a Sequence of values $\theta^0, \theta^1, \ldots$ that Converge to MLE
$\hat{\theta}$;
often the Method of Moements (\S\ref{sec:moments_method}) is a good starting
value of $\theta^0$

(Wasserman04 \S13.2):
 under assumption of Normality ($Y_i | X_i \sim N(\mu_i, \sigma^2)$), the Least
 Squares Estimator (\S\ref{sec:least_squares}) is also the MLE



\subparagraph{Method of Moments}\label{sec:moments_method}\hfill

method of Estimating Population Parameters (\S\ref{sec:population_parameter})

Moment (\S\ref{sec:moment})

for $k$ unknown Parameters $\theta_1, \theta_2, \ldots, \theta_k$ builds a
System of $k$ Equations with $k$ Unknowns:
\begin{flalign*}
  & \hat{\mu_1} & = \mu_1 (\hat{\theta}_n) \\
  & \hat{\mu_2} & = \mu_2 (\hat{\theta}_n) \\
  &             & \vdots \\
  & \hat{\mu_k} & = \mu_k (\hat{\theta}_n) \\
\end{flalign*}
where $\mu_j = E_\theta(X^j) = \int x^j dF_\theta(x)$ is the $j^{th}$ Moment and
$\hat{\mu_j} = \frac{1}{n}\sum_{i=1}^n X_j^i$ is the $j^{th}$ Sample Moment, and
$\hat{\theta}_n$ is the \emph{Method of Moments Estimator}

can be used to derive Least-squares (\S\ref{sec:least_squares}) Estimator



\subparagraph{Maximum A Posteriori (MAP) Estimation}
\label{sec:map_estimator}\hfill

Bayesian Estimation

cf. Bayes Estimator (\S\ref{sec:bayes_estimator})



\paragraph{Interval Estimator}\label{sec:interval_estimator}\hfill

Confidence Intervals (Frequentist Inference \S\ref{sec:confidence_interval})

$\forall \theta \in \Theta, P_\theta(a(X) < \theta < b(X)) = 1 - \alpha$

Credible Intervals (Bayesian Inference \S\ref{sec:credible_interval})

$P(a(x) < \Theta < b(x) | X = x) = 1 - \alpha$

Prediction Interval (Regression Analysis \S\ref{sec:prediction_interval})

$\forall \theta \in \Theta, P_\theta(a(X) < Y < b(X)) = 1 - \alpha$

Likelihood Intervals (TODO)

Fiducial Intervals (TODO)

Tolerance Interval (TODO)



\paragraph{Horvitz-Thompson Estimator}\label{sec:horvitz_thompson}\hfill

method for Estimating Total and Mean of a Superpopulation in a Stratified Sample
(\S\ref{sec:stratified_sample})

cannot be derived from a Bayesian or Likelihood (\S\ref{sec:likelihood}) point
of view

Survey Analysis, Missing Data



\paragraph{Consistent Estimator}\label{sec:consistent_estimator}\hfill

or \emph{Asymptotically Consistent Estimator}

as the number of Data Points used increases, the resulting Sequence Converges in
Probability to the true value



\subsubsection{Mean Signed Deviation}\label{sec:mean_signed_deviation}

or \emph{Mean Signed Difference} or \emph{Mean Signed Error}

Average (Expected Value) of Estimation Error



\subsubsection{Mean Squared Deviation (MSD)}\label{sec:msd}

or \emph{Mean Squared Error (MSE)}

Average of the Squared Error of the Estimated value (produced by an Estimator)
from the ``true'' value; MSD is the Second Moment of the Error; for an Unbiased
Estimator the MSD is the \emph{Variance} (\S\ref{sec:variance}) of the Estimator

Expected Value of the Squared Errors

Squared Deviation (\S\ref{sec:squared_deviation})

cf. Mean Absolute Deviation (MAD \S\ref{sec:mad})

cf. Square Deviation from the Mean (SDM \S\ref{sec:sdm}), Sum of Squared
Deviations (\S\ref{sec:sum_squared_deviation})

\fist Decision Theory (\S\ref{sec:decision_theory}): when Loss Function
(\S\ref{sec:objective_function}) is Squared Error, the Risk (Average Loss
\S\ref{sec:risk}) is the MSE



\paragraph{Root-Mean-Square Deviation (RMSD)}\label{sec:rmsd}\hfill

or RMSE

Square Root of the MSD (cf. Standard Deviation \S\ref{sec:standard_deviation})

Sample Standard Deviation (\S\ref{sec:standard_deviation}) of Residuals

measure of Accuracy (\S\ref{sec:accuracy})



\subsubsection{Residual}\label{sec:residual}

or \emph{Fitting Deviation}

Deviation (Signed Difference \S\ref{sec:deviation}) of an Observed Value
(\S\ref{sec:observation}) from an Estimate of the ``true'' value

cf. Error (\S\ref{sec:error}), Sum of Squared Residuals (SSR \S\ref{sec:ssr})

\fist Regression Residual (\S\ref{sec:regression_residual})

\emph{Residual Diagnostics} is a means of \emph{Model Validation}
(\S\ref{sec:model_validation}) based on the Sample Data (\S\ref{sec:sample})
that was used to construct a Statistical Model (\S\ref{sec:statistical_model}),
consisting of analyzing whether Residuals of a constructed Statistical Model
(\S\ref{sec:statistical_model}) are \emph{Random}
(\S\ref{sec:statistical_randomness}), another method being analyzing how well
the Model Predictions (\S\ref{sec:prediction}) \emph{Fit}
(\S\ref{sec:model_fit}) the original Data

$y - \hat{y}$

(wiki):

example for Sample (\S\ref{sec:sample}) of IID Normally Distributed Random
Variables, $X_1, \ldots, X_n \sim N(\mu, \sigma^2)$, the Sample Mean
(\S\ref{sec:sample_mean}):
\[
  \overline{X} = \frac{X_1 + \cdots + X_n}{n}
\]
is a Random Variable with Normal Distribution:
\[
  \overline{X} = N(\mu, \frac{\sigma^2}{n})
\]
and the \emph{Statistical Errors} (\S\ref{sec:error}) are:
\[
  e_i = X_i - \mu
\]
and the \emph{Residuals} are:
\[
  r_i = X_i - \overline{X}
\]



\subsubsection{Bias}\label{sec:bias}

cf. \emph{Systematic Error} (Statistical Bias \S\ref{sec:systematic_error})

\emph{Underfitting} (Multiple Regression \S\ref{sec:multiple_regression}) -- too
few Covariates, high Bias

Boosting (\S\ref{sec:boosting}) -- Bias reduction



\paragraph{Unbiased Estimate}\label{sec:unbiased_estimate}\hfill

\paragraph{Efficient Estimate}\label{sec:efficient_estimate}\hfill

Unbiased Estimator with Smallest Variance



\subsubsection{Standard Error}\label{sec:standard_error}

the \emph{Standard Error} $S_E$ of a Statistic (Estimate of a Parameter) is the
Standard Deviation (\S\ref{sec:standard_deviation}) of its Sampling Distribution
(\S\ref{sec:sampling_distribution})

cf. Standard Score (\S\ref{sec:standard_score})

the Standard Error equals the Standard Deviation divided by the square root of
the Sample Size, i.e. the Standard Error of the Mean is a measure of
``Dispersion'' of Sample Means around the Population Mean

\fist Resampling (\S\ref{sec:resampling})

\fist cf. \emph{Observational Error} (Measurement Error
\S\ref{sec:observational_error}), \emph{Statistical Error} (\S\ref{sec:error})



\paragraph{Margin of Error}\label{sec:margin_of_error}\hfill

\fist Confidence Interval (\S\ref{sec:confidence_interval})



\subsubsection{Efficiency}\label{sec:efficiency}

\paragraph{Asymptotic Relative Efficiency (ARE)}\label{sec:are}\hfill



\subsubsection{Benchmarking}\label{sec:benchmarking}

or \emph{Post-stratification} (cf. Stratified Sampling
\S\ref{sec:stratified_sample})

(wiki): use of ``auxiliary information'' to adjust Sampling Weights
(\S\ref{sec:weighted_mean}) in an Estimation process



\subsubsection{Empirical Distribution Function}
\label{sec:empirical_distribution}

an Unbiased Estimator for the CDF (\S\ref{sec:cdf}) associated with the
Empirical Measure (\S\ref{sec:empirical_measure}) of a Sample
(\S\ref{sec:sample})

note that Estimating Non-parametric Density or Regression Functions requires
making Smoothness assumptions, see Nonparametric Regression
(\S\ref{sec:nonparametric_regression})

\fist cf. Empirical Processes (\S\ref{sec:empirical_process})

(Wasserman04 \S7.1)

for $X_1, \ldots, X_n \sim F$ an IID Sample (Random Sample \S\ref{sec:iid})
where $F$ is a CDF on the Real Line, the \emph{Empirical Distribution Function},
$\hat{F}_n$, is the Discrete CDF with Mass assigning $1/n$ at each Data Point
$X_i$:
\[
  \hat{F}_n(x) = \frac{\sum_{i=1}^n I(X_i \leq x)}{n}
\]
where:
\[
  I(X_i \leq x) = \begin{cases}
    1 & \text{if}\ X_i \leq x \\
    0 & \text{if}\ X_i > x \\
  \end{cases}
\]

\textbf{Thm.} \emph{
  At any fixed value of $x$:
  \begin{align*}
    E(\hat{F}_n(x)) & = F(x)                     \\
    V(\hat{F}_n(x)) & = \frac{F(x)(1 - F(x))}{n} \\
    MSE & = \frac{F(x)(1-F(x))}{n} \rightarrow 0 \\
    \hat{F}_n(x) & \xrightarrow{P} F(x)          \\
  \end{align*}
}

\emph{Glivenko-Cantelli Theorem}

\emph{Dvoretsky-Kiefer-Wolfowitz (DKW) Inequality} -- can be used to construct a
Non-parametric $1-\alpha$ Confidence Band (\S\ref{sec:confidence_band}) for $F$
(TODO)



\paragraph{Plug-in Principle}\label{sec:plugin_principle}\hfill

(wiki):

method of Estimation of Statistical Functionals (Functions of the CDF $F$) of a
Population Distribution by evaluating the same Functionals at the Empirical
Distribution based on a Sample

(Wasserman04 \S7.2)

the \emph{Plug-in Estimator} for a Statistical Functional
(\S\ref{sec:statistical_functional}) $\theta = T(F)$ is:
\[
  \hat{\theta} = T(\hat{F}_n)
\]

the Plug-in Estimator for a Linear Functional (\S\ref{sec:linear_functional}):
\[
  T(\hat{F}_n) = \frac{1}{n}\sum_{i=1}^n r(X_i)
\]

Sample Correlation

Sample Quantile



\subsubsection{Density Estimation}\label{sec:density_estimation}

a form of Unsupervised Learning (cf. Cluster Analysis
\S\ref{sec:cluster_analysis})

(Wasserman04, Ch.20)

compared to Non-parametric Estimation of CDFs (via Empirical Distribution
Functions \S\ref{sec:empirical_distribution}), Estimating Non-parametric Density
or Regression Functions requires making Smoothness assumptions

cf. Non-parametric Regression (\S\ref{sec:nonparametric_regression})

Smoothing (Curve Estimation \S\ref{sec:curve_estimation})

more Smoothing leads to larger Bias, less Smoothing leads to higher Variance;
Optimal Smoothing leads to minimized Risk (Expected Loss \S\ref{sec:loss})

$Risk = Bias^2 + Variance$

Cross-validation Estimator (\S\ref{sec:cross_validation}) of Risk

Confidence Band (\S\ref{sec:confidence_band})

\emph{Curse of Dimensionality} -- Risk increases quickly with Dimension

(Wasserman04, Ch.21)

Orthogonal Function (\S\ref{sec:orthogonal_function}) Density Estimation

Haar Basis, Haar Wavelet (\S\ref{sec:haar_wavelet}) Density
Estimation



\paragraph{Mean Integrated Squared Error (MISE)}\label{sec:mise}\hfill

Loss Function: \emph{Integrated Squared Error (ISE)}

$L^2$ Risk Function (\S\ref{sec:risk_function})



\paragraph{Histogram}\label{sec:histogram}\hfill

\emph{Histogram Estimator}

converges at rate $n^{-2/3}$;

Frequency Histogram

Relative Frequency Histogram (Percentages)

Equilibria of Markov Processes (\S\ref{sec:markov_process}) -- a Markov Process
is said to enter an ``Equilibrium'' if the Histogram of states Converges over
time



\paragraph{Kernel Density Estimation (KDE)}\label{sec:kde}\hfill

cf. Kernel Regression (\S\ref{sec:kernel_regression})

\emph{Kernel Function}

\emph{Bandwidth}

converges at a rate $n^{-4/5}$;
under weak assumptions there does not exist a Non-parametric Estimator that
converges faster than $n^{-4/5}$

\emph{Stone's Theorem}



\subsubsection{Resampling}\label{sec:resampling}

methods of Estimating the precision of Sample Statistics (\S\ref{sec:statistic})

\fist Standard Error (\S\ref{sec:standard_error})

Non-parametric Inference (\S\ref{sec:nonparametric_model}), Permutation Tests
(\S\ref{sec:permutation_test})



\paragraph{Bootstrap Method}\label{sec:bootstrap_method}\hfill

Wasserman04 Ch. 8

for a Statistic (\S\ref{sec:statistic}) $T_n(F_n)$ where
$X = X_1, \ldots, X_n \sim F_n$, two steps:
\begin{enumerate}
  \item Estimate $T_n(F_n)$ with $T_n(\hat{F}_n)$ (Plug-in Principle
    \S\ref{sec:plugin_principle})
  \item Approximate $T_n(\hat{F}_n)$ using ``\emph{Simulation}'': drawing an
    Observation from $\hat{F}_n$ is equivalent to drawing one Point at Random
    from the original Data Set $X$
\end{enumerate}

Bootstrap Normal Interval, Bootstrap Pivotal Interval, Bootstrap Percentile
Interval

Parametric Bootstrap (Wasserman04 \S9.11)



\paragraph{Jackknife Method}\label{sec:jackknife_method}\hfill



\subsubsection{Least Squares}\label{sec:least_squares}

a \emph{Least Square Estimate} is an approximate solution of an Overdetermined
System that minimizes the Sum of Squared Residuals (SSR \S\ref{sec:ssr})

$2$-norm Best Fit \fist cf. $1$-norm Best Fit (\S\ref{sec:1norm_best_fit}),
Chebyshev Approximation ($\infty$-norm Best Fit
\S\ref{sec:chebyshev_approximation})

earliest form of Regression Analysis (\S\ref{sec:regression_analysis})
-- the Sum of Squared Residuals (SSR) gives a measure of how well
an Estimated Regression Function $\hat{r}(x)$ ``Fits'' the Data, and the
Regression Parameters that minimize SSR are called \emph{Least Squares
  Estimates}

(Wasserman04, \S13.2):
 under assumption of Normality ($Y_i | X_i \sim N(\mu_i, \sigma^2)$), the Least
 Squares Estimator is also the Maximum Likelihood Estimator (MLE
 \S\ref{sec:mle})

cf. Squared Deviation from the Mean (SDM \S\ref{sec:sdm})

(wiki): can be derived as a Method of Moments Estimator
(\S\ref{sec:moments_method});
when Observations come from an Exponential Family
(\S\ref{sec:exponential_family}), under mild conditions the Least-squares
Estimates and Maximum-Likelihood Estimates are identical



\paragraph{Linear Estimator}\label{sec:linear_estimator}\hfill

%FIXME



\subsubsection{Least Absolute Deviations (LAD)}\label{sec:lad}

cf. Iteratively Re-weighted Least Squares (IRLS \S\ref{sec:irls})



\subparagraph{Best Linear Unbiased Estimator (BLUE)}\label{sec:blue}\hfill

Estimating Fixed Effects (\S\ref{sec:fixed_effect})

cf. Best Linear Unbiased Predictor (BLUP \S\ref{sec:blup})
-- Predicting Random Effects (\S\ref{sec:random_effect})

\textbf{Gauss-Markov Theorem} \emph{
  In a Linear Model (\S\ref{sec:linear_regression}) where Errors are
  Uncorrelated, have Mean Zero, and equal Variances, the Best Linear Unbiased
  Estimator of the Coefficients is given by the Ordinary Least-Squares (OLS
  \S\ref{sec:ols}) Estimator.
}



\paragraph{Linear Least Squares (LLS)}\label{sec:lls}\hfill

Linear Regression (\S\ref{sec:linear_regression})

Overdetermined Systems (\S\ref{sec:overdetermined_system}); cf. ``Least Norm''
solution for Underdetermined Systems (TODO: xref)

QR Decomposition (\S\ref{sec:qr_decomposition})

has a Closed-form solution

UC Math 352, Lecture 7. - \url{https://www.youtube.com/watch?v=ZWGIchXVbho}



\subparagraph{Ordinary Least Squares (OLS)}\label{sec:ols}\hfill

(MIT 18.086 2006, Lec.21)

as an Optimization Problem:
\begin{flalign*}
  \vec{u}^* + \mathbf{X}\vec{\beta}^* & = \vec{y} \\
  \mathbf{X}^T \vec{u}^*              & = 0 \\
\end{flalign*}
``Saddle-point System'', ``Kuhn-Tucker Equations'':
\[
  \begin{bmatrix}
    \mathbf{I}   & \mathbf{X} \\
    \mathbf{X}^T & \mathbf{0} \\
  \end{bmatrix} \begin{bmatrix}
    \vec{u}^*     \\
    \vec{\beta}^* \\
  \end{bmatrix} = \begin{bmatrix}
    \vec{y} \\
    \vec{0} \\
  \end{bmatrix}
\]

because of the Constraint $\mathbf{X}^T \vec{u}^* = 0$, multiplying the first
equation by $\mathbf{X}^T$ yields the Normal Equation
(\S\ref{sec:normal_equation}):
\[
  \mathbf{X}\vec{\beta}^* = \vec{y}
\]

alternatively, by elimination on the System Equation:
\[
  \begin{bmatrix}
    \mathbf{I} & \mathbf{X} \\
    \mathbf{0} & -\mathbf{X}^T\mathbf{X} \\
  \end{bmatrix} \begin{bmatrix}
    \vec{u}^*     \\
    \vec{\beta}^* \\
  \end{bmatrix} = \begin{bmatrix}
    \vec{y} \\
    -\mathbf{X}^T \vec{y} \\
  \end{bmatrix}
\]

\textbf{Gauss-Markov Theorem} \emph{
  In a Linear Model (\S\ref{sec:linear_regression}) where Errors are
  Uncorrelated, have Mean Zero, and equal Variances, the Best Linear Unbiased
  Estimator (BLUE \S\ref{sec:blue}) of the Coefficients is given by the Ordinary
  Least-Squares Estimator.
}



\subparagraph{Normal Equation}\label{sec:normal_equation}\hfill

UC Math 352 Lec. 7 \url{https://www.youtube.com/watch?v=ZWGIchXVbho}

$A\vec{x} = \vec{b}$

$\mathrm{min}_{\vec{x}} \|A_{\vec{x}} - \vec{b}\|$

\emph{Normal Equation}: $(A^TA)\vec{x} = A^T\vec{b}$ -- Condition Number
(\S\ref{sec:condition_number}) is $\kappa(A)^2$; see QR Factorization
(\S\ref{sec:qr_factorization}) for a better Conditioned solution

Project $\vec{b}$ onto the Column Space of $A$

\[
  \vec{x} = (A^TA)^{-1}A^T\vec{b}
\]

solve by \emph{Cholesky Factorization} (\S\ref{sec:cholesky_decomposition}) ...
TODO \url{https://www.youtube.com/watch?v=VJ-04jOfu-E}



\subparagraph{QR Factorization}\label{sec:qr_factorization}\hfill

QR Decomposition (\S\ref{sec:qr_decomposition})

UC Math 352 Lec. 7 \url{https://www.youtube.com/watch?v=ZWGIchXVbho}

better Condition Number than Normal Equations (\S\ref{sec:normal_equation})

$A\vec{x} = \vec{b}$

$A = QR$ ($Q$ is Square, Orthogonal)

Residual $\vec{r} = A\vec{x} - \vec{b}$

\begin{align*}
     \vec{r} & = QR\vec{x} - \vec{b} \\
  Q^T\vec{r} & = R\vec{x} - Q^T\vec{b} \\
\end{align*}

because Orthogonal Matrices preserve Distances and $Q$ is Orthogonal:
\[
  \|Q^T\vec{r}\|_2 = \|\vec{r}\|_2
\]
minimizing $Q^T\vec{r} = \vec{\rho}$ is equivalent to minimizing $\vec{r}$

splitting $\vec{\rho}$ into:
\begin{enumerate}
  \item $\hat{\rho}   = \hat{R}\vec{x} - \hat{Q}^T\vec{b}$
  \item $\vec{\rho}_N = -Q_N^T\vec{b}$
\end{enumerate}
$\hat{rho}$ can be made Zero by solving $\hat{R}\vec{x} - \hat{Q}^T\vec{b}$ for
$\vec{x}$, which is an Upper Triangular Matrix that can be solved efficiently:
\[
  \hat{\vec{x}} = \hat{R}^{-1}\hat{Q}^T\vec{b}
\]
and $\vec{rho}_N$ is independent of $\vec{x}$ so it is \emph{fixed}, so:
\[
  \|\vec{r}\|^2_2 = \|\hat{Q}_N^T\vec{b}\|_2^2
\]



\paragraph{Generalized Least Squares (GLS)}\label{sec:gls}\hfill

Linear Regression (\S\ref{sec:linear_regression}) technique when there is a
degree of Correlation between Residuals

\begin{itemize}
  \item Heteroscedastic (\S\ref{sec:heteroscedasticity}) Errors -- unequal
    Variances (diagonal entries of the Covariance Matrix)
    \begin{itemize}
      \item Weighted Least Squares (WLS \S\ref{sec:wls})
    \end{itemize}
  \item Correlation between Errors -- off-diagonal entries of the Covariance
    Matrix
\end{itemize}

(wiki):

$\vec{y} = \mathbf{X}\vec{\beta} + \vec{\epsilon}$

$E[\epsilon | \mathbf{X}] = 0$

$cov[\epsilon | \mathbf{X}] = \mathbf{K}$

Estimate $\vec{\beta}$ by minimizing the Squared Mahalanobis Length
(\S\ref{sec:mahalanobis_distance}) of the Residual
$\vec{y} - \mathbf{X}\hat{\beta}$:
\begin{flalign*}
  \hat{\beta}
    & = argmin_{\vec{\beta}} (\vec{y} - \mathbf{X}\vec{\beta})^T
      \mathbf{K}^{-1} (\vec{y} - \mathbf{X}\vec{\beta}) \\
    & = (\mathbf{X}^T \mathbf{K}^{-1} \mathbf{X})^{-1}
      \mathbf{X}^T \mathbf{K}^{-1} \vec{y} \\
\end{flalign*}

the GLS Estimator is Unbiased, Consistent, Efficient, and Asymptotically Normal
with $E[\hat{\beta} | \mathbf{X}] = \vec{\beta}$ and
$cov[\hat{\beta} | \mathbf{X}] = (\mathbf{X}^T \mathbf{K}^{-1} \mathbf{X})^{-1}$

GLS is equivalent to applying OLS to Linearly Transformed version of the Data

WLS is a special case where $\mathbf{K}$ is Diagonal



\subparagraph{Weighted Least Squares (WLS)}\label{sec:wls}\hfill

Variance of Errors are unequal accross Observations (\emph{Heteroscedasticity}
\S\ref{sec:heteroscedasticity})-- Error Covariance Matrix
(\S\ref{sec:covariance_matrix}) may be a Diagonal Matrix other than Identity
Matrix

(wiki):

the ``weight'' for ``unit'' $i$ is proportional to the reciprocal of the
Variance of the Response for unit $i$ (TODO: clarify)

Normal Equations:
\[
  (diag(\vec{w})\mathbf{X})^T diag(\vec{w})\mathbf{X} \hat{\beta}
    = (diag(\vec{w})\mathbf{X})^T (diag(\vec{w})\vec{y}
\]

TODO

\[
  \hat{\beta} = (\mathbf{X}^T \mathbf{W X})^{-1} \mathbf{X}^T \mathbf{W} \vec{y}
\]

\fist Iteratively Re-weighted Least Squares (IRLS \S\ref{sec:irls}) -- for
$L^p$-norm Linear Regression, IRLS at step $k+1$ involves solving WLS



\subparagraph{Feasible Generalized Least Squares (FGLS)}\label{sec:fgls}\hfill

unknown Error Covariance Matrix $\mathbf{K}$

\begin{enumerate}
  \item Estimate Model by OLS and use the Residuals to build a (Consistent)
    Estimator of the Errors Covariance Matrix $\hat{\mathbf{K}}$
  \item use $\hat{\mathbf{K}}$ to perform GLS
\end{enumerate}



\paragraph{Iteratively Re-weighted Least Squares (IRLS)}\label{sec:irls}\hfill

Iterative Method (\S\ref{sec:iterative_method})

equivalent to \emph{minimizing} the \emph{Log-likelihood}
(\S\ref{sec:log_likelihood}) of a Bernoulli Process using Newton's Method
(\S\ref{sec:newtons_method})

for $L^p$-norm Linear Regression, IRLS at step $k+1$ involves solving Weighted
Least Squares (WLS \S\ref{sec:wls})

Least Absolute Deviations (LAD \S\ref{sec:lad}) -- $L^1$-norm Linear Regression

(wiki) --
Maximum Likelihood Estimation (MLE \S\ref{sec:mle}) in Logistic Regression
(\S\ref{sec:logistic_regression}):

Parameters $\vec{\beta}^T = [\beta_0, \beta_1, \ldots]$

Independent Variables $\vec{x}_i^T = [1, x_{i1}, x_{i2}, \ldots]$

Expected Value of the Bernoulli Distribution
$\mu_{y_i | \vec{x}_i} = 1 / (1 + e^{-\vec{\beta}^T \vec{x_i}})$

Iteratively solving for the $(k+1)$th Estimate given the $k$th Estimate of
$\vec{\beta}$:
\[
  \vec{\beta}_{k+1} = (\mathbf{X}^T \mathbf{S}_k \mathbf{X})^{-1} \mathbf{X}^T
    (\mathbf{S}_k \mathbf{X} \vec{\beta}_k + \vec{y} - \vec{\mu}_k)
\]
where:
\begin{itemize}
  \item $\mathbf{S} = diag(\mu_i - \mu_i^2)$ is a
    \emph{Diagonal Weighted Matrix}
  \item $\vec{\mu} = [\mu_1, \ldots, \mu_n]$ is the Vector of Expected Values
  \item $\mathbf{X} = [\vec{1}, \vec{x}_1, \vec{x}_2, \ldots]$ is the Regressor
    (Design) Matrix
  \item $\vec{y}_i^T = [y_1, y_2, \ldots]$ is the Vector of Response Variables
\end{itemize}



\paragraph{Polynomial Least Squares}\label{sec:polynomial_least_squares}\hfill

\paragraph{Non-Linear Least Squares (NLLS)}\label{sec:nlls}\hfill

Non-linear Regression (\S\ref{sec:nonlinear_regression})

examples:
\begin{itemize}
  \item Logistic Regression (\S\ref{sec:logistic_regression})
  \item Probit Regression (\S\ref{sec:probit_regression})
  \item Threshold Regression (TODO)
  \item Smooth Regression (TODO)
  \item Box-Cox Transformed Regression (TODO)
\end{itemize}

Normal Equations:
\[
  (\mathbf{J} \mathbf{W J}) \Delta \vec{\beta} =
    \mathbf{J} \mathbf{W} \Delta \vec{y}
\]



\subparagraph{Gauss-Newton Algorithm}\label{sec:gauss_newton}\hfill

cf. Backpropagation (\S\ref{sec:backpropagation})

QR methods

Gradient methods



\subsubsection{Pooled Estimate}\label{sec:pooled_estimate}

%FIXME



\subsubsection{Set Estimation}\label{sec:set_estimation}

Set-membership approach to Estimation Theory (cf. Probabilistic approach)



\subsubsection{Importance Sampling}\label{sec:importance_sampling}

Umbrella Sampling (Physics)

\fist Independence Metropolis-Hastings (Markov Chain Monte Carlo Method
\S\ref{sec:mcmc})

(Wasserman04 \S24.3)

can be used to reduce Variance in Monte Carlo Methods (\S\ref{sec:monte_carlo})

Sampling from a known Distribution $g$:
\[
  E_g(Y) = \int \frac{h(x)f(x)}{g(x)} g(x) dx
\]
where $Y = h(X)f(X)/g(X)$

Simulating $X_1, \ldots, X_n \sim g$ Estimates $E_g(Y)$ by:
\[
  \hat{E_g(Y)} = \frac{1}{N}\sum_i Y_i
\]
Converges with appropriate choice of $g$ such that the Variance is not Infinite
(FIXME: clarify)

(Thm.) The choice of $g$ that minimizes the Variance of $\hat{E_g(Y)}$ is:
\[
  g^*(x) = \frac{|h(x)| f(x)}{\int|h(s)| f(s) ds}
\]

this may not be useful if it is not known how to sample from $f$

in practice, $g$ should be a tick-tailed Distribution similar to $f|h|$



% ------------------------------------------------------------------------------
\subsection{Hypothesis Testing}\label{sec:hypothesis_testing}
% ------------------------------------------------------------------------------

or \emph{Confirmatory Data Analysis}

\url{https://github.com/puolival/multipy} -- Python library

A \emph{Statistical Test} is a ``procedure'' with Samples as input and results
in a \emph{Hypothesis} (\S\ref{sec:hypothesis}), i.e. a Conjecture
(\S\ref{sec:conjecture}) concerning one or more Statistical Populations
(\S\ref{sec:population}).

\fist In Bayesian Inference (\S\ref{sec:bayesian_inference}), a Hypothesis is
assigned a Probability, while in Frequentist Inference, a Hypothesis is Tested
without assigning a Probability.

Partitioning the Parameter Space (\S\ref{sec:parametric_model}) $\Theta$ into
Disjoint Sets $\Theta_0$ and $\Theta_1$, the \emph{Null Hypothesis}
(\S\ref{sec:null_hypothesis}), $H_0 = \vdash \theta \in \Theta_0$, represents
any Hypothesis, and the \emph{Alternative Hypothesis}
(\S\ref{sec:alternative_hypothesis}), $H_1 = \vdash \theta \in \Theta_1$,
represents an Hypothesis that is accepted in the case that the Null Hypothesis
is Rejected

\begin{enumerate}
  \item Sufficient Evidence: Reject $H_0$ in favor of $H_1$
  \item Insufficient Evidence: fail to Reject $H_0$
\end{enumerate}

\emph{Test Statistic} (\S\ref{sec:test_statistic}) $T(x)$

\emph{One-tail (One-sided) Test}:
\[
  H_0 = \vdash \theta \leq \theta_0 \quad\quad H_1 = \vdash \theta > \theta_0
\]
or:
\[
  H_0 = \vdash \theta \geq \theta_0 \quad\quad H_1 = \vdash \theta < \theta_0
\]

\emph{Two-tail (Two-sided) Test}:
\[
  H_0 = \vdash \theta = \theta_0 \quad\quad H_1 = \vdash \theta \neq \theta_0
\]

Test on a single Mean

Test on a single Sample

\emph{Critical Region} (\S\ref{sec:critical_region}) $R = \{ x : T(x) > c \}$

Type I Error: Rejection of $H_0$ when it is True

Type II Error: Non-Rejection of $H_0$ when it is False

$\beta$: Probability of committing a Type II Error

\begin{align*}
  P(\hat{\theta} | H_0) < \alpha & \Rightarrow \text{reject } H_0 \\
  P(\hat{\theta} | H_0) \geq \alpha & \Rightarrow \text{fail to reject } H_0 \\
\end{align*}

(Wasserman04, Ch.10)

the \emph{Size} or \emph{Significance Level}
(\S\ref{sec:statistical_significance}) of a Test:
\[
  \alpha = \sup_{\theta \in \Theta_0} \beta(\theta)
\]
is the Probability of making a Type I Error

a Test has \emph{Level} $\alpha$ if its Size is less than or equal to $\alpha$

$p$-value: lowest Level of Significance at which the observed Value of
the Statistic is Significant

\emph{Power} (\S\ref{sec:statistical_power}) $1 - \beta$: Probability of
Rejecting $H_0$ given that a specific alternative is True (Probability of
\emph{not} making a Type II Error)

the \emph{Power Function} of a Test with Rejection Region $R$:
\[
  \beta(\theta) = P_\theta(X \in R)
\]

\begin{itemize}
  \item Test for Statistical Randomness (\S\ref{sec:statistical_randomness})
\end{itemize}

\emph{Neyman-Pearson Lemma} -- most Powerful Test for Simple Null Hypothesis
$H_0 = \vdash \theta = \theta_0$ and Simple Alternative Hypothesis
$H_1 = \vdash \theta = \theta_1$

\asterism

\textbf{Bayesian Testing} (\S\ref{sec:bayesian_inference})

(Wasserman04 \S11.8)

places a Prior Probability Distribution (\S\ref{sec:prior_distribution}) on
$H_0$ and on $\theta$ and then computing $P(H_0 | X^n)$; Priors cannot be
Improper; a Prior-free bound on $P(H_0|X^n = x^n)$:
\[
  \frac{\mathcal{L}(\theta_0)}{\mathcal{L}(\theta_0) + \mathcal{L}(\hat\theta)}
    \leq P(H_0|X^n = x^n) \leq 1
\]

\emph{Lindley's Paradox} (\emph{Jeffreys-Lindley Paradox})



\subsubsection{Hypothesis}\label{sec:hypothesis}

A \emph{Statistical Hypothesis} is a Conjecture (\S\ref{sec:conjecture}) or
Assertion (\S\ref{sec:assertion}) concerning one or more Populations
(\S\ref{sec:population}).

cf. Hypothesis (Antecedent \S\ref{sec:antecedent} of a Hypothetical Proposition
\S\ref{sec:proposition})



\paragraph{Null Hypothesis}\label{sec:null_hypothesis}\hfill

$H_0$



\paragraph{Alternative Hypothesis}\label{sec:alternative_hypothesis}\hfill

$H_1$



\paragraph{Simple Hypothesis}\label{sec:simple_hypothesis}\hfill

Hypothesis specifies the Population Distribution completely

$\theta = \theta_0$



\paragraph{Composite Hypothesis}\label{sec:composite_hypothesis}\hfill

$\theta < \theta_0$ or $\theta > \theta_0$



\subsubsection{Test Statistic}\label{sec:test_statistic}

Statistic (\S\ref{sec:statistic}), $T$

(Wasserman04, Ch.10)

\begin{itemize}
  \item $z$-statistic
  \item $t$-statistic
  \item $F$-test
  \item ...
\end{itemize}



\paragraph{Critical Region}\label{sec:critical_region}\hfill

or \emph{Rejection Region}

set of Values of the Test Statistic for which the Null Hypothesis is rejected

\emph{Critical Values} -- boundaries of the Critical Region

$R = \{ x : T(x) > c \}$



\subsubsection{Significance Testing}\label{sec:significance_testing}

Fisher



\paragraph{Statistical Significance}\label{sec:statistical_significance}\hfill

the \emph{Size} or \emph{Significance Level} of a Test:
\[
  \alpha = \sup_{\theta \in \Theta_0} \beta(\theta)
\]
is the Probability of making a Type I Error

a Test has \emph{Level} $\alpha$ if its Size is less than or equal to $\alpha$

increasing $\alpha$ increases Power (\S\ref{sec:statistical_power}), but
increases the Probability of a Type I Error

\fist ANalaysis Of VAriance (ANOVA \S\ref{sec:variance_analysis}) -- compare

three or more ``group means'' for Significance

Exact Tests (\S\ref{sec:exact_test})



\paragraph{$p$-value}\label{sec:p_value}\hfill

lowest Level of Significance at which the Observed value of the Statistic is
Significant:
\[
  P(\hat{\theta} | H_0)
\]

(Wasserman04 \S10.2):

the $p$-value is the Probability under the Null Hypothesis $H_0$ of Observing a
value of the Test Statistic the same as or more extreme than what was actually
Observed

\textbf{Thm.} \emph{
  If the Test Statistic has a Continuous Distribution, then under
  $H_0 = \vdash \theta = \theta_0$ the $p$-value has a $Uniform(0,1)$
  Distribution and therefore one Rejects $H_0$ when $p$-value is less than the
  Significance Level $\alpha$, and the Probability of a Type I Error is
  $\alpha$.
}



\paragraph{Statistical Power}\label{sec:statistical_power}\hfill

Probability that the Test rejects the Null Hypothesis when the Alternative
Hypothesis is True, or equivalently, the Probability of \emph{not} making a Type
II Error

increasing $\alpha$ increases Power, but increases the Probability of a Type I
Error

increasing Sample Size will also increase Power

if the underlying Data has a lower Variability or if the true Parameter is far
from $H_0$, this also increases Power



\subsubsection{Multiple Testing Problem}\label{sec:multiple_testing}

or \emph{Multiple Comparisons Problem}




\paragraph{False Discovery Rate (FDR)}\label{sec:fdr}\hfill

\subparagraph{Bonferroni Method}\label{sec:bonferroni_method}\hfill

\emph{False Discovery Rate (FDR)}



\paragraph{Bonferroni Method}\label{sec:bonferroni_method}\hfill

or \emph{Holm-Bonferroni Method}



\subsubsection{Wald Test}\label{sec:wald_test}

\subsubsection{$t$-test}\label{sec:t_test}

\emph{Student's $t$-test}

\fist $t$-statistic (\S\ref{sec:t_statistic}),
$t$-distribution (\S\ref{sec:t_distribution})

essentially equal to Wald Test for moderately large $n$

\fist cf. ANalysis Of VAriance (ANOVA \S\ref{sec:variance_analysis}) --
generalization of $t$-test to more than two groups



\subsubsection{$F$-test}\label{sec:f_test}

\fist $F$-statistic (\S\ref{sec:f_statistic}),
$F$-distribution (\S\ref{sec:f_distribution})

Linear Regression



\subsubsection{Chi-squared Test}\label{sec:chi_squared_test}

$\chi^2$ Distribution (\S\ref{sec:chi_squared})

Chi-squared Statistic -- Randomness Condition, Large Counts Condition ($>5$
expected), Independence Condition

Goodness-of-fit (\S\ref{sec:model_fit})

Test for Homogeneity, Association (or Independence)

Logistic Regression



\paragraph{Pearson's Chi-squared Test}\label{sec:pearsons_chi_squared}\hfill



\subsubsection{Exact Test}\label{sec:exact_test}

\emph{Exact Statistics} (\S\ref{sec:exact_statistics}) -- not based on Large
Sample Theory (Asymptotic Theory \S\ref{sec:asymptotic_theory})



\paragraph{Permutation Test}\label{sec:permutation_test}\hfill

or \emph{Re-randomization Test}

Significance Testing (\S\ref{sec:significance_test})

Non-parametric method for testing whether two Distributions are ``the same''

\fist cf. Resampling (\S\ref{sec:resampling})



\subsubsection{Likelihood-Ratio (LR) Test}\label{sec:lr_test}

used for comparing Fit (\S\ref{sec:model_fit}) of two Statistical Models



% ------------------------------------------------------------------------------
\subsection{Asymptotic Theory}\label{sec:asymptotic_theory}
% ------------------------------------------------------------------------------

or \emph{Large Sample Theory}

\fist cf. \emph{Exact Statistics} (\S\ref{sec:exact_statistics}) -- not based on
Large Sample Theory

\fist Asymptotic Distributions (\S\ref{sec:asymptotic_distribution})

\fist cf. Asymptotic Analysis (\S\ref{sec:asymptotic_analysis})

\fist cf. Asymptotically Consistent Estimator (\S\ref{sec:consistent_estimator})

(wiki):

framework for assessing properties of Estimators (\S\ref{sec:estimator}) and
Statistical Tests (Hypothesis Testing \S\ref{sec:hypothesis_testing}) as Sample
Size (\S\ref{sec:sample_size}) $n \rightarrow \infty$

\fist Stochastic Convergence (\S\ref{sec:stochastic_convergence}) -- Convergence
of Sequences (\S\ref{sec:convergent_sequence}) of Random Variables to Limit
Random Variables

Asymptotic Thoerems:
\begin{itemize}
  \item \emph{Law of Large Numbers} (\S\ref{sec:large_numbers}) --
    for Random Variables $X_1, \ldots, X_n$, the Sample Mean
    (\S\ref{sec:sample_mean}) $\overline{X}_n = \frac{1}{n}\sum_i X_i$ Converges
    in Probability to $\mu = E(X_i)$ as $n \rightarrow \infty$, i.e.
    $\overline{X}_n$ is close to $\mu$ with high Probability
  \item \emph{Central Limit Theorem} (\S\ref{sec:central_limit})
    for a Sequence of Random Variables $X_i, \ldots, X_n$ with Sample Mean
    $\overline{X}_n$, $\sqrt{n}(\overline{X}_n - \mu)$
    Converges in Distribution to a Normal Distribution
    (\S\ref{sec:normal_distribution}) as $n \rightarrow \infty$, i.e. the Sample
    Mean has approximately a Normal Distribution for large $n$
  \item ...
\end{itemize}



\subsubsection{Large Deviations Theory}\label{sec:large_deviations_theory}

\paragraph{Rate Function}\label{sec:rate_function}\hfill



% ------------------------------------------------------------------------------
\subsection{Exact Statistics}\label{sec:exact_statistics}
% ------------------------------------------------------------------------------

not based on Large Sample Theory (Asymptotic Theory
\S\ref{sec:asymptotic_theory})

\fist Exact Test (\S\ref{sec:exact_test})

Non-parametric



% ------------------------------------------------------------------------------
\subsection{Frequentist Inference}\label{sec:frequentist_inference}
% ------------------------------------------------------------------------------

Frequency Interpretation
(\url{https://plato.stanford.edu/entries/probability-interpret/#FreInt}) --
differs from the Classical Interpretation in counting only the \emph{actual}
Outcomes instead of the \emph{possible} Outcomes; Finite Frequentism (Venn)

$f(x; \theta)$

(Wasserman04 \S11.1)

Frequentist postulates:
\begin{enumerate}
  \item Probability refers to limiting Relative Frequencies and Probabilities
    are \emph{objective} properties of the ``real world''
  \item Parameters are fixed, unknown Constants, and no useful Probability
    statements can be made about Parameters
  \item Statistical procedures should be designed to have well-defined long-run
    Frequency properties
\end{enumerate}

cf. \emph{Bayesian Inference} (\S\ref{sec:bayesian_inference}) -- focus is on
subjective ``degree of belief''; assigns Probabilities to Parameters (they are
Random Variables)



\subsubsection{Relative Frequency}\label{sec:relative_frequency}

\emph{Empirical Probability} or \emph{Experimental Probability} or
\emph{Long-run Probability}

after conducting many Trials (\S\ref{sec:trial}) of the same Experiment
(\S\ref{sec:experiment}), the Relative Frequencies of the various Outcomes
(\S\ref{sec:outcome}) and Events (\S\ref{sec:probability_event}) can be assessed

\url{https://plato.stanford.edu/entries/probability-interpret/#FreInt}:

\emph{Hypothetical Frequentism}: extension of Relative Frequencies of an actual
Sequence of ``Trials'' to counterfactual, limiting Relative Frequencies in case
of an Infinite number of Trials

\emph{Reference Class Problem}: Relative Frequencies must be ``Relativised'' to
a ``Reference Class'' (other interpretations of Probability may have this
problem as well)--

solutions restrict to certain Sequences of Outcomes, e.g. (Infinite)
``\emph{Collectives}'' (Von Mises57)--cf. Infinite Bernoulli Sequences
(\S\ref{sec:bernoulli_sequence})--where a \emph{Place-selection} is an effective
method of selecting indices of Members of a Sequence such that the selection or
not of Index $i$ depends \emph{at most} on the first $i-1$ Outcomes
(``attributes''), with the Axioms of \emph{Convergence} (the limiting Relative
Frequency of any Outcome exists) and \emph{Randomness} (the limiting Relative
Frequency of each Outcome in a Collective $\omega$ is the same in any Infinite
Subsequence of $\omega$ determined by Place-selection; note that trivial
Sequences such as $H,H,H,\ldots$ satisfy this ``Randomness'' Axiom; cf. the
Principle of Maximum Entropy in Classical Probability), Algorithmic Randomness
(\S\ref{sec:algorithmic_randomness});
issues with limiting Relative Frequencies are that they violate Countable
Additivity and the Domain of Definition is not a Set-field or a $\sigma$-algebra
(de Finetti72)



\subsubsection{Propensity}\label{sec:propensity}

(wiki):

\emph{Chance} or \emph{Single-case Probability}

a purported ``\emph{cause}'' or explanation of an observed stable Relative
Frequency

invokes the Law of Large Numbers (\S\ref{sec:large_numbers}) to explain stable
\emph{long-run} Frequencies as a manifestation of invariant \emph{single-case}



\subsubsection{Frequency Distribution}\label{sec:frequency_distribution}

\paragraph{Contingency Table}\label{sec:contingency_table}\hfill

or \emph{Cross Tabulation} or \emph{Crosstab}

displays the Multivariate (\S\ref{sec:multivariate_statistics}) Frequency
Distribution of Variables

Two-way Tables

Chi-squared Test (\S\ref{sec:chi_squared_test}) -- Degrees of Freedom =
(rows - 1)(columns - 1)

Log-linear Model (\S\ref{sec:log_linear})



\subsubsection{Confidence Interval}\label{sec:confidence_interval}

or \emph{Confidence Set} for Parameter Spaces of Dimension $2$ or greater

(wiki):

for a Random Sample (\S\ref{sec:sample}) Vector (IID \S\ref{sec:iid}) $X$ from a
Distribution with Parameters $\theta \in \Theta$, a \emph{Confidence Interval}
for $\theta$ with \emph{Confidence Level} (or \emph{Confidence Coefficient}) $1
- \alpha$ is an Interval with Random Endpoints $(a(X), b(X))$, determined by the
Random Variables $a(X)$ and $b(Y)$ such that:
\[
  \forall \theta \in \Theta, P_\theta(a(X) < \theta < b(X)) = 1 - \alpha
\]
note that $\theta$ is a fixed ``true'' value (not a Random Variable)

\fist Standard Score (\S\ref{sec:standard_score}), Margin of Error
(\S\ref{sec:margin_of_error}), $t$-statistic (\S\ref{sec:t_statistic})

assumptions:
\begin{itemize}
  \item Sample is Random
  \item Normal Condition -- more than 10 ``Successes'' and Failures in a Sample
  \item Independence Condition -- when Sampling without replacement, the Sample
    Size $n$ should be less than 10\% of the Population size
\end{itemize}

Estimating a Population Proportion (\S\ref{sec:proportion})

Confidence Limit

Prediction Interval (\S\ref{sec:prediction_interval})

Interval Measurement (\S\ref{sec:measurement_level})

Interval Estimate (\S\ref{sec:interval_estimator})

cf. Credible Intervals (Bayesian Inference \S\ref{sec:credible_interval})

Hypothesis Testing (\S\ref{sec:hypothesis_testing})

One-tail, Two-tail



\paragraph{Confidence Band}\label{sec:confidence_band}\hfill

represents Uncertainty in a Curve Estimate (cf. Smoothing \S\ref{sec:smoothing},
Density Estimation \S\ref{sec:density_estimation}, Kernel Regression
\S\ref{sec:kernel_regression})



\paragraph{Hoeffding's Inequality}\label{sec:hoeffdings_inequality}\hfill

used the analyze the number of required Samples needed to obtain a Confidence
Interval

\fist Probability Inequalities (Classification Error
\S\ref{sec:classification_error})

\textbf{Thm.} (Hoeffding's Inequality)

\emph{
  For $Y_1, \ldots, Y_n$ Independent Observations (\S\ref{sec:observation}) such
  that $E(Y_i) = 0$ and $a_i \leq Y_i \leq b_i$, given $\epsilon > 0$, for any
  $t > 0$:
  \[
    P\Big(\sum_i Y_i \geq \epsilon\Big) \leq
      e^{-t\epsilon} \prod_i e^{t^2(b_i - a_i)^2/8}
  \]
}



% ------------------------------------------------------------------------------
\subsection{Bayesian Inference}\label{sec:bayesian_inference}
% ------------------------------------------------------------------------------

\emph{Evidential Probability} or \emph{Bayesian Probability} -- interpretation
of Probability as a ``reasonable'' \emph{Expectation}
(\S\ref{sec:expected_value}) or ``degree of belief''

$f(x | \theta)$

Conditional Probabilities (\S\ref{sec:conditional_probability}), Bayes' Rule
(\S\ref{sec:bayes_theorem})

\fist Bayesian Network (Probabilistic Directed Acyclic Graphical Model
\S\ref{sec:bayes_network})

\fist Dirichlet Processes (\S\ref{sec:dirichlet_process})

Subjective Probability %FIXME: section
(\url{https://plato.stanford.edu/entries/probability-interpret/#SubPro}),
Conditioning (\S\ref{sec:conditioning})

\fist Subjective Logic (\S\ref{sec:subjective_logic})

(wiki): every unique Bayesian ``Procedure'' (Decision Rule
\S\ref{sec:decision_rule}) is Admissable (\S\ref{sec:admissable_decision}) and
every Admissable Statistical Procedure is either a Bayesian Procedure or a Limit
of Bayesian Procedures (Wald)

\fist Aumann1987 - \emph{Correlated Equilibrium as an Expression of Bayesian
  Rationality} -- \emph{Correlated Equilibrium}
(\S\ref{sec:correlated_equilibrium}) ``does away with'' the ``dichotomy usually
perceived'' between the \emph{Bayesian} and \emph{Game-theoretic} world-views

(Wasserman04, Ch.11)

Bayesian postulates:
\begin{enumerate}
  \item Probability describes \emph{degree of belief} (not limiting Frequency),
    so Probability statements can be made about things other than Random
    Variables
  \item Probability statements can be made about Statistical Parameters
  \item Inferences about a Parameter $\theta$ are made by producing a
    Probability Distribution for $\theta$, and Inferences such as Point
    Estimates and Interval Estimates can be extracted from this Distribution
\end{enumerate}

cf. \emph{Frequentist Inference} (\S\ref{sec:frequentist_inference}) -- focus is
on ``objective'' long-run Relative Frequencies, and Statistical Parameters are
assumed to be fixed constants, not Random Variables

\fist Bayesian Methods are tied to the \emph{Likelihood Function}
(\S\ref{sec:likelihood}) which does not yield accurate Inferances in
High-dimensional and Non-parametric problems

\emph{Bayesian Method}:
\begin{enumerate}
  \item choose a \emph{Prior Distribution} (\S\ref{sec:prior_distribution}) for
    Model Parameters $\theta$ defined by PDF (\S\ref{sec:pdf}) $f(\theta)$
  \item choose a \emph{Statistical Model} (\S\ref{sec:statistical_model})
    $f(x|\theta)$ reflecting the degree of ``belief'' about $x$ given $\theta$
  \item Observe (\S\ref{sec:observation}) Data (\S\ref{sec:statistical_sample})
    $X_1, \ldots, X_n$ and \emph{update} beliefs and calculate the
    \emph{Posterior Distribution} (\S\ref{sec:posterior_distribution})
    $f(\theta | X_1, \ldots, X_n)$
\end{enumerate}

for Discrete $\theta$ and single Discrete $X$:
\[
  P(\Theta = \theta | X = x) = \frac{
    P(X = x|\Theta = \theta)P(\Theta = \theta)
  }{
    \sum_\theta P(X = x | \Theta = \theta) P(\Theta = \theta)
  }
\]
(Bayes' Theorem \S\ref{sec:bayes_theorem})

for Continuous Variables:
\[
  f(\theta | x) = \frac{
    f(x|\theta)f(\theta)
  }{
    \int f(x|\theta)f(\theta) d\theta
  }
\]

for $n$ IID Observations $X_1, \ldots, X_n$:
\[
  f(x_1, \ldots, x_n | \theta) =
    \prod_{i=1}^n f(x_i | \theta) = \mathcal{L}_n(\theta)
\]
where $\mathcal{L}_n$ is the \emph{Likelihood Function}
(\S\ref{sec:likelihood_function})

for $x^n = (x_1, \ldots, x_n)$:
\[
  f(\theta|x^n) = \frac{\mathcal{L}_n(\theta)f(\theta)}{c_n}
    \propto \mathcal{L}_n(\theta)f(\theta)
\]
where $cn = \int \mathcal{L}_n(\theta)f(\theta) d\theta$ is the
\emph{Normalizing Constant}
%FIXME: same concept as Normalizing Constant for continuous random variables ?

i.e. \emph{Posterior is Proportional-to Likelihood times Prior}:
\[
  f(\theta | x^n) \propto \mathcal{L}(\theta)f(\theta)
\]

when the Prior and Posterior Distributions are in the same family, the Prior is
said to be ``\emph{Conjugate}'' with respect to the Model

for multiple Parameters $\theta = (\theta_1, \ldots, \theta_p)$, the Posterior
Density Function $f(\theta|x^n)$ is the same as above, and the \emph{Marginal
  Posterior} for an individual Parameter $\theta_1$ is:
\[
  f(\theta_1 | x^n) =
    \int\cdots\int f(\theta_1,\ldots,\theta_p | x^n) d\theta_2 \cdots d\theta_p
\]
Integral can be approximated by ``\emph{Simulation}''
(\S\ref{sec:stochastic_simulation}), i.e. ``drawing Randomly'' from the
Posterior (Wasserman04 11.7)



\subsubsection{Prior Distribution}\label{sec:prior_distribution}

$f(\theta)$

or \emph{Prior Probability}

when the Prior and Posterior Distributions (\S\ref{sec:posterior_distribution})
are in the same family, the Prior is said to be ``\emph{Conjugate}'' with
respect to the Model

\emph{Subjectivism}: Prior should reflect ``subjective opinion'' about $\theta$
before the Data are collected

\emph{Non-informative Prior} -- alternative to Subjective Prior, e.g. Flat
Prior, Jeffrey's prior

\emph{Proper Prior}

\emph{Improper Prior} -- $f(\theta) d\theta = \infty$

\emph{Flat Prior} -- $f(\theta) \propto c$ for some Constant $c$ (also an
Improper Prior since $\int f(\theta) d\theta = \infty$); Flat Priors are not
\emph{Transformation Invariant}: the notion of a Flat Prior is not well-defined
because a Flat Prior on a Parameter does not imply a Flat Prior on a Transformed
Parameter

\emph{Jeffrey's Prior} -- uses Fisher Information (\S\ref{sec:fisher_metric});
Transformation Invariant

(wiki):

\emph{Cromwell's Rule} -- Prior Probabilities of $0$ and $1$ should only be used
for Statements that are Logically True or False, e.g. $2+2 = 4$

\emph{Bernstein-von Mises Theorem} -- Posterior Distribution for unknown
quantities in any problem is effectively Asymptotically Independent of the Prior
Distribution, assuming it obeys \emph{Cromwell's Rule}, as the Sample Data
(\S\ref{sec:statistical_sample}) grows large

the effect of the Prior diminishes as $n$ (i.e. $(X_1, \ldots, X_n)$) increases



\subsubsection{Posterior Distribution}\label{sec:posterior_distribution}

$f(\theta | x^n)$

\emph{Posterior is Proportional-to Likelihood times Prior}
(\S\ref{sec:prior_distribution}):
\[
  f(\theta | x^n) \propto \mathcal{L}(\theta)f(\theta)
\]

(Wasserman04 \S24.1):
\[
  f(\theta | X^n) = \frac{
    \mathcal{L}(\theta) f(\theta)
  }{
    \int \mathcal{L}(\theta) f(\theta) d\theta
  }
\]
where the Denominator is the \emph{Normalizing Constant}

Marginal Posterior Density -- may require computing high-dimensional Integrals

Posterior Estimates:

\emph{Posterior Mean} (Point Estimate)

\[
  \overline{\theta} = \int \theta f(\theta | X^n) d\theta
\]

for Distributions satisfying ``Regularity Conditions'', e.g. Bernoulli and
Normal Distributions, Posterior Mean is generally close to the MLE (Mean
Likelihood Estimate \S\ref{sec:mle})

Posterior Mean is Admissable (\S\ref{sec:admissable_rule}) for any Strictly
Positive Prior

\emph{Posterior Interval} (Credible Interval \S\ref{sec:credible_interval})

(Wasserman04 \S11.4) Posteriors can be Approximated using ``\emph{Simulation}''
(\S\ref{sec:stochastic_simulation})

\emph{Bernstein-von Mises Theorem} -- Posterior Distribution for unknown
quantities in any problem is effectively Asymptotically Independent of the Prior
Distribution, assuming it obeys \emph{Cromwell's Rule}, as the Sample Data
(\S\ref{sec:statistical_sample}) grows large



\subsubsection{Conditioning}\label{sec:conditioning}

Subjective Probability
(\url{https://plato.stanford.edu/entries/probability-interpret/#SubPro}),
Orthodox Bayesianism (\S\ref{sec:bayesian_inference})

\fist cf. Passive, Active Conditioning (Causal Inference
\S\ref{sec:active_conditioning})

\fist not to be confused with Condition Numbers (Numerical Analysis
\S\ref{sec:condition_number})



\subsubsection{Likelihood}\label{sec:likelihood}

(Fisher)

whereas Probability is some Area under a given PDF, the \emph{Likelihood} is the
Density of some PDF at a given Observation value, that is, the Joint Probability
Distribution of Observed Data expressed as a Function of Statistical Parameters
(FIXME: Clarify)

\fist Bayesian Methods are tied to the Likelihood Function which does not yield
accurate Inferances in High-dimensional and Non-parametric problems

\emph{Likelihood Function} $\mathcal{L} : \Theta \rightarrow [0, \infty)$ -- the
  Joint Density (\S\ref{sec:joint_probability}) of Sample Data
  (\S\ref{sec:sample}):
\[
  \mathcal{L}(\theta | x) = f_\theta(x)
\]
for the given Observation $x$ of Random Variable $X$ with an Absolutely
Continuous Probability Distribution with PDF (\S\ref{sec:pdf}) $f$ depending on
Parameters (\S\ref{sec:population_parameter}) $\theta$; for a Discrete
Distribution:
\[
  \mathcal{L}(\theta | x) = P_\theta(X = x)
\]

\emph{Likelihood Principle}

\emph{Likelihoodist Statistics} (cf. Frequentism, Bayesianism)

cf. \emph{Probability} (\S\ref{sec:probability}) -- a Probability refers to
variable Data for a fixed Hypothesis (\S\ref{sec:hypothesis_testing}), while a
Likelihood refers to variable Hypotheses for fixed Data

\emph{Maximum Likelihood Estimation} (MLE \S\ref{sec:mle}) -- $\hat{\theta}$:
the value of $\theta$ that Maximizes $\mathcal{L}(\theta)$

Likelihood Interval

Likelihood-ratio Test

\fist a Statistic $T(X^n)$ is \emph{Sufficient}
(\S\ref{sec:sufficient_statistic}) if the Likelihood Function can be computed
knowing only $T(X^n)$ (Wasserman04 \S9.13.2)



\paragraph{Log-likelihood}\label{sec:log_likelihood}\hfill

$\ell$

(wiki): viewing Data as ``evidence'', Log-likelihood is the ``weight'' of
evidence or providing ``\emph{support}'' for a particular Model; the support of
a Model given an Event is the Negative of the Surprisal (Information Content
\S\ref{sec:information_content}), i.e. the Log-probability
(\S\ref{sec:log_probability}), of the Event given the Model: a Model is
supported by an Event to the extent that the Event is ``\emph{unsurprising}''
given the Model

Iteratively Re-weighted Least Squares (\S\ref{sec:irls}) -- equivalent to
\emph{minimizing} the Log-likelihood of a Bernoulli Process
(\S\ref{sec:bernoulli_process}) using Newton's Method
(\S\ref{sec:newtons_method}); used for MLE in Logistic Regression
(\S\ref{sec:logistic_regression})

\fist Cross-entropy Error Function -- minimizing \emph{Negative Log-likelihood}
is the same as minimizing Cross Entropy (\S\ref{sec:cross_entropy})



\subparagraph{Score}\label{sec:score}\hfill

\emph{Score Function} is the Derivative of the Log-likelihood Function

\fist Fisher Information (\S\ref{sec:fisher_metric})



\subsubsection{Credible Interval}\label{sec:credible_interval}

\emph{Posterior Interval} (\S\ref{sec:posterior_distribution})

Interval Estimator (\S\ref{sec:interval_estimator})

Prediction Interval (\S\ref{sec:prediction_interval})

cf. Confidence Interval (Frequentist Inference \S\ref{sec:confidence_interval})



\subsubsection{Bayes Estimator}\label{sec:bayes_estimator}\hfill

or \emph{Bayes Action}

Estimator (or Decision Rule (\S\ref{sec:decision_rule}) that minimizes
(maximizes) Posterior Expected Value of a Loss (Utility) Function
(\emph{Posterior Expected Loss/Utility})

cf. Maximum A Priori (MAP) Estimator (\S\ref{sec:map_estimator})

the Mean Likelihood Estimate (\S\ref{sec:mle}) approximates the Bayes Estimator

Bayes Estimators with constant Risk Function (\S\ref{sec:risk_function}) are
Minimax (\S\ref{sec:minimax})



\subsubsection{Linear Quadratic Estimation (LQE)}\label{sec:lqe}

dual of Linear Quadratic Regulation (LQR \S\ref{sec:lqr})



% ------------------------------------------------------------------------------
\subsection{Predictive Inference}\label{sec:predictive_inference}
% ------------------------------------------------------------------------------

cf. ``Predictive Analytics''

\fist cf. Regression Analysis (\S\ref{sec:regression_analysis})

$\hat{y}$



\subsubsection{Predictive Model}\label{sec:predictive_model}

cf. Detection Theory (\emph{Signal Recovery}) %TODO

Cross-validation (\S\ref{sec:cross_validation})



\subsubsection{Prediction}\label{sec:prediction}

\subsubsection{Prediction Interval}\label{sec:prediction_interval}\hfill

Interval Estimate (\S\ref{sec:interval_estimator}) of where future Observations
(\S\ref{sec:observation}) will fall with a certain Probability, given what has
already been Observed

Frequentist: Confidence Interval (\S\ref{sec:confidence_interval})

Bayesian: Credible Interval (\S\ref{sec:credible_interval})

\emph{Predictive Performance} -- a means of Model Validation
(\S\ref{sec:model_validation}) which is an analysis of whether a constructed
Statistical Model (\S\ref{sec:statistical_model}) holds up when applied to new
Data (\S\ref{sec:sample})



\paragraph{Prediction Band}\label{sec:prediction_band}\hfill



\subsubsection{Predictability}\label{sec:predictability}

\fist Predictable Process (\S\ref{sec:predictable_process})



\subsubsection{Linear Predictor}\label{sec:linear_predictor}

\emph{Linear Predictor Function}

\fist Linear Regression (\S\ref{sec:linear_regression}) -- models Relationships
in Multivariate Data using Linear Predictor Functions with parameters Estimated
from the Data

\fist Generalized Linear Model (\S\ref{sec:glm}) -- Linear Predictor is one
component of a GLM along with a family of Exponential Distributions and a Link
Function

\fist Linear Classifier (\S\ref{sec:linear_classifier})



\paragraph{Best Linear Unbiased Prediction (BLUP)}\label{sec:blup}\hfill

Predicting Random Effects (\S\ref{sec:random_effect});
cf. Mixed Models (\S\ref{sec:mixed_model})

cf. Best Linear Unbiased Estimator (BLUE \S\ref{sec:blue}) -- Estimating
Fixed Effects

under ``suitable assumptions'' on the Priors, Gaussian Process Regression
(Kriging \S\ref{sec:gaussian_process_regression}) gives the best BLUP of the
intermediate values



% ------------------------------------------------------------------------------
\subsection{Causal Inference}\label{sec:causal_inference}
% ------------------------------------------------------------------------------

cf. Experimental Studies

(wiki):

identification of the Cause of an ``Effect'' by establishing \emph{Covariation}
(\S\ref{sec:covariation}) of Cause and Effect, a \emph{Time-order Relation} with
the Cause preceding the Effect, and the elimination of plausible alternative
Causes

the main difference between \emph{Causal Inference} and an Inference of
\emph{Association} (Dependence \S\ref{sec:dependence}) is that the former
analyzes the ``response'' of the ``effect variable'' when the Cause is changed.

an example of ``Causal Reasoning'' (TODO: xref)

\url{http://www.inference.vc/untitled/} - \emph{ML beyond Curve Fitting: An
  Intro to Causal Inference and do-Calculus}

(Wasserman04, Ch.16)



\subsubsection{Causation}\label{sec:causation}

%FIXME: move section?

cf. Covariance (\S\ref{sec:covariance})

\fist (wiki): for Ergodic Signals with a Linear System Function, Signal
Coherence (\S\ref{sec:signal_coherence}) can be used to Estimate the Causality
between System input and output (FIXME: clarify)



\subsubsection{Causal Model}\label{sec:causal_model}

%FIXME: move section?



\paragraph{Counterfactual Model}\label{sec:counterfactual}\hfill

(Wasserman04, \S16.1)

\textbf{Binary Random Variable $X$}

Outcome Variable $Y$

introduce two new Random Variables $(C_0, C_1)$ called \emph{Potential Outcomes}
where $C_0$ is the Outcome if $X = 0$ and $C_1$ is the Outcome if $X = 1$

\emph{Consistency Relationship}:
\[
  Y = \begin{cases}
    C_0 & \text{if} X = 0 \\
    C_1 & \text{if} X = 1 \\
  \end{cases}
\]

when $X = 0$, $C_1$ is a \emph{Counterfactual}, and vice versa when $X = 1$,
$C_0$ is Counterfactual

measuring ``\emph{Causal Effect}''

\begin{itemize}
  \item \emph{Average Causal Effect}:
    \[
      \theta = E[C_1] - E[C_0]
    \]
    i.e. $\theta$ is the Mean if every Observed $X = 1$, minus the Mean if every
    Observed $X = 0$

  \item for Binary $C_0$, $C_1$, the \emph{Causal Odds Ratio}:
    \[
      \frac{
        \frac{P(C_1 = 1)}{P(C_1 = 0)}
      }{
        \frac{P(C_0 = 1)}{P(C_0 = 0)}
      }
    \]
    and \emph{Causal Relative Risk}:
    \[
      \frac{P(C_1 = 1)}{P(C_0 = 1)}
    \]
\end{itemize}

the \emph{Association}:
\[
  \alpha = E[Y | X = 1] - E[Y | X = 0]
\]

\textbf{Thm.} \emph{Association is not Causation, i.e. in general
$\theta \neq \alpha$}

this is because $(C_0, C_1)$ is not Independent of $X$

instead by using \emph{Random Assignment} (cf. Random Sampling
\S\ref{sec:random_sample}) of $X$ (FIXME: explain), $\theta = \alpha$, and any
Consistent Estimator (\S\ref{sec:consistent_estimator}) of $\alpha$ is a
Consistent Estimator of $\theta$

\emph{Conditional Causal Effect}

\textbf{Continuous $X$}

$(C_0, C_1)$ is replaced by the \emph{Counterfactual Function} $C(x)$ is the
Outcome for an Observed $x$

Consistency Relation $Y \equiv C(X)$

\emph{Causal Regression Function}:
\[
  \theta(x) = E(C(x))
\]

\emph{Association Regression Function}:
\[
  r(x) = E[Y | X = x]
\]

\textbf{Thm.} \emph{In general, $\theta(x) \neq r(x)$, but when $X$ is Randomly
  Assigned, $\theta(x) = r(x)$}


\textbf{Observational Study} -- a study in which $X$ is \emph{not} Randomly
Assigned; \emph{Confounding Variables}, \emph{Adjusted Treatment Effect}



\paragraph{Causal Graph}\label{sec:causal_graph}\hfill

or \emph{Causal Network}

\fist Bayesian Network (\S\ref{sec:bayes_network}) -- ``Dependency structure'';
Probabilistic DAG (\S\ref{sec:dag})

alternative to Counterfactuals for representing Causal Relations

finding the correct Causal Graph from Data of two Variables is impossible; for
more Variables there are Large Sample methods under certain assumptions, but
there is no way to know whether the Sample Size is large enough to be reliable

(Wasserman04, Ch.17)

Conditional Independence (\S\ref{sec:conditional_independence}) -- for Random
Variables $X$, $Y$, $Z$, given $Z$, $X$ and $Y$ are \emph{Conditionally
  Independent}, $X \coprod Y | Z$ if for all $x,y,z$:
\[
  f_{X,Y|Z}(x,y|z) = f_{X|Z}(x|z) f_{Y|Z}(y|z)
\]
i.e. when $Z$ is known, $Y$ provides no extra information about $X$;
equivalently:
\[
  f(x|y, z) = f(x|z)
\]

$X \coprod Y | Z \Rightarrow Y \coprod X | Z$

in a Probabilistic DAG, each Vertex represents a Random Variable

a DAG $\mathcal{G}$ with Vertices $V = (X_1, \ldots, X_n)$ \emph{Represents} a
Distribution $P$ for $V$ with PDF $f$ if:
\[
  f(v) = \prod_{i=1}^k f(x_i | \pi_i)
\]
where $\pi_i$ are the Parents of $X_i$; the Set of Distributions Represented by
$\mathcal{G}$ is denoted $M(\mathcal{G})$

Markov Condition (\S\ref{sec:markov_condition}) -- every Node is Conditionally
Independent of its Non-descendents, given its Parents

Directional Separation (\S\ref{sec:directional_separation})

$\mathcal{I}(\mathcal{G})$ -- Independence Statements implied by $\mathcal{G}$

two DAGs $\mathcal{G}_1$, $\mathcal{G}_2$ are Markov Equivalent if
$\mathcal{I}(\mathcal{G}_1) = \mathcal{I}(\mathcal{G}_2)$



\subparagraph{Active Conditioning}\label{sec:active_conditioning}\hfill

(Wasserman04, \S17.08)

\emph{Passive Conditioning} -- Conditioning by Observation

\emph{Active Conditioning} -- Conditioning by Intervention



\subparagraph{Structural Equation Modeling (SEM)}\label{sec:sem}\hfill

%FIXME: move section ?

Confirmatory Factor Analysis, Confirmatory Composite Analysis, Path Analysis,
Partial Least Squares Path Modeling, Latent Growth Modeling



\subparagraph{Pairwise Markov Graph}\label{sec:pairwise_markov}\hfill

(Wasserman04, \S18.2)

Undirected Graph (\S\ref{sec:undirected_graph})

encodes a Set of Pairwise Conditional Independence Relations
(\S\ref{sec:independence})

Global Markov Property



% ------------------------------------------------------------------------------
\subsection{Fiducial Inference}\label{sec:fiducial_inference}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Topological Inference}\label{sec:topological_inference}
% ------------------------------------------------------------------------------

Wasserman14 - \emph{Robust Topological Inference}

TDA (R package)



% ==============================================================================
\section{Multivariate Statistics}\label{sec:multivariate_statistics}
% ==============================================================================

\emph{simultaneous} Observation (\S\ref{sec:observation}) and Analysis of more
than one Outcome Variable (\emph{Multivariate Random Variables} or \emph{Random
  Vectors} \S\ref{sec:random_vector})

\begin{itemize}
  \item Multivariate Analysis (\S\ref{sec:multivariate_analysis})
  \item Statistical Classification (\S\ref{sec:classification})
    -- Discrete Response Variable
  \item Regression Analysis (\S\ref{sec:regression_analysis}) -- Estimating
    (\S\ref{sec:estimation_theory}) the Relation between Variables in
    Multivariate Data; note that this is different from Multivariate Analysis in
    that only the Univariate Conditional Distribution of a single Outcome
    Variable is considered; cf. Multivariate Regression
    (\S\ref{sec:multivariate_regression})
  \item Cluster Analysis (\S\ref{sec:cluster_analysis}) --
    ``Unsupervised Learning''
  \item Artificial Neural Networks (\S\ref{sec:ann}) -- extends Regression and
    Clustering to Non-linear Multivariate Models
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Multivariate Analysis}\label{sec:multivariate_analysis}
% ------------------------------------------------------------------------------

\subsubsection{Interaction}\label{sec:interaction}

\emph{Interaction Variable}

product of two or more Explanatory Variables

cf. Basis Functions (\S\ref{sec:basis_function})



\subsubsection{Ordination}\label{sec:ordination}

or \emph{Gradient Analysis}

cf. Gradient (Vector Calculus \S\ref{sec:gradient})

cf. Clustering (\S\ref{sec:cluster_analysis})



\paragraph{Principal Components Analysis}\label{sec:pca}\hfill

cf. Factor Analysis (\S\ref{sec:factor_analysis})



\paragraph{Multidimensional Scaling}\label{sec:multidimensional_scaling}\hfill

\paragraph{Correspondence Analysis}\label{sec:correspondence_analysis}\hfill

\subparagraph{Detrended Correspondence Analysis}
\label{sec:detrended_correspondence}\hfill

\subparagraph{Canonical Correspondence Analysis}
\label{sec:canonical_correspondence}\hfill



\paragraph{Bray-Curtis Ordination}\label{sec:bray_curtis_ordination}\hfill

\paragraph{Redundancy Analysis}\label{sec:redundancy_analysis}\hfill



\subsubsection{Factor Analysis}\label{sec:factor_analysis}

cf. PCA (\S\ref{sec:pca})



\subsubsection{Multivariate Analysis of Variance (MANOVA)}\label{sec:manova}

Variance Analysis (ANOVA \S\ref{sec:variance_analysis})



\subsubsection{Discriminant Analysis}\label{sec:discriminant_analysis}



% ==============================================================================
\section{Statistical Learning Theory}\label{sec:statistical_learning_theory}
% ==============================================================================

% ------------------------------------------------------------------------------
\subsection{Learning Algorithm}\label{sec:learning_algorithm}
% ------------------------------------------------------------------------------

(wiki)

Model Fitting (\S\ref{sec:model_fit}):
\begin{itemize}
  \item Parameter Estimation (\S\ref{sec:estimation_theory})
  \item Feature Selection (\S\ref{sec:feature_selection})
\end{itemize}

a Model (\S\ref{sec:statistical_model}), e.g. Naive Bayes Classifier
(\S\ref{sec:naive_bayes}), ANN (\S\ref{sec:ann}), is ``Trained'' on a Training
Dataset (\S\ref{sec:training_dataset}) using a \emph{Supervised Learning Method}
(cf. Statistical Classification \S\ref{sec:classification}):
\begin{itemize}
  \item Gradient Descent (\S\ref{sec:gradient_descent})
  \item Stochastic Gradient Descent (SGD \S\ref{sec:sgd})
  \item ...
\end{itemize}

\fist cf. Learning Process (ANNs \S\ref{sec:learning_process})



\subsubsection{Hyperparameter}\label{sec:hyperparameter}

Parameters set before Learning Algorithm begins



\subsubsection{Training Dataset}\label{sec:training_dataset}

examples used to initially \emph{Fit} the Parameters of a Statistical Model

cf. Statistical Sample (\S\ref{sec:sample}), Dataset (\S\ref{sec:dataset})



\subsubsection{Validation Dataset}\label{sec:validation_dataset}

Fitted Model is used to \emph{Predict} Responses for Observations in the
Validation Dataset

tuning Hyperparameters (\S\ref{sec:hyperparameter})



\subsubsection{Test Dataset}\label{sec:test_dataset}

used to provide an Unbiased evaluation of the final Model Fit on the Training
Dataset



% ------------------------------------------------------------------------------
\subsection{Statistical Classification}\label{sec:classification}
% ------------------------------------------------------------------------------

\emph{Supervised Learning} where the Response Variable is \emph{Discrete}; cf.
\emph{Regression} where the Response Variable is Continuous

cf. Parameter Estimation (\S\ref{sec:estimation_theory}), Feature Selection
(\S\ref{sec:feature_selectioN})

example of \emph{Pattern Recognition} (assignment of some Output Value to a
given Input Value), other examples are Regression Analysis
(\S\ref{sec:regression_analysis}) and Cluster Analysis (Unsupervised Learning
\S\ref{sec:cluster_analysis})

(wiki):

\emph{Features} (Properties of Observations \S\ref{sec:observation} or
\emph{Instances} \S\ref{sec:feature_vector}) are \emph{Explanatory Variables}
(Regressors \S\ref{sec:independent_variable}) and possible values of the
Dependent Variable (\S\ref{sec:dependent_variable}) are prediction
\emph{Categories} (or \emph{Classes}, i.e. Categorical Variables
\S\ref{sec:statistical_data_type}), sometimes called \emph{Outcomes} (cf. Trial
Outcomes \S\ref{sec:outcome})

an Algorithm (\S\ref{sec:algorithm}) that implements Classification is called a
\emph{Classifier} (or \emph{Classification Rule})

finding a Classifier is based on a \emph{Training Dataset}
(\S\ref{sec:training_dataset}) --FIXME: clarify

often done with Logistic Regression (\S\ref{sec:logistic_regression})

\emph{Categorical Cross-entropy} (\S\ref{sec:cross_entropy}) -- Loss Function
for Classification (cf. Squared Error Loss Function for Regression)

\fist VC Dimension (\S\ref{sec:vc_dimension}) -- measure of the capacity
(expressive power) of a Space of Functions that can be Learned by a
Classification Algorithm

\fist Decision Trees (Decision Theory \S\ref{sec:decision_tree}) --
``Hierarchical Axis-parallel Classifiers''; Partitioning of Covariate Space;
paths from Root to Leaf represent Classification Rules

(Wasserman04, Ch.22)



\subsubsection{Feature Vector}\label{sec:feature_vector}

Explanatory Variable (Regressor), ``Instance''



\subsubsection{Classification Model}\label{sec:classification_model}

\paragraph{Generative Model}\label{sec:generative_model}\hfill

Statistical Model of the Joint Probability Distribution
(\S\ref{sec:joint_probability}) $P(X,Y)$

Generative methods of determining Parameters for a Linear Classifier
(\S\ref{sec:linear_classifier}):
\begin{itemize}
  \item Linear Discriminant Analysis (LDA or Fisher's Linear Discriminant
    \S\ref{sec:lda})
  \item Naive Bayes Classifier (\S\ref{sec:naive_bayes})
\end{itemize}



\paragraph{Discriminative Model}\label{sec:discriminative_model}\hfill

Statistical Model of the Conditional Probability
(\S\ref{sec:conditional_probability}) $P(Y | X = x)$

Discriminative methods of determining Parameters for a Linear Classifier
(\S\ref{sec:linear_classifier}):
\begin{itemize}
  \item Logistic Regression (\S\ref{sec:logistic_regression})
  \item Perceptron (\S\ref{sec:perceptron})
  \item Support Vector Machines (\S\ref{sec:svm})
\end{itemize}



\subsubsection{Classification Error}\label{sec:classification_error}

(Wasserman04, \S22.8)

Loss Functions for Classifiers:
\begin{itemize}
  \item True Error Rate
  \item Empirical Error Rate (Training Error Rate)
\end{itemize}

note that the Training Error Rate is a bad Estimate because it is Biased
downward

Bias-Variance tradeoff

Estimating the Error Rate:

Cross-validation Estimate

Probability Inequalities -- Confidence Interval \fist Hoeffding's Inequality
(\S\ref{sec:hoeffdings_inequality}); Empirical Risk Minimization (ERM
\S\ref{sec:erm})



\subsubsection{Naive Bayes Classifier}\label{sec:naive_bayes}

Generative Model (\S\ref{sec:generative_model}) for Linear Classification
(\S\ref{sec:linear_classifier})

assumes Components of $X$ are Independent

useful when $x$ is High-dimensional and Discrete



\subsubsection{Binary Classifier}\label{sec:binary_classifier}

Linear (\S\ref{sec:linear_classifier}) Binary Classifiers:
\begin{itemize}
  \item Perceptron (\S\ref{sec:perceptron})
  \item Support Vector Machine (SVM \S\ref{sec:svm}) -- Non-probabilistic
\end{itemize}



\subsubsection{Linear Classifier}\label{sec:linear_classifier}

a \emph{Linear Predictor Function} (\S\ref{sec:linear_predictor}) assigns a
``score'' to each possible category $k$ by taking the Dot Product of the Feature
Vector with a Vector of \emph{Weights}

methods for determining Parameters of a Linear Classifier

Generative (\S\ref{sec:generative_model}) methods:
\begin{itemize}
  \item Linear Discriminant Analysis (LDA or Fisher's Linear Discriminant
    \S\ref{sec:lda})
  \item Naive Bayes Classifier (\S\ref{sec:naive_bayes})
\end{itemize}

Discriminative (\S\ref{sec:discriminative_model}) methods:
\begin{itemize}
  \item Logistic Regression (\S\ref{sec:logistic_regression})
  \item Perceptron (\S\ref{sec:perceptron}) -- also a Binary Classifier
    (\S\ref{sec:binary_classifier})
  \item Support Vector Machines (\S\ref{sec:svm})
\end{itemize}

Probit Regression (\S\ref{sec:probit_regression}) -- FIXME: Discrminative ???

``Kernalization'' (Wasserman04, \S22.10) -- a Linear Classifier in a
Higher-dimensional Space corresponds to a Non-linear Classifier in the original
space; \emph{Mercer's Theorem}



\paragraph{Linear Discriminant Analysis (LDA)}\label{sec:lda}\hfill

\emph{Fisher's Linear Discriminant}

cf. Logistic Regression (\S\ref{sec:logistic_regression}) -- in LDA, the Joint
Distribution $f(x,y = f(x|y)f(y)$ is Estimated by maximizing the Likelihood; in
Logistic Regression, only $f(y|x)$ is Estimated and the Conditional Likelihood
is maximized, neglecting the Marginal Distribution $f(x)$



\subparagraph{Discriminant Function}\label{sec:discriminant_function}\hfill



\paragraph{Support Vector Machine (SVM)}\label{sec:svm}\hfill

or \emph{Perceptron of Optimal Stability}

an extension of the Perceptron (\S\ref{sec:perceptron}) Model where the
Separating Hyperplanes are chosen to have the largest distance to the nearest
Training-data Point of any Class (\emph{Functional Margin})

Non-probabilistic Binary Linear Classifier

Discriminative Model (\S\ref{sec:discriminative_model})

Support Vectors

Maximum Margin Hyperplane

Slack Variables

Quadratic Programming (\S\ref{sec:quadratic_programming})



\paragraph{Perceptron}\label{sec:perceptron}\hfill

Discriminative Method (\S\ref{sec:discriminative_method})

Binary (\S\ref{sec:binary_classifier}) Linear Classifier
(\S\ref{sec:linear_classifier})

\fist Support Vector Machine (SVM \S\ref{sec:svm}) -- an extension of the
Perceptron (\S\ref{sec:perceptron}) Model where the Separating Hyperplanes are
chosen to have the largest distance to the nearest Training-data Point of any
Class (\emph{Functional Margin})

\fist Neural Networks (\S\ref{sec:ann}) -- a Perceptron (or \emph{Linear
  Threshold Unit}) is an \emph{Artificial Neuron}
(\S\ref{sec:artificial_neuron}) using the Unit Step Function
(\S\ref{sec:unit_step_function}) as the Activation Function

\fist Single-layer Perceptron (\S\ref{sec:single_layer_perceptron})
-- simplest Feed-forward Neural Network (\S\ref{sec:ffnn})

\emph{Delta Rule} -- special case of Backpropagation
(\S\ref{sec:backpropagation}) for training a Single-layer Neural network

\fist Threshold Logic Unit (TLU \S\ref{sec:tlu})



\subparagraph{Multiclass Perceptron}\label{sec:multiclass_perceptron}\hfill

\fist Multiclass Classification (\S\ref{sec:multiclass})



\subsubsection{Quadratic Classifier}\label{sec:quadratic_classifier}

Quadratic Disciminant Analysis (QDA)



\subsubsection{k-nearest Neighbors (KNN) Classfier}\label{sec:knn_classifier}

Non-parametric method

Instance-based Learning or Lazy Learning



\subsubsection{Multiclass Classification}\label{sec:multiclass}

or \emph{Multinomial Classification}

Multiclass Perceptron (\S\ref{sec:multiclass_perceptron})



\subsubsection{Multi-label Classification}\label{sec:multiclass}

generalization of Multiclass Classification (\S\ref{sec:multiclass}) where
Multiple ``Labels'' may be assigned to each ``Instance'' (FIXME: clarify)



\subsubsection{Ensemble Learning}\label{sec:ensemble_learning}

use of multiple Learning Algorithms to obtain better Predictive performance



\paragraph{Bayes Classifier}\label{sec:bayes_classifier}\hfill

\emph{Bayes Optimal Classifier}

\emph{Bayes Rule} (\S\ref{sec:bayes_rule})

(Wasserman04, \S22.2)

$h^*(x)$

note the Bayes Classifier is not ``Bayesian'', i.e. it can be Estimated using
either Frequentist or Bayesian methods

\textbf{Thm.} \emph{Bayes Rule is Optimal, i.e. if $h$ is any other Classifier
  then $L(h^*) \leq L(h)$ where $L$ is the True Error Rate Loss Function}

approaches:
\begin{itemize}
  \item Empirical Risk Minimization (ERM \S\ref{sec:erm})
  \item Regression
  \item Density Estimation
\end{itemize}

Regression Function $r(x)$

Bayes Classifier for $Y \in \mathcal{Y} = \{0, 1\}$:
\[
  h^*(x) = \begin{cases}
    1 & \text{if} r(x) > 0.5 \\
    0 & \text{otherwise} \\
  \end{cases}
\]



\paragraph{Bootstrap Aggregation}\label{sec:bootstrap_aggregation}\hfill

or \emph{Bagging}

Variance reduction

useful for highly Non-linear Classifiers (cf. Decision Trees
\S\ref{sec:decision_tree})



\subparagraph{Random Subspace Method}\label{sec:random_subspace_method}\hfill

\emph{Feature Bagging} or \emph{Attribute Bagging}



\paragraph{Boosting}\label{sec:boosting}\hfill

Bias (\S\ref{sec:bias}) reduction

emphasizes Mis-classifications in previous Models

AdaBoost

Gradient Boosting



\paragraph{Stacked Generalization}\label{sec:stacked_generalization}\hfill

or \emph{Stacking}



\subsubsection{Probabilistic Classification}
\label{sec:probabilistic_classification}

use of Statistical Inference (\S\ref{sec:statistical_inference})



% ------------------------------------------------------------------------------
\subsection{Regression Analysis}\label{sec:regression_analysis}
% ------------------------------------------------------------------------------

\emph{Regression} (or \emph{Curve Estimation}) is the Estimation
(\S\ref{sec:estimation_theory}) of \emph{Relations} (Dependencies
\S\ref{sec:dependence}) in Multivariate Data (\S\ref{sec:random_vector}).

Note that Regression Analysis is different from Multivariate Analysis
(\S\ref{sec:multivariate_analysis}) in that only the Univariate Conditional
Distribution of a single Outcome Variable is considered (cf. Multivariate
Regression \S\ref{sec:multivariate_regression}).

\emph{Supervised Learning} where the Response Variable is \emph{Continuous}; cf.
\emph{Classification} (\S\ref{sec:classification}) where the Response Variable
is Discrete

specifically, an Estimation of the \emph{Regression Function}

$r(x) = E(Y | X = x)$.

commonly this is an Estimate of the Conditional Expectation
(\S\ref{sec:conditional_expectation}) of a Dependent Variable for a given
Independent Variable; also the Quantile (\S\ref{sec:quantile}) or other Location
Parameter

Interaction Variables (\S\ref{sec:interaction}), Basis Functions
(\S\ref{sec:basis_function})

\fist cf. Curve Fitting (\S\ref{sec:curve_fitting}), Curve Estimation (Smoothing
\S\ref{sec:smoothing})

\emph{Regression Variable}, ``Regressor'', ``Predictor'', ``Feature'', or
``Explanatory Variable'' -- \emph{Independent Variable}
(\S\ref{sec:independent_variable}); Covariate

\emph{Response Variable}, ``Regressand'', ``Outcome'', or ``Explained Variable''
-- \emph{Dependent Variable} (\S\ref{sec:dependent_variable}); Criterion

\emph{Regression Function} -- the Function of the Independent Variables to be
Estimated (\S\ref{sec:estimation_theory}):
\[
  r(x) = E(Y | X = x) = \int y f(y|x) dy
\]
that is, the Expected Value of the Response Variable given that the Regression
Variable takes a specific value, where $r \in \mathcal{F}$ is specified by
choice of (Regression) Model Parameters (\S\ref{sec:statistical_model}) $\theta$

\fist cf. Predictive Inference (\S\ref{sec:predictive_inference}),
Prediction Interval (\S\ref{sec:prediction_interval})

Regression Analysis is also concerned with characterizing the \emph{variation}
of the Dependent Variable $X$ around the \emph{Prediction}
(\S\ref{sec:prediction}) $Y$ of the Regression Function using a Probability
Distribution

cf. ``Predictive Analytics''

example of \emph{Pattern Recognition} (assignment of some Output Value to a
given Input Value), other examples are Statistical Classification
(\S\ref{sec:classification})--when the Response Variable is
Discrete--and Cluster Analysis (\S\ref{sec:cluster_analysis})

\emph{Squared Error} (\S\ref{sec:squared_deviation}) -- Loss Function for
Regression (cf. Categorical Cross-entropy Loss Function for Classification)

cf. Numerical Analysis (\S\ref{sec:numerical_analysis}): Interpolation
(\S\ref{sec:interpolation}), Extrapolation (TODO)

\fist Artificial Neural Networks (ANNs \S\ref{sec:ann}) generalize Regression
and Clustering (\S\ref{sec:cluster_analysis}) to Non-linear Multivariate Models

\emph{Statistical Assumptions} (\S\ref{sec:statistical_assumption}):
\begin{itemize}
  \item the Sample is ``representative'' of the Population for the Inference
    Prediction
  \item the Error is a Random Variable with Mean $0$ Conditional on the
    Regressor(s)
  \item the Regressors are Measured (Observed) with no Error (cf. Measurement
    Error Models \S\ref{sec:measurement_error_model})
  \item the Regressors are Linearly Independent
  \item the Errors are Uncorrelated (\S\ref{sec:statistical_correlation})
  \item (\emph{Homoscedasticity} \S\ref{sec:homoscedasticity}) the Variance of
    the Error is Constant accross Observations (cf. Weighted Least Squares
    \S\ref{sec:wls})
\end{itemize}
at are sufficient for the Least-squares Estimator (\S\ref{sec:least_squares}) to
be Unbiased (\S\ref{sec:unbiased_estimate}), Consistent
(\S\ref{sec:consistent_estimator}), and Efficient
(\S\ref{sec:efficient_estimate}) in the Class of \emph{Linear Unbiased
  Estimators} (TODO: xref)

\asterism

(Wasserman04, Ch.13)

Estimate the Regression Function $r(x)$ from Sample Data (\S\ref{sec:sample}) of
the form:
\[
  (Y_1,X_1), \ldots, (Y_n,X_n) \sim F_{X,Y}
\]

Estimate $\hat{r}(x)$

\emph{Predicted (Fitted) Values}:
\[
  \hat{Y}_i = \hat{r}(X_i)
\]

\emph{Residuals} (\S\ref{sec:regression_residual}):
\[
  \hat{\epsilon}_i = Y_i - \hat{Y}_i
\]

the \emph{Residual Sum of Squares} (SSR \S\ref{sec:ssr}) is a measure of how
well the Estimated Regression Function ``Fit'' the Data:
\[
  \sum_{i=1}^n \hat{\epsilon}_i^2
\]
the Regression Parameters that miminize SSR are caled \emph{Least Squares
  Estimates} (\S\ref{sec:least_squares})



\subsubsection{Regression Model}\label{sec:regression_model}

a \emph{Statistical Model} (\S\ref{sec:statistical_model}) which makes some
assumption about the Relations (Dependences \S\ref{sec:dependence}) among
Multivariate Data (\S\ref{sec:random_vector})

\emph{Regression Model}:
\begin{itemize}
  \item \emph{Unknown Parameters} ($\beta$)
  \item \emph{Independent Variables} ($X$) -- ``Regression Variable'',
    ``Regressor'', ``Covariate'', ``Explanatory Variable''
  \item \emph{Dependent Variable} ($Y$) -- ``Response Variable'',
    ``Regressand'', ``Criterion'', ``Explained Variable''; variable whose values
    are to be ``explained'' in terms of the Independent Variable
\end{itemize}

the Regression Parameters that miminize Residual Sums of Squares (SSR
\S\ref{sec:ssr}) are called \emph{Least Squares Estimates}
(\S\ref{sec:least_squares})

(Wasserman04 \S13.2):
 under assumption of Normality ($Y_i | X_i \sim N(\mu_i, \sigma^2)$), the Least
 Squares Estimator is also the Maximum Likelihood Estimator (MLE
 \S\ref{sec:mle})

(Wasserman04 \S13.6)

Model Selection

\emph{Prediction Risk}, \emph{Training Error}

\emph{Mallows's $C_p$}, AIC (\S\ref{sec:aic})

Leave-one-out Cross-validation (\S\ref{sec:cross_validation}),
$k$-fold Cross-validation

Bayesian Information Criterion (BIC) %TODO: xref

Zheng-Loh Model Selection Method

Linear Regression Models (\S\ref{sec:linear_regression})

...



\paragraph{Measurement Error Model}\label{sec:measurement_error_model}\hfill

accounts for Observational (Measurement) Error (\S\ref{sec:observational_error})



\subsubsection{Regression Error}\label{sec:regression_error}

\fist cf. Statistical Error (\S\ref{sec:error})

Mean Squared Error (MSE) or Mean Squared Deviation (MSD)

Deviation from value Predicted by the ``\emph{true}'' Regression Function

$\epsilon$



\subsubsection{Regression Residual}\label{sec:regression_residual}

Deviation from value Predicted by the Estimated Regression Function

\fist cf. Residual (\S\ref{sec:residual})

$y - \hat{y}$

the Vector of Regression Residuals $\hat{e}$ can be expressed in terms of the
Influence Matrix (\S\ref{sec:influence_matrix}), $\hat{y} = \mathbf{H}\vec{y}$:
\[
  \hat{e} = \vec{y} - \hat{y} = \vec{y} - \mathbf{H}\vec{y} =
    (\mathbf{I} - \mathbf{H})\vec{y}
\]
where $(\mathbf{I} - \mathbf{H})$ is the \emph{Residual Maker Matrix}

$S$ -- Standard Deviation (\S\ref{sec:standard_deviation}) of Residuals

Residual Plot

SSE -- Sum of Squared Residuals (SSR or RSS \S\ref{sec:ssr}); for a Simple
Linear Model (\S\ref{sec:simple_linear_regression}):
\[
  \sum_n (y_i - \hat{\beta_1} x_i + \hat{\beta_0})
\]
can be re-written as:
\[
  n (\overline{y^2} - 2 \hat{\beta_1} \overline{x y}
    - 2 \hat{\beta_0} \overline{y} + \hat{\beta_1}^2 \overline{x^2}
    + 2 \hat{\beta_1} \hat{\beta_0} \overline{x} + \hat{\beta_0}^2)
\]
finding where the Partial Derivative with respect to $\hat{\beta_0}$ and
$\hat{\beta_1}$ are both Zero gives the Least-squares Estimate
(\S\ref{sec:least_squares}) of the Regression Function

solving for $\hat{\beta_1}$:
\[
  \hat{\beta_1} = \frac{
    (\overline{x})\overline{y} - \overline{xy}
  }{
    (\overline{x})^2 \overline{x^2}
  }
\]
or equivalently:
\[
  \hat{\beta_1} = \frac{
    Cov(x,y)
  }{
    Var(x)
  }
\]
and substituting to solve for $\hat{\beta_0}$:
\[
  \hat{\beta_0} = \overline{y} - \frac{
    \overline{x} Cov(x,y)
  }{
    Var(x)
  }
\]



\subsubsection{Determination Coefficient}\label{sec:determination_coefficient}

``\emph{R-squared}''

how much the variation in $y$ is ``explained'' by $x$

$R^2 = SSR/SST$

\[
  r^2 = 1 - \frac{
    ESS_{\hat{y}}
  }{
    TSS_{\overline{y}}
  }
\]

ESS -- Explained Sum of Squares (\S\ref{sec:ess})

TSS -- Total Sum of Squares (\S\ref{sec:tss})

cf. $r$ -- Correlation Coefficient (\S\ref{sec:correlation_coefficient})

measure of Goodness-of-fit (\S\ref{sec:model_fit}) in Logistic Regression
(\S\ref{sec:logistic_regression})



\subsubsection{Influence Matrix}\label{sec:influence_matrix}

or \emph{Hat Matrix} or \emph{Projection Matrix} (cf.
Linear Projection \S\ref{sec:projection})

(wiki):

relates the Vector of Observed Response Values $\vec{y}$ to the Vector of Fitted
Values $\hat{y}$:
\[
  \hat{y} = \mathbf{H}\vec{y}
\]

the Vector of Regression Residuals (\S\ref{sec:regression_residual}) $\hat{e}$
can be expressed in terms of the Influence Matrix:
\[
  \hat{e} = \vec{y} - \hat{y} = \vec{y} - \mathbf{H}\vec{y} =
    (\mathbf{I} - \mathbf{H})\vec{y}
\]
where $(\mathbf{I} - \mathbf{H})$ is the \emph{Residual Maker Matrix}

\begin{itemize}
  \item $\mathbf{H} \equiv \mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T$
    -- OLS (\S\ref{sec:ols})
  \item $\mathbf{H} \equiv \mathbf{X}
    (\mathbf{X}^T\mathbf{\Psi}^{-1}\mathbf{X})^{-1}
    \mathbf{X}^T\mathbf{\Psi}^{-1}$
    -- GLS (\S\ref{sec:gls})
\end{itemize}



\subsubsection{Non-parametric Regression}\label{sec:nonparametric_regression}

Regression Function is chosen from an Infinite-dimensional Family of Functions

\fist cf. Density Estimation (\S\ref{sec:density_estimation})

(Wasserman04, \S20.4)

(Wasserman04, Ch.21)

Orthogonal Function (\S\ref{sec:orthogonal_function}) Regression Estimator

Haar Basis, Haar Wavelet (\S\ref{sec:haar_wavelet}) Regression



\paragraph{Kernel Regression}\label{sec:kernel_regression}\hfill

cf. Kernel Density Estimation (KDE \S\ref{sec:kde})

Kernel Function

Nadaraya-Watson Kernel Estimator

Kernel Smoother

Confidence Bands (\S\ref{sec:confidence_band})



\paragraph{Additive Regression}\label{sec:additive_regression}\hfill

Additive Model (AM)

not fully Non-parametric

\emph{Backfitting} Algorithm



\subparagraph{Generalized Additive Model (GAM)}\label{sec:gam}\hfill

Generalized Linear Model (\S\ref{sec:glm}) where the Linear Predictor depends
Linearly on unknown Smooth Functions of Predictor Variables



\paragraph{k-nearest Neighbors (KNN) Regression}\label{sec:knn_regression}

Instance-based Learning or Lazy Learning



\subsubsection{Linear Regression}\label{sec:linear_regression}

\emph{Linear Regression Model}

Relationships are modeled using \emph{Linear Predictor Functions}
(\S\ref{sec:linear_predictor}) which are Linear Functions of a Set of
Coefficients and Explanatory (Independent) Variables:
\[
  Y_i = \beta_0 + \beta_1\phi_1(X_{i1}) + \cdots +
    \beta_p\phi_p(X_{ip}) + \varepsilon_i
\]
for $i \in \{1, \ldots, n\}$ where $\phi$ are Basis Functions
(\S\ref{sec:basis_function})

Assuming $\varepsilon_i | X_i \sim N(0, \sigma^2)$ is the same as Assuming
$Y_i | X_i \sim N(\mu_i, \sigma^2)$

cf. \emph{Correlation} (\S\ref{sec:statistical_correlation}) -- measure of how
close two Random Variables are to having a \emph{Linear Relationship}

\begin{itemize}
  \item Simple Linear Regression (\S\ref{sec:simple_linear_regression})
  \item Multivariate (``General'') Linear Regression
    (\S\ref{sec:multivariate_linear_regression})
  \item Generalized Linear Models (GLMs \S\ref{sec:glm})
\end{itemize}

Fit using Estimators:
\begin{itemize}
  \item Linear Least Squares (\S\ref{sec:lls}): if Errors are
    \emph{Normally Distributed}, Least Squares ($2$-norm Best Fit) should be
    used
    \begin{itemize}
      \item Ordinary Least Squares (\S\ref{sec:ols}): if Errors are
        \emph{Normally Distributed}, Least Squares ($2$-norm Best Fit) should be
        used
    \end{itemize}
  \item Generalized Least Squares (\S\ref{sec:gls}): if
    there is a degree of Correlation between Residuals (Fitting Deviations
    \S\ref{sec:residual})
  \item ...
\end{itemize}

\textbf{Gauss-Markov Theorem} \emph{
  In a Linear Model where Errors are Uncorrelated, have Mean Zero, and equal
  Variances, the Best Linear Unbiased Estimator (BLUE \S\ref{sec:blue}) of the
  Coefficients is given by the OLS Estimator.
}

OLS can be solved by:
\begin{itemize}
  \item in the case of a Simple Linear Regression Model
    (\S\ref{sec:simple_linear_regression}):
    \begin{flalign*}
      \hat{\beta_1} & = \frac{
        \overline{X} \overline{Y} - \overline{XY}
      }{
        (\overline{X})^2 - \overline{X^2}
      } \\
      \hat{\beta_0} & = \overline{Y} - \hat{\beta_1} \overline{X} \\
    \end{flalign*}
    or equivalently:
    \begin{flalign*}
      \hat{\beta_1} & = \frac{Cov(X,Y)}{Var(X)} \\
      \hat{\beta_0} & = \overline{Y} - \frac{\overline{X} Cov(X, Y)}{Var(X)} \\
    \end{flalign*}
    (\url{https://www.youtube.com/watch?v=8RSTQl0bQuw})
  \item in the general case $\vec{y} = \mathbf{X}\vec{\beta}$, solving the
    Normal Equation (\S\ref{sec:normal_equation})
    $(\mathbf{X}^T\mathbf{X})\vec{\beta} = \mathbf{X}^T\vec{\beta}$:
    \[
      \hat{\vec{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\vec{y}
    \]
    note that solution using Cholesky Factorization
    (\S\ref{sec:cholesky_decomposition}) is \emph{Ill-conditioned}
  \item the standard method uses QR-factorization (\S\ref{sec:qr_factorization})
    $\mathbf{X} = QR$ ($Q$ is Square, Orthogonal) to avoid the Ill-conditioning
    in the Normal Equation:
    \[
      \hat{\vec{\beta}} = \hat{R}^{-1}\hat{Q}^T\vec{y}
    \]
  \item Gradient Descent (\S\ref{sec:gradient_descent}) ... TODO
\end{itemize}

\fist cf. Convex Optimization (\S\ref{sec:convex_optimization}) -- for Linear
Regression, a Mean-Square Error Loss Function is always \emph{Convex} (example
\url{https://towardsdatascience.com/introduction-to-machine-learning-algorithms-linear-regression-14c4e325882a}

\fist cf. Linear Programming (\S\ref{sec:linear_programming})
-- article: \emph{Linear Programming for Linear Regression};
\url{https://lazyprogrammer.me/linear-programming-for-linear-regression/}

\fist Hierarchical Linear Models (Multilevel Models
\S\ref{sec:multilevel_model})



\paragraph{Simple Linear Regression}\label{sec:simple_linear_regression}\hfill

single (One-dimensional) Regressor (Independent Variable)

Regression Coefficients

Error Term $\varepsilon$

$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$

for the $i$th Observation (\S\ref{sec:observation})

assuming that $Y$ can be Approximated by a Linear Function of $X$ and the IID
Distribution of the $\varepsilon_i$s is Normal with Mean Zero, the
\emph{Regression Model} (\S\ref{sec:statistical_model}) has three Parameters--
$\beta_0$, $\beta_1$, and the Variance $\sigma^2$ of $\varepsilon$:
\[
  \theta = (\beta_0, \beta_1, \sigma^2)
\]
and each possible value of $\theta$ determines a Distribution $P_\theta$ on the
Sample Space (\S\ref{sec:sample_space}) $S$ of all possible $(Y, X)$ pairs

\url{https://www.youtube.com/watch?v=FGesqq22TCM}: Equation for a Regression
Line passing through the Sample Mean $(\overline{X}\overline{Y})$ with Slope
$r(s_y/s_x)$ where $r$ is the Sample Correlation Coefficient, and $s_y$ and
$s_x$ are Sample Standard Deviations

\url{https://www.youtube.com/watch?v=8RSTQl0bQuw}:
\begin{flalign*}
  \hat{\beta_1} & = \frac{
    \overline{X} \overline{Y} - \overline{XY}
  }{
    (\overline{X})^2 - \overline{X^2}
  } \\
  \hat{\beta_0} & = \overline{Y} - \hat{\beta_1} \overline{X} \\
\end{flalign*}
or equivalently:
\begin{flalign*}
  \hat{\beta_1} & = \frac{Cov(X,Y)}{Var(X)} \\
  \hat{\beta_0} & = \overline{Y} - \frac{\overline{X} Cov(X, Y)}{Var(X)} \\
\end{flalign*}

\asterism

\url{https://www.youtube.com/watch?v=8w6EPyEqE9M} (Khan)

Standard Error of Estimated Parameters (Coefficients); Estimate of the Standard
Deviation of the Sampling Distribution of the Slope; Confidence Interval
(\S\ref{sec:confidence_interval})-- DoF for a Slope Coefficient in a Linear
Model is the number of Sample Points minus 2

$z$-statistic (\S\ref{sec:z_statistic}):
\[
  z = \frac{b - \beta_0}{\sigma_b}
\]

$t$-statistic (\S\ref{sec:t_statistic}):
\[
  t = \frac{b - \beta_0}{SE_b}
\]

\asterism

(Wasserman04 \S13.1)

Least Squares Estimates (\S\ref{sec:least_squares}): TODO



\paragraph{Multiple Linear Regression}
\label{sec:multiple_linear_regression}\hfill

Multiple Regression (\S\ref{sec:multiple_regression}) --
multiple Correlated \emph{Independent Variables}

cf. Multivariate (General Linear) Regression
(\S\ref{sec:multivariate_linear_regression}) -- multiple Correlated
\emph{Dependent Variables}

(wiki) $p$ Independent Variables:
\[
  y_i = \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} +
    \varepsilon_i
\]
where $x_{ij}$ is the $i$-th Observation (\S\ref{sec:observation}) of the $j$-th
Independent Variable



\paragraph{Multivariate Regression}
\label{sec:multivariate_regression}\hfill

\emph{Multivariate Regression Model} or \emph{General Linear Model}

multiple Correlated \emph{Dependent Variables}

cf. Multiple Linear Regression (\S\ref{sec:multiple_linear_regression})
-- multiple Correlated \emph{Independent Variables}

\fist not to be confused with Generalized Linear Models (GLMs \S\ref{sec:glm}):
here ``General'' just means a Multivariate Regressor as opposed to Univariate
Regressor; GLMs are a generalization of Linear Models (General or otherwise)
that allows the the Range of the Regressand to be Categorical (Discrete)--as
opposed to Continuous--and for the Variance of the Regressand to depend on the
Mean (Expected Value)

cf. Multivariate Statistics (\S\ref{sec:multivariate_statistics})

(wiki):

$\mathbf{Y} = \mathbf{XB} + \mathbf{U}$

$\mathbf{Y}$ -- Matrix of Multivariate Measurements: each column being a Set of
Measurements on one of the Dependent Variables

$\mathbf{X}$ -- Matrix of Observations of Independent Variables: each column
being a Set of Observations of one of the Independent Variables

$\mathbf{B}$ -- Matrix of Parameters to be Estimated

$\mathbf{U}$ -- Matrix of Errors

\begin{itemize}
  \item Variance Analysis (ANOVA \S\ref{sec:variance_analysis})
\end{itemize}

\fist Artificial Neural Networks (ANNs \S\ref{sec:ann}) generalize Regression
and Clustering (\S\ref{sec:cluster_analysis}) to Non-linear Multivariate Models

\asterism

\emph{Regression and Automated Differentiation} -
\url{https://idontgetoutmuch.wordpress.com/2013/04/26/regression-and-automated-differentiation-4/}
-- Automatic Differentiation (\S\ref{sec:automatic_differentiation})

Model:
\[
  y_i = \vec{\theta}^T \vec{x}_i + e_i
\]
where $i \in \{1, \ldots, n\}$ for $n$ Observations, and $\vec{\theta}$ and
$\vec{x}$ are both Column Vectors of length $m$ (FIXME: is this really
multivariate or should it be multiple regression instead ???)

Maximize the Likelihood (\S\ref{sec:likelihood}) with respect to $\vec{\theta}$:
\[
  \mathcal{L}(\vec{\theta}; \mathbf{X}, \vec{y}) =
    \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma}}
      e^\frac{-(y_i - \vec{\theta}^T \vec{x}_i)^2}{2\sigma^2}
\]
use Log-likelihood (\S\ref{sec:log_likelihood}) $\log \mathcal{L}(\vec{\theta})
= \lambda(\vec{\theta})$ instead since $\log$ is Monotonic; Maximizing the
Likelihood is the same a Minimizing the (Biased) Variance Estimate:
\[
  \frac{1}{n} \sum_{i=1}^n (y_i - \vec{\theta}^T\vec{x}_i)^2
\]
define a Cost Function (\S\ref{sec:objective_function}):
\[
  \mathcal{J}(\vec{\theta}) =
    \frac{1}{2n} \sum_{i=1}^n (y_i - \vec{\theta}^T \vec{x}_i)^2
\]
(FIXME: this is sum of squared deviations ???)
Minimize Cost Function using \emph{Gradient Descent}
(\S\ref{sec:gradient_descent}):
\[
  \vec{\theta}_{k+1} = \vec{\theta}_k - \gamma \nabla \mathcal{J}(\vec{\theta})
\]
where $\vec{\theta}_k$ is the $k$th Estimate of $\vec{\theta}$, and $\gamma$ is
a \emph{Learning Rate}

for large numbers of Observations, see Stochastic Gradient Descent (SGD
\S\ref{sec:sgd})



\paragraph{Orthogonal Regression}\label{sec:orthogonal_regression}\hfill

\subparagraph{Deming Regression}\label{sec:deming_regression}\hfill

accounts for Error in $X$ and $Y$ Observations (cf. Simple Linear Regression
which only accounts for Vertical Errors)



\subsubsection{Polynomial Regression}\label{sec:polynomial_regression}

Regression Analysis using Basis Functions (\S\ref{sec:basis_function})



\subsubsection{Segmented Regression}\label{sec:segmented_regression}

\subsubsection{Generalized Linear Model (GLM)}\label{sec:glm}

generalization of Simple and Multivariate Linear Regression to Models where:
\begin{enumerate}
  \item Regressands can be Categorical (Discrete) Variables
  \item the Variance of Regressands can depend on the Mean (Expected Value)
  \item Error Distributions other than the Normal Distribution
\end{enumerate}

not to be confused with ``General'' (Multivariate) Linear Models''
(\S\ref{sec:multivariate_regression}): special case of GLM where the
Distribution of Residuals follow a Conditionally Normal Distribution
(FIXME: and response variables are continuous, and variance is constant ???)

\fist Generalized Additive Model (GAM \S\ref{sec:gam}) -- GLM where the Linear
Predictor depends Linearly on unknown Smooth Functions of Predictor Variables

(wiki):

three components of a GLM:
\begin{enumerate}
  \item a Linear Predictor (\S\ref{sec:linear_predictor})
    $\eta = \mathbf{X\beta}$
  \item a \emph{Link Function} (\S\ref{sec:link_function}) $g$ such that:
    \[
      E(\mathbf{Y}|\mathbf{X}) = \mu = g^{-1}(\eta)
    \]
  \item Variance Function $V$ (usually ``follows from an Exponential Family of
    Distributions''):
    \[
      Var(Y) = V(\mu)
    \]
\end{enumerate}
(TODO: clarify variance function )

Natural Exponential Families (\S\ref{sec:natural_exponential_family})

Exponential Dispersion Model (\S\ref{sec:exponential_dispersion})

Least-squares Estimate (\S\ref{sec:least_squares}) may be used to fit a
Generalized Linear Model by iteratively applying the Local Quadratic
Approximation (FIXME: explain)

\begin{itemize}
  \item Binomial Regression (\S\ref{sec:binomial_regression})
  \item Log-linear (Poisson) Regression (\S\ref{sec:log_linear})
  \item Linear Regression (\S\ref{sec:linear_regression})
  \item ...
\end{itemize}



\paragraph{Link Function}\label{sec:link_function}\hfill

\paragraph{Binomial Regression}\label{sec:binomial_regression}\hfill

essentially the same as Binary Choice Models (\S\ref{sec:binary_choice_model})



\subparagraph{Binary Regression}\label{sec:binary_regression}

Models:
\begin{itemize}
  \item Logistic (Logit) Regression (\S\ref{sec:logistic_regression})
  \item Probit Regression (\S\ref{sec:probit_regression})
\end{itemize}



\paragraph{Logistic Regression}\label{sec:logistic_regression}\hfill

or \emph{Logit Regression}

Binary Regression (\S\ref{sec:binary_regression})

Non-linear Model

Non-Linear Least Squares (NLLS \S\ref{sec:nlls})

can be formulated as a special case of Generalized Linear Models
(\S\ref{sec:glm})

cf. Statistical Classification (\S\ref{sec:classification}) -- Logistic
Regression as a Discriminative (\S\ref{sec:discriminative_model}) method of
determining Parameters for a Linear Classifier (\S\ref{sec:linear_classifier})

\fist Linear Discriminant Analysis (LDA \S\ref{sec:lda}) -- in LDA, the Joint
Distribution $f(x,y = f(x|y)f(y)$ is Estimated by maximizing the Likelihood; in
Logistic Regression, only $f(y|x)$ is Estimated and the Conditional Likelihood
is maximized, neglecting the Marginal Distribution $f(x)$

\emph{Logistic Model}: uses a Logistic Function (\S\ref{sec:logistic_function})
to Model a \emph{Binary Dependent Variable} $Y_i \in \{ 0, 1 \}$

Logistic Function $e^x / (1 + e^x)$

for a $k$-dimensional Covariate $X$:
\[
  p_i \equiv P(Y_i = 1 | X = x) = \frac{
    e^{\sum_{j=1}^k \beta_j x_{ij}}
  }{
    1 + e^{\sum_{j=1}^k \beta_j x_{ij}}
  }
\]

\[
  logit(p_i) = \sum_{j=1}^k \beta_j x_{ij}
\]
where:
\[
  logit(p) = log\Big(\frac{p}{1-p}\Big)
\]
(FIXME: explain)

\[
  Y_i | X_i = x_i \sim Bernoulli(p_i)
\]

Conditional Likelihood:
\[
  \mathcal{L}(\beta) = \prod_{i=1}^n p_i(\beta)^{Y_i} (1 - p_i(\beta))^{1-Y_i}
\]

the Maximum Likelihood Estimate (MLE \S\ref{sec:mle}) can be obtained by
maximizing $\mathcal{L}(\beta)$ numerically using Iteratively Re-weighted Least
Squares (\S\ref{sec:irls}):

choose starting $\hat{\beta}^0 = (\hat{\beta}_1^0, \ldots, \hat{\beta}_k^0)$
and compute $p_i^0$ for $i = 1, \ldots, n$, and iterate from $s = 0$:
\begin{enumerate}
  \item set
    \[
      Z_i = logit(p_i^s) + \frac{Y_i - p_i^s}{p_i^s(1 - p_i^s)}
    \]
  \item let $W$ be a Diagonal Matrix with $(i,i)$ equal to $p_i^s(1 - p_i^s)$
  \item set
    \[
      \hat{\beta}^s = (X^T W X)^{-1} X^T W Z
    \]
  corresponding to doing a Weighted Linear Regression of $Z$ on $X$
\end{enumerate}

(wiki): Logistic Regression Predicts the \emph{Probability} of particular
Outcomes rather than the Outcomes themselves

Logistic Regression Models violate the Assumptions in Linear Regression Models
in that the Residuals cannot be Normally Distributed; in a Logistic Model, the
Conditional Distribution $y | x$ is a Bernoulli Distribution
(\S\ref{sec:bernoulli_distribution}), whereas in Linear Regression the
Conditional Distribution is Normally Distributed

\emph{Binary Logistic Regression} -- Models \emph{Probability} of output in
terms of input, and does \emph{not} perform Statistical Classification, although
it can be \emph{used} to make a Binary Classifier by choosing a ``cutoff'' value
and Classifying inputs with Probability greater than the cutoff as one class and
below as the other class

the Model ``Coefficients'' (FIXME: clarify) are generally not Estimated by a
Closed-form Expression (unlike Linear Least Squares in Linear Regression),
instead they are Estimated using \emph{Maximum Likelihood Estimation} (MLE
\S\ref{sec:mle}) by an \emph{Iterative Process} (\S\ref{sec:iterative_method})

see also:
\begin{itemize}
  \item Multinomial Logistic Regression (\S\ref{sec:multinomial_regression})
  \item Ordered Logistic Regression (Ordered Logit \S\ref{sec:ordered_logit})
\end{itemize}

\asterism

\url{https://www.youtube.com/watch?v=ckkiG-SDuV8}:

in Logistic Regression, the Odds Ratio (\S\ref{sec:odds_ratio}) for an
Independent Variable represents how the Odds change with a 1 unit increase in
the Independent Variable, holding all other variables constant

\url{https://www.youtube.com/watch?v=NmjT1_nClzg}:

the Dependent Variable in Logistic Regression follows a \emph{Bernoulli
  Distribution} (\S\ref{sec:bernoulli_distribution}):
\[
  Y | X = x \sim Bernoulli(p)
\]
in Logistic Regression, the unknown Parameter $p$ is Estimated for a given
Linear Combination of Independent Variables

the \emph{Logit} (Inverse Logistic Function \S\ref{sec:logit}) or \emph{Log
  Odds}--the Natural Log of the Odds (\S\ref{sec:odds})--links the Linear
Combination of Independent Variables, with Domain $(-\infty, \infty)$, to the
Bernoulli Parameter $p$, with Domain $[0, 1]$:
\[
  logit(p) = \ln odds = \ln \Big(\frac{p}{1 - p}\Big) = \ln p - \ln (1 - p)
\]

the Standard Logistic Function (\S\ref{sec:logistic_function}), $\sigma(t)$,
that is the Inverse Logit, or \emph{Mean Function}:
\[
  \mu_{y | x} = p(x) = \sigma(t) = logit^{-1}(t) = \frac{1}{1 + e^{-t}}
\]
gives the \emph{Probability} of the Dependent (Bernoulli) Random Variable being
$1$ \emph{given} some Linear Combination $t = \beta_0 + \beta_1 x$ of
Independent Variable $x$

now the Logit of $p(x)$ is expressible as a Linear Function of the Dependent
Variable $x$:
\[
  logit(p(x)) = \ln \Big(\frac{p(x)}{1 - p(x)}\Big) = \beta_0 + \beta_1 x
\]

note that Response Variables $Y_i$ are \emph{not Identically Distributed} as
$P(Y_i = 1 | X)$ differs for each $X_i$, although they \emph{are Independent}
for a given Design Matrix $\mathbf{X}$ and shared Parameters $\vec{\beta}$
(wiki)

this is derived by expressing the Log Odds as a Linear Function of the
Independent Variables and solving for $\hat{p}$:
\begin{flalign*}
  \ln \Big(\frac{\hat{p}}{1 - \hat{p}}\Big) & = \beta_0 + \beta_1 x \\
  \frac{\hat{p}}{1 - \hat{p}}               & = e^{\beta_0 + \beta_1 x} \\
  \hat{p} & = \frac{e^{\beta_0 + \beta_1 x}}{1 + e^{\beta_0 + \beta_1 x}} \\
          & = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x)}} \\
\end{flalign*}

Regression Coefficients for Logistic Regression are calculated using Maximum
Likelihood Estimation (MLE \S\ref{sec:mle})

Iteratively Re-weighted Least Squares (IRLS \S\ref{sec:irls})

Parameters $\vec{\beta}^T = [\beta_0, \beta_1, \ldots]$

Independent Variables $\vec{x}_i^T = [1, x_{i1}, x_{i2}, \ldots]$

Expected Value of the Bernoulli Distribution
$\mu_{y_i | \vec{x}_i} = 1 / (1 + e^{-\vec{\beta}^T \vec{x_i}})$

Iteratively solving for the $(k+1)$th Estimate given the $k$th Estimate of
$\vec{\beta}$:
\[
  \vec{\beta}_{k+1} = (\mathbf{X}^T \mathbf{S}_k \mathbf{X})^{-1} \mathbf{X}^T
    (\mathbf{S}_k \mathbf{X} \vec{\beta}_k + \vec{y} - \vec{\mu}_k)
\]
where:
\begin{itemize}
  \item $\mathbf{S} = diag(\mu_i - \mu_i^2)$ is a
    \emph{Diagonal Weighted Matrix}
  \item $\vec{\mu} = [\mu_1, \ldots, \mu_n]$ is the Vector of Expected Values
  \item $\mathbf{X} = [\vec{1}, \vec{x}_1, \vec{x}_2, \ldots]$ is the Regressor
    (Design) Matrix
  \item $\vec{y}_i^T = [y_1, y_2, \ldots]$ is the Vector of Response Variables
\end{itemize}

Goodness-of-fit (\S\ref{sec:model_fit}) measured using Coefficient of
Determination $R^2$ (\S\ref{sec:determination_coefficient})

Deviance Table, $\chi$-square (cf. ANOVA Table, $f$-test in Linear Regression)

\url{https://www.youtube.com/watch?v=hWLdFMccpTY}:

Gradient of Negative Log-likelihood (\S\ref{sec:log_likelihood}):
$\nabla_{\vec{\beta}} -\ell = \mathbf{X}^T (\vec{\mu} - \vec{y})$

Hessian:
$\nabla_{\vec{\beta}}^2 -\ell = \mathbf{X}^T \mathbf{S} \mathbf{X}$

since the above Hessian is Positive Semi-definite, $-\ell$ is Convex

IRLS: update equation for Newton's Method takes the form of a solution for a WLS
(\S\ref{sec:wls}) problem

\asterism

2019 - Khan - PUCIT CS667 - Advanced Machine Learning --
Newton-Raphson (Newton's Method \S\ref{sec:newtons_method}) update for
minimizing a Function $f(\vec{w})$:
\[
  \vec{w}^{k+1} = \vec{w}^k - \mathsf{H}^{-1}\nabla_{\vec{w}} f(\vec{w})
\]
where $\mathsf{H}$ is the Hessian Matrix of Second Derivatives:
\[
  \frac{\partial^2 f}{\partial{w_i} \partial{w_j}}
\]

Cost Function (TODO)

\emph{Logistic Loss}: Negative Log-likelihood Function, Cross-entropy Error
Function (TODO)

Iteratively Re-weighted Least Squares (IRLS \S\ref{sec:irls})

\asterism

with the Logistic (Sigmoid) Activation Function
(\S\ref{sec:activation_function}), a Single-layer Neural Network
(\S\ref{sec:ffnn}) is identical to a Logistic Regression Model

\emph{Neural Networks} (\S\ref{sec:ann}) can be viewed as a generalization of
Logistic Regression
(\url{https://idontgetoutmuch.wordpress.com/2013/05/31/neural-networks-and-automated-differentiation-3/})

\emph{Logistic Regression and Automated Differentiation} -
\url{https://idontgetoutmuch.wordpress.com/2013/04/30/logistic-regression-and-automated-differentiation-3/}
-- Automatic Differentiation (\S\ref{sec:automatic_differentiation})

\begin{flalign*}
  P(y = 1 | \vec{x}; \vec{\theta}) & = h_{\vec{\theta}}(\vec{x}) \\
  P(y = 0 | \vec{x}; \vec{\theta}) & = 1 - h_{\vec{\theta}}(\vec{x}) \\
\end{flalign*}
where $\vec{x}$ and $\vec{\theta}$ are Vectors of length $m$, and:
\[
  h_{\vec{\theta}}(\vec{x}) = g(\vec{\theta}^T \vec{x})
\]
where $g$ is a Function such as the Logistic Function
(\S\ref{sec:logistic_function}) $g(x) = 1/(1 + e^{-x})$ or Hyperbolic Tangent
(\S\ref{sec:hyperbolic_function}) $g(x) = tanh x$

rewriting as a Conditional Distribution:
\[
  p(y | \vec{x}; \vec{\theta}) =
    (h_{\vec{\theta}}(\vec{x}))^y (1 - h_{\vec{\theta}}(\vec{x}))^{1-y}
\]

in order to find the value of $\vec{\theta}$ that ``gives the maximum
Probability'' to the Observations, Maximize the Likelihood
(\S\ref{sec:likelihood}):
\begin{flalign*}
  \mathcal{L}(\vec{\theta})
    & = \prod_{i=1}^n p(y_i | \vec{x}_i; \vec{\theta}) \\
    & = \prod_{i=1}^n (h_{\vec{\theta}}\vec{x}_i)^{y_i}
          (1 - h_{\vec{\theta}}\vec{x}_i)^{1-y_i} \\
\end{flalign*}
assuming $n$ Observations

Maximize the Log-likelihood (\S\ref{sec:log_likelihood}) since $\log$ is
Monotonic:
\begin{flalign*}
  \lambda (\vec{\theta})
    & = \log \mathcal{L}(\vec{\theta}) \\
    & = \sum_{i=1}^n y_i \log h_{\vec{\theta}} \vec{x}_i +
          (1-y_i) \log (1 - h_{\vec{\theta}} \vec{x}_i) \\
\end{flalign*}
using Gradient Descent (\S\ref{sec:gradient_descent}):
\[
  \vec{\theta}_{k+1} = \vec{\theta}_k - \gamma \nabla \mathcal{J} (\vec{\theta})
\]
where $\theta_k$ is the $k$th Estimate of the Parameters $\theta$ and $\gamma$
is a \emph{Learning Rate}

when number of Observations is high, cheaper alternative is Stochastic Gradient
Descent (SGD \S\ref{sec:sgd})

when the Observations/Training Data (Dataset) are Linearly Separable, then the
magnitude of the Parameters can grow without bound as the Parameterized Logistic
Function tends to the Unit Step Function (\S\ref{sec:unit_step_function}), and
there may be more than one separating Hyperplane-- to avoid this, instead
Maximize a \emph{Penalized Log-likelihood Function}:
\[
  \lambda (\vec{\theta}) = \sum_{i=1}^n
    y_i \log h_{\vec{\theta}} \vec{x}_i
    + (1-y_i) \log (1 - h_{\vec{\theta}} \vec{x}_i)
    - \frac{\delta}{2} \|\vec{\theta}\|^2
\]
(TODO: explain)



\subparagraph{Multinomial Logistic Regression}
\label{sec:multinomial_regression}\hfill



\paragraph{Probit Regression}\label{sec:probit_regression}

Binary Regression (\S\ref{sec:binary_regression})

Linear Classifier (\S\ref{sec:linear_classifier})

Non-linear Model

Non-Linear Least Squares (NLLS \S\ref{sec:nlls})



\paragraph{Ordinal Regression}\label{sec:ordinal_regression}\hfill

\emph{Ranking Learning}



\subparagraph{Ordered Logit}\label{sec:ordered_logit}\hfill

\emph{Ordered Logistic Regression} or \emph{Proportional Odds Model}



\paragraph{Log-linear Model}\label{sec:log_linear}\hfill

or \emph{Poisson Regression}

count data

\emph{Contingency Tables} (\S\ref{sec:contingency_table})

Natural Language Processing

(Wasserman04, Ch.19)

Multivariate Discrete Data --
fitting Discrete Data to a Graphical Model (\S\ref{sec:graphical_model})

Undirected Graphs \fist Pairwise Markov Graph (\S\ref{sec:pairwise_markov})

Dicrete Random Vector $X = (X_1, \ldots, X_m)$ where each
$X_j \in \{ 1, 2, \ldots, r_j \}$ for some $r_j$

Probability Mass Function $f(x) = P(X = x) = P(X_1 = x_1, \ldots, X_m = x_m)$

a Sample of $n$ Vectors is a Sample from a Multinomial Distribution
(\S\ref{sec:multinomial_distribution}) with $N = r_1 r_2 \cdots r_m$ Categories
where Data can be represented as ``counts'' in a
$r_1 \times r_2 \times \cdots \times r_m$ table (FIXME: clarify)

$p = (p_1, \ldots, p_N)$ -- Multinomial Parameter

given a Vector $x = (x_1, \ldots, x_n)$ and Subset
$A \subset \{ 1, \ldots, m \}$, let $x_A = (x_j : j \in A)$

\textbf{Thm.} \emph{
  The Joint Probability Function $f(x)$ of a Random Vector
  $X = (X_1, \ldots, X_n)$ can be written as the \textbf{Log-linear Expansion}
  of $f$:
  \[
    \log f(x) = \sum_A \psi_A(x)
  \]
  over all $A \in 2^{\{ 1, \ldots, m\}}$ where $\psi$ satisfies:
  \begin{enumerate}
    \item $\psi_{\varnothing}(x)$ is Constant
    \item $\psi_A(x)$ is only a Function of $x_A$ and not any other $x_j$
    \item if $i \in A$ and $x_i = 0$ then $\psi_A(x) = 0$
  \end{enumerate}
}

Parameter Spaces (TODO)

\textbf{Graphical Log-linear Model}

if ``missing terms'' correspond only to Conditional Independence Constraints,
not any other kinds of ``Constraints''
(FIXME: explain)

\textbf{Hierarchical Log-linear Model}

\emph{Hierarchical} if $\psi_A = 0$ and $A \subset B$ implies $\psi_B = 0$

Superset of Graphical Models

Hierarchical Models can be written using \emph{Generators}

\emph{Saturated Model}

Submodel \emph{Deviance}

\textbf{Negative Binomial Regression}



\subsubsection{Multiple Regression}\label{sec:multiple_regression}

Definite Quadratic Forms (\S\ref{sec:definite_quadratic})

Multiple Linear Regression (\S\ref{sec:multiple_linear_regression})

note that adding more Covariates, the Bias of the Predictions descreases and the
Variance increases

\emph{Underfitting} -- too few Covariates, high Bias

\emph{Overfitting} -- too many Covariates, high Variance

(wiki): uses Additive Logic (FIXME: xref ???); cf. Necessary Condition Analysis
(NCA \S\ref{sec:nca}) -- uses Necessary Logic (\S\ref{sec:alethic_logic})



\subsubsection{Gaussian Process Regression}
\label{sec:gaussian_process_regression}

\emph{Kriging} or \emph{Wiener-Komogorov Prediction}

under ``suitable assumptions'' on the Priors, Kriging gives the \emph{Best
  Linear Unbiased Prediction} (BLUP \S\ref{sec:blup}) of the intermediate values

\fist Spatial Analysis (\S\ref{sec:spatial_analysis})



\subsubsection{Nonlinear Regression}\label{sec:nonlinear_regression}

Observational Data Modeled by a by a Non-linear Function of Model Parameters and
one or more Independent Variables

$Y = f(\vec{X}, \vec{b})$

Non-Linear Least Squares (NLLS \S\ref{sec:nlls})



\subsubsection{Necessary Condition Analysis (NCA)}\label{sec:nca}

(wiki): uses Necessity Logic (\S\ref{sec:alethic_logic});
cf. Multiple Regression (\S\ref{sec:multiple_regression}) -- uses Additive Logic
(FIXME: xref ???)



% ------------------------------------------------------------------------------
\subsection{Cluster Analysis}\label{sec:cluster_analysis}
% ------------------------------------------------------------------------------

Unsupervised Learning

cf. Classification (Supervised Learning \S\ref{sec:classification})

cf. Density Estimation (\S\ref{sec:density_estimation})

example of Pattern Recognition (assignment of some Output Value to a given Input
Value), other examples are Statistical Classification and Regression Analysis
(\S\ref{sec:regression_analysis})

Artificial Neural Networks (ANNs \S\ref{sec:ann}) generalize Regression
(\S\ref{sec:regression_analysis}) and Clustering to Non-linear Multivariate
Models



\subsubsection{Hierarchical Clustering}\label{sec:hierarchical_clustering}

\subsubsection{Dimensionality Reduction}\label{sec:dimensionality_reduction}

Feature Selection

Feature Extraction



% ------------------------------------------------------------------------------
\subsection{Artificial Neural Network (ANN)}\label{sec:ann}
% ------------------------------------------------------------------------------

%FIXME: move section ?

or \emph{Connectionist System}

extends Regression (\S\ref{sec:regression_analysis}) and Clustering
(\S\ref{sec:cluster_analysis}) to Non-linear Multivariate Models

(Wasserman04, \S22.11) --
simplest Neural Network Regression Model:
\[
  Y = \beta_0 + \sum_{j=1}^p \beta_j \sigma (\alpha_0 + \alpha^T X)
\]
where $\sigma$ is a Smooth Function, often:
\[
  \sigma(v) = \frac{1}{1 + e^{-v}}
\]

Stochastic Gradient Descent (SGD \S\ref{sec:sgd}) -- \emph{de facto} standard
Algorithm for training ANNs

(wiki) applications:
\begin{itemize}
  \item Function Approximation, Regression Analysis
  \item Classification, Pattern Recognition
  \item Cluster Analysis, Filtering, Compression
  \item Non-linear System (\S\ref{sec:nonlinear_equation_system})
    Identification and Control
\end{itemize}

\emph{Neural Networks and Automated Differentiation} -
\url{https://idontgetoutmuch.wordpress.com/2013/05/31/neural-networks-and-automated-differentiation-3/}

Neural Networks can be viewed as a generalization of Logistic Regression
(\S\ref{sec:logistic_regression})

\asterism

\url{http://www.cs.stir.ac.uk/courses/ITNP4B/lectures/} -- slides

ANNs can be represented as \emph{Weighted Directed Graphs}
(\emph{Directed Networks} \S\ref{sec:directed_network})



\subsubsection{Artificial Neuron}\label{sec:artificial_neuron}

the \emph{Nodes} of an ANN

receives one or more \emph{Inputs} (cf. Synapse), individually \emph{Weights}
each Input, and passes the \emph{Sum} of Weighted Inputs through a (usually
Non-linear) \emph{Activation Function} (\S\ref{sec:activation_function}) to
produce an \emph{Output} (cf. Axon)

\begin{itemize}
  \item $\{ x_0, x_1, \ldots, x_n \}$ -- Inputs
  \item $\{ w_0, w_1, \ldots, w_n \}$ -- Weights
\end{itemize}

usually Input $x_0$ is assigned the value $1$, so that $w_0 = b$ is a
\emph{Bias}

the \emph{Output}, $y$:
\[
  y = \varphi \Big( \sum_{i=0}^n w_i x_i \Big)
\]
where $\varphi$ is the \emph{Activation Function}
(\S\ref{sec:activation_function})

the Output may either be propagated to the Input of the next Layer, or exit the
Network as part of an Output Vector

a Neuron has no ``learning process'' (FIXME: clarify)

\begin{itemize}
  \item Threshold Logic Unit (TLU \S\ref{sec:tlu})
  \item Perceptron (\S\ref{sec:perceptron}) or ``\emph{Linear Threshold Unit}''
    -- Neuron using the Unit Step Function (\S\ref{sec:unit_step_function}) as
    the Activation Function
  \item ...
\end{itemize}



\paragraph{Activation Function}\label{sec:activation_function}\hfill

sometimes ``Transfer Function'', not to be confused with the Transfer Function
(\S\ref{sec:transfer_function}) of a Control System (\S\ref{sec:control_system})
or the Transfer Function (Evolution Function \S\ref{sec:evolution_function}) of
a Dynamical System

defines the \emph{Output} of a Node for a given Input or Set of Inputs

the Activation Function is applied to the Dot Product (Weighted Sum)
$\vec{w}^T \vec{x}$, called the \emph{Activation}

(wiki):

Training by Backpropagation (\S\ref{sec:backpropagation}) requires Derivatives
of Activation Functions, which can be computed using Automatic Differentiation
(\S\ref{sec:automatic_differentiation})

any Multi-Layer Peceptron (MLP \S\ref{sec:mlp}) Network using a Linear
Activation Function has an equivalent \emph{Single-layer} Network; i.e. to gain
advantages from multiple Layers requires a \emph{Non-linear} Activation Function

\emph{Universal Approximation Theorem} (\S\ref{sec:universal_approximation}):
when the Activation Function is Non-linear, a Two-layer Neural Network can be
proven to be a Universal Function Approximator

\begin{itemize}
  \item Identity
  \item Binary Step
  \item Logistic (Sigmoid)
  \item Tanh
  \item Arctan
  \item Arsinh
  \item Softsign (ElliotSig)
  \item Inverse Square Root Unit (ISRU)
  \item SQuare Non-Linearity (SQNL)
  \item Rectified Linear Unit (ReLU) -- most common in DNNs (\S\ref{sec:dnn})
  \item Exponential Linear Unit (ELU)
  \item Adaptive Piecewise Linear (APL)
  \item SoftPlus
  \item Bent Identity
  \item Sigmoid Linear (SiL)
  \item SoftExponential
  \item Soft Clipping
  \item Sinusoid
  \item Sinc
\end{itemize}

with the Logistic (Sigmoid) Activation Function, a Single-layer Neural Network
is identical to a Logistic Regression Model (\S\ref{sec:logistic_regression})



\paragraph{Threshold Logic Unit (TLU)}\label{sec:tlu}\hfill

McCulloch-Pitts Neuron

cf. Perceptron (\S\ref{sec:preceptron})



\subsubsection{Layer}\label{sec:ann_layer}

a \emph{Layer} is a Set of Nodes that have the same distance from ``the Inputs''
(FIXME: clarify)

\emph{Input Layer} or \emph{Visible Layer} -- Input Variables: by convention
this ``Layer'' is \emph{not counted}, or referred to as ``Layer $0$'', e.g. a
Single-layer Perceptron has Input Variables and an Output Layer only, an MLP
with a single Hidden Layer is a 2-layer MLP

\emph{Output Layer} -- Layer of Nodes (Neurons) that produce Output Variables

\emph{Hidden Layer}

\begin{itemize}
  \item Single-layer Perceptron (\S\ref{sec:single_layer_perceptron})
  \item Multi-Layer Perceptron (MLP \S\ref{sec:mlp})
\end{itemize}

notation for the number of Layers (from Input to Output): 2/8/1 --
(\url{https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/})

\emph{Fully-connected Layer} -- every Node in one Layer is connected to every
Node in the next layer



\subsubsection{Learning Process}\label{sec:learning_process}

\emph{Learning Rule} or \emph{Learning Process} -- Algorithm by which the Weight
and Bias levels of a Network are repeatedly updated to improve the Network's
``performance''

\begin{itemize}
  \item Unsupervised Learning -- Dentity Estimation
    (\S\ref{sec:density_estimation}), Cluster Analysis
    (\S\ref{sec:cluster_analysis})
  \item Supervised Learning -- Classification (\S\ref{sec:classification}),
    Regression Analysis (\S\ref{sec:regression_analysis})
  \item Reinforcement Learning (\S\ref{sec:reinforcement_learning})
\end{itemize}

\fist cf. Learning Algorithm (\S\ref{sec:learning_algorithm}),
Training Set (\S\ref{sec:training_dataset})

Online methods:
\begin{itemize}
  \item Stochastic Gradient Descent (\S\ref{sec:sgd})
\end{itemize}

Batch methods:
\begin{itemize}
  \item Conjugate Gradient Descent (\S\ref{sec:conjugate_gradient_method})
\end{itemize}



\paragraph{Backpropagation}\label{sec:backpropagation}\hfill

1982 - Werbos -
\emph{Applications of Advances in Nonlinear Sensitivity Analysis}

2017 - Fong, Spivak, Tuy\'eras - \emph{Backprop as Functor: A compositional
  perspective on supervised learning}

process of ``Training'' a Regression Model (\S\ref{sec:regression_analysis});
cf. Maximum Likelihood Estimation (MLE \S\ref{sec:mle})

cf. Gauss-Newton Algorithm (Non-linear Least Squares \S\ref{sec:gauss_newton})

cf. \emph{Least Mean Squares} (LMS \S\ref{sec:lms})

\emph{Neural Networks and Automated Differentiation} -
\url{https://idontgetoutmuch.wordpress.com/2013/05/31/neural-networks-and-automated-differentiation-3/}

\emph{Backpropagation} -- Gradient Descent (\S\ref{sec:gradient_descent}) with
Reverse-mode Automatic Differentiation (\S\ref{sec:automatic_differentiation})

\emph{Delta Rule} -- special case of Backpropagation for updating the Weights of
Input to Neurons in a Single-layer Neural Network

(wiki): requires Derivatives of Activation Functions, which can be computed
using Automatic Differentiation

Backpropagation computes the Gradients, while Stochastic Gradient Descent
(\S\ref{sec:sgd}) \emph{uses} the Gradients for ``Training'' the Model via
Optimization

Loss Functions -- Squared Error (Regression), Cross-entropy (Classification)

Gradient Descent requires computing the Derivative for the \emph{Loss Function}
with respect to the Weights in the Network

Assumptions on the Loss Function, $L$, for use in Backpropagation:
\begin{enumerate}
  \item can be written as an Average $L = \frac{1}{n} \sum_x L_x$ over Loss
    Functions $F_x$ for $n$ individual Training examples, $x$-- this is required
    because Backpropagation calculates the Gradient of the Loss Function for a
    \emph{single} Training example, which needs to be generalized to the
    \emph{overall} Loss Function
  \item can be written as a Function of the \emph{Outputs} from the Neural
    Network
\end{enumerate}

Backpropagation is not guaranteed to find the Global Minimum of the Loss
Function, only a Local Minimum

does not require Normalization of Input Vectors, although Normalization could
improve performance

2013 - Buitl\'eir, Russell, Daly -
\emph{A Functional Approach to Neural Networks}

2019 - Kahn - PUCIT CS667:

application of the Multivariate Chain Rule (\S\ref{sec:chain_rule})

Backpropagation algorithm:
\begin{enumerate}
  \item Forward propagate input to compute Activations and Outputs for every
    Layer
  \item Evaluate the Error for every Neuron in the Output Layer
  \item Evaluate the Error for every Neuron in every Hidden Layer via
    \emph{Backpropagation}
  \item Compute Derivative of each Weight $\partial f / \partial w$ via the
    Error and the Input
  \item Update each Weight via \emph{Gradient Descent}
\end{enumerate}



\subsubsection{Feed-Forward Neural Network (FFNN)}\label{sec:ffnn}

no Cycles between Nodes (Neurons)

with the Logistic (Sigmoid) Activation Function, a Single-layer Neural Network
is identical to a Logistic Regression Model (\S\ref{sec:logistic_regression})



\paragraph{Universal Approximation Theorem}
\label{sec:universal_approximation}\hfill

every Continuous Function mapping Intervals of Real Numbers to some Output
Interval of Real Numbers can be Approximated arbitrarily closely by a
Multi-layer Perceptron with a single Hidden Layer

when the Activation Function is Non-linear, a Two-layer Neural Network can be
proven to be a Universal Function Approximator



\paragraph{Single-layer Perceptron}\label{sec:single_layer_perceptron}\hfill

simplest Feed-Forward Neural Network

cf. Perceptron (\S\ref{sec:perceptron}) -- Binary Linear Classifier
(\S\ref{sec:linear_classifier}); an Artificial Neuron using the Unit Step
Function (\S\ref{sec:unit_step_function}) as the Activation Function; simplest
FFNN

Perceptron Learning Algorithm does not terminate if the ``Learning Set'' is not
Linearly Separable, e.g. a Boolean Exclusive-OR problem

(wiki):

\emph{Delta Rule} -- special case of Backpropagation for Single-layer Neural
Networks; for a Neuron $j$ with Activation Function $\phi(x)$, the Delta Rule
for $j$'s $i$th Weight $w_{ji}$ is given by:
\[
  \Delta w_{ji} = r(t_j - y_j) \phi'(h_j) x_i
\]
where $r$ is the constant Learning Rate, $\phi'$ is the Derivative of the
Activation Function, $x_i$ is the $i$th Input, $t_j$ is $j$'s target Output,
$y_j$ is $j$'s actual Output, and $h_j$ is the Weighted Sum of $j$'s Inputs (the
``Induced Local Field'')



\paragraph{Multi-Layer Perceptron (MLP)}\label{sec:mlp}\hfill

(wiki): any MLP using a Linear Activation Function has an equivalent
\emph{Single-layer} Network; i.e. to gain advantages from multiple Layers
requires a \emph{Non-linear} Activation Function

\fist Convolutional Nueral Network (CNN \S\ref{sec:cnn}) -- ``Regularized''
versions of MLP



\subsubsection{Deep Neural Network (DNN)}\label{sec:dnn}

\emph{Shift-invariant Neural Networks}

\emph{Deep Learning} or \emph{Hierarchical Learning}

reduces the number of connections by reducing the number of free Parameters

connectivity pattern between Neurons inspried by organization of Visual Cortex

Cross-correlation (\S\ref{sec:cross_correlation})

ReLU activation



\paragraph{Convolutional Neural Network (CNN)}\label{sec:cnn}\hfill

``Regularized'' versions of Multi-layer Perceptrons (\S\ref{sec:mlp})



\paragraph{Recurrent Neural Network (RNN)}\label{sec:rnn}\hfill

can be used to learn \emph{Sequential} mappings



% ==============================================================================
\section{Computational Learning Theory}\label{sec:computational_learning_theory}
% ==============================================================================

%FIXME start new document ???



% ------------------------------------------------------------------------------
\subsection{Algorithmic Learning Theory}\label{sec:algorithmic_learning}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Vapnik-Chervonenkis Theory}\label{sec:vc_theory}
% ------------------------------------------------------------------------------

\emph{VC Theory}



\subsubsection{Shattered Set}\label{sec:shattered_set}

\emph{Shatter Coefficient}



\subsubsection{VC Class}\label{sec:vc_class}

\emph{Hypothesis Class}



\paragraph{VC Dimension}\label{sec:vc_dimension}\hfill

\emph{Model Complexity} (\S\ref{sec:statistical_model})

measure of the capacity (expressive power) of a Space of Functions that can be
Learned by a Statistical Classification Algorithm (\S\ref{sec:classification})

defined as the Cardinality of the largest Set of Points that the Algorithm can
\emph{Shatter} (\S\ref{sec:shattered_set})



% ==============================================================================
\section{Statistical Randomness}\label{sec:statistical_randomness}
% ==============================================================================

cf. \emph{Algorithmic Randomness} (\S\ref{sec:algorithmic_randomness}) --
Universal Test, Universal Sequential Test (Martin-L\"of66)

\emph{Subsequence Selection Criterion} (\S\ref{sec:random_sequence}) --
\emph{Mises-Church Randomness}: any Recursive Function which having read the
first $N$ elements of the Sequence decides if it wants to select element $N+1$

cf. Quasi-random Sequences (\S\ref{sec:low_discrepancy})

Tests (\S\ref{sec:hypothesis_testing}):
\begin{itemize}
  \item Frequency test
  \item Serial Test
  \item Poker Test
  \item Gap Test
  \item ...
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Randomization}\label{sec:randomization}
% ------------------------------------------------------------------------------

\begin{itemize}
  \item Random Experiments (\S\ref{sec:experiment}), cf. Observation
    (\S\ref{sec:observation}), Sampling (\S\ref{sec:random_sample})
  \item Survey Sampling
  \item Resampling (\S\ref{sec:resampling})
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Pseudorandom Process}\label{sec:pseudorandom_process}
% ------------------------------------------------------------------------------

Deterministic System (\S\ref{sec:deterministic_system}) exhibiting Statistical
Randomness

cf. \emph{Stochastic Process} (\S\ref{sec:stochastic_process})

\emph{Hash Functions} can create ``Random Numbers'' solely based on an Input
with no dependency on previous queries

2015 -
\url{http://blog.runevision.com/2015/01/primer-on-repeatable-random-numbers.html}
- \emph{Primer on Repeatable Random Numbers}



\subsubsection{Middle-square Method}\label{sec:middle_square_method}



% ==============================================================================
\section{Stochastic Process}\label{sec:stochastic_process}
% ==============================================================================

or \emph{Random Process}

Sequences of \emph{Dependent} (\S\ref{sec:dependence}) Random Variables; cf. IID
(\S\ref{sec:iid}) Sequences (often of \emph{Observations}
\S\ref{sec:observation})

\fist a \emph{Random Sequence} (\S\ref{sec:random_sequence}) is a special case
of Stochastic Process where the Index Set is some Subset of the Integers; a
Sequence of IID Observations is a special case (cf. Random Sample
\S\ref{sec:random_sample})

\fist cf. Data Generating Process (\S\ref{sec:data_generating_process})

\fist a \emph{Pseudorandom Process} (\S\ref{sec:pseudorandom_process}) is a
Determinstic Process exhibiting Statistical Randomness
(\S\ref{sec:statistical_randomness})

\fist Stochastic Calculus (\S\ref{sec:stochastic_calculus}):
\begin{itemize}
  \item Predictable Process (\S\ref{sec:predictable_process}) -- Process whose
    value is knowable at a prior time; smallest Class of Processes that is
    Closed under taking limits of Sequences (FIXME: clarify)
  \item Adapted Proces (Non-anticipative Process \S\ref{sec:adapted_process}) --
    cannot be Predicted into the Future (FIXME: clarify)
\end{itemize}

cf. Harmonic Functions (\S\ref{sec:harmonic_function})

\fist cf. Stochastic Optimization (\S\ref{sec:stochastic_optimization})

\fist cf. Non-deterministic Dynamical Systems
(\S\ref{sec:nondeterministic_dynamical_system})

\fist Stochastic Differential Equations (SDEs \S\ref{sec:sde}) -- a Differential
Equation in which one or more Terms is a Stochastic Process

First-hitting-time Model

Wasserman04, Ch.23:

\emph{Stochastic Process} -- collection of Random Variables:
\[
  \{ X(t) : t \in T \}
\]
with Index Set $T$, taking values in the \emph{State Space} (cf. Dynamical
Systems \S\ref{sec:dynamical_system}), $\mathcal{X}$

\begin{itemize}
  \item Markov Process (\S\ref{sec:markov_process}) -- Probability Distribution
    of $X_i$ Depends only on $X_{i-1}$
  \item Random Field (\S\ref{sec:random_field}) -- $T$ allowed to be any
    Topological Space
\end{itemize}

the Joint Probability Density Function (\S\ref{sec:joint_probability}) of
$X_1, \ldots, X_n$ Random Variables can be written as:
\begin{flalign*}
  f(x_1, \ldots, x_n)
    & = f(x_1) f(x_2 | x_1) \cdots f(x_n | x_1, \ldots, x_{n-1}) \\
    & = \prod_{i=1}^n f(x_i | x_1, \ldots, x_{i-1}) \\
\end{flalign*}
for a Markov Process, this simplifies to:
\[
  f(x_0, \ldots, x_t) = f(x_1)f(x_2|x_1)f(x_3|x_2) \cdots f(x_t|x_{t-1})
\]



% ------------------------------------------------------------------------------
\subsection{Statistical Fluctuation}\label{sec:statistical_fluctuation}
% ------------------------------------------------------------------------------

Statistical Mechanics \& Thermodynamics; e.g. Shot (Poisson
\S\ref{sec:poisson_process}) Noise in electronics and optical devices--
originates from discrete nature of electric charge and particle nature of light,
resp.



% ------------------------------------------------------------------------------
\subsection{Stochastic Convergence}\label{sec:stochastic_convergence}
% ------------------------------------------------------------------------------

Convergence of Sequences (\S\ref{sec:convergent_sequence}) of Random Variables
(\S\ref{sec:random_variable}) to a Limit Random Variable

\fist Asymptotic Theory (Large Sample Theory \S\ref{sec:asymptotic_theory})

\fist cf. Measure Convergence (\S\ref{sec:measure_convergence})

Wasserman04 Ch.5

\textbf{Modes of Convergence}
For a Sequence of Random Variables $X_1, X_2, \ldots$, and Random Variable $X$,
with $F_{X_n}$ the CDF (\S\ref{sec:cdf}) of $X_n$ and $F_X$ the CDF of $X$:
\begin{itemize}
  \item \emph{Convergence in Distribution} (\emph{Weak Convergence}) --
    $X_n \rightsquigarrow X$ if for all $x$ at which $F_X$ is Continuous:
    \[
      \lim_{n\rightarrow\infty} F_{X_n}(x) = F_X(x)
    \]
  \item \emph{Convergence in Probability} -- $X_n \xrightarrow{P} X$ if for
    every $\epsilon > 0$:
    \[
      \lim_{n\rightarrow\infty}P(|X_n - X| > \epsilon) = 0
    \]
  \item \emph{Almost Sure (Everywhere) Convergence} (\emph{Strong Convergence})
    -- $X_n \xrightarrow{as} X$ if:
    \[
      P(\lim_{n\rightarrow\infty}X_n = X) = 1
    \]
  \item \emph{Sure (Everywhere) Convergence} (\emph{Pointwise Convergence})
  \item \emph{Convergence in the $r$th Mean} or \emph{$L^r$-norm}
    (\S\ref{sec:lp_space})
    \begin{itemize}
      \item \emph{Convergence in Quadratic Mean ($L^2$)} --
        $X_n \xrightarrow{qm} X$ if:
        \[
          \lim_{n\rightarrow\infty} E(X_n - X)^2 = 0
        \]
      \item \emph{Convergence in $L^1$} -- $X_n \xrightarrow{L^1} X$ if:
        \[
          \lim_{n\rightarrow\infty} E(|X_n - X|) = 0
        \]
    \end{itemize}
\end{itemize}

\textbf{Thm.}
\begin{itemize}
  \item $X_n \xrightarrow{qm} X \Rightarrow X_n \xrightarrow{L^1} X$
  \item $X_n \xrightarrow{L^1} X \Rightarrow X_n \xrightarrow{P} X$
  \item $X_n \xrightarrow{as} X \Rightarrow X_n \xrightarrow{P} X$
  \item $X_n \xrightarrow{P} X \Rightarrow X_n \rightsquigarrow X$
  \item $X \rightsquigarrow X \wedge \exists c : P(X = c) = 1 \Rightarrow
    X_n \xrightarrow{P} X$
\end{itemize}

\emph{Slutsky's Theorem}



% ------------------------------------------------------------------------------
\subsection{Discrete-time Stochastic Process}\label{sec:discretetime_stochastic}
% ------------------------------------------------------------------------------

\subsubsection{Bernoulli Process}\label{sec:bernoulli_process}

Mathematical Formalization of \emph{Binomial (Bernoulli) Trials}
(\S\ref{sec:binomial_trial})

Binary Entropy (\S\ref{sec:binary_entropy}) -- Entropy of a Bernoulli Process
with Probabilty $p$

Stochastic Computing

cf. \emph{Binomial Process} (Point Process \S\ref{sec:binomial_process})

Iteratively Re-weighted Least Squares (IRLS \S\ref{sec:irls}) -- equivalent to
minimizing the Log-likelihood (\S\ref{sec:log_likelihood}) of a Bernoulli
Distributed Process using Newton's Method (\S\ref{sec:newtons_method}); used for
MLE in Logistic Regression (\S\ref{sec:logistic_regression})



\paragraph{Bernoulli Sequence}\label{sec:bernoulli_sequence}\hfill

Random Sequence (\S\ref{sec:random_sequence})

\emph{Infinite Bernoulli Sequences} -- cf. \emph{Collectives} (Von Mises57); a
solution to the ``Reference Class Problem'' of Frequentist Probability Theory;
cf. (Martin-L\"of66)



\subsubsection{Martingale}\label{sec:martingale}

\begin{itemize}
  \item Stopped Brownian Motion
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Continuous-time Stochastic Process}\label{sec:continuous_stochastic}
% ------------------------------------------------------------------------------

\subsubsection{Gaussian Process}\label{sec:gaussian_process}

a 1D Gaussian Random Field (\S\ref{sec:gaussian_random_field})

can be seen as the Infinite-dimensional generalization of Multivariate Normal
Distributions (\S\ref{sec:normal_distribution})

the Distribution of a Gaussian Process is the Joint Distribution of infinitely
many Random Variables, i.e. it is a Distribution over Functions with a
Continuous Domain

Machine Learning: Lazy Learning (1D Gaussian Distributions)

Gaussain Process Regression (Kriging \S\ref{sec:gaussian_process_regression})



\paragraph{Fractional Brownian Motion}\label{sec:fractional_brownian}\hfill

(\emph{fBm})

$H \in (0,1) \subset \reals$ -- Hurst index

$H = 1/2$ -- Wiener Process (Brownian Motion \S\ref{sec:wiener_process})

for $H > 1/2$, increments of the process are Positively Correlated, and exhibits
Long-range dependence

for $H < 1/2$, increments of the process are Negatively Correlated

Hausdorff and Box Dimension of $2 - H$

\fist Multifractals (\S\ref{sec:multifractal_system}): generalized framework of
Fractional Brownian Motions



\subparagraph{Wiener Process}\label{sec:wiener_process}\hfill

or \emph{Brownian Motion}

$H = 1/2$



\subparagraph{Geometric Brownian Motion (GBM)}\label{sec:gbm}\hfill

Stochastic Differential Equations (SDEs \S\ref{sec:sde})

Black-Scholes

(wiki):

GBM as a model of Stock Prices is unrealistic in that Stock Price Volatility
changes over time (possibly Stochastically), but in GBM, Volatility is assumed
Constant; also Stock Prices may have discontinous ``jumps'' in Price, whereas
GBM is Path Continuous

\emph{Local Volatility} -- treat Volatility as a Function of Price and Time

\emph{Stochastic Volatility} -- allow Volatility to be Stochastic



% ------------------------------------------------------------------------------
\subsection{Stationary Process}\label{sec:stationary_process}
% ------------------------------------------------------------------------------

Stochastic Process for which the Unconditional Joint Probability Distribution
(\S\ref{sec:joint_probability}) does not change when shiften in Time (TODO:
xref)



% ------------------------------------------------------------------------------
\subsection{Random Walk}\label{sec:random_walk}
% ------------------------------------------------------------------------------

\subsubsection{Law of Iterated Logarithm}\label{sec:iterated_logarithm}

describes magnitude of Fluctuations of a Random Walk

cf. Law of Large Numbers (\S\ref{sec:large_numbers})



\subsubsection{Markov Process}\label{sec:markov_process}

(or \emph{Markov Chain})

(Wasserman04, \S23.2)

\emph{Markov Property} (``Memorylessness'') --
Distribution of $X_i$ Depends only on $X_{i-1}$:
\[
  P(X_t = x | X_0, \ldots, X_{t-1}) = P(X_t = x | X_{t-1})
\]
for all $t$ and $x \in \mathcal{X}$

Density:
\[
  f(x_0, \ldots, x_t) = f(x_1)f(x_2|x_1)f(x_3|x_2) \cdots f(x_t|x_{t-1})
\]

a Markov Process can be represented as the DAG:
\[
  X_0 \longrightarrow X_1 \longrightarrow \cdots \longrightarrow X_n
    \longrightarrow \cdots
\]
where each Random Variable has a single parent (the previous Observation)

cf. Poisson Process (\S\ref{sec:poisson_process})

\fist can be seen as a special case of Petri Nets (\S\ref{sec:petri_net}) where
every Transition has a single Input and a single Output

``Equilibria'' -- a Discrete Markov Process where the Histogram (Density
Estimate) of States Converges is said to reach an ``Equilibrium''

a Markov Process is \emph{Homogeneous} if Transition Probabilities
$P(X_{n+1} = j | X_n = i)$ are Constant over time, i.e.:
\[
  P(X_{n+1} = j | X_n = i) = P(X_1 = j| X_0 = i)
\]

a Probability $p_{ij}$:
\[
  p_{ij} \equiv P(X_{n+1} = j | X_n = i)
\]
is called a \emph{Transition Probability}, and the Square Matrix $\mathbf{P}$ of
Transition Probabilities is called the \emph{Transition Matrix} (or
\emph{Stochastic Matrix});
$p_{ij} \geq 0$, and each Row is a Probability Mass Function (\S\ref{sec:pmf}),
since $\sum_i p_{ij} = 1$

an \emph{$n$-step Transition Probability}:
\[
  p_{ij}(n) = P(X_{m+n} = j | X_m = i)
\]
is the Probability of going from State $i$ to State $j$ in $n$ steps

for Homogeneous Markov Processes:

$\mathbf{P}^n$ -- $n$-step Transition Matrix, i.e. $\mathbf{P}$

\emph{Chapman-Kolmogorov Equations}:
\[
  p_{ij}(m + n) = \sum_k p_{ik}(m) p_{kj}(n)
\]
which is the same as Multiplication of the $m$- and $n$-step Transition
Matrices:
\[
  \mathbf{P}^{m+n} = \mathbf{P}^m \mathbf{P}^n
\]

the Marginal Probability that Markov Process is in State $i$ at Time $n$:
\[
  \mu_n(i) = P(X_n = i)
\]

let $\mu_n = [\mu_n(1), \ldots, \mu_n(N)]$ be a Row Vector (``Distribution'')

$\mu_0$ is the \emph{Initial Distribution}

to \emph{Simulate} (\S\ref{sec:stochastic_simulation}) a Markov Process, only
$\mu_0$ and $\mathbf{P}$ are needed:
\begin{enumerate}
  \item ``draw'' $X_0 \sim \mu_0$; therefore $P(X_0 = i) = \mu_0(i)$
  \item when the Outcome of (1.) is $i$, drawing $X_1 \sim \mathbf{P}$ gives
    $P(X_1 = j | X_0 = i) = p_{ij}$
  \item when the Outcome of (2.) is $j$, drawing $X_2 \sim \mathbf{P}$ gives
    $P(X_2 = k | X_1 = j) = p_{jk}$
  \item and so on...
\end{enumerate}

$\mu_n$ gives the Histogram of collecting all Outcomes at Time $n$

(Lemma) the Marginal Probabilities are given by $\mu_n = \mu_0 \mathbf{P}^n$

$j$ is \emph{Accessible} from $i$, $i \rightarrow j$, if $p_{ij}(n) > 0$ for
some $n$; if $i \rightarrow j$ and $j \rightarrow i$, then $i$ and $j$
\emph{Communicate}, $i \leftrightarrow j$

(Thm.) the Communication Relation Satisfies:
\begin{itemize}
  \item $i \leftrightarrow i$
  \item $i \leftrightarrow j \Longrightarrow j \leftrightarrow i$
  \item $i \leftrightarrow j \wedge j \leftrightarrow k \Longrightarrow
    i \leftrightarrow k$
  \item the State Space $\mathcal{X}$ can be written as a Disjoint Union of
    Communication Classes $\mathcal{X}_1 \cup \mathcal{X}_2 \cup \cdots$
    generated by the Communication Relation in which any two States $i$ and $j$
    Communicate with eachother if and only if they are in the same Class
\end{itemize}

if all States Communicate, the Markof Process is called \emph{Irreducible}

a Set of States is \emph{Closed} if once entered, the Process never leaves; a
Closed Set of States consisting of a single State is called an \emph{Absorbing
  State}

if in a State $i$, the Process will eventually return to State $i$ with
Probability $1$:
\[
  \exists n \geq 1 . P(X_n = i | X_0 = i) = 1
\]
then State $i$ is called \emph{Recurrent} or \emph{Persistent}, otherwise $i$ is
\emph{Transient}

(Thm.) a State $i$ is Recurrent if and only if:
\[
  \sum_n p_{ii}(n) = \infty
\]
a State $i$ is Transient if and only if:
\[
  \sum_n p_{ii} < \infty
\]

(Thm.)
\begin{itemize}
  \item if State $i$ is Recurrent and $i \leftrightarrow j$ then $j$ is
    Recurrent
  \item if State $i$ is Transient and $i \leftrightarrow j$ then $j$ is
    Transient
  \item a Finite Markov Process must have at least one Recurrent State
  \item the States of a Finite, Irreducible Markov Process are all Recurrent
\end{itemize}

\emph{Decomposition Theorem}:
the State Space $\mathcal{X}$ can be written as the Disjoint Union:
\[
  \mathcal{X} = \mathcal{X}_T \cup \mathcal{X}_1 \cup \mathcal{X}_2 \cup \cdots
\]
where $\mathcal{X}_T$ are the Transient States and each $\mathcal{X}_i$ is a
Closed, Irreducible Set of Recurrent States

\emph{Recurrence Time}

\emph{Mean Recurrence Time}

a Recurrent State is \emph{Null} if the Mean Recurrence Time is Infinite;
otherwise it is \emph{Positive} (or \emph{Non-null})

(Lemma) if a Sate is Null and Recurrent, then $p_{ii}^n \rightarrow 0$

(Lemma) in a Finite State Markov Process, all Recurrent States are Positive

State $i$ has \emph{Period} $d$ if any return to State $i$ \emph{must} occur in
Multiples of $d$ time steps; $d$ is the largest Integer such that
$p_{ii}(n) = 0$ whenever $n$ is not Divisible by $d$ ($\neg d | n$), i.e.
$d = gcd\{n : p_{ii}(n) > 0 \}$

State $i$ is \emph{Periodic} if $d(i) > 1$ and \emph{Aperiodic} if $d(i) = 1$

an Irreducible Markov Process needs only one Aperiodic State to imply all States
are Aperiodic

every State of a Bipartite Graph (\S\ref{sec:bipartite_graph}) has an Even
Period

(Lemma) if a State $i$ has Period $d$ and $i \leftrightarrow j$, then $j$ has
Period $d$

a State is \emph{Ergodic} (cf. Ergodic Theory \S\ref{sec:ergodic_theory}) if it
is:
\begin{itemize}
  \item Recurrent -- will eventually be returned to
  \item Positive -- has a Finite Mean Recurrence Time
  \item Aperiodic -- the GCD of the number of steps of any return is $1$
\end{itemize}
a Markov Process is Ergodic if all its States are Ergodic

a Distribution $\pi = [\pi_i : i \in \mathcal{X}]$ is \emph{Stationary} (or
\emph{Invariant}) if $\pi = \pi \mathbf{P}$; i.e. if the Process ever ``has
Distribution'' (FIXME: clarify) $\pi$, then it will continue to have
Distribution $\pi$ forever

a Markov Process has \emph{Limiting Distribution} $\pi$ if:
\[
  P^n \rightarrow \begin{bmatrix}
    \pi \\
    \pi \\
    \vdots \\
    \pi \\
  \end{bmatrix}
\]
for some $\pi$, i.e. $\pi_j = \lim_{n\rightarrow\infty} \mathbf{P}_{ij}^n$
exists and is independent of $i$

\textbf{Thm.} (Convergence) \emph{
  An Irreducible, Ergodic Markov Process has a
  unique Stationary Distribution $\pi$, and a Limiting Distribution equal to
  $\pi$, and for any Bounded Function $g$, with Probability $1$:
\[
  \lim_{N\rightarrow\infty} \frac{1}{N} \sum_{n=1}^N g(X_n)
    \rightarrow E_\pi(g) \equiv \sum_j g(j) \pi_j
\]
}

note that a Markov Process having a Stationary Distribution does not imply
Convergence

\emph{Detailed Balance}

\fist Markov Chain Monte Carlo (MCMC \S\ref{sec:mcmc}) -- Estimate the Integral
$\int h(x) f(x) dx$ using a Markov Chain with Stationary Distribution $f$



\paragraph{Branching Process}\label{sec:branching_process}\hfill



% ------------------------------------------------------------------------------
\subsection{Random Measure}\label{sec:random_measure}
% ------------------------------------------------------------------------------

a Measure-valued Random Element (\S\ref{sec:random_variable})

definition as Transition Kernels

\begin{itemize}
  \item $P_n(A) = \frac{1}{n}\sum_{i=1}^n \delta_{X_i}(A)$ --
    Empirical Measure (\S\ref{sec:empirical_measure})
  \item $\mu = \sum_{n=1}^N \delta_{X_n}$ -- Point Process
    (\S\ref{sec:point_process})
\end{itemize}



\subsubsection{Empirical Measure}\label{sec:empirical_measure}

$P_n(A) = \frac{1}{n}\sum_{i=1}^n \delta_{X_i}(A)$

where $\delta$ is the Dirac Measure (\S\ref{sec:dirac_measure})

the CDF (\S\ref{sec:cdf}) associated with the Empirical Measure of a Sample
(\S\ref{sec:sample}) is the \emph{Empirical Distribution Function}
(\S\ref{sec:empirical_distribution})



\subsubsection{Point Process}\label{sec:point_process}

a \emph{Point Process} (or \emph{Point Field}) is a Random Measure
(\S\ref{sec:random_measure}) of the form:
\[
  \mu = \sum_{n=1}^N \delta_{X_n}
\]
where $\delta$ is the Dirac Measure (\S\ref{sec:dirac_measure})

a Point Process is a Random Element (\S\ref{sec:random_variable}) whose values
are ``Point Patterns'' or \emph{Locally-finite Counting Measures}
(\S\ref{sec:counting_measure}) on a Set $S$

for most purposes, ``Point Patterns'' can be thought of as Countable Subsets of
$S$ that have no Limit Points (FIXME: clarify)

Poisson Point Process (\S\ref{sec:poisson_process}) -- spatial generalization of
Poisson Process



% ------------------------------------------------------------------------------
\subsection{Counting Process}\label{sec:counting_process}
% ------------------------------------------------------------------------------

a Stochastic Process with values that are Non-negative, Non-decreasing Integers



\subsubsection{Poisson Process}\label{sec:poisson_process}

Counting occurrences of ``Events'' over time (e.g. traffic accidents,
radioactive decay; cf. Propensity Interpretation of Probability)

Memory-less

Properties of a Poisson Process on the Real Line: the number of Points
(``Events'') in Disjoint Intervals are Independent and have a Poisson
Distribution (\S\ref{sec:poisson_distribution})

cf. Markov Process (\S\ref{sec:markov_process})

Queueing Theory (\S\ref{sec:queueing_theory})

Poisson Point Process (\S\ref{sec:point_process}) -- spatial generalization of
Poisson Process

(Wasserman04 \S 23.3)

\emph{Intensity Function} $\lambda(t)$

\emph{Homogenous Poisson Process}, \emph{Rate} $\lambda \equiv \lambda(t)$

\emph{Waiting Times} $W_n$, \emph{Interrarival (Sojourn) Times} $S_n$

(Thm.) Interrarival Times are IID Random Variables with Exponential Distribution
with Mean $1/\lambda$, i.e. PDF for $s \geq 0$:
\[
  f(s) = \lambda e^{-\lambda s}
\]
and the Waiting Time $W_n \sim Gamma(n, 1/\lambda)$, i.e. has PDF:
\[
  f(w) = \frac{1}{\Gamma(n)}\lambda^n w^{n-1} e^{-\lambda t}
\]
and therefore:
\begin{flalign*}
  E(W_n) & = \frac{n}{\lambda} \\
  V(W_n) & = \frac{n}{\lambda^2} \\
\end{flalign*}




\subsubsection{Binomial Process}\label{sec:binomial_process}

cf. \emph{Bernoulli Process} (\S\ref{sec:bernoulli_process})



\subsubsection{Renewal Theory}\label{sec:renewal_theory}



% ------------------------------------------------------------------------------
\subsection{Random Field}\label{sec:random_field}
% ------------------------------------------------------------------------------

(wiki):

a Stochastic Process where the underlying Index Set does not need to be a Real
of Integer Valued ``Time'', but can be any Topological Space
(\S\ref{sec:topological_space})

for a Probability Space $(\Omega, \mathcal{F}, P)$, an \emph{$X$-valued
  Random Field}, $F$, is a collection of $X$-valued Random Variables indexed by
elements in a Topological Space $T$:
\[
  F = \{ F_t : t \in T \}
\]
where each $F_t$ is an $X$-valued Random Variable

Tensor-valued Random Fields



\subsubsection{Markov Random Field}\label{sec:markov_random_field}

(MRF)



\subsubsection{Gibbs Random Field}\label{sec:gibbs_random_field}

\subsubsection{Conditional Random Field}\label{sec:conditional_random_field}

Machine Learning: Sequence MOdelling



\subsubsection{Gaussian Random Field}\label{sec:gaussian_random_field}

(GRF)

a 1D GRF is a Gaussian Process (\S\ref{sec:gaussian_process})



% ------------------------------------------------------------------------------
\subsection{Empirical Process}\label{sec:empirical_process}
% ------------------------------------------------------------------------------

Empirical Measure (\S\ref{sec:empirical_measure}):

Empirical Distribution Function (\S\ref{sec:empirical_distribution}):

$P_n(A) = \frac{1}{n}\sum_{i=1}^n \delta_{X_i}(A)$

where $\delta$ is the Dirac Measure (\S\ref{sec:dirac_measure})



% ------------------------------------------------------------------------------
\subsection{Dirichlet Process}\label{sec:dirichlet_process}
% ------------------------------------------------------------------------------

Bayesian Inference (\S\ref{sec:bayesian_inference})



% ------------------------------------------------------------------------------
\subsection{Stochastic Simulation}\label{sec:stochastic_simulation}
% ------------------------------------------------------------------------------

approximation of Integrals (\S\ref{sec:numerical_integration})

approximation of Posteriors (\S\ref{sec:posterior_distribution}) in Bayesian
Inference (\S\ref{sec:bayesian_inference})

cf. Stochastic Gradient Descent (SGD \S\ref{sec:sgd})



\subsubsection{Monte Carlo Simulation}\label{sec:monte_carlo}

Monte Carlo Integration (\S\ref{sec:monte_carlo_integration}) -- Monte Carlo
Method applied to Numerical Integration

Importance Sampling (\S\ref{sec:importance_sampling}) can be used to reduce
Variance



\paragraph{Markov Chain Monte Carlo (MCMC)}\label{sec:mcmc}\hfill

Markov Processes (\S\ref{sec:markov_process})

(Wasserman04 \S24.4)

Estimate the Integral $\int h(x) f(x) dx$ using a Markov Chain with Stationary
Distribution $f$

\emph{Random-walk Metropolis-Hastings}

\emph{Independence Metropolis-Hastings} -- Importance-sampling
(\S\ref{sec:importance_sampling})

\emph{Gibbs Sampling} -- higher Dimensions; Multilevel Models
(\S\ref{sec:multilevel_model})



% ------------------------------------------------------------------------------
\subsection{Probability Monad}\label{sec:probability_monad}
% ------------------------------------------------------------------------------

1980 - Giry - \emph{A Categorical Approach to Probability Theory}

collapsing a Probability Distribution (Measure) of Probability Distrubtions to a
Probability Distribution is called the ``Giry Monad'' (TODO)

\url{https://ncatlab.org/nlab/show/Giry+monad}

assigns to a Space of Outcomes $X$ a new Space $P X$ containing Random Outcomes
of $X$

\url{https://golem.ph.utexas.edu/category/2019/05/partial_evaluations.html}
(Perrone 2018):

Partial Evaluations (\S\ref{sec:partial_evaluation}) as Conditional Expectations
(\S\ref{sec:conditional_expectation})



\subsection{Kantorovich Monad}\label{sec:kantorovich_monad}

(Breugel)

\url{https://golem.ph.utexas.edu/category/2019/03/the_kantorovich_monad.html}

Probability Monad on the Category of Metric Spaces; can be described purely in
terms of Combinatorics of Finite Sequences of Elements

2017 - Fritz, Perrone - \emph{A Probability Monad as the Colimit of Spaces of
  Finite Samples}



% ==============================================================================
\section{Statistical Mechanics}\label{sec:statistical_mechanics}
% ==============================================================================

Thermodynamics, ``Irreversibility''

Jarzynski Equality

Crooks' Fluctuation Theorem



% ------------------------------------------------------------------------------
\subsection{Non-equilibrium Statistical Mechanics}
\label{sec:nonequilibrium_statistical_mechanics}
% ------------------------------------------------------------------------------

Jarzynski



% ------------------------------------------------------------------------------
\subsection{Statistical Ensemble}\label{sec:statistical_ensemble}
% ------------------------------------------------------------------------------

a Probability Distribution (\S\ref{sec:probability_distribution}) for the state
of a Physical System



\subsubsection{Thermodynamic Ensemble}\label{sec:thermodynamic_ensemble}



% ==============================================================================
\section{Geometric Probability}\label{sec:geometric_probability}
% ==============================================================================

``\emph{Continuous Combinatorics}'': analogies between \emph{Counting} and
\emph{Measure} (\S\ref{sec:measure}) \fist Combinatorics (Part
\ref{part:combinatorics}), Measure Theory (Part \ref{part:measure_theory})



% ------------------------------------------------------------------------------
\subsection{Integral Geometry}\label{sec:integral_geometry}
% ------------------------------------------------------------------------------

Theory of Measures (\S\ref{sec:measure}) on ``Geometrical Space'' Invariant
under Symmetry Group (\S\ref{sec:symmetry_group}) of that Space

Integral Transforms (\S\ref{sec:integral_transform}) as Equivariant
Transformations from the Function Space of one Geometrical Space to another
(e.g. Radon Transform)



% ------------------------------------------------------------------------------
\subsection{Stochastic Geometry}\label{sec:stochastic_geometry}
% ------------------------------------------------------------------------------



% ==============================================================================
\section{Information Geometry}\label{sec:information_geometry}
% ==============================================================================

Harper09 - \emph{The Replicator Equation as an Inference Dynamic}

Harper09 - \emph{Information Geometry and Evolutionary Game Theory}

\url{http://math.ucr.edu/home/baez/information/}

\url{https://johncarlosbaez.wordpress.com/2017/01/31/biology-as-information-dynamics/}

application of Differential Geometry
(\S\ref{sec:differential_geometry}) techniques to Probability Theory



% ------------------------------------------------------------------------------
\subsection{Statistical Manifold}\label{sec:statistical_manifold}
% ------------------------------------------------------------------------------

Riemannian Manifold (\S\ref{sec:riemannian_manifold}) with the
\emph{Fisher Information Metric} as the Riemannian Metric
(\S\ref{sec:riemannian_metric})



\subsubsection{Fisher Information Metric}\label{sec:fisher_metric}

$I$

Riemannian Metric (\S\ref{sec:riemannian_metric}) for a Statistical Manifold

Score Function (\S\ref{sec:score})

Fisher Information Matrix

Jeffrey's Prior (\S\ref{sec:prior_distribution})

\fist \textbf{Fisher's Fundamental Theorem of Natural Selection},
Quasi-linkage Equilibrium: approximation in the case of Weak Selection
and Weak Epistasis -- Evolutionary Optimization
(\S\ref{sec:evolutionary_optimization}) %FIXME

\url{https://golem.ph.utexas.edu/category/2018/05/the_fisher_metric_will_not_be.html}
