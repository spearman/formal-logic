%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Probability Theory}\label{part:probability_theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\fist Measure Theory (Part \ref{part:measure_theory})

\fist Probabilistic Logic (\S\ref{sec:probabilistic_logic}) --
2013 - \emph{Logic and Probability} -
\url{https://plato.stanford.edu/entries/logic-probability/} (Stanford
Encyclopedia of Philosophy)

\fist cf. Inductive Logic (\S\ref{sec:inductive_logic}) -- makes extensive use
of Probabilistic notions

\emph{Bayesian Epistemology}: Probability as a formal representation of Belief
(cf. Bayesian Inference \S\ref{sec:bayesian_inference})

\emph{Knowledge Representation}: Probability in Artificial Intelligence

\fist cf. Fuzzy Logic (\S\ref{sec:fuzzy_logic})

\fist cf. Quantum Logic (\S\ref{sec:quantum_logic}) --
\emph{Quantum Logic and Probability Theory} (2002) -
\url{https://plato.stanford.edu/entries/qt-quantlog/}

\fist Decision Theory (\S\ref{sec:decision_theory}) --
(wiki): Probabilistic Decision Theory is Sensitive
(\S\ref{sec:sensitivity_analysis}) to \emph{Assumptions} about Probabilities of
Events; Non-probabilistic Decision Rules (\S\ref{sec:decision_rule}), such as
Minimax (\S\ref{sec:minimax}), are \emph{Robust} (\S\ref{sec:robust_statistics})
in that they don't make such Assumptions (FIXME: clarify)

2018 - \emph{A Categorical Look at Random Variables} -
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html} (article):

$\cat{Prob}$ -- Category with Objects as Probability Spaces
(\S\ref{sec:probability_space}) and Morphisms are ``Almost-everywhere-equality
Equivalence Classes'' of Measure-preserving Maps

``Probability Theory is \emph{not} about the Category $\cat{Prob}$, in the sense
that Group Theory or Topology might be said (however incompletely) to be about
the Categories $\cat{Grp}$ or $\cat{Top}$''

\emph{Isomorphic Objects} in $\cat{Prob}$ are \emph{not} the same from the point
of view of \emph{Probability Theory}

example: the Distributions (\S\ref{sec:probability_distribution}) of a Uniform
Random Variable in an Interval, an Infinite Sequence of independent ``coin
flips'', and Brownian Motion $\{B_t : t \geq 0\}$ are \emph{different} things in
Probability Theory, but are Isomorphic in $\cat{Prob}$

the fundamental ``objects'' in Probability Theory are the Morphisms of
$\cat{Prob}$ and those Morphisms are \emph{Random Variables}
(\S\ref{sec:random_variable})

\fist Giry Monads (Probability Monads \S\ref{sec:probability_monad})

\asterism

1933 - Kolmogorov - \emph{Foundations of the Theory of Probability}

\emph{Field of Probabilities} (\emph{$\sigma$-algebra}
(\S\ref{sec:sigma_algebra})



% ==============================================================================
\section{Experiment}\label{sec:experiment}
% ==============================================================================

(wiki): any ``procedure'' that can be infinitely repeated and has a well-defined
Set of possible \emph{Outcomes} (\S\ref{sec:outcome})

when an Experiment is ``performed'' (or ``conducted'') one and only one possible
Outcome ``results'', and any Events (\S\ref{sec:probability_event}), i.e.
Subsets of the Sample Space, containing that Outcome are said to have
``occurred''

a \emph{Random Experiment} has more than one possible Outcome; a Random
Experiment with exactly two possible (Mutually Exclusive) outcomes is called a
\emph{Binomial (Bernoulli) Trial} (\S\ref{sec:bernoulli_trial})

a \emph{Deterministic Experiment} has only a single possible Outcome

a number of repetitions of an Experiment is called a \emph{Composed Experiment},
and the individual repetitions are called ``\emph{Trials}'' (\S\ref{sec:trial})

after conducting many Trials of the same Experiment, the \emph{Relative
  Frequency} (Empirical Probability \S\ref{sec:relative_frequency}) of the
various Outcomes and Events can be assessed

\fist cf. Experimental Unit (Unit of Observational
\S\ref{sec:observational_unit}) -- one Member of a Set of objects that are
initially equivalent until each object is subjected to an ``Exprimental
Treatment''

\fist cf. Data Collection (Data Generating Process
\S\ref{sec:data_generating_process})

\fist cf. Replication (Sampling \S\ref{sec:replication})



% ------------------------------------------------------------------------------
\subsection{Trial}\label{sec:trial}
% ------------------------------------------------------------------------------

an individual repetition of a Composed Experiment



\subsubsection{Binomial Trial}\label{sec:binomial_trial}

or \emph{Bernoulli Trial}

Binomial Distribution (\S\ref{sec:binomial_distribution}); special case:
Bernoulli Distribution (\S\ref{sec:bernoulli_distribution})

Mathematical Formalization: Bernoulli Process (\S\ref{sec:bernoulli_process})

\begin{enumerate}
  \item repeated Trials
  \item each Trial results in an Outcome
  \item Probability of Success is Constant
  \item each Trial is Independent
\end{enumerate}

Number of Successes in $n$ Bernoulli Trials is a \emph{Binomial Random
  Variable} (\S\ref{sec:binomial_random_variable})

\fist Statistical Odds (\S\ref{sec:odds}) -- Ratio of the Probability that an
Event will occur versus the Probability that it will not occur, i.e. a Binomial
Trial



% ------------------------------------------------------------------------------
\subsection{Outcome}\label{sec:outcome}
% ------------------------------------------------------------------------------

a possible result of an Experiment (or Trial)

a Subset of Outcomes in a Sample Space is called an \emph{Event}
(\S\ref{sec:probability_event})

if an actual Outcome is inside an Event, the Event is said to have
``\emph{occurred}''

\fist cf. \emph{Observation} (or \emph{Realization} \S\ref{src:observation}):
the ``Outcome'' of a \emph{Random Variable} (\S\ref{sec:random_variable}), i.e.
the Member of the Random Variable's State Space corresponding to an Outcome
which occurred in the Sample Space of a performed Experiment



% ------------------------------------------------------------------------------
\subsection{Sample Space}\label{sec:sample_space}
% ------------------------------------------------------------------------------

a.k.a. \emph{Possibility Space} or \emph{Event Space}

Set of all possible Outcomes of Statistical \emph{Experiment}
(\S\ref{sec:experiment})

$S$

an \emph{Event} (\S\ref{sec:probability_event}) is a Subset of a Sample Space

the Probability (\S\ref{sec:probability}) $P$ of an Event $E$ is usually defined
such that $P$ satisfies the Kolmogorov Axioms (\S\ref{sec:probability_axioms})
\fist \emph{Unit Measure Axiom}: the total Probability of the Sample Space is
$1 = P(S)$

Random Variable (\S\ref{sec:random_variable}): Function on a Sample Space to a
Measurable \emph{State Space}

a Statistical Model (\S\ref{sec:statistical_model}) $(S,\mathcal{P})$ is a
Sample Space $S$ together with a Set of Probability Distributions
(\S\ref{sec:probability_distribution}) $\mathcal{P}$ on $S$

\fist cf. \emph{Sample} (\S\ref{sec:sample}) -- a Subset of a Population
(\S\ref{sec:population})



% ------------------------------------------------------------------------------
\subsection{Event}\label{sec:probability_event}
% ------------------------------------------------------------------------------

Subset of a Sample Space (\S\ref{sec:sample_space})

if an actual Outcome is inside an Event (Subset), the Event is said to have
``\emph{occurred}''

\emph{Probability} (\S\ref{sec:probability})

(Kolmogorov33) analogy between the \emph{Measure} (\S\ref{sec:measure}) of a Set
and the Probability of an Event

(FIXME: cf. Observation \S\ref{sec:observation})



\subsubsection{Elementary Event}\label{sec:elementary_event}

or \emph{Atomic Event} or \emph{Simple Event} is an Event which contains only a
\emph{single Outcome} in the Sample Space, i.e. it is a Singleton Subset of the
Sample Space

the Unitarity Axiom (\S\ref{sec:probability_axioms}) states that the
Probability that at least one of the Elementary Events in the Entire Sample
Space will Occur is $1$



\subsubsection{Mutually Exclusive Event}\label{sec:mutually_exclusive}

$\sigma$-additivity Axiom (\S\ref{sec:probability_axioms}): the Probability of
a Countable Sequence of Disjoint Sets is equal to the Sum of the individual
Probabilities

a Quasiprobability Distribution (\S\ref{sec:quasiprobability_distribution})
violates the $\sigma$-additivity Axiom by not representing Probabilities of
Mutually Exclusive States



\subsubsection{Independent Event}\label{sec:independent_event}

\fist cf. Independence (\S\ref{sec:independence})

Independent if and only if $P(A \cap B) = P(A) P(B)$

\fist two Events are Independent if and only if their Odds Ratio
(\S\ref{sec:odds_ratio}) equals $1$

in terms of Conditional Probability (\S\ref{sec:conditional_probability}), $A$
and $B$ are Independent if and only if $P(A|B) = P(A)$ or $P(B|A) = P(B)$

an Event is Self-independent if and only if $P(A) = 0$ or $P(A) = 1$

$n$ Events are Independent if:
\[
  P(A_i \cap A_j \cap \cdots \cap A_g) = P(A_i)P(A_j) \cdots P(A_g)
\]
for any distinct Events $i,j,\ldots,g$

Pairwise Independence does not imply $n$-way Independence

$P(A \cap B | C) = P(A|C)P(B|C)$

\fist Conditional Independence (\S\ref{sec:conditional_independence})

note that two Events may be Independent, but not \emph{Conditionally}
Independent, i.e. the Intersection of each Independent Event $A$ and $B$ with
the Conditioning Event $C$ may be Disjoint, making them \emph{Dependent}



% ==============================================================================
\section{Probability}\label{sec:probability}
% ==============================================================================

Probability of an Event (\S\ref{sec:probability_event}) $A$, $P(A)$ is the Sum
of Weights of all Sample Points in $A$

the Probability $P$ of an Event $E$ is usually defined such that $P$ satisfies
the Kolmogorov Axioms (\S\ref{sec:probability_axioms})

(Kolmogorov33) analogy between the \emph{Measure} (\S\ref{sec:measure}) of a Set
and the Probability of an Event

cf. Uncertainty (\S\ref{sec:uncertainty})

cf. \emph{Likelihood} (\S\ref{sec:likelihood}) -- a Probability refers to
variable ``Sample Data'' (\S\ref{sec:sample}) for a fixed Hypothesis
(\S\ref{sec:hypothesis_testing}), while a Likelihood refers to variable
Hypotheses for fixed Data

$\frac{|A|}{|S|}$

$P(A \cup B) = P(A) + P(B) - P(A \cap B)$

$P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) -
P(B \cap C) + P(A \cap B \cap C)$

Corollary: for Disjoint $A_1, A_2, \ldots$:
\[
  P(A_1 \cup A_2 \cup \ldots) = P(A_1) + P(A_2) + \ldots
\]

$P(A_1 \cap A_2 \cap \ldots \cap A_k) = P(A_1) P(A_2 | A_1) P(A_3 |
A_1 \cap A_2) \ldots P(A_k | A_1 \cap A_2 \cap \ldots \cap A_{k-1})$

\textbf{(Thm.) Continuity of Probabilities} \emph{If $A_n \rightarrow A$, then:}
\[
  P(A_n) \rightarrow P(A)
\]
\emph{as $n \rightarrow \infty$}.

cf. \emph{Probability Measure} (\S\ref{sec:probability_measure}),
\emph{Probability Measure Function} (\S\ref{sec:probability_measure_function})

\fist Algorithmic Probability (\S\ref{sec:algorithmic_probability})

(wiki):

two broad categories of \emph{Probability Interpretations}:
\begin{enumerate}
  \item \emph{Physical Probabilities} -- ``Objective'' or \emph{Frequency
    Probabilities} associated with ``Random'' Physical Systems
    \begin{enumerate}
      \item \emph{Frequentist Probability} (``Long-run Probability'') -- defines
        an Event's (\S\ref{sec:probability_event}) Probability as the Limit of
        its Relative Frequency (Empirical Probability
        \S\ref{sec:relative_frequency}) in a large number of Trials
        (\S\ref{sec:trial}); cf. Frequentist Inference
        (\S\ref{sec:frequentist_inference})
      \item \emph{Propensity Probability} (``Single-case Probability'') -- a
        Propensity (\S\ref{sec:propensity}) is not a Relative Frequency but a
        purported ``\emph{cause}'' or explanation of the observed stable
        Relative Frequencies; invokes the Law of Large Numbers
        (\S\ref{sec:large_numbers}) to explain stable \emph{long-run}
        Frequencies as a manifestation of invariant \emph{single-case}
        Probabilities
    \end{enumerate}
  \item \emph{Evidential Probabilities} -- \emph{Bayesian Probability};
    interpretation of Probability as ``reasonable'' \emph{Expectation}
    (\S\ref{sec:expectation}) or ``degree of belief''; assigns Probability to
    Statements even when no Random Process (\S\ref{sec:stochastic_process}) is
    involved; assigns Probability to Hypotheses (\S\ref{sec:hypothesis}), unlike
    Frequentist Inference which Tests Hypotheses without assigning Probability
    \begin{enumerate}
      \item \emph{Classical Interpretation}
      \item \emph{Subjective Interpretation}
      \item \emph{Inductive (Epistemic) Interpretation}
      \item \emph{Logical Interpretation}
      \item \emph{Intersubjective Interpretation}
    \end{enumerate}
\end{enumerate}

2011 - \emph{Interpretations of Probability} -
\url{https://plato.stanford.edu/entries/probability-interpret/}:
\begin{itemize}
  \item \emph{Classical Probability} (Laplace) -- Probability shared equally
    among ``possible outcomes'' (cf. Keynes ``Principle of Indifference'');
    issues include Infinite Probability Spaces and the elimination of
    Irrational-valued Probabilities; extension to Countable Infinities by
    generalizing the Principle of Indifference to the ``Principle of Maximum
    Entropy'' (Jaynes)-- select from the family of all Probability Functions
    consistent with evidence the Function that maximizes Entropy; for
    difficulties with Uncountable Infinities cf. the \emph{Bertrand Paradox}--
    Probabilities may not be Well-defined if the method that produces the Random
    Variable is not Well-defined, cf. \emph{Invariance Condition} (Jaynes): two
    problems with the same evidence should assign the same Probabilities
  \item \emph{Logical Probability} (``Non-deductive Logic''
    \S\ref{sec:probabilistic_logic}) -- generalizes Classical Interpretation to
    assigning unequal weights to possibilities, and Probabilities may be
    computed from asymmetric evidence; generalizes Deductive Logic and its
    notion of Implication to a complete theory of Inference with a notion of
    ``\emph{Degree of Implication}'' that relates Evidence to Hypotheses;
    Deductive Logic is the case where the Confirmation Function takes values 0
    and 1; Carnap-- choice of Language and Confirmation Function are in a sense
    arbitrary
  \item \emph{Subjective Probability} (``Subjective Bayesianism'', cf.
    Subjective Logic \S\ref{sec:subjective_logic}) --
    Probability as a \emph{degree of ``belief''}, cf. Doxastic Logic
    (\S\ref{sec:doxastic_logic}); betting analysis (de Finetti): ``operational''
    definition of Probability as a measurement of belief as a basis of action
    (Ramsey); Utilities (``desirabilities'') of outcomes, Probabilities of
    outcomes, and ``rational Preferences'' can be derived from one another in
    different ways-- (Ramsey26) derives Utilities and Probabilities from
    Preferences alone (``Logic of Partial Belief''); see also ``Expected Utility
    Representation'' (Savage54, Jeffrey66) ``Decision Theory''
    (\S\ref{sec:decision_theory}) in which ``rational choice'' maximizes
    Expected Utility;
    these accounts presuppose a connection between ``desire-like states'' and
    ``belief-like states'' rendered explicit in the connections between
    Preferences and Probabilities;
    \emph{Orthodox Bayesianism}, Conditioning (\S\ref{sec:conditioning});
    compare also Probabilistic Coherence (Regularity)--only \emph{a priori}
    falsehoods are assigned Probability 0--to Consistency in ordinary Doxastic
    Logic; cf. Moore's Paradox
  \item \emph{Frequency Interpretations} -- Relative Frequency (Empirical
    Probability \S\ref{sec:relative_frequency}); identifies the Probability of
    an Outcome with the Frequency of the Outcome in a suitable Sequence of
    ``trials''; differs from the Classical Interpretation in counting only the
    \emph{actual} Outcomes instead of the \emph{possible} Outcomes; Finite
    Frequentism (Venn)-- dominant view in Statistics; problems handling
    single-cases and ``unrepeatable'' events; Hypothetical Frequentism:
    extension of Relative Frequencies of an actual Sequence of ``Trials'' to
    counterfactual, limiting Relative Frequencies in case of an Infinite number
    of Trials; Reference Class Problem: Relative Frequencies must be
    ``Relativised'' to a ``Reference Class'' (this problem may exist for other
    interpretations as well)-- solutions restrict to certain Sequences of
    Outcomes, e.g. (Infinite) ``\emph{Collectives}'' (Von Mises57)--cf. Infinite
    Bernoulli Sequences (\S\ref{sec:bernoulli_sequence})--where a
    \emph{Place-selection} is an effective method of selecting indices of
    Members of a Sequence such that the selection or not of Index $i$ depends
    \emph{at most} on the first $i-1$ Outcomes (``attributes''), with the Axioms
    of Convergence (the limiting Relative Frequency of any Outcome exists) and
    Randomness (the limiting Relative Frequency of each Outcome in a Collective
    $\omega$ is the same in any Infinite Subsequence of $\omega$ determined by
    Place-selection; note that trivial Sequences such as $H,H,H,\ldots$ satisfy
    this ``Randomness'' Axiom; cf. the Principle of Maximum Entropy in Classical
    Probability), Algorithmic Randomness (\S\ref{sec:algorithmic_randomness});
    issues with limiting Relative Frequencies are that they violate Countable
    Additivity and the Domain of Definition is not a Set-field or a
    $\sigma$-algebra (de Finetti72)
  \item \emph{Propensity Interpretations} (Pierce10, Popper57) -- Probability as
    a ``physical'' tendency or disposition of a given ``physical situation'' to
    yield an Outcome of a certain kind, or to yield long-run Relative Frequency
    of such an Outcome; motivated by ``single-case'' Probability attributions
    (e.g. atom decay); distinction between \emph{long-run} and
    \emph{single-case} Propensities (Gillies00); \emph{Humphreys' Paradox}:
    Propensities as measures of ``causal tendencies'' violates Bayes' Theorem
    which allows the reversal of a Conditional Probability-- cf. alternative
    ``Probabilistic Causal Calculus'' (Fetzer81)
  \item \emph{Best-system Interpretations} (Lewis94) -- a Theory of the
    ``Physical Laws'' of the Universe ``optimally balances'' simplicity,
    strength, and ``fit'' (assigning a higher Probability to the ``actual''
    history of the Universe
\end{itemize}

(\url{https://plato.stanford.edu/entries/logic-probability/}):

Probabilistic Semantics (\S\ref{sec:probabilistic_semantics}) for Logical
Consequence Relation yields \emph{Probability Preserving} (dually,
\emph{Uncertainty Propagating}) Deductive Validity (\S\ref{sec:validity}),
rather than Truth Preserving (\S\ref{sec:truth_preservation})

\emph{Probability, Knowledge, and Meta-probability}:
\url{https://www.lesswrong.com/posts/2xmKZu73gZLDEQw7c/probability-knowledge-and-meta-probability}



% ------------------------------------------------------------------------------
\subsection{Probability Axioms}\label{sec:probability_axioms}
% ------------------------------------------------------------------------------

\emph{Kolmogorov Axioms}

the Probability $P$ of an Event $E$ is usually defined such that $P$ satisfies
the Kolmogorov Axioms

\begin{enumerate}
  \item (\emph{Non-negativity}) The Probability of an Event is a Non-negative
    (Finite) Real Number
  \item (\emph{Unit Measure}) The Probability that at least one of the
    Elementary Events in the entire Sample Space will Occur is $1$
  \item (Countable \emph{$\sigma$-additivity}) Any Countable Sequence of
    Disjoint Sets (Mutually Exclusive Events) $E_1, E_2, \ldots$ satisfies:
    \[
      P (\bigcup_{i=1}^\infty = \sum_{i=1}^\infty P(E_i)
    \]
\end{enumerate}

\fist Unit Measure: cf. \emph{Unitarity} in Physics is used as a synonym for
``Consistency'', esp. the condition that the Hamiltonian is bounded from below,
i.e. there is a State of Minimal Energy (the \emph{Ground State} or
\emph{Vacuum State}), which is needed for the Third Law of Thermodynamics to
hold

the Third Axiom is relaxed in Quasiprobability Distributions
(\S\ref{sec:quasiprobability_distribution}); to compensate sometimes they are
allowed to have regions of Negative Probability
(\S\ref{sec:negative_probability}) Density

\fist cf. Probabilistic Logic (\S\ref{sec:probabilistic_logic})

(wiki): note that Axiomatic Probability Theory avoids definition of a
\emph{Random Sequence} (\S\ref{sec:random_sequence})



% ------------------------------------------------------------------------------
\subsection{Law of Total Probability}\label{sec:total_probability}
% ------------------------------------------------------------------------------

For a Countably Inifinite Partition of a Sample Space
(\S\ref{sec:sample_space}), $\{ B_n : n = 1,2,3,\ldots \}$, with each Event
$B_n$ being Measurable (\S\ref{sec:measure}), then for any Event $A$ in the same
Probability Space (\S\ref{sec:probability_space}):
\[
  P(A) = \sum_n P(A \cap B_n)
\]
or equivalently:
\[
  P(A) = \sum_n P(A|B_n) P(B_n)
\]
where terms such that $P(B_n) = 0$ are omitted from the summation.



% ------------------------------------------------------------------------------
\subsection{Conditional Probability}\label{sec:conditional_probability}
% ------------------------------------------------------------------------------

where Event $A$ is known to have occurred:

$P(B|A) = \frac{P(A \cap B)}{P(A)}$ when $P(A) > 0$

$P(A \cap B) = P(A) P(B|A)$ when $P(A) > 0$

$P(A|A) = 1$

note that Conditional Probability is only defined when the Conditioning Event
has a Non-zero (Positive) Probability

$A$ and $B$ are Independent (\S\ref{sec:independent_event}) if and only if
$P(A|B) = P(A)$

\fist Conditional Independence (\S\ref{sec:conditional_independence})

\fist Negative Probability (\S\ref{sec:negative_probability})

(Witten18): Quantum Information Theory doesn't have a good analog to defining a
Conditional Probability Distribution as in Classical Information Theory, but
does have an analog of \emph{Strong Subadditivity of Entropy}
(\S\ref{sec:entropy})



% ------------------------------------------------------------------------------
\subsection{Baye's Theorem}\label{sec:bayes_theorem}
% ------------------------------------------------------------------------------

or \emph{Bayes Rule}

\url{https://arbital.com/p/bayes_rule/?l=1zq}

\emph{Bayesian Inference} (\S\ref{sec:bayesian_inference})

\[
  P(A|B) = \frac{P(A)P(B|A)}{P(B)}
\]

for a Partition $A_1, \ldots, A_k$ of $\Omega$ such that $P(A_i) > 0$ for all
$i$, if $P(B) > 0$ then for $i \in \{1, \ldots, k\}$:
\[
  P(A_i|B) = \frac{
    P(B|A_i)P(A_i)
  }{
    \sum_j P(B|A_j)P(A_j)
  }
\]
where $A_i$ is the \emph{Prior Probability} of $A$ and $P(A_i|B)$ is the
\emph{Posterior Probability} of $A$ (FIXME: what is $A$ here ???)

\fist Relative Entropy (Kullback-Leibler Divergence
\S\ref{sec:relative_entropy})



% ------------------------------------------------------------------------------
\subsection{Independence}\label{sec:independence}
% ------------------------------------------------------------------------------

\emph{Property of Probabilistic Independence}

$P(A \cap B) = P(A)P(B)$

two Random Variables (\S\ref{sec:random_varible}) are \emph{Dependent}
(\S\ref{sec:dependence}) if they do not Satisfy the Property of
Probabilistic Independence:
\[
  P(X \in A, Y \in B) = P(X \in A) P(Y \in B)
\]

\fist cf. Independent Event (\S\ref{sec:independent_event}) --
two Events are Independent if and only if their Odds Ratio
(\S\ref{sec:odds_ratio}) equals $1$

if $X$ and $Y$ are Independent and have Finite Second Moments, then they are
Uncorrelated (\S\ref{sec:correlation}); not all Uncorrelated Variables are
Independent

Tests for Independence (Wasserman04, Ch.15) %TODO



\subsubsection{Conditional Independence}\label{sec:conditional_independence}

$P(A \cap B | C) = P(A|C)P(B|C)$

note that two Events may be Independent, but not \emph{Conditionally}
Independent, i.e. the Intersection of each Independent Event $A$ and $B$ with
the Conditioning Event $C$ may be Disjoint, making them \emph{Dependent}

\fist cf. Conditional Probability (\S\ref{sec:conditional_probability})

\fist Bayesian Networks (\S\ref{sec:bayes_network});
Markov Condition (\S\ref{sec:markov_condition}) -- every Node is Conditionally
Independent (\S\ref{sec:conditional_independence}) of its Non-descendents, given
its Parents

\fist Pairwise Markov Graph (\S\ref{sec:pairwise_markov_graph}) -- encodes a Set
of Pairwise Conditional Independence Relations

\url{http://lesswrong.com/lw/pi/classical_configuration_spaces/}
-- ``Conditional Independence happens when the Joint Probability Distribution
is the Product of the individual Probability Distributions''



% ------------------------------------------------------------------------------
\subsection{Odds}\label{sec:odds}
% ------------------------------------------------------------------------------

an expression of Relative Probabilities: the Odds \emph{in favor} of an Event or
Proposition is the Ratio of the Probability that the Event will occur to the
Probability that it will not occur, i.e. a \emph{Binomial Trial}
(Bernoulli Trial \S\ref{sec:binomial_trial})



\subsubsection{Odds Ratio}\label{sec:odds_ratio}

Statistic (\S\ref{sec:statistic})

quantifies strength of Association (Dependence \S\ref{sec:dependence}) between
two Events

\fist cf. Risk Ratio (\S\ref{sec:risk_ratio}), Risk Difference
(\S\ref{sec:risk_difference})

two Events are Independent if and only if their Odds Ratio equals $1$



\subsubsection{Log Odds Ratio}\label{sec:log_odds}



% ------------------------------------------------------------------------------
\subsection{Negative Probability}\label{sec:negative_probability}
% ------------------------------------------------------------------------------

or \emph{Quasiprobability}

may apply to \emph{Unobservable Events} or \emph{Conditional Probability}
(\S\ref{sec:conditional_probability})

forbidden by the First Kolmogorov Axiom (\S\ref{sec:probability_axioms})

the Third Axiom ($\sigma$-additivity) is relaxed in Quasiprobability
Distributions (\S\ref{sec:quasiprobability_distribution}); to compensate
sometimes they are allowed to have regions of Negative Probability Density,
violating the First Law

Wigner Distribution in Phase Space (Quantum Corrections)



% ==============================================================================
\section{Probability Space}\label{sec:probability_space}
% ==============================================================================

$(\Omega, \Sigma, P)$

A \emph{Probability Space} is a Measure Space (\S\ref{sec:measure_space}) with a
\emph{Probability Measure} (\S\ref{sec:probability_measure}).

\fist cf. Measure-preserving Dynamical Systems
(\S\ref{sec:measure_preserving_system})

$\cat{Prob}$ -- Category with Objects as Probability Spaces and Morphisms are
``Almost-everywhere-equality Equivalence Classes'' of Measure-preserving Maps
--
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html}:
``Probability Theory is not about the Category $\cat{Prob}$''

$\cat{Prob}$ -- Category with Objects as Probability Spaces and Morphisms are
``Almost-everywhere-equality Equivalence Classes'' of Measure-preserving Maps
(\S\ref{sec:measure_preserving_map})

the fundamental ``objects'' of Probability Theory are the \emph{Morphisms} of
$\cat{Prob}$ and these Morphisms are \emph{Random Variables}
(\S\ref{sec:random_variable})



% ------------------------------------------------------------------------------
\subsection{Probability Measure}\label{sec:probability_measure}
% ------------------------------------------------------------------------------

A \emph{Probability Measure} is a Measure (\S\ref{sec:measure}) that assigns the
Value $1$ to the entire Measure Space (making it a Probability Space).

cf. \emph{Probability} (\S\ref{sec:probability})

\fist a \emph{Probability Distribution} (\S\ref{sec:probability_distribution})
is the Pushforward Measure (\S\ref{sec:pushforward_measure}) of a Random
Variable (\S\ref{sec:random_variable})

\emph{Choquet Simplex} (\S\ref{sec:choquet_theory}) -- any Point in a Choquet
Simplex is represented by a unique Probability Measure



\subsubsection{Probability Measure Function}
\label{sec:probability_measure_function}

\subsubsection{Kullback-Leibler Divergence}\label{sec:kullback_leibler}

can be used to characterize Relative Entropy (\S\ref{sec:relative_entropy}),
Randomness (\S\ref{sec:statistical_randomness})

defined between PDFs (\S\ref{sec:pdf})

can be used to show Consistency of MLE (\S\ref{sec:mle})



% ==============================================================================
\section{Random Variable}\label{sec:random_variable}
% ==============================================================================

A general \emph{Random Element} is a Measurable Function
(\S\ref{sec:measurable_function}) on a Sample Space (\S\ref{sec:sample_space})
mapping Outcomes (\S\ref{sec:outcome}) in the Sample Space to some other Set of
Values called the \emph{State Space}:
\[
  X : \Omega \rightarrow E
\]
The Type (\S\ref{sec:datatype}) of a State Space is called a \emph{Statistical
  Data Type} (\S\ref{sec:statistical_data_type}).

A Realization of a Random Element resulting from a specific Outcome is called an
\emph{Observation} (\S\ref{sec:observation}).

A \emph{Random Variable} is a Random Element where $E = \reals$ is the Real Line
(\S\ref{sec:real_line}).

other types of Random Elements:
\begin{itemize}
  \item Random Measure (\S\ref{sec:random_measure})
  \item ...
\end{itemize}

\fist cf. \emph{Statistical Unit} (\S\ref{sec:statistical_unit}) -- one Member
of a Set of entities being analyzed, providing the ``material source'' for an
abstract Random Variable (wiki)

\fist a \emph{Statistic} (\S\ref{sec:statistic}) is an Observable Random
Variable defined as a Function of a Random Variable constituting a Random Sample
(IID \S\ref{sec:random_sample})

Discrete Random Variable (\S\ref{sec:discrete_random_variable})

Continuous Random Variable (\S\ref{sec:continuous_random_variable})

a \emph{Probability Distribution} (\S\ref{sec:probability_distribution})
is the Pushforward Measure (\S\ref{sec:pushforward_measure}) of $X$

such a distribution records all the individual Probabilities $P(X = x)$,
sometimes written $p_X(x)$

a \emph{Dependence} (Association \S\ref{sec:association}) between two Random
Variables (``Bivariate Data'' \S\ref{sec:bivariate_distribution}) is any
``Statistical Relationship'' (which may or may not be Causal)

Wasserman04 Ch.2

two Random Variables $X$ and $Y$ are \emph{Independent}, sometimes denoted
$X \coprod Y$, if they Satisfy the Property of \emph{Probabilistic Independence}
(\S\ref{sec:independence}):
\[
  P(X \in A, Y \in B) = P(X \in A) P(Y \in B)
\]
that is, for every $x$ and $y$, the Events $\{X \leq x\}$ and $\{Y \leq y\}$ are
Independent Events (\S\ref{sec:independent_event}); in terms of CDFs:
\[
  \forall x,y\ F_{X,Y}(x,y) = F_X(x)F_Y(y)
\]
or in terms of Probability Mass or Density Functions (if they exist):
\[
  \forall x,y\ f_{X,Y}(x,y) = f_X(x)f_Y(y)
\]

\textbf{Thm.} \emph{If the Range of Random Variables $X$ and $Y$ is a (possibly
  Infinite) Rectangle and $f_{X,Y}(x,y) = g(x)h(y)$ for arbitrary Functions $g$
  and $h$, then $X$ and $Y$ are Independent.}

\fist Relative Entropy (\S\ref{sec:relative_entropy}), Mutual Information
(\S\ref{sec:mutual_information})

cf. \emph{Statistical Randomness} (\S\ref{sec:statistical_randomness}),
\emph{Algorithmic Randomness} (\S\ref{sec:algorithmic_randomness})

a Discrete Random Variable $Y = r(X)$ that is a Transformation of a Discrete
Random Variable $X$, the Probability Mass Function is given by:
\[
  f_Y(y) = P(Y = y) = P(r(X) = y) = P(X \in r^{-1}(y))
\]
for Continuous Random Variables, the CDF is defined as the Integral of the PDF
$f_X(x)$ over the Set $A_y = \{x : r(x) \leq y\}$:
\[
  F_Y(y) = \int_{A_y} f_X(x) dx
\]
and the PDF can be defined as $f_Y(y) = F_Y'(y)$

for Continuous $X$ with CDF $F_X$, $Y = F_X(X)$ is called a \emph{Probability
  Integral Transform} (\S\ref{sec:probability_integral_transform}) and has a
Standard Uniform Distribution

\asterism

\emph{A Categorical Look at Random Variables} -
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html}:

$\cat{Prob}$ -- Category with Objects as Probability Spaces
(\S\ref{sec:probability_space}) and Morphisms are ``Almost-everywhere-equality
Equivalence Classes'' of Measure-preserving Maps
(\S\ref{sec:measure_preserving_map})

the fundamental ``objects'' of Probability Theory are the \emph{Morphisms} of
$\cat{Prob}$ and these Morphisms are \emph{Random Variables}

a Random Variable is defined as a Measurable Map
(\S\ref{sec:measurable_function}):
\[
  X : \Omega \rightarrow E
\]
where $(\Omega,\mathbb{P})$ is a Probability Space and $E$ is an arbitrary
Measurable Space

***

MIT 6.041SC Lec. 5 - \url{https://www.youtube.com/watch?v=3MOahpLxj6A}:

Functions of Random Variables are also Random Variables

Probability Mass Function (\S\ref{sec:pmf}) $p_X$ assigns
Probabilities to Elements of $x \in E$:
\[
  p_X(x) = P(X = x)
\]

$p_X(x) \geq 1$

$\sum_x p_X(x) = 1$

Expected Value (\S\ref{sec:expected_value}) of a Random Variable is a kind of
``average'' where Probabilities are treated like ``frequencies'':
\[
  E[X] = \sum_x xp_X(x)
\]
for a Function of a Random Variable $Y = g(X)$:
\[
  E[Y] = \sum_x g(x)p_X(x)
\]

for a PMF that is Symmetric around a certain point, that point is the Expected
Value



% ------------------------------------------------------------------------------
\subsection{Observation}\label{sec:observation}
% ------------------------------------------------------------------------------

An \emph{Observation} (\emph{Observed Value}, \emph{Measurement},
\emph{Realization}, or \emph{Random Variate}) is the Element of a Random
Variable's State Space corresponding to the actual Outcome (\S\ref{sec:outcome})
resulting from performing an Experiment (\S\ref{sec:experiment}).

\fist A \emph{Data Generating Process} (\S\ref{sec:data_generating_process})
is a possibly unspecified \emph{Probabilistic (Statistical) Model}
(\S\ref{sec:statistical_model}) governing the ``Generation'' of Observed Data.
The \emph{Level of Measurement} (\S\ref{sec:measurement_level}) is a
classification of the \emph{Statistical Data Type}
(\S\ref{sec:statistical_data_type}) of a State Space.

\fist A \emph{(Statistical) Population} (\S\ref{sec:population}) is a totality
of Observations. A \emph{Statistical Sample} (\S\ref{sec:sample}) is
a Subset of a Population selected by a definite \emph{Sampling Procedure}
(\S\ref{sec:sampling}). A \emph{``Data Point''} is an Observation of a
\emph{Statistical Unit} (\S\ref{sec:statistical_unit}) in the Statistical
Sample. A \emph{Statistic} (\S\ref{sec:statistic}) is an Observable Random
Variable defined as a Function of a Random Variable constituting a Random
Sample.

\fist \emph{Statistical Inference} (\S\ref{sec:inferential_statistics}) is the
use of Sample Data to \emph{Infer} (cf. Logical Inference
\S\ref{sec:logical_inference}, Inference Rules \S\ref{sec:inference_rule}) the
Distribution (\S\ref{sec:probability_distribution}) that \emph{Generated}
(\S\ref{sec:data_generating_process}) the Data.

\fist \emph{Observational Error} (\emph{Measurement Error}
\S\ref{sec:observational_error}) is the
difference between an Observed Value (Random Variate) and the ``true'' Value;
a \emph{Statistical Error} (\S\ref{sec:error}) is the difference between an
Observed Value and its \emph{Expected Value};
the \emph{Residual} (\S\ref{sec:residual}) of an Observed Value is the
difference between the Observed Value and the \emph{Estimated}
(\S\ref{sec:estimation_theory}) Value

\fist Multivariate Statistics (\S\ref{sec:multivariate_statistics}) --
\emph{simultaneous} Observation and Analysis of more than one Outcome Variable
(Random Vector \S\ref{sec:random_vector})

\fist Curve Fitting (\S\ref{sec:curve_fitting}), Regression Analysis
(\S\ref{sec:regression_analysis}): the process of constructing a Curve (or
Function) that has the ``best Fit'' to a Series of Data Points (Observations),
possibly subject to constraints

\fist cf. \emph{Observable} (\S\ref{sec:observable})



% ------------------------------------------------------------------------------
\subsection{Expected Value}\label{sec:expected_value}
% ------------------------------------------------------------------------------

The \emph{Expected Value}, \emph{Expectation}, or \emph{Mean} (First Raw Moment
\S\ref{sec:moment}/Cumulant \S\ref{sec:cumulant}) of a Random Variable is a kind
of ``average'' where Probabilities are treated like ``frequencies''. (FIXME:
clarify)

as an Estimate (\S\ref{sec:estimation_theory}) of $X$, the Expected Value $E[X]$
minimizes Squared Error (\S\ref{sec:error}); cf. the Median (\S\ref{sec:median})
minimizes Absolute Error

note that $E(X + Y) = E(X) + E(Y)$, but not for $m(X+Y)$

\fist Sample Mean (Estimator \S\ref{sec:sample_mean}) -- minimizes Squares of
the Residuals;
by the Law of Large Numbers (\S\ref{sec:large_numbers}), the Arithmetic Mean
Converges to the Expected Value as the Sample Size gets larger

(Kolmogorov33) analogy between the \emph{Expectation} of a Random Variable, and
\emph{Lebesgue Integration} (\S\ref{sec:lebesgue_integral})

For a Random Variable $X$ defined on Probability Space $(\Omega,\Sigma,P)$, the
Expected Value $\mu_X = E[X]$ of $X$ is defined as the Lebesgue Integral:
\[
  \mu_X = E[X] = \int_\Omega X(\omega) dP(\omega)
\]

In terms of the Cumulative Distribution Function (\S\ref{sec:cdf}) $F_X$ of $X$
and a Radon Integral (\S\ref{sec:radon_integral}):
\[
  \mu_X = E[X] = \int\limits_{-\infty}^{\infty} x dF_X(x)
\]

For Discrete Random Variable $X$ with Probability Mass Function
(\S\ref{sec:pmf}) $f_X(x)$, the Expected Value of $X$ is:
\[
  E[X] = \sum_x x f_X(x)
\]
For a PMF that is Symmetric around a certain point, that point is the Expected
Value.

For a Continuous Random Variable $X$ with Probability Density Function
(\S\ref{sec:pdf}) $f_X(x)$, the Expected Value of $X$ is:
\[
  E[X] = \int x f(x) dx
\]

note that some Distributions have no Expected Value, e.g. the Cauchy
Distribution (\S\ref{sec:cauchy_distribution})

for Linear Function $g$:
\[
  E[g(X)] = g(E[X])
\]

Expectations of Constants (i.e. as ``degenerate'' Random Variables) are just
the Constants themselves: $E[a] = a$

Expectations of Random Variables multiplied by Constant is the Constant
multiplied by the Expectation of the Random Variable:
\[
  E[aX] = aE[X]
\]

Expectation of a Random Variable with the addition of a Constant is the
Constant added to the Expectation of the Random Variable:
\[
  E[X + b] = E[X] + b
\]

for a Function of a Random Variable $Y = g(X)$:
\[
  E[Y] = \sum_x g(x) p_X(x)
\]
%FIXME: is this only for discrete random variables ???

For Random Variable $X$ with Probability Density Function $f(x)$, the
Expected Value of a Measurable Function
(\S\ref{sec:measurable_function}) of $X$, $g(X)$, is:
\[
  \mu_{g(X)} = E[g(X)] = \int\limits_{-\infty}^{\infty} g(x) f(x) dx
\]

For Joint Probability Density Function:
\[
  E[X Y] = \int\int x y j(x,y) dx dy
\]
\fist Note that $E[X Y]$ is not necessarily equal to $E[X] E[Y]$, see Covariance
(\S\ref{sec:covariance}).

For $X$ and $Y$ Independent (\S\ref{sec:independence}), $E[X,Y] = E[X] E[Y]$

If $a$ and $b$ are Constants, then $E[aX + b] = a E[X] + b$

$E [g(X) \pm h(X)] = E[g(X)] \pm E[h(X)]$

$E [g(X,Y) \pm h(X,Y)] = E[g(X,Y)] \pm E[h(X,Y)]$

Wasserman04 Ch.3

\textbf{Thm.} for $X_1, \ldots, X_n$ Random Variables and $a_1, \ldots, a_n$
Constants:
\[
  E\Big(\sum_i a_i X_i\Big) = \sum_i a_i E(X_i)
\]

\textbf{Thm.} for $X_1, \ldots, X_n$ Independent Random Variables:
\[
  E\Big(\prod_{i=1}^n X_i\Big) = \prod_i E(X_i)
\]

\emph{Conditional Expectation} -- $E(X|Y)$ is a Random Variable whose Value is
$E(X|Y = y)$ when $Y = y$

\textbf{Thm.} (Rule of Iterated Expectations) \emph{
  For Random Variables $X$ and $Y$, assuming Expectations exist, then:
  \[
    E(E(Y|X)) = E(Y) \quad\quad E(E(X|Y)) = E(X)
  \]
  or generally for any Function $r(x,y)$:
  \[
    E(E(r(X,Y)|X)) = E(r(X,Y))
  \]
}

Moment-generating Function (\S\ref{sec:moment_generating_function}):
$M_X(t) := E(e^{tX})$ for $t \in \reals$

the Variance (Expected Value of the Squared Deviation \S\ref{sec:deviation}) of
a Random Variable $X$ is equal to:
\begin{align*}
  \sigma^2 = V(X) & = E(X - E(X))^2   \\
                  & = E(X^2) - E(X)^2 \\
                  & = \int(x - E(X))^2 dF(x) \\
\end{align*}
assuming the Expectation exists

$V(Y) = E(V(Y|X)) + V(E(Y|X))$

\textbf{Thm.} \emph{Covariance (\S\ref{sec:covariance}) Satisfies:
  \[
    Cov(X,Y) = E(XY) - E(X)E(Y)
  \]
}

example of Probability as a special case of Expectation (Wasserman Ch. 3): for
Event $A$ with Indicator Function $I_A(x)$:
\[
  E(I_A(X)) = \int I_A(x)f_X(x)dx = \int_A f_X(x) dx = P(X \in A)
\]

the \emph{$k^{th}$ Moment} (\S\ref{sec:moment}) of $X$ is defined as $E(X^k)$
assuming that $E(|X|^k) < \infty$

\emph{Cauchy-Schwarz Inequality} (\S\ref{sec:cauchy_schwarz}):
\[
  E|XY|^2 \leq \sqrt{E(X^2)E(Y^2)}
\]
where $X$ and $Y$ have Finite Variances

\textbf{Thm.} (Jensen's Inequality) \emph{
  If $g$ is a Convex Function, then:
  \[
    E(g(X)) \geq g(E(X))
  \]
  and if $g$ is Concave, then:
  \[
    E(g(X)) \leq g(E(X))
  \]
}
examples: $E(X^2) \geq E(X)^2$; if $X$ is Positive, then $E(1/X) \geq 1/E(X)$;
since $\log$ is Concave $E(\log X) \leq \log E(X)$



\subsubsection{Law of Large Numbers}\label{sec:large_numbers}

the Sample Mean (\S\ref{sec:sample_mean})
$\overline{X}_n = \frac{1}{n}\sum_i X_i$ of a Sequence of Random Variables
$X_1, \ldots, X_n$ \emph{Converges in Probability}
(\S\ref{sec:stochastic_convergence}) to the Expectation
(\S\ref{sec:expected_value}) $\mu = E(X_i)$ as $n \rightarrow \infty$, i.e.
$\overline{X}_n$ is close to $\mu$ with high Probability

\textbf{Thm.} (Weak Law of Large Numbers) \emph{If $X_1, \ldots, X_n$ are IID
  (\S\ref{sec:iid}), then:
  \[
    \overline{X}_n \xrightarrow{P} \mu = E(X_1)
  \]
}
(note that since $X_i$ are IID, $\mu$ is identical for all $X_i$)

\textbf{Thm.} (Strong Law of Large Numbers) \emph{If $X_1, \ldots, X_n$ are IID,
  and $\mu = E(|X_1|) < \infty$, then $\overline{X}_n \xrightarrow{as} \mu$}

\fist cf. Law of Iterated Logarithm (\S\ref{sec:iterated_logarithm})

\fist \emph{Propensity Probability} (``Single-case Probability''
\S\ref{sec:propensity}) -- invokes the Law of Large Numbers to explain stable
\emph{long-run} Relative Frequencies (\S\ref{sec:relative_frequency}) as a
manifestation of invariant \emph{single-case} Probabilities

\fist cf. Asymptotic Theory (Large Sample Theory \S\ref{sec:asymptotic_theory})



\subsubsection{Markov's Inequality}\label{sec:markovs_inequality}

\textbf{Thm.} (Markov's Inequality) \emph{
  Given a Random Variable $X$ with Expectation $E(X)$, for any $t > 0$:
  \[
    P(X > t) \leq \frac{E(X)}{t}
  \]
}



\subsubsection{Conditional Expectation}\label{sec:conditional_expectation}

or \emph{Conditional Mean}

\fist Regression Analysis (\S\ref{sec:regression_analysis}) commonly Estimates
the Conditional Expectation of a Dependent Variable given an Independent
Variable



\subsubsection{Risk}\label{sec:risk}

the Expected Value of an ``undesirable'' Outcome (\emph{Absolute Risk})



\paragraph{Risk Ratio}\label{sec:risk_ratio}\hfill

or \emph{Relative Risk}

cf. Odds Ratio (\S\ref{sec:odds_ratio})



\paragraph{Risk Difference}\label{sec:risk_difference}\hfill

cf. Odds Ratio (\S\ref{sec:odds_ratio})



% ------------------------------------------------------------------------------
\subsection{Covariance}\label{sec:covariance}
% ------------------------------------------------------------------------------

$Cov(X,Y) = E [(X - \mu_X)(Y - \mu_Y)]$

$Cov(X,X)$ -- Variance (\S\ref{sec:variance})

\fist cf. Causation (\S\ref{sec:causation})

$n$ Discrete Samples:
\[
  \sigma_{X,Y} = Cov(X,Y) = E [(X - \mu_X)(Y - \mu_Y)] =
    \frac{1}{n} \sum_{i=1}^n (x_i - \mu_X) (y_i - \mu_Y)
\]

Continuous:
\[
  Cov(X,Y) = E [(X - \mu_X)(Y - \mu_Y)] =
  \int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty}
  (x - \mu_X) (y - \mu_Y) f(x,y) dx dy
\]
where $f(x,y)$ is the Joint Probability Distribution
(\S\ref{sec:joint_probability}) of $X$, $Y$

\fist Sample Covariance (\S\ref{sec:sample_covariance})

\textbf{Thm.} \emph{Covariance Satisfies:
  \[
    Cov(X,Y) = E(XY) - E(X)E(Y)
  \]
}

the Correlation (\S\ref{sec:correlation}) is defined in terms of the Covariance:
\[
  \rho_{X,Y} = \frac{Cov(X,Y)}{\sigma_X \sigma_Y}
\]
if $X$ and $Y$ are Independent (\S\ref{sec:dependence}), then
$Cov(X,Y) = \rho = 0$



\subsubsection{Variance}\label{sec:variance}

the \emph{Variance} is the Expected Value of the Squared Deviation (Error
\S\ref{sec:error}) of a Random Variable

$\sigma_X^2 = Cov(X,X)$

the \emph{Sum of Squared Deviations} (\S\ref{sec:sum_squared_deviation})
Estimates (\S\ref{sec:estimation_theory}) the Variance when scaled for the
number of \emph{Degrees of Freedom} (\S\ref{sec:statistical_freedom})

\emph{Overfitting} (Multiple Regression \S\ref{sec:multiple_regression}) -- too
many Covariates, high Variance

\fist ANalaysis Of VAriance (ANOVA \S\ref{sec:variance_analysis}) --
Variance is defined as either the Expected Value of the
Squared Deviation from the Mean (SDM \S\ref{sec:sdm}), considering a theoretical
Distribution, or its Sample Mean (\S\ref{sec:sample_mean})

Second Central Moment (\S\ref{sec:moment})/Second Cumulant
(\S\ref{sec:cumulant})

Variances are always Non-negative

the Variance of a Random Variable $X$ is equal to:
\begin{align*}
  \sigma^2 = V(X) & = E(X - E(X))^2   \\
                  & = E(X^2) - E(X)^2 \\
                  & = \int(x - E(X))^2 dF(x) \\
\end{align*}
assuming the Expected Value (\S\ref{sec:expected_value}) $E(\cdot)$ exists

Discrete Random Variable $X$:
\[
  Var(X) = \sigma_X^2 = \sum_{i=1}^n f(x_i) (x_i - \mu)^2 = \sum_{i=1}^n
  f(x_i) x_i^2 - \mu^2
\]
where $\mu = \sum_{i=1}^n f(x_i) x_i$

Continuous Random Variable $X$:
\[
  Var(X) = \sigma_X^2 = \int (x - \mu)^2 f(x) dx = \int x^2 f(x) dx -
  \mu^2
\]
where $\mu = \int x f(x) dx$

For Random Variables $X$, $Y$ with Joint Probability Distribution
$f(x,y)$ and $a$, $b$, $c$ are Constants, then:
\[
  \sigma^2_{a X + b Y + c} = a^2 \sigma^2_X + b^2 \sigma^2_Y + 2ab
  \sigma_{X Y}
\]

\fist Estimator: Sample Variance (\S\ref{sec:sample_variance})

\emph{Conditional Variance} $V(X|Y)$

$V(Y) = E(V(Y|X)) + V(E(Y|X))$



\subsubsection{Covariance Matrix}\label{sec:covariance_matrix}

or \emph{Variance-Covariance Matrix}

Positive semi-definite (\S\ref{sec:positive_semidefinite})

the Inverse of the Covariance Matrix is called the \emph{Precision Matrix}



% ------------------------------------------------------------------------------
\subsection{Skewness}\label{sec:skewness}
% ------------------------------------------------------------------------------

Asymmetry %FiXME

``lopsided-ness''

Third Central Moment (\S\ref{sec:moment})/Third Cumulant (\S\ref{sec:cumulant})



% ------------------------------------------------------------------------------
\subsection{Kurtosis}\label{sec:kurtosis}
% ------------------------------------------------------------------------------

Fourth Central Moment (\S\ref{sec:moment})

 Measure of the ``heaviness'' of the tail of a Distribution



% ------------------------------------------------------------------------------
\subsection{Dependence}\label{sec:dependence}
% ------------------------------------------------------------------------------

or \emph{Association}

any ``\emph{Statistical Relationship}'' between two Random Variables
(``Bivariate Data'')

may or may not be Causal -- (wiki): the main difference between
\emph{Causal Inference} (\S\ref{sec:causal_inference}) and an Inference of
\emph{Association} is that the former analyzes the ``response'' of the ``effect
variable'' when the Cause is changed

Random Variables are \emph{Dependent} if they do not Satisfy the Property of
\emph{Probabilistic Independence} (\S\ref{sec:independence})

\fist Regression Analysis (\S\ref{sec:regression_analysis}) -- Estimation
(\S\ref{sec:estimation_theory}) of Relations in Multivariate Data
(\S\ref{sec:random_vector})

\fist a \emph{Structural Assumption} is a Model-baesd Statistical Assumption
(\S\ref{sec:statistical_assumption}) about the Functional Dependence between
Variables in a Statistical Model



\subsubsection{Correlation}\label{sec:statistical_correlation}

$\rho$

measure of how close two Random Variables are to having a \emph{Linear
  Relationship}

\fist cf. Linear Regression (\S\ref{sec:linear_regression})

\[
  \rho_{X,Y} = \frac{Cov(X,Y)}{\sigma_X \sigma_Y}
\]
where $Cov(X,Y)$ is the Covariance (\S\ref{sec:covariance})

if $X$ and $Y$ are Independent (\S\ref{sec:dependence}) and have Finite Second
Moments, then they are Uncorrelated; not all Uncorrelated Variables are
Independent

if $X$ and $Y$ are Independent, then $Cov(X,Y) = \rho = 0$

\fist Correlation Coefficient (\S\ref{sec:correlation_coefficient})

(wiki):




\paragraph{Correlation Coefficient}\label{sec:correlation_coefficient}\hfill

\emph{Pearson Product-moment Correlation Coefficient}

$\rho_{xy} = \frac{\sigma_{xy}}{\sigma_x \sigma_y}$



% ------------------------------------------------------------------------------
\subsection{Moment-generating Function}\label{sec:moment_generating_function}
% ------------------------------------------------------------------------------

$M_X(t) = E(e^{tX}) = \int e^{tx} dF(x)$ for $t \in \reals$

the Cauchy Distribution (\S\ref{sec:cauchy_distribution}) has no
Moment-generating Function

the Cumulant-generating Function (\S\ref{sec:cumulant_generating_function}) is
the Natural Logarithm of the Moment-generating Function

\fist Laplace Transform (\S\ref{sec:laplace_transform})
%FIXME: explain relation

cf. Characteristic Function (\S\ref{sec:characteristic_function}) --
if a Random Variable has a Moment-generating Function then the Characteristic
Function can be extended to the Complex Plane



% ------------------------------------------------------------------------------
\subsection{Cumulant-generating Function}
\label{sec:cumulant_generating_function}
% ------------------------------------------------------------------------------

Natural Logarithm of the Moment-generating Function



% ------------------------------------------------------------------------------
\subsection{Characteristic Function}\label{sec:characteristic_function}
% ------------------------------------------------------------------------------

for a Scalar Random Variable $X$, the \emph{Characteristic Function} is the
Expected Value of $e^{itX}$ where $i$ is the Imaginary Unit and $t \in \reals$
is the Argument of the ``Characteristic Function'' $\varphi_X : \reals
\rightarrow \comps$:
\[
  \varphi_X(t) = E[e^{itX}] = \int_\reals e^{itx} dF_X(x)
\]
where $F_X$ is the Cumulative Distribution Function (\S\ref{sec:cdf}) of $X$ and
the Integral is a Riemann-Sieltjes Integral (TODO: xref)

like the Cumulative Distribution Function, completely determines the behavior
and properties of the Probability Distribution

cf. Moment-generating Function (\S\ref{sec:moment_generating_function}) --
the Characteristic Function always exists even when the Moment-generating
Function and Probability Density Function (\S\ref{sec:pdf}) do not exist;
if a Random Variable has a Moment-generating Function then the Characteristic
Function can be extended to the Complex Plane

if the Random Variable admits a Probability Density Function then the
Characteristic Function is the Fourier Transform (\S\ref{sec:fourier_transform})
of the Probability Density Function and vice versa

\fist cf. Indicator Functions (\S\ref{sec:indicator_function})



% ------------------------------------------------------------------------------
\subsection{Discrete Random Variable}\label{sec:discrete_random_variable}
% ------------------------------------------------------------------------------

State Space is a Countable Set

has a Cumulative Distribution Function (\S\ref{sec:cdf}) that is Piecewise
Constant (\S\ref{sec:step_function})

\fist Discrete Probability Distributions (\S\ref{sec:discrete_probability})



\subsubsection{Probability Mass Function (PMF)}\label{sec:pmf}

for a Discrete Random Variable $X$, the \emph{Probability Mass Function} is
defined as:
\[
  f_X(x) = P(X = x)
\]
and has the Properties:
\begin{enumerate}
  \item $f_X(x) \geq 0$
  \item $\sum_x f_X(x) = 1$
\end{enumerate}

characterizes a Discrete Probability Distribution
(\S\ref{sec:discrete_probability})

related to the CDF (\S\ref{sec:cdf}) $F_X$ of $X$ by:
\[
  F_X(x) = P(X \leq x) = \sum_{x_i \leq x} f_X(x_i)
\]

for a Probability Mass Function that is Symmetric around a certain point, that
point is the Expected Value (\S\ref{sec:expected_value})



\paragraph{Probability Generating Function}
\label{sec:probability_generating_function}\hfill

(Ordinary) Generating Function (\S\ref{sec:generating_function})--i.e. Formal
Power Series representation--of the Probability Mass Function of a Discrete
Random Variable



\subsubsection{Binomial Random Variable}\label{sec:binomial_random_variable}

Binomial (Bernoulli) Trial (\S\ref{sec:binomial_trial})

Binomial Distribution (\S\ref{sec:binomial_distribution})

$X \sim B(n,p)$

Probability Mass Function:
\[
  f(k,n,p) = P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}
\]
for $k = 0,1,2, \ldots, n$



% ------------------------------------------------------------------------------
\subsection{Continuous Random Variable}\label{sec:continuous_random_variable}
% ------------------------------------------------------------------------------

has Probability $0$ of assuming a particular Value

\fist Continuous Probability Distributions (\S\ref{sec:continuous_probability})



\subsubsection{Probability Density Function (PDF)}\label{sec:pdf}

\emph{Probability Density Function} $f_X(x)$ of a Continuous Random Variable $X$
has the Properties:
\begin{enumerate}
  \item $\forall x \in \reals, f_X(x) \geq 0$
  \item $\int\limits_{-\infty}^{\infty} f_X(x) dx = 1$
  \item $\forall a \leq b, P (a < X < b) = \int\limits_a^b f(x) dx$
\end{enumerate}
the CDF (\S\ref{sec:cdf}) $F_X$ of $X$ can be defined in terms of $f_X$ as:
\[
  F_X(x) = \int_{-\infty}^x f_X(t)dt
\]
i.e. the CDF of a Continuous Random Variable gives the Area under the PDF from
$-\infty$ to $x$, and $f_X(x) = F'_X(x)$ at all Points $x$ at which $F_X$ is
Differentiable

characterizes a Continuous Probability Distribution
(\S\ref{sec:continuous_probability})

for a Random Variable that admits a Probability Density Function, the
Characteristic Function (\S\ref{sec:characteristic_function}) of the Random
Variable is the Fourier Transform (\S\ref{sec:fourier_transform}) of its
Probability Density Function and vice versa

\fist Probability Amplitude (Quantum Systems \S\ref{sec:probability_amplitude}):
Complex Number with Modulus Squared representing a Probability Density

\fist Kullback-Leibler Divergence (\S\ref{sec:kullback_leibler})



\paragraph{Normalizing Constant}\label{sec:normalizing_constant}\hfill

used to reduce any Probability Function to a Probability Density Function with
total Probability $1$

%FIXME: same concept as Normalizing Constant for bayesian inference ?



% ------------------------------------------------------------------------------
\subsection{Random Sequence}\label{sec:random_sequence}
% ------------------------------------------------------------------------------

(wiki):

a Random Sequence is a special case of \emph{Stochastic Process}
(\S\ref{sec:stochastic_process}) where the Index Set is some Subset of the
Integers

cf. Random Vector (\S\ref{sec:random_vector})

note that Axiomatic Probability Theory (\S\ref{sec:probability_axioms})
avoids definition of a \emph{Random Sequence}

paradigms:
\begin{itemize}
  \item \emph{Frequency / Measure-theoretic} approach -- (Mises-Church); the
    Sets ``Coding'' Frequency-based Stochastic properties are special kinds of
    Null Sets (\S\ref{sec:null_set}) (Martin-L\"of)
  \item \emph{Complexity / Compressibility} approach -- (Kolmogorov-Chatin)
    Algorithmic (Kolmogorov) Complexity (\S\ref{sec:algorithmic_complexity})
  \item \emph{Predictability} approach -- (Schnorr) Constructive Martingales
    (\S\ref{sec:martingale})
\end{itemize}

Bernoulli Sequence (\S\ref{sec:bernoulli_sequence})

\emph{Subsequence Selection Criterion} -- \emph{Mises-Church Randomness}: any
Recursive Function which having read the first $N$ elements of the Sequence
decides if it wants to select element $N+1$; cf. Algorithmic Randomness
(\S\ref{sec:algorithmic_randomness})

\emph{Reference Class Problem}: Relative Frequencies must be ``Relativised'' to
a ``Reference Class'' (other interpretations of Probability may have this
problem as well)--

solutions restrict to certain Sequences of Outcomes, e.g. (Infinite)
``\emph{Collectives}'' (Von Mises57)--cf. Infinite Bernoulli Sequences --where a
\emph{Place-selection} is an effective method of selecting indices of Members of
a Sequence such that the selection or not of Index $i$ depends \emph{at most} on
the first $i-1$ Outcomes (``attributes''), with the Axioms of \emph{Convergence}
(the limiting Relative Frequency of any Outcome exists) and \emph{Randomness}
(the limiting Relative Frequency of each Outcome in a Collective $\omega$ is the
same in any Infinite Subsequence of $\omega$ determined by Place-selection; note
that trivial Sequences such as $H,H,H,\ldots$ satisfy this ``Randomness'' Axiom;
cf. the Principle of Maximum Entropy in Classical Probability), Algorithmic
Randomness (\S\ref{sec:algorithmic_randomness});
issues with limiting Relative Frequencies are that they violate Countable
Additivity and the Domain of Definition is not a Set-field or a $\sigma$-algebra
(de Finetti72)



% ------------------------------------------------------------------------------
\subsection{Multivariate Random Variable}\label{sec:random_vector}
% ------------------------------------------------------------------------------

or \emph{Random Vector}

$X = (X_1, \ldots, X_n)$

cf. \emph{Random Sequence} (\S\ref{sec:random_sequence})

\fist Multivariate Statistics (\S\ref{sec:multivariate_statistics}) --
\emph{simultaneous} Observation and Analysis of more than one Outcome Variable

Multinomial Distribution (\S\ref{sec:multinomial_distribution})

Multivariate Normal Distribution (\S\ref{sec:multivariate_normal})



\subsubsection{Independent and Identically Distributed (IID)}\label{sec:iid}

if $X_1, \ldots, X_n$ are Independent and each has the same Marginal
Distribution (\S\ref{sec:marginal_distribution}) with CDF $F$, then $X_1,
\ldots, X_n$ are said to be \emph{Independent and Identically Distributed
  (IID)}, writing:
\[
  X_1, \ldots, X_n \sim F
\]
and if $F$ has Density $f$, then:
\[
  X_1, \ldots, X_n \sim f
\]
$X_1, \ldots, X_n$ are then called a \emph{Random Sample of Size $n$ from $F$}
(\S\ref{sec:random_sample})

in Statistics it is commonly assumed that Observations are IID



\subsubsection{Homoscedasticity}\label{sec:homoscedasticity}

an Assumption in Regression Analysis (\S\ref{sec:regression_analysis}): Error is
Constant accross Observations



% ==============================================================================
\section{Probability Distribution}\label{sec:probability_distribution}
% ==============================================================================

the Pushforward Measure (\S\ref{sec:pushforward_measure}) of a Random Variable
(\S\ref{sec:random_variable})

cf. Probability Measure (\S\ref{sec:probability_measure})

\emph{Probability Distribution Function} of a Random Variable $X$ often means
the Cumulative Distribution Function (\S\ref{sec:cdf}) $F_X$, but can also refer
to:
\begin{itemize}
  \item Probability Mass Function (\S\ref{sec:pmf}) -- Discrete Probability
    Distributions (\S\ref{sec:discrete_probability})
  \item Probability Density Function (\S\ref{sec:pdf}) -- Continuous Probability
    Distributions (\S\ref{sec:continuous_probability})
\end{itemize}

\fist cf. Probability Measure Function
(\S\ref{sec:probability_measure_function}), Distribution Function (Measure
Theory \S\ref{sec:distribution_function}), Distribution (Analysis
\S\ref{sec:distribution}), Frequency Distribution
(\S\ref{sec:frequency_distribution})

\fist \emph{Statistical Inference} (\S\ref{sec:inferential_statistics}) -- using
Sample Data (\S\ref{sec:sample_sample}) to \emph{Infer} the Distribution
that \emph{Generated} (\S\ref{sec:data_generating_process}) the Data; a
Statistical Model (\S\ref{sec:statistical_model}) $(S,\mathcal{P})$ is a Sample
Space (\S\ref{sec:sample_space}) $S$ together with a Set of Probability
Distributions $\mathcal{P}$ on $S$

\fist Random Graphs (\S\ref{sec:random_graph}) -- Probability Distribution over
a Graph

collapsing a Probability Distribution (Measure) of Probability Distrubtions to a
Probability Distribution is called the ``Giry Monad'' (TODO)

(wiki): a Statistical (or Population) Parameter
(\S\ref{sec:population_parameter}) is a ``quantity'' that indexes a Family of
Probability Distributions

the Entropy (\S\ref{sec:entropy}) of a Distribution is the Mean number
of Bits-per-symbols in an Optimal Encoding (\S\ref{sec:encoding}) --
\url{https://golem.ph.utexas.edu/category/2017/02/functional_equations_iii_expla.html}

Cross Entropy (\S\ref{sec:cross_entropy}) measures the average number of Bits
needed to identify an Event drawn from an underlying Set of Events under two
Probability Distributions $p$ and $q$, if the ``coding scheme'' is optimized for
an ``unnatural'' Distribution $q$ rather than a ``true'' Distribution $p$
%FIXME: clarify

\emph{Principle of Maximum Entropy}; cf. Axiom of Randomness in Frequentist
Probability (Von Mises57)

(Witten18): Quantum Information Theory doesn't have a good analog to defining a
Conditional Probability Distribution (\S\ref{sec:conditional_probability}) as in
Classical Information Theory, but does have an analog of \emph{Strong
  Subadditivity of Entropy}

the Quantum analog of a Classical Probability Distribution is a \emph{Density
  Matrix} (\S\ref{sec:density_matrix}), a representation of the Linear
\emph{Density Operator} \S\ref{sec:density_operator})-- a Self-adjoint
(Hermitian), Positive Semi-definite, Trace One, and may be Infinite-dimensional
Matrix; every Matrix with these properties can be ``Purified'', meaning that it
is the Density Matrix of \emph{some} Pure State on some ``Bipartite'' System
$AB$; there is no ``classical analog'' for Purification, i.e. there is no way to
make Probability Distribution ``pure'' (one outcome with Probability $1$) by
adding more Variables



% ------------------------------------------------------------------------------
\subsection{Moment}\label{sec:moment}
% ------------------------------------------------------------------------------

the \emph{$k^{th}$ Moment} of $X$ is defined as $E(X^k) = \int x^k dF(x)$
assuming that $E(|X|^k) < \infty$, where $F$ is the CDF (\S\ref{sec:cdf}) of $X$

the \emph{$k^{th}$ Sample Moment} of a Sample (\S\ref{sec:sample}) $X_1, \ldots,
X_n$ is:
\[
  \frac{1}{n}\sum_{i=1}^n X^k_{i}
\]

\fist Cumulants (\S\ref{sec:cumulant}) -- Moments determine Cumulants and vice
versa

\textbf{Thm.} \emph{If $j < k$ and the $k$th Moment Exists, then the $j$th
  moment exists.}

Mean (Expected Value \S\ref{sec:expected_value}) -- First Raw Moment; Sample
Mean (\S\ref{sec:sample_mean})

Variance (\S\ref{sec:variance}) -- Second Central Moment

Skewness (\S\ref{sec:skewness}) -- Third Central Moment; ``lopsided-ness''

Kurtosis (\S\ref{sec:kurtosis}) -- Fourth Central Moment; Measure of the
``heaviness'' of the tail of a Distribution

Fourth and higher-order Cumulants are not equal to Central Moments

\fist Moment-generating Function (\S\ref{sec:moment_generating_function})

\fist Method of Moments (\S\ref{sec:moments_method}) -- Estimator of Statistical
Model Parameters



% ------------------------------------------------------------------------------
\subsection{Cumulant}\label{sec:cumulant}
% ------------------------------------------------------------------------------

\fist Moments (\S\ref{sec:moment}) -- Cumulants determine Moments and vice
versa

Mean (Expected Value \S\ref{sec:expected_value}) -- First Cumulant

Variance (\S\ref{sec:variance}) -- Second Cumulant

Skewness (\S\ref{sec:skewness}) -- Third Cumulant; ``lopsided-ness''

Fourth and higher-order Cumulants are not equal to Central Moments

\fist Cumulant-generating Function (\S\ref{sec:cumulant_generating_function})



% ------------------------------------------------------------------------------
\subsection{Cumulative Distribution Function (CDF)}\label{sec:cdf}
% ------------------------------------------------------------------------------

(wiki):

the \emph{Cumulative Distribution Function (CDF)} of a Real-valued Random
Variable $X$ evaluated at $x$ is equal to the Probability that $X$ will take a
value less than or equal to $x$:
\[
  \forall x \in \reals, F_X(x) = P(X \leq x)
\]
every CDF is Non-decreasing and Right-continuous

special case of Distribution Function (Measure Theory
\S\ref{sec:distribution_function}) with the boundary conditions
$\lim_t\rightarrow\infty F_X(t) = 0$ and $\lim_{t\rightarrow\infty}F_X(t) = 1$

every Function with these four Properties is a CDF, i.e. for every such Function
a Random Variable can be defined such that the Function is a CDF of that Random
Variable

a Random Variable $X$ with CDF $F$ is indicated by the notation $X \sim F$, but
note that this does not mean ``apprximate equality''

the CDF $F_X$ of a Discrete Random Variable can be related to its Probability
Mass Function (\S\ref{sec:pmf}) $f_X$ by:
\[
  F_X(x) = P(X \leq x) = \sum_{x_i \leq x} f_X(x_i)
\]

the CDF of a Continuous Random Variable can be expressed as the Integral of its
Probability Density Function (\S\ref{sec:pdf}) $f_X$:
\[
  F_X(x) = \int\limits_{-\infty}^x f_X(t) dt
\]
i.e. the CDF of a Continuous Random Variable gives the Area under the PDF from
$-\infty$ to $x$

if $F_X$ is Absolutely Continuous (\S\ref{sec:absolute_continuity}), then there
exists a Lebesgue-integrable Function $f_X(x)$ such that:
\[
  F_X(b) - F_X(a) = P(a < X \leq b) = \int_a^b f_X(x) dx
\]
for all Real Numbers $a, b$ and $f_X$ is the PDF of the Distribution of $X$
and equals the Derivative of $F_X$ almost everywhere

\fist \emph{Empirical Distribution Function}
(\S\ref{sec:empirical_distribution}) -- an Unbiased Estimator for $F$ defined as
the CDF of the Empirical Measure (\S\ref{sec:empirical_measure}) of a Sample
(\S\ref{sec:sample})



\subsubsection{Quantile Function}\label{sec:quantile_function}

\emph{Inverse CDF} $F^{-1}$

$F^{-1}(0.25)$ -- \emph{First Quartile}

$F^{-1}(0.5)$ -- \emph{Median} (or \emph{Second Quartile})

$F^{-1}(0.75)$ -- \emph{Third Quartile}

Location Parameter



\paragraph{Probit}\label{sec:probit}\hfill

Quantile Function of the Normal Distribution



\subsubsection{Statistical Functional}\label{sec:statistical_functional}

(Wasserman04 Example 6.05):

a Function of a CDF is called a \emph{Statistical Functional}

can be used to compute various Summary Statistics
(\S\ref{sec:summary_statistic}):
\begin{itemize}
  \item $\mu = T(F) = \int x dF(x)$
    -- Mean (Expectation \S\ref{sec:expected_value})
  \item $\sigma^2 = T(F) = \int (x - \mu)^2 dF(x)$
    -- Variance (\S\ref{sec:variance})
  \item $m = T(F) = F^{-1}(0.5)$
    -- Median (\S\ref{sec:median})
\end{itemize}

Non-parametric Inference (\S\ref{sec:nonparametric_model})

the \emph{Plug-in Estimator} (\S\ref{sec:plugin_principle}) for a Functional
$\theta = T(F)$ is:
\[
  \hat{\theta} = T(\hat{F}_n)
\]
where $\hat{F}_n$ is the Empirical Distribution Function
(\S\ref{sec:empirical_distribution})



\paragraph{Linear Functional}\label{sec:linear_functional}\hfill

a Functional of the form:
\[
  T(F) = \int r(x) dF(x)
\]
for some Function $r(x)$

called ``Linear'' because in this case $T$ satisfies
$T(aF + bG) = aT(F) + bT(G)$, i.e. $T$ is Linear in all arguments

the Plug-in Estimator (\S\ref{sec:plugin_principle}) for a Linear Functional:
\[
  T(\hat{F}_n) = \frac{1}{n}\sum_{i=1}^n r(X_i)
\]
where $\hat{F}_n$ is the Empirical Distribution Function
(\S\ref{sec:empirical_distribution})



% ------------------------------------------------------------------------------
\subsection{Discrete Probability Distribution}
\label{sec:discrete_probability}
% ------------------------------------------------------------------------------

Probability Distribution of a Discrete Random Variable
(\S\ref{sec:discrete_random_variable})

characterized by a Probability Mass Function (\S\ref{sec:pmf})

Cumulative Distribution Function (\S\ref{sec:cdf}) increases only by Jump
Discontinuities

\begin{itemize}
  \item \emph{Point Mass Distribution} -- $X \sim \delta_a$ has CDF:
    \[
      F_X(x) = \begin{cases}
        0 & x <    a \\
        1 & x \geq a \\
      \end{cases}
    \]
    and PMF:
    \[
      f_X(x) = \begin{cases}
        1 & x = a \\
        0 & \text{otherwise} \\
      \end{cases}
    \]
  \item \emph{Discrete Uniform Distribution} (\S\ref{sec:uniform_distribution})
  \item \emph{Bernoulli Distribution} (\S\ref{sec:bernoulli_distribution}) --
    $X \sim Bernoulli(p)$
  \item \emph{Binomial Distribution} (\S\ref{sec:binomial_distribution}) --
    $X \sim Binomial(n,p)$
  \item \emph{Geometric Distribution} (\S\ref{Sec:geometric_distribution}) --
    $X \sim Geom(p)$
  \item \emph{Poisson Distribution} (\S\ref{Sec:poisson_distribution}) --
    $X \sim Poisson(\lambda)$
\end{itemize}



\subsubsection{Multinomial Distribution}\label{sec:multinomial_distribution}

$k$ Outcomes $E_1, E_2, \ldots, E_k$

Probabilities $p_1, p_2, \ldots, p_k$

Probability Distribution of $x_1, x_2, \ldots, x_k$ number of
Occurences for $E_1, E_2, \ldots, E_k$ in $n$ Independent Trials:
\[
  f(x_1, x_2, \ldots, x_k) = \binom{n}{x_1, x_2, \ldots, x_k} =
  p_1^{x_1} p_2^{x_2} \cdots p_k^{x_k}
\]
and $\sum_{i=1}^k x_i = n$ and $\sum_{i=1}^k {p_i} = 1$

for $X = (X_1, \ldots, X_k) \sim Multinomial(n, p)$ and
$p = (p_1, \ldots, p_k)$, the Marginal Distribution
(\S\ref{sec:marginal_distribution}) of $X_j$ is $Binomial (n, p_j)$



\paragraph{Bernoulli Distribution}\label{sec:bernoulli_distribution}\hfill

$n = 1$

for a Random Variable $X$ representing a Binary Outcome:
\begin{itemize}
  \item $P(X=1) = p$
  \item $P(X=0) = 1-p$
\end{itemize}
for some $p \in [0,1]$

PMF:
\[
  f(x) = p^x(1-p)^{1-x}
\]
or equivalently:
\[
  f(x) = \begin{cases}
    p   & x = 1 \\
    1-p & x = 0 \\
  \end{cases}
\]
for $x \in \{0, 1\}$

\fist cf. Logistic Regression (\S\ref{sec:logistic_regression}) -- Model with
Binary Data $Y_i$:
\[
  Y_i | X_i = x_i \sim Bernoulli(p_i)
\]

generalization: Categorical Distribution (\S\ref{sec:categorical_distribution})



\paragraph{Binomial Distribution}\label{sec:binomial_distribution}\hfill

Random Variable $X$ with Binomial Distribution where $n \in \nats$ and
$p \in [0,1]$:
\[
  X \sim B(n,p)
\]
describes the Probability of getting exactly $x$ ``successes'' in $n$ ``trials''
where the Probability of ``success'' is $p$:
\[
  P(x,n,p) = \binom{n}{x}p^x(1-p)^{n-x}
\]

Expected Value $E(X) = np$

Binomial Random Variable (\S\ref{sec:binomial_random_variable})

Binomial (Bernoulli) Trial (\S\ref{sec:binomial_trial})

generalized as Multinomial Distributions (\S\ref{sec:multinomial_distribution})

Mean $\mu = n p$

Variance $\sigma^2 = n p q$

Sample Proportion %FIXME



\subparagraph{Negative Binomial Distribution}\label{sec:negative_binomial}\hfill

$b^*(x; k,p) = \binom{x-1}{k-1} p^k 2^{k-k}$



\subparagraph{Normal Approximation}\label{sec:normal_approximation}\hfill

For Binomial Random Variable $X$ with Mean $\mu = np$ and Variance
$\sigma^2 = npq$, then:
\[
  Z = \frac{X - np}{\sqrt{npq}}
\]
as $n \rightarrow \infty$ is the Standard Normal Distribution
(\S\ref{sec:normal_distribution}) $n(Z;0,1)$



\paragraph{Categorical Distribution}\label{sec:categorical_distribution}
\hfill

generalization of Bernoulli Distribution (\S\ref{sec:bernoulli_distribution})



\paragraph{Softmax Function}\label{sec:softmax}
\hfill

or \emph{Normalized Exponential Function}

generalization of Logistic Function (\S\ref{sec:softmax}); the Logistic Function
is the Derivative of Softplus --TODO

output can be used to represent a Categorical Distribution

often used as final layer of a Neural Network-based Classifier



\subsubsection{Poisson Distribution}\label{sec:poisson_distribution}

Poisson Process (\S\ref{sec:poisson_process})

$P(x; \lambda t) = \frac{e^{-\lambda t} (\lambda t)^x}{x!}$
where $\lambda$ is the average number of outcomes per unit time

models counts of rare events, e.g. radioactive decay, traffic accidents



\subsubsection{Geometric Distribution}\label{sec:geometric_distribution}

$P(X = k) = p(1-p)^{k-1}$ for $k \in \{1, 2, 3, \ldots\}$

where $X$ is the number of Trials needed until the first Success



\subsubsection{Hypergeometric Distribution}
\label{sec:hypergeometric_distribution}

$h(x; N, n, k) = \frac{\binom{k}{x} \binom{N-k}{n-x}}{\binom{N}{n}}$

Mean $\mu = \frac{nk}{N}$

Variance $\sigma^2 = \frac{N-n}{N-1} n \frac{k}{N}(1 - \frac{k}{N})$



\paragraph{Multivariate Hypergeometric Distribution}
\label{sec:multivariate_hypergeometric}\hfill



\subsubsection{Parabolic Fractal Distribution}
\label{sec:parabolic_fractal_distribution}

\subsubsection{Discrete Power Law Distribution}
\label{sec:discrete_power_law_distribution}

\fist Continuous Power Law Distributions
(\S\ref{sec:continuous_power_law_distribution})



\paragraph{Zipf Distribution}\label{sec:zipf_distribution}\hfill

\paragraph{Zeta Distribution}\label{sec:zeta_distribution}\hfill

Normalization of the Zipf Distribution

\paragraph{Yule-Simon Distribution}
\label{sec:yule_simon_distribution}\hfill



% ------------------------------------------------------------------------------
\subsection{Continuous Probability Distribution}
\label{sec:continuous_probability}
% ------------------------------------------------------------------------------

Probability Distribution of a Continuous Random Variable
(\S\ref{sec:continuous_random_variable})

characterized by a Probability Density Function
(\S\ref{sec:probability_density})

has a Continuous Cumulative Distribution Function (\S\ref{sec:cdf})

\fist Discrete Power Law Distributions
(\S\ref{sec:discrete_power_law_distribution})

\begin{itemize}
  \item \emph{Uniform Distribution} (\S\ref{sec:uniform_distribution}) --
    $X \sim Uniform(a,b)$
  \item \emph{Normal (Gaussian) Distribution} (\S\ref{sec:normal_distribution})
    -- $X \sim N(\mu, \sigma^2)$
  \item \emph{Exponential Distribution} (\S\ref{sec:exponential_distribution})
    -- $X \sim Exp(\beta) = Gamma(1, \beta)$
  \item \emph{Gamma Distribution} (\S\ref{sec:gamma_distribution})
    -- $X \sim Gamma(\alpha, \beta)$
  \item \emph{Beta Distribution} (\S\ref{sec:beta_distribution})
    -- $X \sim Beta(\alpha, \beta)$
  \item \emph{$t$-distribution} (\S\ref{sec:t_distribution})
    -- $X \sim t_\nu$
  \item \emph{Cauchy-Lorenz Distribution} (\S\ref{sec:cauchy_distribution})
    -- $X \sim t_\nu=1$
  \item \emph{$\chi^2$-distribution} (\S\ref{sec:chi_squared})
    -- $X \sim \chi^2_p$
\end{itemize}



\subsubsection{Normal Distribution}\label{sec:normal_distribution}

(or \emph{Gaussian Distribution})

\[
  n (x; \mu, \sigma) =
  \frac{1}{\sqrt{2\pi \sigma}} e^{-\frac{1}{2 \sigma^2}(x - \mu)^2}
\]

a Normal Distribution corresponds to a $t$-distribution
(\S\ref{sec:t_distribution}) with $\nu = \infty$ Degrees of Freedom

the Ratio $X_1/X_2$ of two Normally Distributed Independent Random Variables
$X_1, X_2 \sim N(0,1)$ is a Cauchy Distribution

\emph{Central Limit Thoerem} (\S\ref{sec:central_limit_theorem}) -- ``the
Distribution of a Sum of Independent Random Variables can be approximated by a
Normal Distribution'';
for a Sequence of Random Variables (\S\ref{sec:random_variable})
$X_i, \ldots, X_n$ with Sample Mean (\S\ref{sec:sample_mean})
$\overline{X}_n$, $\sqrt{n}(\overline{X}_n - \mu)$
\emph{Converges in Distribution} to a Normal Distribution
(\S\ref{sec:normal_distribution}) as $n \rightarrow \infty$, i.e. the Sample
Mean has approximately a Normal Distribution for large $n$

as a consequence of the Central Limit Theorem, Random Errors
(\S\ref{sec:random_error}) tend to be Normally Distributed

\fist Gaussian Processes (\S\ref{sec:gaussian_process}) can be seen as
Infinite-dimensional generalizations of Multivariate Normal Distributions

2018 - Eric Jang
- \emph{Normalizing Flows Tutorial}
- \url{https://blog.evjang.com/2018/01/nf1.html}



\paragraph{Mill's Inequality}\label{sec:mills_inequality}\hfill

\textbf{Thm.} (Mill's Inequality) \emph{
  For $Z \sim N(0,1)$:
  \[
    P(|Z| > t) \leq \sqrt{\frac{2}{\pi}}\frac{e^{-t^2/2}}{t}
  \]
}

\paragraph{Standard Normal Distribution}\label{sec:standard_normal}\hfill

Mean $\mu = 0$

Variance $\sigma^2 = 1$

by convention Standard Normal Random Variables are denoted by $Z$, PDF by
$\phi(z)$ and CDF by $\Phi(z)$

there is no Closed-form Expression (\S\ref{sec:closed_form_expression}) for
$\Phi$ (requires use of the Error Function \S\ref{sec:error_function})



\paragraph{Multivariate Normal Distribution}\label{sec:multivariate_normal}
\hfill

Multivariate Random Variable (\S\ref{sec:random_vector})



\subsubsection{$t$-distribution}\label{sec:t_distribution}

(or \emph{Student's $t$-distribution})

$\nu$ -- Degrees of Freedom

a Normal Distribution (\S\ref{sec:normal_distribution}) corresponds to a
$t$-distribution with $\nu = \infty$ Degrees of Freedom

$t$-test (\S\ref{sec:t_test})



\paragraph{Cauchy Distribution}\label{sec:cauchy_distribution}\hfill

or \emph{Cauchy-Lorentz Distribution}

$\nu = 1$

Expected Value (\S\ref{sec:expected_value}) and Variance (\S\ref{sec:variance})
are undefined; the ``average'' of $n$ Independent Cauchy Random Variables with
$x_0 = 0$ \emph{does not} Converge to $0$ as $n \rightarrow \infty$ with
Probability $1$-- ``it'' stays a Cauchy Distribution of the same size; however
$0$ is the Median and Mode (FIXME: clarify)
--\url{https://stats.stackexchange.com/questions/36027/why-does-the-cauchy-distribution-have-no-mean}

\url{https://stats.stackexchange.com/questions/232967/what-makes-the-mean-of-some-distributions-undefined/233950#233950}:
the Cauchy Distribution is a ``disguised'' form of the Uniform Distribution on a
Circle

has no Moment-generating Function (\S\ref{sec:moment_generating_function})

the Ratio $X_1/X_2$ of two Normally Distributed Independent Random Variables
$X_1, X_2 \sim N(0,1)$ is a Cauchy Distribution



\subsubsection{Log-normal Distribution}\label{sec:lognormal_distribution}

\subsubsection{Gamma Distribution}\label{sec:gamma_distribution}

Gamma Function (\S\ref{sec:gamma_function})

Continuous Random Variable $X$ with parameters $\alpha > 0$ and $\beta
> 0$:
\[
  f(x; \alpha, \beta) =
  \begin{cases}
  \frac{1}{\beta^\alpha \Gamma(\alpha)} x^{\alpha-1} e^{\sfrac{-x}{\beta}}
        & \quad x > 0 \\
  0     & \quad\text{else} \\
  \end{cases}
\]

Mean $\mu = \alpha \beta$

Variance $\sigma^2 = \alpha \beta^2$



\paragraph{Exponential Distribution}\label{sec:exponential_distribution}\hfill

a $Gamma(1,\beta)$ Distribution

Continuous Random Variable $X$ with parameter $\beta > 0$:
\[
  f(x; \beta) =
  \begin{cases}
  \frac{1}{\beta} e^{\sfrac{-x}{\beta}}     & \quad x > 0 \\
  0     & \quad\text{else} \\
  \end{cases}
\]

models lifetimes of electronic components, wait times between rare events



\subparagraph{Double Exponential Distribution}
\label{sec:double_exponential}\hfill

or \emph{Laplace Distribution}



\paragraph{$\chi^2$ Distribution}\label{sec:chi_squared}\hfill

Non-symmetric

\[
  f(x; v) =
  \begin{cases}
    \frac{1}{2^{\sfrac{v}{2}}\Gamma(\sfrac{v}{2})}
      x^{\sfrac{v}{2-1}} e^{\sfrac{-x}{2}}
          & \quad x > 0 \\
    0     & \quad\text{else} \\
  \end{cases}
\]

\fist Pearson's Chi-squared Test (\S\ref{sec:pearsons_chi_squared})



\paragraph{Wishart Distribution}\label{sec:wishart_distribution}\hfill



\subsubsection{Beta Distribution}\label{sec:beta_distribution}

Gamma Function (\S\ref{sec:gamma_function})



\subsubsection{Continuous Power Law Distribution}
\label{sec:continuous_power_law_distribution}

Scale Invariance (\S\ref{sec:scale_invariance})



\paragraph{Pareto Distribution}\label{sec:pareto_distribution}\hfill

prototypical Power Law Distribution



% ------------------------------------------------------------------------------
\subsection{Symmetric Probability Distribution}
\label{sec:symmetric_probability}
% ------------------------------------------------------------------------------

\subsubsection{Uniform Distribution}\label{sec:uniform_distribution}

for a Finite Sample Space $\Omega$:
\[
  P(A) = \frac{\|A\|}{\|\Omega\|}
\]

a Uniform Distribution is defined by a rectangle formed on the interval Interval
$[min,max]$ such that the area is $1$

$Uniform(0,1)$ -- \emph{Standard Uniform Distribution}

\url{https://stats.stackexchange.com/questions/232967/what-makes-the-mean-of-some-distributions-undefined/233950#233950}:
the Cauchy Distribution (\S\ref{sec:cauchy_distribution}) is a ``disguised''
form of the Uniform Distribution on a Circle



\paragraph{Probability Integral Transform}
\label{sec:probability_integral_transform}\hfill

for Continuous $X$ with CDF $F_X$, $Y = F_X(X)$ is called a \emph{Probability
  Integral Transform} and has a Standard Uniform Distribution

\emph{Universal Random Number Generator} (Wasserman04 Ch.2 Exercise 15) -- TODO



% ------------------------------------------------------------------------------
\subsection{Joint Probability Distribution}\label{sec:joint_probability}
% ------------------------------------------------------------------------------

$f(x,y,\ldots)$ for two or more Random Variables $X,Y,\ldots$

Discrete Random Variables:
\begin{enumerate}
  \item $f(x,y) \geq 0$
  \item $\sum_x \sum_y f(x,y) = 1$
  \item $P(X = x, Y = y) = f(x,y)$
\end{enumerate}

Continuous Random Variables:
\begin{enumerate}
  \item $\forall (x,y) \in X \times Y, f(x,y) \geq 0$
  \item $\int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty}
    f(x,y) dx dy = 1$
  \item $P[(X,Y) \in B] = \iint\limits_B f(x,y) dA$
\end{enumerate}

\fist \emph{Cross-variation Assumptions} -- Model-based Statistical Assumptions
(\S\ref{sec:statistical_assumption}) involving Joint Probability Distributions
of either Observations or Random Errors in a Model; simple Models may Assume
that Observations or Errors are Statistically Independent
(\S\ref{sec:independence})

Conditional Independence (\S\ref{sec:conditional_independence}) happens when
the Joint Probability Distribution is the Product of the individual Probability
Distributions
--\url{http://lesswrong.com/lw/pi/classical_configuration_spaces/}

\fist a Stationary Process (\S\ref{sec:stationary_process}) is a Stochastic
Process whose Unconditional Joint Probability Distribution is unchanged in Time



\subsubsection{Bivariate Distribution}\label{sec:bivariate_distribution}

$P(X = x, Y = y)$



\subsubsection{Kalman Filter}\label{sec:kalman_filter}

a series of papers on ``Kalman Folding'':
\url{http://vixra.org/author/brian_beckman}



% ------------------------------------------------------------------------------
\subsection{Conditional Distribution}
\label{sec:conditional_distribution}
% ------------------------------------------------------------------------------

for Discrete Random Variables $X$, $Y$:

\[
  P(X = x | Y = y) = P(X = x, Y = y)/P(Y = y)
\]
the Conditional Probability Mass Function, assuming $f_Y(y) > 0$:
\[
  f_{X|Y}(x|y) = P(X = x|Y = y) =
    \frac{P(X = x, Y = y)}{P(Y = y)} =
    \frac{f_{X,Y}(x,y)}{f_Y(y)}
\]

for Continuous Random Variables $X$, $Y$, the Conditional Probability Density
Function:
\[
  f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}
\]
and:
\[
  P(X \in A| Y = y) = \int_A f_{X|Y}(x|y) dx
\]

cf. \emph{Borel-Kolmogorov Paradox} -- the concept of a Conditional Probability
with regard to an isolated given Hypothesis whose Probability equals $0$ is
inadmissable (Kolmogorov33); Conditional Probability Density Functions need not
be Invariant under Coordinate Transformations



% ------------------------------------------------------------------------------
\subsection{Marginal Distribution}\label{sec:marginal_distribution}
% ------------------------------------------------------------------------------

Marginal Probability Mass Functions:

$f_X(x) = P(X = x) = \sum_y P(X = x, Y = y) = \sum_y P(X = x | Y = y) P(Y = y)$

$f_Y(y) = P(Y = y) = \sum_x P(X = x, Y = y) = \sum_x P(Y = y | X = x) P(X = x)$

Marginal Probability Density Functions:

$f_X(x) = \int f_{X,Y}(x,y) dy$

$f_Y(y) = \int f_{X,Y}(x,y) dx$



% ------------------------------------------------------------------------------
\subsection{Asymptotic Distribution}\label{sec:asymptotic_distribution}
% ------------------------------------------------------------------------------

\fist cf. Asymptotic Theory (Large Sample Theory \S\ref{sec:asymptotic_theory})



\subsubsection{Central Limit Theorem}\label{sec:central_limit}

``the Distribution of a Sum of Independent Random Variables can be approximated
by a Normal Distribution''

for a Sequence of Random Variables (\S\ref{sec:random_variable})
$X_i, \ldots, X_n$ with Sample Mean (\S\ref{sec:sample_mean})
$\overline{X}_n$, $\sqrt{n}(\overline{X}_n - \mu)$
\emph{Converges in Distribution} to a Normal Distribution
(\S\ref{sec:normal_distribution}) as $n \rightarrow \infty$, i.e. the Sample
Mean has approximately a Normal Distribution for large $n$

\textbf{Thm.} (Central Limit Theorem) \emph{For IID (\S\ref{sec:iid}) Random
  Variables $X_1, \ldots, X_n$ with Mean $\mu$ and Variance $\sigma^2$, then:
  \[
    Z_n \equiv \frac{\overline{X}_n - \mu}{\sqrt{V(\overline{X}_n)}} =
      \frac{\sqrt{n}(\overline{X}_n - \mu)}{\sigma} \rightarrow Z \sim N(0,1)
  \]
  i.e:
  \[
    \lim_{n\rightarrow\infty} P(Z_n \leq z) = \Phi(z) =
      \int_{-\infty}^z \frac{1}{\sqrt{2\pi}}e^{-x^2/2} dx
  \]
}

\emph{Berry-Ess\'een Inequality}

\emph{Multivariate Central Limit Theorem}

generalization: \emph{Local Asymptotic Normality}

as a consequence of the Central Limit Theorem, Random Errors
(\S\ref{sec:random_error}) tend to be Normally Distributed

\fist an instance of \emph{Renormalization} (\S\ref{sec:renormalization})

\fist origin of ``Multifractality'' (\S\ref{sec:multifractal_system}) in
Sequential (Time Series) data attributed to ``convergence effects'' related to
the Central Limit Theorem that have Foci of Convergence in the family of Tweedie
Exponential Dispersion Models (Probability Distributions
\S\ref{sec:tweedie_distribution})



% ------------------------------------------------------------------------------
\subsection{Tweedie Distribution}\label{sec:tweedie_distribution}
% ------------------------------------------------------------------------------

(wiki): \emph{Tweedie Convergence Theorem}: describes the Convergence of certain
Statistical Processes towards the Family of Statistical Models known as
\emph{Tweedie Distributions}; Variance-to-Mean Power Law (TODO: xref); cf.
Taylor's Power Law, \emph{Fluctuation Scaling}; alternative paradigm to explain
Power Law manifestations attributed to ``Self-organized Criticality''
(SOC \S\ref{sec:soc})

Pink ($1/f$) Noise

\fist origin of ``Multifractality'' (\S\ref{sec:multifractal_system}) in
Sequential (Time Series) data attributed to ``convergence effects'' related to
the Central Limit Theorem (\S\ref{sec:central_limit}) that have Foci of
Convergence in the family of Tweedie Exponential Dispersion Models



% ------------------------------------------------------------------------------
\subsection{Quasiprobability Distribution}
\label{sec:quasiprobability_distribution}
% ------------------------------------------------------------------------------

relaxation of the Third Kolmogorov Axiom ($\sigma$-additivity
\S\ref{sec:probability_axioms})

to compensate some Quasiprobability Distributions have regions of Negative
Probability (\S\ref{sec:negative_probability}) Density, contradicting the First
Axiom

regions Integrated under them do not represent Probabilities of Mutually
Exclusive States (\S\ref{sec:mutually_exclusive})

cf. Phase Space (\S\ref{sec:phase_space}) Formulation of Quantum Mechanics:
Position and Momentum Variables on equal footing in Phase Space (cf.
Schr\"odinger formulation uses Position \emph{or} Momentum representations)

\fist Time-Frequency Analysis (\S\ref{sec:time_frequency_analysis}): analysis
of Signals with Time-varying Statistics (cf. Entropy \S\ref{sec:entropy}), e.g.
Transient Signals (\S\ref{sec:transient})



% ==============================================================================
\section{Statistical Analysis}\label{sec:statistical_analysis}
% ==============================================================================

Statistical Theory -- FIXME

Statistical Population (\S\ref{sec:population})

Statistical Sample (\S\ref{sec:sample})

Statistic (\S\ref{sec:statistic}) -- a Function of a Random Variable
(\S\ref{sec:random_variable}) constituting a Random Sample

Descriptive Statistics (\S\ref{sec:descriptive_statistics})

Statistical Parameter (\S\ref{sec:population_parameter})

Statistical Model (\S\ref{sec:statistical_model})

Statistical Inference (\S\ref{sec:inferential_statistics})

Statistical Learning Theory (\S\ref{sec:statistical_learning_theory})



% ------------------------------------------------------------------------------
\subsection{Population}\label{sec:population}
% ------------------------------------------------------------------------------

\emph{Statistical Population}

totality of Observations (\S\ref{sec:observation})

Value of a Random Variable $X$ having some Probability Distribution $f(x)$

Paired Observation (Dependent) (???)

(wiki):

\emph{Statistical Population} -- a Set of ``similar items'' or Events
(\S\ref{sec:probability_event}) of interest

\fist cf. Data Generating Process (\S\ref{sec:data_generating_process}), Data
Collection (\S\ref{sec:data_collection})

A Subset of the Population is a \emph{Statistical Sample} (\S\ref{sec:sample}).
A \emph{Statistical Model} (\S\ref{sec:statistical_model}) is a Set of
Statistical Assumptions (\S\ref{sec:statistical_assumption}) concerning the
Generation (\S\ref{sec:data_generating_process}) of Sample Data.

A \emph{Statistical Hypothesis} is a Conjecture (\S\ref{sec:conjecture})
concerning one or more Populations.



% ------------------------------------------------------------------------------
\subsection{Data Generating Process}\label{sec:data_generating_process}
% ------------------------------------------------------------------------------

(wiki):

\begin{itemize}
  \item \emph{Data Collection} (\S\ref{sec:data_collection})
  \item a ``notional'', \emph{non-specific} Probabilistic Model
    that would include all of the ``Random influences'' that lead to individual
    Observations (\S\ref{sec:observation})
  \item a \emph{specific} \emph{Statistical Model}
    (\S\ref{sec:statistical_model}) used to represent Random Variations in
    Observations
\end{itemize}

\fist \emph{Model Validation} (\S\ref{sec:model_validation}) is the process of
confirming that the ``outputs'' of a Statistical Model are ``acceptable'' with
respect to the ``real'' Data Generating Process

\fist cf. Sample Data (Statistical Sample \S\ref{sec:sample})

\fist cf. Stochastic Process (\S\ref{sec:stochastic_process})



% ------------------------------------------------------------------------------
\subsection{Level of Measurement}\label{sec:measurement_level}
% ------------------------------------------------------------------------------

\begin{itemize}
  \item \emph{Nominal} -- Central Tendency: Mode (\S\ref{sec:mode})
  \item \emph{Ordinal} -- Central Tendency: Median (\S\ref{sec:median})
  \item \emph{Interval} -- Central Tendency: Mean (\S\ref{sec:arithmetic_mean}),
    Deviation (\S\ref{sec:deviation})
  \item \emph{Ratio} -- Central Tendency: Geometric Mean
    (\S\ref{sec:geometric_mean}), Variation Coefficient (TODO)
\end{itemize}



\subsubsection{Statistical Data Type}\label{sec:statistical_data_type}

\fist cf. \emph{Datatype}

cf. Statistical Unit (\S\ref{sec:statistical_unit})

\emph{Simple Data Types}:
\begin{itemize}
  \item Binary
  \item Categorical
  \item Ordinal
  \item Binomial
  \item Count
  \item Real
  \item Positive Real
  \item ...
\end{itemize}

\emph{Multivariate Data Types}:
\begin{itemize}
  \item Random Vector
  \item Random Sequence
  \item Bayes Networks
  \item Random Process
  \item Random Field
  \item ...
\end{itemize}

(TODO: xrefs)



% ------------------------------------------------------------------------------
\subsection{Population Parameter}\label{sec:population_parameter}
% ------------------------------------------------------------------------------

or \emph{Statistical Parameter}

(wiki): a ``quantity'' that indexes a Family of Probability Distributions
(\S\ref{sec:probability_distribution}), i.e. a ``numerical characteristic'' of a
\emph{Statistical Model} (\S\ref{sec:statistical_model})

Parametric Models (\S\ref{sec:parametric_model}) have a Finite Set of Parameters

example: the Family of Normal Distributions (\S\ref{sec:normal_distribution})
are Parameterized by the Mean and Standard Deviation

Non-parametric models (\S\ref{sec:nonparametric_model}) have an Infinite Set of
Parameters

a \emph{Parameter} is to a \emph{Population} as a \emph{Statistic}
(\S\ref{sec:statistic}) is to a \emph{Sample} (\S\ref{sec:sample})

\fist an \emph{Estimator} (\S\ref{sec:estimator}) is a Statistic used to
Estimate a Population Parameter:
\begin{itemize}
  \item Maximum Likelihood Estimation (MLE \S\ref{sec:mle})
  \item Method of Moments (\S\ref{sec:moments_method})
  \item ...
\end{itemize}

$\mu$, $\sigma$

\begin{itemize}
  \item Location Parameter -- Quantile
  \item Dispersion Parameter
  \item Scale Parameter
  \item Shape Parameter
  \item Concentration Parameter
  \item Regression Coefficient
\end{itemize}
(TODO: xrefs



\subsubsection{Proportion}\label{sec:statistical_proportion}

\paragraph{Lexis Ratio}\label{sec:lexis_ratio}\hfill



% ------------------------------------------------------------------------------
\subsection{Statistical Sample}\label{sec:sample}
% ------------------------------------------------------------------------------

A \emph{Statistical Sample} (or \emph{Data Sample}) is a Subset of a Statistical
Population, selected by a definite procedure (\emph{Sampling Procedure}
\S\ref{sec:sampling}).

A \emph{Data Point} is an Observation (Random Variate \S\ref{sec:observation})
of a Statistical Unit (\S\ref{sec:statistical_unit}) in a Statistical Sample.

\fist cf. \emph{Data} (\S\ref{sec:data}), \emph{Data Generating Process}
(\S\ref{sec:data_generating_process})

\fist cf. Frequency Distribution (\S\ref{sec:frequency_distribution})

\fist a Statistical Model (\S\ref{sec:statistical_model}) ``embodies'' the Set
of Statistical Assumptions that concern the \emph{Generation}
(\S\ref{sec:data_generating_process}) of Sample Data



% ------------------------------------------------------------------------------
\subsection{Statistical Unit}\label{sec:statistical_unit}
% ------------------------------------------------------------------------------

one of a Member of a Set of entities being analyzed, providing the ``material
source'' for abstract Random Variables (\S\ref{sec:random_variable})

cf. Statistical Data Type (\S\ref{sec:statistical_data_type})



\subsubsection{Unit of Observation}\label{sec:observational_unit}

\emph{Unit of Observation} or \emph{Unit of Collection}

\begin{itemize}
  \item \emph{Experimental Unit} -- a Member of a Set of objects that are
    initially equivalent until each object is subjected to an ``Experimental
    Treatment'' (\S\ref{sec:experiment})
  \item \emph{Sampling Unit} -- an object that has been Sampled
    (\S\ref{sec:sample}) from a Statistical Population (\S\ref{sec:population})
\end{itemize}

\fist Observation (Random Variate \S\ref{sec:observation})



\subsubsection{Unit of Analysis}\label{sec:analysis_unit}

the entity that frames what is being ``analyzed'' in a ``study'' (cf. Experiment
\S\ref{sec:experiment})



% ------------------------------------------------------------------------------
\subsection{Sampling}\label{sec:sampling}
% ------------------------------------------------------------------------------

\emph{Sampling} is the \emph{selection} of a Subset (Statistical Sample) from
within a Statistical Population

\fist cf. \emph{Data Collection} (\S\ref{sec:data_collection})

\fist \emph{Sampling Unit} (Unit of Observation \S\ref{sec:observational_unit})
-- an object that has been Sampled from a Population

\fist \emph{Sampling Error} (\S\ref{sec:sampling_error}) -- Statistical Error
arising from the Estimation of Statistical characteristics of a Population from
a Subset (Sample)

\fist \emph{Design-based Assumptions} -- Statistical Assumptions
(\S\ref{sec:statistical_assumption}) of the way Observations have been made,
e.g. Assumption of Randomization during Sampling (\S\ref{sec:random_sample})

\emph{Empirical Distribution Function} (\S\ref{sec:empirical_distribution}) --
an Unbiased Estimator for the CDF (\S\ref{sec:cdf}) associated with the
Empirical Measure (\S\ref{sec:empirical_measure}) of a Sample



\subsubsection{Data Collection}\label{sec:data_collection}

%FIXME: cf. measurement, observation ?



\subsubsection{Sample Size}\label{sec:sample_size}

\emph{Sample Size Determination} -- choosing the number of Observations
(\S\ref{sec:observation}) or Replicates (\S\ref{sec:replication}) to include in
a Statistical Sample

\fist Asymptotic Theory (Large Sample Theory \S\ref{sec:asymptotic_theory}):
evaluates properties of Estimators (\S\ref{sec:estimator}) and Statistical Tests
(\S\ref{sec:hypothesis_testing}) as Sample Size $n \rightarrow \infty$



\subsubsection{Replication}\label{sec:replication}

cf. Experiment (\S\ref{sec:experiment})



\subsubsection{Observational Error}\label{sec:observational_error}

\emph{Observational Error} (or \emph{Measurement Error}) is the difference
between an Observed Value (Random Variate \S\ref{sec:observation}) of a
``quantity'' and its ``true'' Value

cf. \emph{Statistical Error} (\S\ref{sec:statistical_error})



\paragraph{Random Error}\label{sec:random_error}\hfill

or \emph{Random Variation}

inconsistency of repeated Observations (Measurements) of a Constant attribute or
quantity

usually Normally Distributed due to the Central Limit Theorem
(\S\ref{sec:central_limit})

\fist a \emph{Distributional Assumption} is a Model-baesd Statistical Assumption
(\S\ref{sec:statistical_assumption}) about the Probability Distribution of
Random Errors



\paragraph{Systematic Error}\label{sec:systmatic_error}\hfill

or \emph{Statistical Bias}

cf. \emph{Sampling Bias} (\S\ref{sec:nonrandom_sample})

inaccuracy inherent to Observation (Measurement) process



% ------------------------------------------------------------------------------
\subsection{Random Sample}\label{sec:random_sample}
% ------------------------------------------------------------------------------

A \emph{Random Sample} (or \emph{Probability Sample}) is a Sample where each
individual Member of the Population has a known Non-zero Probability of being
selected as part of the Sample.

A Random Vector (Multivariate Random Variable \S\ref{sec:random_vector}) of IID
(\S\ref{sec:iid}) Random Variables $X_1, \ldots, X_n \sim F$ is called a
\emph{Random Sample of Size $n$ from $F$} -- in Statistics it is commonly
assumed that Observations are IID.

\fist cf. \emph{Statistical Randomness} (\S\ref{sec:statistical_randomness}),
\emph{Algorithmic Randomness} (\S\ref{sec:algorithmic_randomness})

\fist Monte Carlo Simulation (\S\ref{sec:monte_carlo})

\fist Random Assignment (Counterfactual Causal Inference
\S\ref{sec:counterfactual_model})



\subsubsection{Simple Random Sample}\label{sec:simple_random_sample}

\subsubsection{Systematic Sample}\label{sec:systematic_sample}

\subsubsection{Stratified Random Sample}\label{sec:stratified_random_sample}

cf. Benchmarking (``\emph{Post-stratification}'' \S\ref{sec:benchmarking})

Horvitz-Thompson Estimator (\S\ref{sec:horvitz_thompson})



% ------------------------------------------------------------------------------
\subsection{Non-random Sample}\label{sec:nonrandom_sample}
% ------------------------------------------------------------------------------

(or \emph{Non-probability Sample} or \emph{Biased Sample})

cf. Statistical Bias (\S\ref{sec:statistical_bias})

\emph{Accidental Sample} (\emph{Convience Sample})

\emph{Consecutive Sample}

\emph{Snowball Sample}

\emph{Purposive Sample} (\emph{Judgemental Sample})

\emph{Quota Sample}

\emph{Quadrature Nodes} (Quasi-Monte Carlo Methods) %FIXME: xref



% ------------------------------------------------------------------------------
\subsection{Statistic}\label{sec:statistic}
% ------------------------------------------------------------------------------

(wiki):

or \emph{Sample Statistic}

Computed by applying a Function (Statistical Algorithm) to Sample Data, i.e. a
Statistic is a Function of the Random Variable (\S\ref{sec:random_variable})
constituting a Random Sample, therefore a Statistic itself is an
\emph{Observable} Random Variable:
\[
  T_n = g(X_1, \ldots, X_n)
\]

the term \emph{Statistic} may be used both for the Function and for the value of
the Function on a given Sample

the Probability Distribution (\S\ref{sec:probability_distribution}) of a
Statistic is a \emph{Sampling Distribution} (\S\ref{sec:sampling_distribution})

a \emph{Statistic} is to a \emph{Sample} as a \emph{Parameter}
(\S\ref{sec:population_parameter}) is to a Population (\S\ref{sec:population})

\fist an \emph{Estimator} (\S\ref{sec:estimator}) is a Statistic used to
Estimate a Population Parameter

\fist Resampling (\S\ref{sec:resampling}) is a method of Estimating the
precision of a Sample Statistic

$\overline{x}$, $\sigma^2$

\begin{itemize}
  \item Descriptive Statistics (\S\ref{sec:descriptive_statistics}) --
    Descriptive (Summary) Statistic (\S\ref{sec:summary_statistic}) used to
    describe Data
  \item Estimation Theory (\S\ref{sec:estimation_theory}) -- Estimator used to
    describe Population Parameter
  \item Hypothesis Testing (\S\ref{sec:hypothesis_testing}) -- Test Statistic
    (\S\ref{sec:test_statistic}) used to Test a Hypothesis
\end{itemize}

(Wasserman04 \S9.13.2) a Statistic induces a \emph{Partition} on the Set of
Outcomes (FIXME: clarify)



\subsubsection{Sampling Distribution}\label{sec:sampling_distribution}

Probability Distribution of a Statistic (\S\ref{sec:statistic})

Statistical Inference (\S\ref{sec:inferential_statistics})

the Standard Deviation (\S\ref{sec:standard_deviation}) of a Sampling
Distribution is called the \emph{Standard Error} (\S\ref{sec:standard_error})

(Wasserman04 \S6.3.1):
the Distribution of a Point Estimator (\S\ref{sec:point_estimator})
$\hat{\theta}_n = g(X_1,\ldots,X_n)$



\subsubsection{Robust Statistic}\label{sec:robust_statistic}

\fist Info-gap Decision Theory (\S\ref{sec:info_gap}) -- Non-probabilistic
Decision Theory seeking to optimize Robustness to ``failure'' under severe
Uncertainty (\S\ref{sec:uncertainty_analysis})



\subsubsection{Sufficient Statistic}\label{sec:sufficient_statistic}

a \emph{Sufficient Statistic} is a Statistic that contains all the
Information (\S\ref{sec:information}) in the Data

(Wasserman04 \S9.13.2):

a Statistic if Sufficient if the Likelihood Function (\S\ref{sec:likelihood})
can be computed knowing only $T(X^n)$,
\emph{or}: a Statistic is Sufficient if the Distribution of $X^n$ given
$T(X^n) = t$ does not depend on Model Paramters $\theta$

a Statistic is \emph{Minimal Sufficient} if it is Sufficient and is a Function
of every other Sufficient Statistic

\emph{Factorization Theorem}

\emph{Rao-Blackwell Theorem} -- an Estimator (\S\ref{sec:estimator}) that does
not depend on a Sufficient Statistic is sub-optimal

for Exponential Family Distributions (\S\ref{sec:exponential_family}) which have
PDFs of the form:
\[
  f(x; \theta) = h(x) e^{\eta(\theta)T(x) - B(\theta)}
\]
$T$ is called the \emph{Natural Sufficient Statistic}



\subsubsection{Degrees of Freedom}\label{sec:statistical_freedom}



% ------------------------------------------------------------------------------
\subsection{Variance Analysis}\label{sec:variance_analysis}
% ------------------------------------------------------------------------------

ANalysis Of VAriance (ANOVA)

repeated Measures (Observations \S\ref{sec:observation})

cf. Mixed Models (\S\ref{sec:mixed_model})

Analysis of the the differences among ``group means'' (FIXME: clarify) in a
Sample (\S\ref{sec:sample})

generalizes $t$-test (\S\ref{sec:t_test}) to more than two groups

compare three or more ``group means'' for Significance
(\S\ref{sec:statistical_significance})

\fist Multivariate Analysis of Variance (MANOVA \S\ref{sec:manova})



\subsubsection{Squared Deviation from Mean (SDM)}\label{sec:sdm}

Variance (\S\ref{sec:variance}) is defined as either the Expected Value of the
SDM, considering a theoretical Distribution, or its Sample Mean
(\S\ref{sec:sample_mean})

cf. Least Squares (\S\ref{sec:least_squares}), Regression
(\S\ref{sec:regression_analysis})



\subsubsection{Sum of Squared Deviation}\label{sec:sum_squared_deviation}

\fist cf. Least Squares (\S\ref{sec:least_squares})

unscaled measure of \emph{Dispersion} (Variability \S\ref{sec:dispersion})

Estimates the Variance (\S\ref{sec:variance}) when scaled for the number of
\emph{Degrees of Freedom} (\S\ref{sec:statistical_freedom})



\paragraph{Total Sum of Squares (TSS)}\label{sec:tss}\hfill

equal to SSR + ESS



\paragraph{Sum of Squared Residuals (SSR)}\label{sec:ssr}\hfill

Residuals (\S\ref{sec:residual})

\fist a \emph{Least Square Estimate} (\S\ref{sec:least_squares}) is an
approximate solution of an Overdetermined System that minimizes the Sum of
Squared Residuals (SSR)

the SSR is a measure of how well an Estimated Regression Function
(\S\ref{sec:regression_analysis}) $\hat{r}(x)$ ``Fits'' the Data; Regression
Parameters that minimize SSR are called \emph{Least Squares Estimates}

\[
  \sum_{i=1}^n \hat{\epsilon}_i^2
\]



\paragraph{Explained Sum of Squares (ESS)}\label{sec:ess}\hfill



\subsubsection{Partition of Sum of Squares}\label{sec:partition_squares}



% ==============================================================================
\section{Descriptive Statistics}\label{sec:descriptive_statistics}
% ==============================================================================

Summary of Data: Mean, Median, Mode, Standard Deviation

cf. Test Statistics (\S\ref{sec:test_statistic})

Descriptive Statistics are often Non-parametric
(\S\ref{sec:nonparametric_model})



% ------------------------------------------------------------------------------
\subsection{Summary Statistics}\label{sec:summary_statistics}
% ------------------------------------------------------------------------------

various Summary Statistics can be computed by Statistical Functionals
(\S\ref{sec:statistical_functional}), i.e. Functions of the CDF
(\S\ref{sec:cdf}):
\begin{itemize}
  \item $\mu = T(F) = \int x dF(x)$
    -- Mean (Expectation \S\ref{sec:expected_value})
  \item $\sigma^2 = T(F) = \int (x - \mu)^2 dF(x)$
    -- Variance (\S\ref{sec:variance})
  \item $m = T(F) = F^{-1}(0.5)$
    -- Median (\S\ref{sec:median})
\end{itemize}



\subsubsection{Central Tendency}\label{sec:central_tendency}

\paragraph{Median}\label{sec:median}\hfill

Central Tendency for Ordinal Measurement (\S\ref{sec:measurement_level})

as an Estimate (\S\ref{sec:estimation_theory}) for $X$, the Median $m[X]$
minimizes Absolute Error (\S\ref{sec:error}); cf. the Mean (Expected Value
\S\ref{sec:expected_value}) minimizes Squared Error

note that $E(X + Y) = E(X) + E(Y)$, but not for $m(X+Y)$



\paragraph{Mode}\label{sec:mode}\hfill

cf. \emph{Unimodality}

Central Tendency for Nominal Measurement (\S\ref{sec:measurement_level})



\paragraph{Arithmetic Mean}\label{sec:arithmetic_mean}\hfill

\emph{Arithmetic Mean} $\overline{x} = \frac{1}{n}\sum_{i=1}^n x_i$

by the Law of Large Numbers (\S\ref{sec:large_numbers}), the Arithmetic Mean
Converges to the Mean (Expected Value \S\ref{sec:expected_value}) as the Sample
Size gets larger

Central Tendency for Interval Measurement (\S\ref{sec:measurement_level})



\subparagraph{Weighted Arithmetic Mean}\label{sec:weighted_mean}\hfill

\emph{Weight Function}

\emph{Weighted Sum} or \emph{Weighted Average}

\fist Benchmarking (\S\ref{sec:benchmarking})

Simpson's Paradox



\paragraph{Geometric Mean}\label{sec:geometric_mean}\hfill

using the Product of Values instead of Sum as in Arithmetic Mean

Central Tendency for Ratio Measurement (\S\ref{sec:measurement_level})



\paragraph{Trimmed Mean}\label{sec:trimmed_mean}\hfill

\paragraph{Sample Median}\label{sec:median}\hfill



\subsubsection{Statistical Dispersion}\label{sec:dispersion}

or \emph{Variability}

measured by Statistics of the Distribution of Deviations (\S\ref{sec:deviation})

quantified by Standard Deviation (\S\ref{sec:standard_deviation})

\fist Sum of Squared Deviations (\S\ref{sec:sum_squared_deviation}) -- unscaled
measure of Dispersion

cf. \emph{Uncertainty}

2018 - \emph{Uncertainty: a Tutorial} -
\url{https://blog.evjang.com/2018/12/uncertainty.html}



\paragraph{Standard Deviation}\label{sec:standard_deviation}\hfill

$\sigma$

Square Root of the Variance (\S\ref{sec:variance}) $\sqrt{V(X)}$

Deviation (\S\ref{sec:deviation})

the Standard Deviation of a Sampling Distribution
(\S\ref{sec:sampling_distribution}) is called the \emph{Standard Error}
(\S\ref{sec:standard_error})

the Standard Error equals the Standard Deviation divided by the square root of
the Sample Size, i.e. the Standard Error of the Mean is a measure of
``Dispersion'' of Sample Means around the Population Mean

cf. Confidence Interval (\S\ref{sec:confidence_interval})

\emph{Uncorrected Standard Deviation}:
\[
  s_n = \sqrt{\frac{1}{n}\sum_{i=1}^n (x_i - \overline{x})^2}
\]

\emph{Corrected Standard Deviation}

\emph{Unbiased Standard Deviation}



\paragraph{Sample Variance}\label{sec:variability}\hfill

$s^2$

Degrees of Freedom, Linear Independence, Biased/Unbiased Estimator
(\S\ref{sec:unbiased_estimate})

Unbiased Sample Variance:
\[
  s^2 = \frac{n}{n-1}\sigma^2_y =
  \frac{1}{n-1} \sum_{i=1}^n (y_i - \overline{y})^2
\]



\subparagraph{Chebyshev's Inequality}\label{sec:chebyshevs_inequality}
\hfill

Probability that a Random Variable $X$ will assume Value within $k$ Standard
Deviations

Random Variable $X$ with Finite Expected Value (\S\ref{sec:expected_value})
$\mu$ and Finite Non-zero Variance $\sigma^2$, for any $k \in \reals : k > 0$:
\[
  P(k\sigma \leq |X - \mu|) \leq \frac{1}{k^2}
\]



% ------------------------------------------------------------------------------
\subsection{Earthmover Distance}\label{sec:earthmover_distance}
% ------------------------------------------------------------------------------

%FIXME: does this section belong here?

a measure of ``nearness'' for Probability Distributions

\url{https://jeremykun.com/2018/03/05/earthmover-distance/}



% ==============================================================================
\section{Inferential Statistics}\label{sec:inferential_statistics}
% ==============================================================================

\emph{Statistical Inference} (or ``\emph{Learning}'' in Computer Science) --
using \emph{Sample Data} (\S\ref{sec:sample}) to \emph{Infer} (cf. Logical
Inference \S\ref{sec:logical_inference}, Inference Rules
\S\ref{sec:inference_rule}) the Distribution
(\S\ref{sec:probability_distribution}) that ``generated'' the Data

\fist cf. Statistical Learning Theory (\S\ref{sec:statistical_learning_theory})

\fist cf. Probabilistic Inference
(\S\ref{sec:probabilistic_inference}), Inductive Inference
(\S\ref{sec:inductive_inference})

\fist Probabilistic Classification (\S\ref{sec:probabilistic_classification}) --
use of Statistical Inference to solve a Statistical Classification
(\S\ref{sec:statistical_classification}) problem

(wiki)

two approaches to Statistical Inference, both relying on some \emph{Statistical
  Model} (\S\ref{sec:statistical_model}) to represent a ``Data-generating
Process'' (cf. Stochastic Process \S\ref{sec:stochastic_process}):
\begin{enumerate}
  \item \emph{Model-based Inference} -- the Model is taken to be initially
    unknown and the goal is to \emph{Select} (\S\ref{sec:model_selection}) a
    Model for Inference
  \item \emph{Design-based Inference} -- the Model is taken to be known and the
    goal is to ensure Sample Data is selected \emph{Randomly}
    (\S\ref{sec:random_sample}) enough for Inference
\end{enumerate}
the Statistical Assumptions (\S\ref{sec:statistical_assumption}) made by a
Statistical Model depends on the approach taken

Wasserman04 - \emph{All of Statistics}, Part II \emph{Models, Statistical
  Inference and Learning}



% ------------------------------------------------------------------------------
\subsection{Statistical Assumption}\label{sec:statistical_assumption}
% ------------------------------------------------------------------------------

(wiki):

\emph{Informally}, a Statistical Model (\S\ref{sec:statistical_model}) can be
thought of as a Set of Statistical Assumptions that allow the calculation of the
Probability of any Event (\S\ref{sec:event}), i.e. the Statistical Model
``embodies'' the Set of Statistical Assumptions that concern the
\emph{Generation} (\S\ref{sec:data_generating_process}) of Sample Data
(\S\ref{sec:sample}).

\emph{Classes of Assumptions} depend on which approach to Statistical Inference
is used (Model-based Inference or Design-based Inference):
\begin{enumerate}
  \item \emph{Model-based Assumptions}:
    \begin{itemize}
      \item \emph{Distributional Assumptions} -- Assumptions about the
        Probability Distribution of Random Errors (\S\ref{sec:random_error})
      \item \emph{Structural Assumptions} -- Assumptions about the form of a
        Statistical Relationship (Dependence \S\ref{sec:dependence}) between
        Variables, e.g. as in Linear Regression (\S\ref{sec:linear_regression})
      \item \emph{Cross-variation Assumptions} -- Assumptions involving Joint
        Probability Distributions (\S\ref{sec:joint_probability}) of either
        Observations or Random Errors in a Model; simple Models may Assume that
        Observations or Errors are Statistically Independent
        (\S\ref{sec:independence})
    \end{itemize}
  \item \emph{Design-based Assumptions} -- Assumptions of the way Observations
    have been made, e.g. Assumption of Randomization during Sampling
    (\S\ref{sec:random_sample})
\end{enumerate}

cf. Statistical Hypothesis (\S\ref{sec:hypothesis})

\fist Assumption (Proof Theory \S\ref{sec:antecedent})



% ------------------------------------------------------------------------------
\subsection{Statistical Model}\label{sec:statistical_model}
% ------------------------------------------------------------------------------

A \emph{Statistical Model} (or \emph{Probabilistic Model})
$\mathfrak{F} = (S,\mathcal{P})$ is a Sample Space (\S\ref{sec:sample_space}),
$S$, together with a Set of Probability Distributions
(\S\ref{sec:probability_distribution}) $\mathcal{P}$ on $S$

(wiki): \emph{Informally}, a Statistical Model can be thought of as a Set of
Statistical Assumptions (\S\ref{sec:statistical_assumption}) that allow the
calculation of the Probability of any Event (\S\ref{sec:event}), i.e. the
Statistical Model ``embodies'' the Set of Statistical Assumptions that concern
the \emph{Generation} (\S\ref{sec:data_generating_process}) of Sample Data
(\S\ref{sec:sample}).

\begin{itemize}
  \item \emph{Parametric Models} (\S\ref{sec:parametric_model}) -- Distributions
    are Parameterized by a Finite number of \emph{Statistical Parameters}
    (Population Parameters \S\ref{sec:population_parameter})
  \item \emph{Non-parametric Models} (\S\ref{sec:nonparametric_model})
    -- has an Infinite-dimensional Parameter Space
  \item \emph{Semi-parametric Models} (\S\ref{sec:semiparametric_model}) -- has
    Finite-dimensional Parameters and Infinite-dimensional
    ``Nuisance Parameters''
  \item \emph{Semi-nonparametric Models} (\S\ref{sec:seminonparametric_model})
    -- has both Finite-dimensional and Infinite-dimensional unknown Parameters
    of interest
\end{itemize}

\fist a \emph{Regression Model} (\S\ref{sec:regression_model}) makes some
assumption about the Relations (Dependences \S\ref{sec:dependence}) among
Multivariate Data (\S\ref{sec:random_vector})

\emph{Estimation} (\S\ref{sec:estimation_theory}): Data $\rightarrow$ Parameters

\emph{Prediction} (\S\ref{sec:prediction})

\emph{Hypothesis Testing} (\S\ref{sec:hypothesis_testing})

(wiki):

$\mathfrak{F} = (S, \mathcal{P})$

$S$ -- ``Sample Space''

$\mathcal{P}$ -- Set of Probability Distributions
(\S\ref{sec:probability_distribution}) on $S$

Wasserman04, Ch.6

\asterism

MIT 6.041SC - \emph{Probabilistic Systems Analysis and Applied Probability}

Probability Laws -- describes ``beliefs'' about which outcomes are more likely
than others; should obey Probability Axioms (\S\ref{sec:probability_axioms})

Sample Space $\Omega$ -- description of possible outcomes

a ``list'' of Events should be Mutually Exclusive
(\S\ref{sec:mutually_exclusive}, for $\sigma$-additivity Axiom) and exhaustive
(for Unitarity Axiom)

\emph{Discrete Uniform Law} (\S\ref{sec:discrete_uniform_law}): all Outcomes are
equally likely

\emph{Continuous Uniform Law} (\S\ref{sec:continuous_uniform_law}): equal Areas
have equal Probabilities

Discrete Models

Continuous Models -- any individual outcome has Zero Probability (TODO: explain)

Models based on Conditional Probabilities (\S\ref{sec:conditional_probability})



\subsubsection{Model Validation}\label{sec:model_validation}

(wiki):

confirming that the ``outputs'' of a Statistical Model are ``acceptable'' with
respect to the ``real'' Data Generating Process
(\S\ref{sec:data_generating_process})

can be based on two types of Sample Data (\S\ref{sec:sample}):
\begin{enumerate}
  \item Data that was used in the \emph{construction} of the Model -- usually
    involves analyzing the \emph{Fit} (\S\ref{sec:model_fit}) or \emph{Residual
      Diagnostics} (\S\ref{sec:residual})
  \item Data that was \emph{not} used in the construction of the Model --
    usually involves analyzing whether the Model's ``\emph{Predictive
      Performance}'' (\S\ref{sec:prediction_interval}) holds up when applied to
    new Data
\end{enumerate}



\paragraph{Fit}\label{sec:model_fit}\hfill

\emph{Goodness-of-Fit}

measures the discrepancy between Observed (\S\ref{sec:observation}) values and
Predicted (\S\ref{sec:prediction}) values under the Statistical Model

\fist analysis of Residuals (Fitting Deviation \S\ref{sec:residual})

cf. Regression Analysis (\S\ref{sec:regression_analysis}), Curve Fitting
(\S\ref{sec:curve_fitting})

Likelihood-Ratio (LR) Test (\S\ref{sec:lr_test})



\paragraph{Cross-validation}\label{sec:cross_validation}\hfill

or \emph{Rotation Estimation} or \emph{Out-of-sample Testing}

Predictive Models (\S\ref{sec:predictive_model})



\subsubsection{Parametric Model}\label{sec:parametric_model}

\emph{Parametric Statistics}

A \emph{Parametric Model} or \emph{Finite-dimensional Model} assumes that Sample
Data (\S\ref{sec:sample}) comes from a Population that follows a Probability
Distribution based on a fixed Finite Set of \emph{Statistical Parameters}
(Population Parameters \S\ref{sec:population_parameter}).

A Parametric Model is defined by a collection of Probability Distributions,
$\mathfrak{F} = \{ F_\theta \ |\ \theta \in \Theta \}$, Indexed by a Finite Set
$\Theta$ called the \emph{Parameter Space}. For a Parametric Model with
Real-valued Parameters, $\Theta \subseteq \reals^k$ for some Positive Integer
$k$.

A Parametric Model consisting of Absolutely Continuous Distributions
can be specified in terms of corresponding Probability Density Functions:
\[
  \mathfrak{F} = \{ f(x; \theta) \ |\ \theta \in \Theta \}
\]

\emph{example}:
\begin{itemize}
  \item the Family of Normal Distributions (\S\ref{sec:normal_distribution}) are
    Parameterized by the Mean and Standard Deviation:
    \[
      \mathfrak{F} = \Big\{
        f(x; \mu, \sigma) =
          \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
        \ \Big|\ \mu \in \reals, \sigma > 0
      \Big\}
    \]
    where $f(x; \mu, \sigma)$ is the PDF of each Normal Distribution
    %FIXME: the above example is from wasserman04, 6.2; the pdf given differs
    % from that on wikipedia for a normal distribution
\end{itemize}

Parameter Estimation:
\begin{itemize}
  \item Method of Moments
  \item Maximum Likelihood Estimation (MLE \S\ref{sec:mle})
  \item ...
\end{itemize}
(TODO: xrefs)

``Parameters of Interest'', ``Nuisance Parameters''



\paragraph{Exponential Family}\label{sec:exponential_family}\hfill

has PDFs of the form:
\[
  f(x; \theta) = h(x) e^{\eta(\theta)T(x) - B(\theta)}
\]
where $T$ is called the \emph{Natural Sufficient Statistic}
(\S\ref{sec:sufficient_statistic}) and $\eta$ is called the \emph{Natural
  Parameter}

includes:
\begin{itemize}
  \item Normal Distribution
  \item Exponential Distribution
  \item Gamma Distribution
  \item Wishart Distribution
  \item Chi-squared Distribution
  \item Beta Distribution
  \item Dirichlet Distribution
  \item Bernoulli Distribution
  \item Poisson Distribution
  \item Categorical Distribution
  \item Geometric Distribution
\end{itemize}
(TODO: xrefs)

when Observations come from an Exponential Family, under mild conditions the
Least-squares Estimates (\S\ref{sec:least_squares}) and Maximum-Likelihood
Estimates (\S\ref{sec:mle}) are identical



\paragraph{Fixed Effects Model}\label{sec:fixed_effect}\hfill

\paragraph{Random Effects Model}\label{sec:random_effect}\hfill

\paragraph{Mixed Model}\label{sec:mixed_model}\hfill

both Fixed Effects and Random Effects

useful in settings where repeated Measurements (Observations
\S\ref{sec:observation}) are made ont he same Statistical Units
(\S\ref{sec:statistical_units}), i.e. a ``Longitudinal Study'', or where
Measurements are made on \emph{clusters} of related Statistical Units

cf. ANOVA (Variance Analysis \S\ref{sec:variance_analysis})

BLUP (\S\ref{sec:blup})



\subsubsection{Non-parametric Model}\label{sec:nonparametric_model}

a Model that cannot be Parameterized by a Finite Parameter Set

e.g. the Model of \emph{all} Cumulative Distribution Functions (CDFs
\S\ref{sec:cdf}) is Non-parametric

Parameter Set (or \emph{Feature Set} in Machine Learning) is not fixed, i.e. it
may increase or decrease as new relevant information is collected

Descriptive Statistics (\S\ref{sec:descriptive_statistics}) are often
Non-parametric

\fist Non-parametric Inference: Statistical Functionals
(\S\ref{sec:statistical_functional}), Resampling Methods
(\S\ref{sec:resampling}), Non-parametric Regression
(\S\ref{sec:nonparametric_regression})

\emph{Stein's Paradox} -- when three or more Parameters are Estimated
simultaneously, there exist combined Estimators more accurate on average (having
lower Expected MSE) than any method handling the Parameters Separately



\paragraph{Order Statistic}\label{sec:order_statistic}

\paragraph{Rank Statistic}\label{sec:rank_statistic}



\subsubsection{Semi-parametric Model}\label{sec:semiparametric_model}

\subsubsection{Semi-nonparametric Model}\label{sec:seminonparametric_model}

\subsubsection{Discrete Choice Model}\label{sec:discrete_choice_model}

\paragraph{Binary Choice Model}\label{sec:binary_choice}\hfill

essentially the same as Binomial Regression
(\S\ref{sec:binomial_regression}) Models



\subsubsection{Logistic Model}\label{sec:discrete_uniform_law}

or \emph{Logit Model}

uses a Logistic Function (\S\ref{sec:logistic_function}) to Model a Binary
Dependent Variable

Logistic Regression (\S\ref{sec:logistic_regression})



\subsubsection{Graphical Model}\label{sec:graphical_model}

\emph{Log-linear Model} (\S\ref{sec:log_linear}) -- Fitting a Graphical Model to
Discrete Data \fist Pairwise Markov Graph (Undirected Graph
\S\ref{sec:pairwise_markov_graph})



\paragraph{Bayes Network}\label{sec:bayes_network}\hfill

or \emph{Probabilistic Directed Acyclic Graphical Model}

DAG (\S\ref{sec:dag}) -- Dependency structure

representation of Probability Distributions based on \emph{Causal Dependencies}
(\S\ref{sec:causal_graph})

\emph{Causality} (Pearl 2009) -- counterfactual reasoning

\url{https://golem.ph.utexas.edu/category/2018/07/bayesian_networks.html}



\subparagraph{Markov Condition}\label{sec:markov_condition}\hfill

every Node is Conditionally Independent (\S\ref{sec:conditional_independence})
of its Non-descendents, given its Parents

\emph{Causal Markov Condition}
--
Causal Graphs (\S\ref{sec:causal_graph})



\subparagraph{Directional Separation}\label{sec:directional_separation}\hfill

Directed Separation or $d$-separation



\subparagraph{Multilevel Model}\label{sec:multilevel_model}\hfill

\subparagraph{Random Tree}\label{sec:random_tree}\hfill



\subsubsection{Latent Variable Model}\label{sec:latent_variable_model}

\emph{Observable Variable} (\emph{Manifest Variable})

\emph{Latent Variable} (\emph{Hidden Variable})



\subsubsection{Discrete Uniform Law}\label{sec:discrete_uniform_law}

MIT 6.041SC Lec. 4 - \url{https://www.youtube.com/watch?v=6oV3pKLgW2I}

every possible Outcome has the same Probability of Occurring

Sample Space $\Omega$

the Probability of an Event $A$:
\[
  P(A) = \frac{|A|}{|\Omega|}
\]

for $|\Omega| = N$, every Element of $\Omega$ has Probability $\frac{1}{N}$

for a Subset $A$ with Cardinality $|A| = n$:
\[
  P(A) = n \frac{1}{N}
\]


Basic Counting Principles

for a Set with Cardinality $n$:
\begin{itemize}
  \item $n^\ell$ -- Possible Sequences of Length $\ell$ (with repetitions)
  \item $2^n$ -- Possible Subsets
  \item $\binom{n}{k}$ -- Possible Subsets of $k$ Elements
  \item $n!$ -- Possible Permutations (Orderings with no repetitions)
  \item $\frac{n!}{(n-k)!}$ -- Possible Permutations of $k$ Elements
  \item $n^2$ -- Possible Ordered Pairs
  \item $\frac{n(n-1)}{2}$ -- Possible Unique Pairings (Handshake problem)
\end{itemize}


Binomial Probabilities \fist Binomial Distribution
(\S\ref{sec:binomial_distribution}) -- Probability of getting exactly $k$
``successes'' in $n$ Trials where the Probability of ``success'' is $p$:
\[
  P(k,n,p) = \binom{n}{k}p^k(1-p)^{n-k}
\]
(FIXME: clarify)



\subsubsection{Continuous Uniform Law}\label{sec:continuous_uniform_law}

\subsubsection{Variational Bayesian Method}
\label{sec:variational_bayesian_method}

Free Energy Principle -- implicit Minimization of Variational Free Energy;
Active Inference (Friston)



\subsubsection{Model Selection}\label{sec:model_selection}

\paragraph{Optimality Criterion}\label{sec:optimality_criterion}\hfill

\fist Decision Rules (Decision Theory \S\ref{sec:decision_rule}): makes a
Choice using an Optimality Critereon



\paragraph{Akaike Information Criterion (AIC)}\label{sec:aic}\hfill

Mallows's $C_p$

\fist Information Theory (Part \ref{part:information_theory})



% ------------------------------------------------------------------------------
\subsection{Estimation Theory}\label{sec:estimation_theory}
% ------------------------------------------------------------------------------

deals with ``\emph{Estimating}'' the values of Statistical Parameters
(\S\ref{sec:population_parameter}) based on data that has a ``\emph{random
  component}'' (FIXME: clarify)

an \emph{Estimator} (\S\ref{sec:estimator}) attempts to approximate unknown
Statistical Parameters using ``measured data''

\fist cf. Decision Theory (\S\ref{sec:decision_theory}) -- choosing Estimators

\emph{Regression} (\S\ref{sec:regression_analysis}) is the Estimation of
Dependencies (\S\ref{sec:dependency}) in Multivariate Data
(\S\ref{sec:random_vector}), i.e. the Estimation of the \emph{Regression
  Function} (\S\ref{sec:regression_function}); commonly this is the Estimate of
the Conditional Expectation (\S\ref{sec:conditional_expectation}) of a Dependent
Variable given an Independent Variable

approaches:
\begin{itemize}
  \item \emph{Probabilistic} -- assume the Sample Data is Random with a
    Probability Distribution (\S\ref{sec:probability_distribution}) dependent on
    the Statistical Parameters of interest
  \item \emph{Set-membership} (\S\ref{sec:set_estimation}) -- assumes the
    Sample Data belongs to a Set that depends on the Parameters
\end{itemize}

\fist cf. Approximation Theory (\S\ref{sec:approximation_theory})



\subsubsection{Estimator}\label{sec:estimator}

\fist Decision Rule (Decision Theory \S\ref{sec:decision_rule})

(wiki):

an \emph{Estimator} attempts to approximate unknown Statistical Parameters
(\S\ref{sec:statistical_paramaeter}) using ``measured data''

when the Data consists of ``multiple variables'' (cf. Multivariate Statistics
\S\ref{sec:multivariate_statistics}), Estimating the ``relation'' between them
is \emph{Regression Analysis} (\S\ref{sec:regression_analysis})
--FIXME: clarify

\emph{Rao-Blackwell Theorem} -- an Estimator that does not depend on a
Sufficient Statistic (\S\ref{sec:sufficient_statistic}) is sub-optimal



\paragraph{Delta Method}\label{sec:delta_method}\hfill

(wiki): concerns the approximate Probability Distribution for a Function of an
Asymptotically Normal Estimator (e.g. MLE \S\ref{sec:mle}) from knowledge of the
limiting \emph{Variance} of the Estimator

\fist cf. Propagation of Error (\S\ref{sec:error_propagation})

\emph{Multivariate Delta Method}



\paragraph{Point Estimator}\label{sec:point_estimator}\hfill

\emph{Point Estimation} -- use of Sample Data to calculate a single value
(\emph{Point Estimate} or \emph{Statistic} \S\ref{sec:statistic}) to serve as an
Estimate of an unknown Population Parameter (\S\ref{sec:population_parameter})

\[
  \hat{\theta}_n = g(X_1, \ldots, X_n)
\]
where $X_1, \ldots, X_n$ are IID (\S\ref{sec:iid})

the Distribution of $\hat{\theta}_n$ is called a \emph{Sampling Distribution}
(\S\ref{sec:sampling_distribution}) and the Standard Deviation
(\S\ref{sec:standard_deviation}) of $\hat{\theta}_n$ is called the
\emph{Standard Error} (\S\ref{sec:standard_error})

\begin{itemize}
  \item Minimum-Variance Mean-Unbiased Estimator (MVUE)
  \item Best Linear Unbiased Estimator (BLUE)
  \item Minimum Mean Squared Error (MMSE)
  \item Median-Unbiased Estimator
  \item Maximum Likelihood Estimator (MLE \S\ref{sec:mle})
  \item Method of Moments (\S\ref{sec:moments_method})
\end{itemize}

Bayesian Point Estimation:
\begin{itemize}
  \item Posterior Mean
  \item Posterior Median
  \item Maximum A Posteriori (MAP)
\end{itemize}

(TODO: xrefs)



\subparagraph{Sample Mean}\label{sec:sample_mean}

Estimates the Population Mean (Expectation \S\ref{sec:expected_value})

for Random Variables (\S\ref{sec:random_variable}) $X_1, \ldots, X_n$:
\[
  \overline{X}_n = \frac{1}{n}\sum_i X_i
\]

\emph{Law of Large Numbers} (\S\ref{sec:large_numbers}): the Sample Mean
$\overline{X}_n = \frac{1}{n}\sum_i X_i$ \emph{Converges in Probability}
(\S\ref{sec:stochastic_convergence}) to the Expectation
(\S\ref{sec:expected_value}) $\mu = E(X_i)$ as $n \rightarrow \infty$, i.e.
$\overline{X}_n$ is close to $\mu$ with high Probability

\emph{Central Limit Theorem} (\S\ref{sec:central_limit}):
$\sqrt{n}(\overline{X}_n - \mu)$ \emph{Converges in Distribution} to a Normal
Distribution (\S\ref{sec:normal_distribution}) as $n \rightarrow \infty$, i.e.
the Sample Mean has approximately a Normal Distribution for large $n$



\subparagraph{Sample Variance}\label{sec:sample_variance}

Estimates the Population Variance



\subparagraph{Sample Covariance}\label{sec:sample_covariance}

Estimates the Population Covariance



\subparagraph{Maximum Likelihood Estimation}\label{sec:mle}\hfill

method of Estimating Population Parameters (\S\ref{sec:population_parameter})

$\hat{\theta}$ -- the value of $\theta$ that maximizes the Likilihood
(\S\ref{sec:likelihood}) $\mathcal{L}(\theta)$

under \emph{Regularity Conditions} (essentially Smoothness Conditions on
$f(x; \theta)$), MLE is Consistent, Equivariant, Asymptotically Normal, and
Asymptotically Optimal (or ``Efficient'' \S\ref{sec:efficiency})

\fist Delta Method (\S\ref{sec:delta_method})

when Observations come from an Exponential Family
(\S\ref{sec:exponential_family}), under mild conditions the Least-squares
Estimates (\S\ref{sec:least_squares}) and Maximum-Likelihood Estimates are
identical

the MLE Approximates (\S\ref{sec:approximation_theory}) the Bayes Estimator
(\S\ref{sec:bayes_estimator})

for Distributions satisfying ``Regularity Conditions'', e.g. Bernoulli and
Normal Distributions, Posterior Mean (\S\ref{sec:posterior_distribution}) is
generally close to the MLE

for Parametric Models satisfying ``Regularity Conditions'', MLE is approximately
Minimax (\S\ref{sec:minimax})

note that MLE is \emph{not} an optimal Estimator for high-dimensional problems,
e.g. when there are as many Parameters as there are Observations

$\hat{\theta} \pm 2\hat{S_E}$ is an approximate 95\% Confidence Interval, where
$S_E$ is the Standard Error

(Wasserman04 \S9.13.4) Numerical Approximations -- Iterative Method:
\begin{itemize}
  \item Newton-Raphson (Newton's Method \S\ref{sec:newtons_method})
  \item Expectation-Maximization (EM) Algorithm
\end{itemize}
produce a Sequence of values $\theta^0, \theta^1, \ldots$ that Converge to MLE
$\hat{\theta}$;
often the Method of Moements (\S\ref{sec:moments_method}) is a good starting
value of $\theta^0$



\subparagraph{Method of Moments}\label{sec:moments_method}\hfill

method of Estimating Population Parameters (\S\ref{sec:population_parameter})

Moment (\S\ref{sec:moment})

for $k$ unknown Parameters $\theta_1, \theta_2, \ldots, \theta_k$ builds a
System of $k$ Equations with $k$ Unknowns:
\begin{flalign*}
  & \hat{\mu_1} & = \mu_1 (\hat{\theta}_n) \\
  & \hat{\mu_2} & = \mu_2 (\hat{\theta}_n) \\
  &             & \vdots \\
  & \hat{\mu_k} & = \mu_k (\hat{\theta}_n) \\
\end{flalign*}
where $\mu_j = E_\theta(X^j) = \int x^j dF_\theta(x)$ is the $j^{th}$ Moment and
$\hat{\mu_j} = \frac{1}{n}\sum_{i=1}^n X_j^i$ is the $j^{th}$ Sample Moment, and
$\hat{\theta}_n$ is the \emph{Method of Moments Estimator}

can be used to derive Least-squares (\S\ref{sec:least_squares}) Estimator



\subparagraph{Maximum A Posteriori (MAP) Estimation}
\label{sec:map_estimator}\hfill

Bayesian Estimation

cf. Bayes Estimator (\S\ref{sec:bayes_estimator})



\paragraph{Interval Estimator}\label{sec:interval_estimator}\hfill

Confidence Intervals (Frequentist Inference \S\ref{sec:confidence_interval})

$\forall \theta \in \Theta, P_\theta(a(X) < \theta < b(X)) = 1 - \alpha$

Credible Intervals (Bayesian Inference \S\ref{sec:credible_interval})

$P(a(x) < \Theta < b(x) | X = x) = 1 - \alpha$

Prediction Interval (Regression Analysis \S\ref{sec:prediction_interval})

$\forall \theta \in \Theta, P_\theta(a(X) < Y < b(X)) = 1 - \alpha$

Likelihood Intervals (TODO)

Fiducial Intervals (TODO)

Tolerance Interval (TODO)



\paragraph{Horvitz-Thompson Estimator}\label{sec:horvitz_thompson}\hfill

method for Estimating Total and Mean of a Superpopulation in a Stratified Sample
(\S\ref{sec:stratified_sample})

cannot be derived from a Bayesian or Likelihood (\S\ref{sec:likelihood}) point
of view

Survey Analysis, Missing Data



\paragraph{Consistent Estimator}\label{sec:consistent_estimator}\hfill

or \emph{Asymptotically Consistent Estimator}

as the number of Data Points used increases, the resulting Sequence Converges in
Probability to the true value



\subsubsection{Deviation}\label{sec:deviation}

\emph{Statistical Dispersion} (``Variability'' \S\ref{sec:dispersion}) is
measured by Statistics of the Distribution of Deviations,
quantified by Standard Deviation (\S\ref{sec:standard_deviation})

Central Tendency (\S\ref{sec:central_tendency}) for Interval Measurement
(\S\ref{sec:measurement_level})
%FIXME

\fist Sum of Squared Deviations (\S\ref{sec:sum_squared_deviation})



\paragraph{Absolute Deviation}\label{sec:absolute_deviation}\hfill

\paragraph{Error}\label{sec:error}\hfill

\emph{Statistical Error} or \emph{Disturbance}

the amount by which an Observation differs from its (``true'')
\emph{Expected Value} (\S\ref{sec:expected_value})

\fist cf. \emph{Observational Error} (Measurement Error
\S\ref{sec:observational_error}), \emph{Standard Error}
  (\S\ref{sec:standard_error})

Absolute Error -- Median minimizes Absolute Error

Squared Error -- Mean (Expected Value) minimizes Squared Error

cf. \emph{Variance} (\S\ref{sec:variance}) -- Expected Squared Error

\fist Regression Error (\S\ref{sec:regression_error})

(wiki):

example for Sample (\S\ref{sec:sample}) of IID Normally Distributed Random
Variables, $X_1, \ldots, X_n \sim N(\mu, \sigma^2)$, the Sample Mean
(\S\ref{sec:sample_mean}):
\[
  \overline{X} = \frac{X_1 + \cdots + X_n}{n}
\]
is a Random Variable with Normal Distribution:
\[
  \overline{X} = N(\mu, \frac{\sigma^2}{n})
\]
and the \emph{Statistical Errors} are:
\[
  e_i = X_i - \mu
\]
and the \emph{Residuals} (\S\ref{sec:residual}) are:
\[
  r_i = X_i - \overline{X}
\]



\subparagraph{Mean Squared Error (MSE)}\label{sec:mse}\hfill

Mean Squared Error (MSE) or Mean Squared Deviation (MSD)

\fist Decision Theory (\S\ref{sec:decision_theory}): when Loss Function
(\S\ref{sec:objective_function}) is Squared Error, the Risk (Average Loss
\S\ref{sec:risk}) is the MSE



\subparagraph{Sampling Error}\label{sec:sampling_error}\hfill

\subparagraph{Non-sampling Error}\label{sec:nonsampling_error}\hfill

Coverage Errors

Response Errors



\paragraph{Residual}\label{sec:residual}\hfill

or \emph{Fitting Deviation}

the \emph{Residual} of an Observed Value is the difference between the Observed
Value and the \emph{Estimated} (\S\ref{sec:estimation_theory}) Value

\fist Regression Residual (\S\ref{sec:regression_residual})

\emph{Residual Diagnostics} is a means of \emph{Model Validation}
(\S\ref{sec:model_validation}) based on the Sample Data (\S\ref{sec:sample})
that was used to construct a Statistical Model (\S\ref{sec:statistical_model}),
consisting of analyzing whether Residuals of a constructed Statistical Model
(\S\ref{sec:statistical_model}) are \emph{Random}
(\S\ref{sec:statistical_randomness}), another method being analyzing how well
the Model Predictions (\S\ref{sec:prediction}) \emph{Fit}
(\S\ref{sec:model_fit}) the original Data

(wiki):

example for Sample (\S\ref{sec:sample}) of IID Normally Distributed Random
Variables, $X_1, \ldots, X_n \sim N(\mu, \sigma^2)$, the Sample Mean
(\S\ref{sec:sample_mean}):
\[
  \overline{X} = \frac{X_1 + \cdots + X_n}{n}
\]
is a Random Variable with Normal Distribution:
\[
  \overline{X} = N(\mu, \frac{\sigma^2}{n})
\]
and the \emph{Statistical Errors} (\S\ref{sec:error}) are:
\[
  e_i = X_i - \mu
\]
and the \emph{Residuals} are:
\[
  r_i = X_i - \overline{X}
\]



\subsubsection{Bias}\label{sec:bias}

cf. \emph{Systematic Error} (Statistical Bias \S\ref{sec:systematic_error})

\emph{Underfitting} (Multiple Regression \S\ref{sec:multiple_regression}) -- too
few Covariates, high Bias



\paragraph{Unbiased Estimate}\label{sec:unbiased_estimate}\hfill

\paragraph{Efficient Estimate}\label{sec:efficient_estimate}\hfill

Unbiased Estimator with Smallest Variance



\subsubsection{Standard Error}\label{sec:standard_error}

the \emph{Standard Error} $S_E$ of a Statistic (Estimate of a Parameter) is the
Standard Deviation (\S\ref{sec:standard_deviation}) of its Sampling Distribution
(\S\ref{sec:sampling_distribution})

the Standard Error equals the Standard Deviation divided by the square root of
the Sample Size, i.e. the Standard Error of the Mean is a measure of
``Dispersion'' of Sample Means around the Population Mean

\fist Resampling (\S\ref{sec:resampling})

\fist cf. \emph{Observational Error} (Measurement Error
\S\ref{sec:observational_error}), \emph{Statistical Error} (\S\ref{sec:error})



\subsubsection{Efficiency}\label{sec:efficiency}

\paragraph{Asymptotic Relative Efficiency (ARE)}\label{sec:are}\hfill



\subsubsection{Benchmarking}\label{sec:benchmarking}

or \emph{Post-stratification} (cf. Stratified Sampling
\S\ref{sec:stratified_sample})

(wiki): use of ``auxiliary information'' to adjust Sampling Weights
(\S\ref{sec:weighted_mean}) in an Estimation process



\subsubsection{Empirical Distribution Function}
\label{sec:empirical_distribution}

an Unbiased Estimator for the CDF (\S\ref{sec:cdf}) associated with the
Empirical Measure (\S\ref{sec:empirical_measure}) of a Sample
(\S\ref{sec:sample})

\fist cf. Empirical Processes (\S\ref{sec:empirical_process})

(Wasserman04 \S7.1)

for $X_1, \ldots, X_n \sim F$ an IID Sample (Random Sample \S\ref{sec:iid})
where $F$ is a CDF on the Real Line, the \emph{Empirical Distribution Function},
$\hat{F}_n$, is the Discrete CDF with Mass assigning $1/n$ at each Data Point
$X_i$:
\[
  \hat{F}_n(x) = \frac{\sum_{i=1}^n I(X_i \leq x)}{n}
\]
where:
\[
  I(X_i \leq x) = \begin{cases}
    1 & \text{if}\ X_i \leq x \\
    0 & \text{if}\ X_i > x \\
  \end{cases}
\]

\textbf{Thm.} \emph{
  At any fixed value of $x$:
  \begin{align*}
    E(\hat{F}_n(x)) & = F(x)                     \\
    V(\hat{F}_n(x)) & = \frac{F(x)(1 - F(x))}{n} \\
    MSE & = \frac{F(x)(1-F(x))}{n} \rightarrow 0 \\
    \hat{F}_n(x) & \xrightarrow{P} F(x)          \\
  \end{align*}
}

\emph{Glivenko-Cantelli Theorem}

\emph{Dvoretsky-Kiefer-Wolfowitz (DKW) Inequality} -- can be used to construct a
Non-parametric $1-\alpha$ Confidence Band (\S\ref{sec:confidence_band}) for $F$
(TODO)



\paragraph{Plug-in Principle}\label{sec:plugin_principle}\hfill

(wiki):

method of Estimation of Statistical Functionals (Functions of the CDF $F$) of a
Population Distribution by evaluating the same Functionals at the Empirical
Distribution based on a Sample

(Wasserman04 \S7.2)

the \emph{Plug-in Estimator} for a Statistical Functional
(\S\ref{sec:statistical_functional}) $\theta = T(F)$ is:
\[
  \hat{\theta} = T(\hat{F}_n)
\]

the Plug-in Estimator for a Linear Functional (\S\ref{sec:linear_functional}):
\[
  T(\hat{F}_n) = \frac{1}{n}\sum_{i=1}^n r(X_i)
\]

Sample Correlation

Sample Quantile



\subsubsection{Resampling}\label{sec:resampling}

methods of Estimating the precision of Sample Statistics (\S\ref{sec:statistic})

\fist Standard Error (\S\ref{sec:standard_error})

Non-parametric Inference (\S\ref{sec:nonparametric_model}), Permutation Tests
(\S\ref{sec:permutation_test})



\paragraph{Bootstrap Method}\label{sec:bootstrap_method}\hfill

Wasserman04 Ch. 8

for a Statistic (\S\ref{sec:statistic}) $T_n(F_n)$ where
$X = X_1, \ldots, X_n \sim F_n$, two steps:
\begin{enumerate}
  \item Estimate $T_n(F_n)$ with $T_n(\hat{F}_n)$ (Plug-in Principle
    \S\ref{sec:plugin_principle})
  \item Approximate $T_n(\hat{F}_n)$ using ``\emph{Simulation}'': drawing an
    Observation from $\hat{F}_n$ is equivalent to drawing one Point at Random
    from the original Data Set $X$
\end{enumerate}

Bootstrap Normal Interval, Bootstrap Pivotal Interval, Bootstrap Percentile
Interval

Parametric Bootstrap (Wasserman04 \S9.11)



\paragraph{Jackknife Method}\label{sec:jackknife_method}\hfill



\subsubsection{Least Squares}\label{sec:least_squares}

a \emph{Least Square Estimate} is an approximate solution of an Overdetermined
System that minimizes the Sum of Squared Residuals (SSR \S\ref{sec:ssr})

$2$-norm Best Fit \fist cf. $1$-norm Best Fit (\S\ref{sec:1norm_best_fit}),
Chebyshev Approximation ($\infty$-norm Best Fit
\S\ref{sec:chebyshev_approximation})

earliest form of Regression Analysis (\S\ref{sec:regression_analysis})
-- the Sum of Squared Residuals (SSR) gives a measure of how well
an Estimated Regression Function $\hat{r}(x)$ ``Fits'' the Data, and the
Regression Parameters that minimize SSR are called \emph{Least Squares
  Estimates}; under assumption of Normality, the Least Squares
Estimator is also the Maximum Likelihood Estimator (MLE \S\ref{sec:mle})

cf. Squared Deviation from the Mean (SDM \S\ref{sec:sdm})

(wiki): can be derived as a Method of Moments Estimator
(\S\ref{sec:moments_method});
when Observations come from an Exponential Family
(\S\ref{sec:exponential_family}), under mild conditions the Least-squares
Estimates and Maximum-Likelihood Estimates are identical



\paragraph{Linear Estimator}\label{sec:linear_estimator}\hfill

%FIXME

\subparagraph{Best Linear Unbiased Estimator (BLUE)}\label{sec:blue}\hfill

Estimating Fixed Effects (\S\ref{sec:fixed_effect})

cf. Best Linear Unbiased Predictor (BLUP \S\ref{sec:blup})
-- Predicting Random Effects (\S\ref{sec:random_effect})

\textbf{Gauss-Markov Theorem} \emph{
  In a Linear Model (\S\ref{sec:linear_regression}) where Errors are
  Uncorrelated, have Mean Zero, and equal Variances, the Best Linear Unbiased
  Estimator of the Coefficients is given by the Ordinary Least-Squares (OLS
  \S\ref{sec:ols}) Estimator.
}



\paragraph{Linear Least Squares (LLS)}\label{sec:lls}\hfill

Linear Regression (\S\ref{sec:linear_regression})

Overdetermined Systems (\S\ref{sec:overdetermined_system})

QR Decomposition (\S\ref{sec:qr_decomposition})

has a Closed-form solution



\subparagraph{Ordinary Least Squares (OLS)}\label{sec:ols}\hfill

\textbf{Gauss-Markov Theorem} \emph{
  In a Linear Model (\S\ref{sec:linear_regression}) where Errors are
  Uncorrelated, have Mean Zero, and equal Variances, the Best Linear Unbiased
  Estimator (BLUE \S\ref{sec:blue}) of the Coefficients is given by the Ordinary
  Least-Squares Estimator.
}



\subparagraph{Normal Equation}\label{sec:normal_equation}\hfill

UC Math 352 Lec. 7 \url{https://www.youtube.com/watch?v=ZWGIchXVbho}

$A\vec{x} = \vec{b}$

$\mathrm{min}_{\vec{x}} \|A_{\vec{x}} - \vec{b}\|$

\emph{Normal Equation}: $(A^TA)\vec{x} = A^T\vec{b}$ -- Condition Number
(\S\ref{sec:condition_number}) is $\kappa(A)^2$; see QR Factorization
(\S\ref{sec:qr_factorization}) for a better Conditioned solution

Project $\vec{b}$ onto the Column Space of $A$

\[
  \vec{x} = (A^TA)^{-1}A^T\vec{b}
\]

solve by Cholesky Factorization (\S\ref{sec:cholesky_decomposition}) ... TODO
\url{https://www.youtube.com/watch?v=VJ-04jOfu-E}



\subparagraph{QR Factorization}\label{sec:qr_factorization}\hfill

QR Decomposition (\S\ref{sec:qr_decomposition})

UC Math 352 Lec. 7 \url{https://www.youtube.com/watch?v=ZWGIchXVbho}

better Condition Number than Normal Equations (\S\ref{sec:normal_equation})

$A\vec{x} = \vec{b}$

$A = QR$ ($Q$ is Square, Orthogonal)

Residual $\vec{r} = A\vec{x} - \vec{b}$

\begin{align*}
     \vec{r} & = QR\vec{x} - \vec{b} \\
  Q^T\vec{r} & = R\vec{x} - Q^T\vec{b} \\
\end{align*}

because Orthogonal Matrices preserve Distances and $Q$ is Orthogonal:
\[
  \|Q^T\vec{r}\|_2 = \|\vec{r}\|_2
\]
minimizing $Q^T\vec{r} = \vec{\rho}$ is equivalent to minimizing $\vec{r}$

splitting $\vec{\rho}$ into:
\begin{enumerate}
  \item $\hat{\rho}   = \hat{R}\vec{x} - \hat{Q}^T\vec{b}$
  \item $\vec{\rho}_N = -Q_N^T\vec{b}$
\end{enumerate}
$\hat{rho}$ can be made Zero by solving $\hat{R}\vec{x} - \hat{Q}^T\vec{b}$ for
$\vec{x}$, which is an Upper Triangular Matrix that can be solved efficiently:
\[
  \vec{x} = \hat{R}^{-1}\hat{Q}^T\vec{b}
\]
and $\vec{rho}_N$ is independent of $\vec{x}$ so it is \emph{fixed}, so:
\[
  \|\vec{r}\|^2_2 = \|\hat{Q}_N^T\vec{b}\|_2^2
\]



\paragraph{Generalized Least Squares (GLS)}\label{sec:gls}\hfill

Linear Regression (\S\ref{sec:linear_regression}) technique when there is a
degree of Correlation between Residuals



\subparagraph{Weighted Least Squares}\label{sec:weighted_least_squares}\hfill

can be used in Regression Analysis to drop the Assumption that the Variance of
the Error is Constant accross Observations (\emph{Homoscedasticity}
\S\ref{sec:homoscedasticity})



\paragraph{Re-weighted Least Squares}\label{sec:reweighted_least_squares}\hfill

Logistic Regression (\S\ref{sec:Logistic_regression})



\paragraph{Polynomial Least Squares}\label{sec:polynomial_least_squares}\hfill

\paragraph{Non-linear Least Squares}\label{sec:nonlinear_least_squares}\hfill



\subsubsection{Pooled Estimate}\label{sec:pooled_estimate}

%FIXME



\subsubsection{Set Estimation}\label{sec:set_estimation}

Set-membership approach to Estimation Theory (cf. Probabilistic approach)



% ------------------------------------------------------------------------------
\subsection{Hypothesis Testing}\label{sec:hypothesis_testing}
% ------------------------------------------------------------------------------

or \emph{Confirmatory Data Analysis}

\url{https://github.com/puolival/multipy} -- Python library

A \emph{Statistical Test} is a ``procedure'' with Samples as input and results
in a \emph{Hypothesis} (\S\ref{sec:hypothesis}), i.e. a Conjecture
(\S\ref{sec:conjecture}) concerning one or more Statistical Populations
(\S\ref{sec:population}).

\fist In Bayesian Inference (\S\ref{sec:bayesian_inference}), a Hypothesis is
assigned a Probability, while in Frequentist Inference, a Hypothesis is Tested
without assigning a Probability.

Partitioning the Parameter Space (\S\ref{sec:parametric_model}) $\Theta$ into
Disjoint Sets $\Theta_0$ and $\Theta_1$, the \emph{Null Hypothesis}
(\S\ref{sec:null_hypothesis}), $H_0 = \vdash \theta \in \Theta_0$, represents
any Hypothesis, and the \emph{Alternative Hypothesis}
(\S\ref{sec:alternative_hypothesis}), $H_1 = \vdash \theta \in \Theta_1$,
represents an Hypothesis that is accepted in the case that the Null Hypothesis
is Rejected

\begin{enumerate}
  \item Sufficient Evidence: Reject $H_0$ in favor of $H_1$
  \item Insufficient Evidence: fail to Reject $H_0$
\end{enumerate}

\emph{Test Statistic} (\S\ref{sec:test_statistic}) $T(x)$

\emph{One-tail (One-sided) Test}:
\[
  H_0 = \vdash \theta \leq \theta_0 \quad\quad H_1 = \vdash \theta > \theta_0
\]
or:
\[
  H_0 = \vdash \theta \geq \theta_0 \quad\quad H_1 = \vdash \theta < \theta_0
\]

\emph{Two-tail (Two-sided) Test}:
\[
  H_0 = \vdash \theta = \theta_0 \quad\quad H_1 = \vdash \theta \neq \theta_0
\]

Test on a single Mean

Test on a single Sample

\emph{Critical Region} (\S\ref{sec:critical_region}) $R = \{ x : T(x) > c \}$

Type I Error: Rejection of $H_0$ when it is True

Type II Error: Non-Rejection of $H_0$ when it is False

$\beta$: Probability of committing a Type II Error

(Wasserman04, Ch.10)

the \emph{Power Function} of a Test with Rejection Region $R$:
\[
  \beta(\theta) = P_\theta(X \in R)
\]

\emph{Power} $1 - \beta$: Probability of Rejecting $H_0$ given that a
specific alternative is True

the \emph{Size} or \emph{Significance Level} (\S\ref{sec:significance_testing})
of a Test:
\[
  \alpha = \sup_{\theta \in \Theta_0} \beta(\theta)
\]

a Test has \emph{Level} $\alpha$ if its Size is less than or equal to $\alpha$

$p$-value: lowest Level of Significance at which the observed Value of
the Statistic is Significant

\begin{itemize}
  \item Test for Statistical Randomness (\S\ref{sec:statistical_randomness})
\end{itemize}

\emph{Neyman-Pearson Lemma} -- most Powerful Test for Simple Null Hypothesis
$H_0 = \vdash \theta = \theta_0$ and Simple Alternative Hypothesis
$H_1 = \vdash \theta = \theta_1$

\asterism

\textbf{Bayesian Testing} (\S\ref{sec:bayesian_inference})

(Wasserman04 \S11.8)

places a Prior Probability Distribution (\S\ref{sec:prior_distribution}) on
$H_0$ and on $\theta$ and then computing $P(H_0 | X^n)$; Priors cannot be
Improper; a Prior-free bound on $P(H_0|X^n = x^n)$:
\[
  \frac{\mathcal{L}(\theta_0)}{\mathcal{L}(\theta_0) + \mathcal{L}(\hat\theta)}
    \leq P(H_0|X^n = x^n) \leq 1
\]

\emph{Lindley's Paradox} (\emph{Jeffreys-Lindley Paradox})



\subsubsection{Hypothesis}\label{sec:hypothesis}

A \emph{Statistical Hypothesis} is a Conjecture (\S\ref{sec:conjecture}) or
Assertion (\S\ref{sec:assertion}) concerning one or more Populations
(\S\ref{sec:population}).

cf. Hypothesis (Antecedent \S\ref{sec:antecedent} of a Hypothetical Proposition
\S\ref{sec:proposition})



\paragraph{Null Hypothesis}\label{sec:null_hypothesis}\hfill

$H_0$



\paragraph{Alternative Hypothesis}\label{sec:alternative_hypothesis}\hfill

$H_1$



\paragraph{Simple Hypothesis}\label{sec:simple_hypothesis}\hfill

Hypothesis specifies the Population Distribution completely

$\theta = \theta_0$



\paragraph{Composite Hypothesis}\label{sec:composite_hypothesis}\hfill

$\theta < \theta_0$ or $\theta > \theta_0$



\subsubsection{Test Statistic}\label{sec:test_statistic}

Statistic (\S\ref{sec:statistic}), $T$

(Wasserman04, Ch.10)

\begin{itemize}
  \item $t$-statistic
  \item $F$-test
  \item ...
\end{itemize}



\paragraph{Critical Region}\label{sec:critical_region}\hfill

or \emph{Rejection Region}

set of Values of the Test Statistic for which the Null Hypothesis is rejected

\emph{Critical Values} -- boundaries of the Critical Region

$R = \{ x : T(x) > c \}$



\subsubsection{Significance Testing}\label{sec:significance_testing}

Fisher



\paragraph{Statistical Significance}\label{sec:statistical_significance}\hfill

the \emph{Size} or \emph{Significance Level} of a Test:
\[
  \alpha = \sup_{\theta \in \Theta_0} \beta(\theta)
\]

a Test has \emph{Level} $\alpha$ if its Size is less than or equal to $\alpha$

\fist ANalaysis Of VAriance (ANOVA \S\ref{sec:variance_analysis}) -- compare

three or more ``group means'' for Significance



\paragraph{$p$-value}\label{sec:p_value}\hfill

$p$-value: lowest Level of Significance at which the Observed value of
the Statistic is Significant

(Wasserman04 \S10.2):

the $p$-value is the Probability under the Null Hypothesis $H_0$ of Observing a
value of the Test Statistic the same as or more extreme than what was actually
Observed

\textbf{Thm.} \emph{
  If the Test Statistic has a Continuous Distribution, then under
  $H_0 = \vdash \theta = \theta_0$ the $p$-value has a $Uniform(0,1)$
  Distribution and therefore one Rejects $H_0$ when $p$-value is less than the
  Significance Level $\alpha$, and the Probability of a Type I Error is
  $\alpha$.
}



\subsubsection{Multiple Testing Problem}\label{sec:multiple_testing}

or \emph{Multiple Comparisons Problem}




\paragraph{False Discovery Rate (FDR)}\label{sec:fdr}\hfill

\subparagraph{Bonferroni Method}\label{sec:bonferroni_method}\hfill

\emph{False Discovery Rate (FDR)}



\paragraph{Bonferroni Method}\label{sec:bonferroni_method}\hfill

or \emph{Holm-Bonferroni Method}



\subsubsection{Wald Test}\label{sec:wald_test}



\paragraph{$t$-test}\label{sec:t_test}\hfill

\emph{Student's $t$-test}

\fist $t$-distribution (\S\ref{sec:t_distribution})

essentially equal to Wald Test for moderately large $n$

\fist cf. ANalysis Of VAriance (ANOVA \S\ref{sec:variance_analysis}) --
generalization of $t$-test to more than two groups



\subsubsection{Pearson's Chi-squared Test}\label{sec:pearsons_chi_squared}

\subsubsection{Exact Test}\label{sec:exact_test}

\emph{Exact Statistics} (\S\ref{sec:exact_statistics}) -- not based on Large
Sample Theory (Asymptotic Theory \S\ref{sec:asymptotic_theory})



\paragraph{Permutation Test}\label{sec:permutation_test}\hfill

\fist Exact Test

Non-parametric method for testing whether two Distributions are ``the same''

\fist cf. Resampling (\S\ref{sec:resampling})



\subsubsection{Likelihood-Ratio (LR) Test}\label{sec:lr_test}

used for comparing Fit (\S\ref{sec:model_fit}) of two Statistical Models



% ------------------------------------------------------------------------------
\subsection{Asymptotic Theory}\label{sec:asymptotic_theory}
% ------------------------------------------------------------------------------

or \emph{Large Sample Theory}

\fist cf. \emph{Exact Statistics} (\S\ref{sec:exact_statistics}) -- not based on
Large Sample Theory

\fist Asymptotic Distributions (\S\ref{sec:asymptotic_distribution})

\fist cf. Asymptotic Analysis (\S\ref{sec:asymptotic_analysis})

\fist cf. Asymptotically Consistent Estimator (\S\ref{sec:consistent_estimator})

(wiki):

framework for assessing properties of Estimators (\S\ref{sec:estimator}) and
Statistical Tests (Hypothesis Testing \S\ref{sec:hypothesis_testing}) as Sample
Size (\S\ref{sec:sample_size}) $n \rightarrow \infty$

\fist Stochastic Convergence (\S\ref{sec:stochastic_convergence}) -- Convergence
of Sequences (\S\ref{sec:convergent_sequence}) of Random Variables to Limit
Random Variables

Asymptotic Thoerems:
\begin{itemize}
  \item \emph{Law of Large Numbers} (\S\ref{sec:large_numbers}) --
    for Random Variables $X_1, \ldots, X_n$, the Sample Mean
    (\S\ref{sec:sample_mean}) $\overline{X}_n = \frac{1}{n}\sum_i X_i$ Converges
    in Probability to $\mu = E(X_i)$ as $n \rightarrow \infty$, i.e.
    $\overline{X}_n$ is close to $\mu$ with high Probability
  \item \emph{Central Limit Theorem} (\S\ref{sec:central_limit})
    for a Sequence of Random Variables $X_i, \ldots, X_n$ with Sample Mean
    $\overline{X}_n$, $\sqrt{n}(\overline{X}_n - \mu)$
    Converges in Distribution to a Normal Distribution
    (\S\ref{sec:normal_distribution}) as $n \rightarrow \infty$, i.e. the Sample
    Mean has approximately a Normal Distribution for large $n$
  \item ...
\end{itemize}



\subsubsection{Large Deviations Theory}\label{sec:large_deviations_theory}

\paragraph{Rate Function}\label{sec:rate_function}\hfill



% ------------------------------------------------------------------------------
\subsection{Exact Statistics}\label{sec:exact_statistics}
% ------------------------------------------------------------------------------

not based on Large Sample Theory (Asymptotic Theory
\S\ref{sec:asymptotic_theory})

\fist Exact Test (\S\ref{sec:exact_test})

Non-parametric



% ------------------------------------------------------------------------------
\subsection{Frequentist Inference}\label{sec:frequentist_inference}
% ------------------------------------------------------------------------------

Frequency Interpretation
(\url{https://plato.stanford.edu/entries/probability-interpret/#FreInt}) --
differs from the Classical Interpretation in counting only the \emph{actual}
Outcomes instead of the \emph{possible} Outcomes; Finite Frequentism (Venn)

$f(x; \theta)$

(Wasserman04 \S11.1)

Frequentist postulates:
\begin{enumerate}
  \item Probability refers to limiting Relative Frequencies and Probabilities
    are \emph{objective} properties of the ``real world''
  \item Parameters are fixed, unknown Constants, and no useful Probability
    statements can be made about Parameters
  \item Statistical procedures should be designed to have well-defined long-run
    Frequency properties
\end{enumerate}

cf. \emph{Bayesian Inference} (\S\ref{sec:bayesian_inference}) -- focus is on
subjective ``degree of belief''; assigns Probabilities to Parameters (they are
Random Variables)



\subsubsection{Relative Frequency}\label{sec:relative_frequency}

\emph{Empirical Probability} or \emph{Experimental Probability} or
\emph{Long-run Probability}

after conducting many Trials (\S\ref{sec:trial}) of the same Experiment
(\S\ref{sec:experiment}), the Relative Frequencies of the various Outcomes
(\S\ref{sec:outcome}) and Events (\S\ref{sec:probability_event}) can be assessed

\url{https://plato.stanford.edu/entries/probability-interpret/#FreInt}:

\emph{Hypothetical Frequentism}: extension of Relative Frequencies of an actual
Sequence of ``Trials'' to counterfactual, limiting Relative Frequencies in case
of an Infinite number of Trials

\emph{Reference Class Problem}: Relative Frequencies must be ``Relativised'' to
a ``Reference Class'' (other interpretations of Probability may have this
problem as well)--

solutions restrict to certain Sequences of Outcomes, e.g. (Infinite)
``\emph{Collectives}'' (Von Mises57)--cf. Infinite Bernoulli Sequences
(\S\ref{sec:bernoulli_sequence})--where a \emph{Place-selection} is an effective
method of selecting indices of Members of a Sequence such that the selection or
not of Index $i$ depends \emph{at most} on the first $i-1$ Outcomes
(``attributes''), with the Axioms of \emph{Convergence} (the limiting Relative
Frequency of any Outcome exists) and \emph{Randomness} (the limiting Relative
Frequency of each Outcome in a Collective $\omega$ is the same in any Infinite
Subsequence of $\omega$ determined by Place-selection; note that trivial
Sequences such as $H,H,H,\ldots$ satisfy this ``Randomness'' Axiom; cf. the
Principle of Maximum Entropy in Classical Probability), Algorithmic Randomness
(\S\ref{sec:algorithmic_randomness});
issues with limiting Relative Frequencies are that they violate Countable
Additivity and the Domain of Definition is not a Set-field or a $\sigma$-algebra
(de Finetti72)



\subsubsection{Propensity}\label{sec:propensity}

(wiki):

\emph{Chance} or \emph{Single-case Probability}

a purported ``\emph{cause}'' or explanation of an observed stable Relative
Frequency

invokes the Law of Large Numbers (\S\ref{sec:large_numbers}) to explain stable
\emph{long-run} Frequencies as a manifestation of invariant \emph{single-case}



\subsubsection{Frequency Distribution}\label{sec:frequency_distribution}

\subsubsection{Confidence Interval}\label{sec:confidence_interval}

or \emph{Confidence Set} for Parameter Spaces of Dimension $2$ or greater

(wiki):

for a Random Sample Vector (IID \S\ref{sec:iid}) $X$ from a Distribution with
Parameters $\theta \in \Theta$, a \emph{Confidence Interval} for $\theta$ with
\emph{Confidence Level} (or \emph{Confidence Coefficient}) $1 - \alpha$ is an
Interval with Random Endpoints $(a(X), b(X))$, determined by the Random
Variables $a(X)$ and $b(Y)$ such that:
\[
  \forall \theta \in \Theta, P_\theta(a(X) < \theta < b(X)) = 1 - \alpha
\]
note that $\theta$ is a fixed ``true'' value (not a Random Variable)

Confidence Limit

Prediction Interval (\S\ref{sec:prediction_interval})

Interval Measurement (\S\ref{sec:measurement_level})

Interval Estimate (\S\ref{sec:interval_estimator})

cf. Credible Intervals (Bayesian Inference \S\ref{sec:credible_interval})

Hypothesis Testing (\S\ref{sec:hypothesis_testing})

One-tail, Two-tail



\paragraph{Confidence Band}\label{sec:confidence_band}\hfill

\paragraph{Hoeffding's Inequality}\label{sec:hoeffdings_inequality}\hfill

used the analyze the number of required Samples needed to obtain a Confidence
Interval

\textbf{Thm.} (Hoeffding's Inequality)

\emph{
  For $Y_1, \ldots, Y_n$ Independent Observations (\S\ref{sec:observation}) such
  that $E(Y_i) = 0$ and $a_i \leq Y_i \leq b_i$, given $\epsilon > 0$, for any
  $t > 0$:
  \[
    P\Big(\sum_i Y_i \geq \epsilon\Big) \leq
      e^{-t\epsilon} \prod_i e^{t^2(b_i - a_i)^2/8}
  \]
}



% ------------------------------------------------------------------------------
\subsection{Bayesian Inference}\label{sec:bayesian_inference}
% ------------------------------------------------------------------------------

\emph{Evidential Probability} or \emph{Bayesian Probability} -- interpretation
of Probability as a ``reasonable'' \emph{Expectation} (\S\ref{sec:expecation})
or ``degree of belief''

$f(x | \theta)$

Conditional Probabilities (\S\ref{sec:conditional_probability}), Bayes' Rule
(\S\ref{sec:bayes_theorem})

\fist Bayesian Network (Probabilistic Directed Acyclic Graphical Model
\S\ref{sec:bayes_network})

Subjective Probability %FIXME: section
(\url{https://plato.stanford.edu/entries/probability-interpret/#SubPro}),
Conditioning (\S\ref{sec:conditioning})

\fist Subjective Logic (\S\ref{sec:subjective_logic})

(wiki): every unique Bayesian ``Procedure'' (Decision Rule
\S\ref{sec:decision_rule}) is Admissable (\S\ref{sec:admissable_decision}) and
every Admissable Statistical Procedure is either a Bayesian Procedure or a Limit
of Bayesian Procedures (Wald)

\fist Aumann1987 - \emph{Correlated Equilibrium as an Expression of Bayesian
  Rationality} -- \emph{Correlated Equilibrium}
(\S\ref{sec:correlated_equilibrium}) ``does away with'' the ``dichotomy usually
perceived'' between the \emph{Bayesian} and \emph{Game-theoretic} world-views

(Wasserman04, Ch.11)

Bayesian postulates:
\begin{enumerate}
  \item Probability describes \emph{degree of belief} (not limiting Frequency),
    so Probability statements can be made about things other than Random
    Variables
  \item Probability statements can be made about Statistical Parameters
  \item Inferences about a Parameter $\theta$ are made by producing a
    Probability Distribution for $\theta$, and Inferences such as Point
    Estimates and Interval Estimates can be extracted from this Distribution
\end{enumerate}

cf. \emph{Frequentist Inference} (\S\ref{sec:frequentist_inference}) -- focus is
on ``objective'' long-run Relative Frequencies, and Statistical Parameters are
assumed to be fixed constants, not Random Variables

\fist Bayesian Methods are tied to the \emph{Likelihood Function}
(\S\ref{sec:likelihood}) which does not yield accurate Inferances in
High-dimensional and Non-parametric problems

\emph{Bayesian Method}:
\begin{enumerate}
  \item choose a \emph{Prior Distribution} (\S\ref{sec:prior_distribution}) for
    Model Parameters $\theta$ defined by PDF (\S\ref{sec:pdf}) $f(\theta)$
  \item choose a \emph{Statistical Model} (\S\ref{sec:statistical_model})
    $f(x|\theta)$ reflecting the degree of ``belief'' about $x$ given $\theta$
  \item Observe (\S\ref{sec:observation}) Data (\S\ref{sec:statistical_sample})
    $X_1, \ldots, X_n$ and \emph{update} beliefs and calculate the
    \emph{Posterior Distribution} (\S\ref{sec:posterior_distribution})
    $f(\theta | X_1, \ldots, X_n)$
\end{enumerate}

for Discrete $\theta$ and single Discrete $X$:
\[
  P(\Theta = \theta | X = x) = \frac{
    P(X = x|\Theta = \theta)P(\Theta = \theta)
  }{
    \sum_\theta P(X = x | \Theta = \theta) P(\Theta = \theta)
  }
\]
(Bayes' Theorem \S\ref{sec:bayes_theorem})

for Continuous Variables:
\[
  f(\theta | x) = \frac{
    f(x|\theta)f(\theta)
  }{
    \int f(x|\theta)f(\theta) d\theta
  }
\]

for $n$ IID Observations $X_1, \ldots, X_n$:
\[
  f(x_1, \ldots, x_n | \theta) =
    \prod_{i=1}^n f(x_i | \theta) = \mathcal{L}_n(\theta)
\]
where $\mathcal{L}_n$ is the \emph{Likelihood Function}
(\S\ref{sec:likelihood_function})

for $x^n = (x_1, \ldots, x_n)$:
\[
  f(\theta|x^n) = \frac{\mathcal{L}_n(\theta)f(\theta)}{c_n}
    \propto \mathcal{L}_n(\theta)f(\theta)
\]
where $cn = \int \mathcal{L}_n(\theta)f(\theta) d\theta$ is the
\emph{Normalizing Constant}
%FIXME: same concept as Normalizing Constant for continuous random variables ?

i.e. \emph{Posterior is Proportional-to Likelihood times Prior}:
\[
  f(\theta | x^n) \propto \mathcal{L}(\theta)f(\theta)
\]

when the Prior and Posterior Distributions are in the same family, the Prior is
said to be ``\emph{Conjugate}'' with respect to the Model

for multiple Parameters $\theta = (\theta_1, \ldots, \theta_p)$, the Posterior
Density Function $f(\theta|x^n)$ is the same as above, and the \emph{Marginal
  Posterior} for an individual Parameter $\theta_1$ is:
\[
  f(\theta_1 | x^n) =
    \int\cdots\int f(\theta_1,\ldots,\theta_p | x^n) d\theta_2 \cdots d\theta_p
\]
Integral can be approximated by ``\emph{Simulation}''
(\S\ref{sec:stochastic_simulation}), i.e. ``drawing Randomly'' from the
Posterior (Wasserman04 11.7)



\subsubsection{Prior Distribution}\label{sec:prior_distribution}

$f(\theta)$

or \emph{Prior Probability}

when the Prior and Posterior Distributions (\S\ref{sec:posterior_distribution})
are in the same family, the Prior is said to be ``\emph{Conjugate}'' with
respect to the Model

\emph{Subjectivism}: Prior should reflect ``subjective opinion'' about $\theta$
before the Data are collected

\emph{Non-informative Prior} -- alternative to Subjective Prior, e.g. Flat
Prior, Jeffrey's prior

\emph{Proper Prior}

\emph{Improper Prior} -- $f(\theta) d\theta = \infty$

\emph{Flat Prior} -- $f(\theta) \propto c$ for some Constant $c$ (also an
Improper Prior since $\int f(\theta) d\theta = \infty$); Flat Priors are not
\emph{Transformation Invariant}: the notion of a Flat Prior is not well-defined
because a Flat Prior on a Parameter does not imply a Flat Prior on a Transformed
Parameter

\emph{Jeffrey's Prior} -- uses Fisher Information (\S\ref{sec:fisher_metric});
Transformation Invariant

(wiki):

\emph{Cromwell's Rule} -- Prior Probabilities of $0$ and $1$ should only be used
for Statements that are Logically True or False, e.g. $2+2 = 4$

\emph{Bernstein-von Mises Theorem} -- Posterior Distribution for unknown
quantities in any problem is effectively Asymptotically Independent of the Prior
Distribution, assuming it obeys \emph{Cromwell's Rule}, as the Sample Data
(\S\ref{sec:statistical_sample}) grows large

the effect of the Prior diminishes as $n$ (i.e. $(X_1, \ldots, X_n)$) increases



\subsubsection{Posterior Distribution}\label{sec:posterior_distribution}

$f(\theta | x^n)$

\emph{Posterior is Proportional-to Likelihood times Prior}
(\S\ref{sec:prior_distribution}):
\[
  f(\theta | x^n) \propto \mathcal{L}(\theta)f(\theta)
\]

Posterior Estimates:

\emph{Posterior Mean} (Point Estimate)

for Distributions satisfying ``Regularity Conditions'', e.g. Bernoulli and
Normal Distributions, Posterior Mean is generally close to the MLE (Mean
Likelihood Estimate \S\ref{sec:mle})

Posterior Mean is Admissable (\S\ref{sec:admissable_rule}) for any Strictly
Positive Prior

\emph{Posterior Interval} (Credible Interval \S\ref{sec:credible_interval})

(Wasserman04 \S11.4) Posteriors can be Approximated using ``\emph{Simulation}''
(\S\ref{sec:stochastic_simulation})

\emph{Bernstein-von Mises Theorem} -- Posterior Distribution for unknown
quantities in any problem is effectively Asymptotically Independent of the Prior
Distribution, assuming it obeys \emph{Cromwell's Rule}, as the Sample Data
(\S\ref{sec:statistical_sample}) grows large



\subsubsection{Conditioning}\label{sec:conditioning}

Subjective Probability
(\url{https://plato.stanford.edu/entries/probability-interpret/#SubPro}),
Orthodox Bayesianism (\S\ref{sec:bayesian_inference})

\fist cf. Passive, Active Conditioning (Causal Inference
\S\ref{sec:active_conditioning})

\fist not to be confused with Condition Numbers (Numerical Analysis
\S\ref{sec:condition_number})



\subsubsection{Likelihood}\label{sec:likelihood}

\fist Bayesian Methods are tied to the Likelihood Function which does not yield
accurate Inferances in High-dimensional and Non-parametric problems

\emph{Likelihood Function} $\mathcal{L} : \Theta \rightarrow [0, \infty)$ -- the
  Joint Density (\S\ref{sec:joint_probability}) of Sample Data
  (\S\ref{sec:sample}):
\[
  \mathcal{L}(\theta | x) = f_\theta(x)
\]
for the given Observation $x$ of Random Variable $X$ with an Absolutely
Continuous Probability Distribution with PDF (\S\ref{sec:pdf}) $f$ depending on
Parameters (\S\ref{sec:population_parameter}) $\theta$; for a Discrete
Distribution:
\[
  \mathcal{L}(\theta | x) = P_\theta(X = x)
\]

\emph{Likelihood Principle}

\emph{Likelihoodist Statistics} (cf. Frequentism, Bayesianism)

cf. \emph{Probability} (\S\ref{sec:probability}) -- a Probability refers to
variable Data for a fixed Hypothesis (\S\ref{sec:hypothesis_testing}), while a
Likelihood refers to variable Hypotheses for fixed Data

\emph{Maximum Likelihood Estimation} (MLE \S\ref{sec:mle}) -- $\hat{\theta}$:
the value of $\theta$ that Maximizes $\mathcal{L}(\theta)$

Likelihood Interval

Likelihood-ratio Test

\fist a Statistic $T(X^n)$ is \emph{Sufficient}
(\S\ref{sec:sufficient_statistic}) if the Likelihood Function can be computed
knowing only $T(X^n)$ (Wasserman04 \S9.13.2)



\paragraph{Score}\label{sec:score}\hfill

\emph{Score Function} is the Derivative of the Log Likelihood Function

\fist Fisher Information (\S\ref{sec:fisher_metric})



\subsubsection{Credible Interval}\label{sec:credible_interval}

\emph{Posterior Interval} (\S\ref{sec:posterior_distribution})

Interval Estimator (\S\ref{sec:interval_estimator})

Prediction Interval (\S\ref{sec:prediction_interval})

cf. Confidence Interval (Frequentist Inference \S\ref{sec:confidence_interval})



\subsubsection{Bayes Estimator}\label{sec:bayes_estimator}\hfill

or \emph{Bayes Action}

Estimator (or Decision Rule (\S\ref{sec:decision_rule}) that minimizes
(maximizes) Posterior Expected Value of a Loss (Utility) Function
(\emph{Posterior Expected Loss/Utility})

cf. Maximum A Priori (MAP) Estimator (\S\ref{sec:map_estimator})

the Mean Likelihood Estimate (\S\ref{sec:mle}) approximates the Bayes Estimator

Bayes Estimators with constant Risk Function (\S\ref{sec:risk_function}) are
Minimax (\S\ref{sec:minimax})



\subsubsection{Linear Quadratic Estimation (LQE)}\label{sec:lqe}

dual of Linear Quadratic Regulation (LQR \S\ref{sec:lqr})



% ------------------------------------------------------------------------------
\subsection{Predictive Inference}\label{sec:predictive_inference}
% ------------------------------------------------------------------------------

cf. ``Predictive Analytics''

\fist cf. Regression Analysis (\S\ref{sec:regression_analysis})



\subsubsection{Predictive Model}\label{sec:predictive_model}

cf. Detection Theory (\emph{Signal Recovery}) %TODO

Cross-validation (\S\ref{sec:cross_validation})



\subsubsection{Prediction}\label{sec:prediction}

\subsubsection{Prediction Interval}\label{sec:prediction_interval}\hfill

Interval Estimate (\S\ref{sec:interval_estimator}) of where future Observations
(\S\ref{sec:observation}) will fall with a certain Probability, given what has
already been Observed

Frequentist: Confidence Interval (\S\ref{sec:confidence_interval})

Bayesian: Credible Interval (\S\ref{sec:credible_interval})

\emph{Predictive Performance} -- a means of Model Validation
(\S\ref{sec:model_validation}) which is an analysis of whether a constructed
Statistical Model (\S\ref{sec:statistical_model}) holds up when applied to new
Data (\S\ref{sec:sample})



\paragraph{Prediction Band}\label{sec:prediction_band}\hfill



\subsubsection{Predictability}\label{sec:predictability}

\fist Predictable Process (\S\ref{sec:predictable_process})



\subsubsection{Linear Predictor}\label{sec:linear_predictor}

\emph{Linear Predictor Function}

\fist Linear Regression (\S\ref{sec:linear_regression}) -- models Relationships
in Multivariate Data using Linear Predictor Functions with parameters Estimated
from the Data



\paragraph{Best Linear Unbiased Prediction (BLUP)}\label{sec:blup}\hfill

Predicting Random Effects (\S\ref{sec:random_effect});
cf. Mixed Models (\S\ref{sec:mixed_model})

cf. Best Linear Unbiased Estimator (BLUE \S\ref{sec:blue}) -- Estimating
Fixed Effects

under ``suitable assumptions'' on the Priors, Gaussian Process Regression
(Kriging \S\ref{sec:gaussian_process_regression}) gives the best BLUP of the
intermediate values



% ------------------------------------------------------------------------------
\subsection{Causal Inference}\label{sec:causal_inference}
% ------------------------------------------------------------------------------

(wiki):

identification of the Cause of an ``Effect'' by establishing \emph{Covariation}
(\S\ref{sec:covariation}) of Cause and Effect, a \emph{Time-order Relation} with
the Cause preceding the Effect, and the elimination of plausible alternative
Causes

the main difference between \emph{Causal Inference} and an Inference of
\emph{Association} (Dependence \S\ref{sec:dependence}) is that the former
analyzes the ``response'' of the ``effect variable'' when the Cause is changed.

an example of ``Causal Reasoning'' (TODO: xref)

\url{http://www.inference.vc/untitled/} - \emph{ML beyond Curve Fitting: An
  Intro to Causal Inference and do-Calculus}

(Wasserman04, Ch.16)



\subsubsection{Causation}\label{sec:causation}

%FIXME: move section?

cf. Covariance (\S\ref{sec:covariance})



\subsubsection{Causal Model}\label{sec:causal_model}

%FIXME: move section?



\paragraph{Counterfactual Model}\label{sec:counterfactual}\hfill

(Wasserman04, \S16.1)

\textbf{Binary Random Variable $X$}

Outcome Variable $Y$

introduce two new Random Variables $(C_0, C_1)$ called \emph{Potential Outcomes}
where $C_0$ is the Outcome if $X = 0$ and $C_1$ is the Outcome if $X = 1$

\emph{Consistency Relationship}:
\[
  Y = \begin{cases}
    C_0 & \text{if} X = 0 \\
    C_1 & \text{if} X = 1 \\
  \end{cases}
\]

when $X = 0$, $C_1$ is a \emph{Counterfactual}, and vice versa when $X = 1$,
$C_0$ is Counterfactual

measuring ``\emph{Causal Effect}''

\begin{itemize}
  \item \emph{Average Causal Effect}:
    \[
      \theta = E[C_1] - E[C_0]
    \]
    i.e. $\theta$ is the Mean if every Observed $X = 1$, minus the Mean if every
    Observed $X = 0$

  \item for Binary $C_0$, $C_1$, the \emph{Causal Odds Ratio}:
    \[
      \frac{
        \frac{P(C_1 = 1)}{P(C_1 = 0)}
      }{
        \frac{P(C_0 = 1)}{P(C_0 = 0)}
      }
    \]
    and \emph{Causal Relative Risk}:
    \[
      \frac{P(C_1 = 1)}{P(C_0 = 1)}
    \]
\end{itemize}

the \emph{Association}:
\[
  \alpha = E[Y | X = 1] - E[Y | X = 0]
\]

\textbf{Thm.} \emph{Association is not Causation, i.e. in general
$\theta \neq \alpha$}

this is because $(C_0, C_1)$ is not Independent of $X$

instead by using \emph{Random Assignment} (cf. Random Sampling
\S\ref{sec:random_sample}) of $X$ (FIXME: explain), $\theta = \alpha$, and any
Consistent Estimator (\S\ref{sec:consistent_estimator}) of $\alpha$ is a
Consistent Estimator of $\theta$

\emph{Conditional Causal Effect}

\textbf{Continuous $X$}

$(C_0, C_1)$ is replaced by the \emph{Counterfactual Function} $C(x)$ is the
Outcome for an Observed $x$

Consistency Relation $Y \equiv C(X)$

\emph{Causal Regression Function}:
\[
  \theta(x) = E(C(x))
\]

\emph{Association Regression Function}:
\[
  r(x) = E[Y | X = x]
\]

\textbf{Thm.} \emph{In general, $\theta(x) \neq r(x)$, but when $X$ is Randomly
  Assigned, $\theta(x) = r(x)$}


\textbf{Observational Study} -- a study in which $X$ is \emph{not} Randomly
Assigned; \emph{Confounding Variables}, \emph{Adjusted Treatment Effect}



\paragraph{Causal Graph}\label{sec:causal_graph}\hfill

or \emph{Causal Network}

\fist Bayesian Network (\S\ref{sec:bayes_network}) -- ``Dependency structure'';
Probabilistic DAG (\S\ref{sec:dag})

alternative to Counterfactuals for representing Causal Relations

finding the correct Causal Graph from Data of two Variables is impossible; for
more Variables there are Large Sample methods under certain assumptions, but
there is no way to know whether the Sample Size is large enough to be reliable

(Wasserman04, Ch.17)

Conditional Independence (\S\ref{sec:conditional_independence}) -- for Random
Variables $X$, $Y$, $Z$, given $Z$, $X$ and $Y$ are \emph{Conditionally
  Independent}, $X \coprod Y | Z$ if for all $x,y,z$:
\[
  f_{X,Y|Z}(x,y|z) = f_{X|Z}(x|z) f_{Y|Z}(y|z)
\]
i.e. when $Z$ is known, $Y$ provides no extra information about $X$;
equivalently:
\[
  f(x|y, z) = f(x|z)
\]

$X \coprod Y | Z \Rightarrow Y \coprod X | Z$

in a Probabilistic DAG, each Vertex represents a Random Variable

a DAG $\mathcal{G}$ with Vertices $V = (X_1, \ldots, X_n)$ \emph{Represents} a
Distribution $P$ for $V$ with PDF $f$ if:
\[
  f(v) = \prod_{i=1}^k f(x_i | \pi_i)
\]
where $\pi_i$ are the Parents of $X_i$; the Set of Distributions Represented by
$\mathcal{G}$ is denoted $M(\mathcal{G})$

Markov Condition (\S\ref{sec:markov_condition}) -- every Node is Conditionally
Independent of its Non-descendents, given its Parents

Directional Separation (\S\ref{sec:directional_separation})

$\mathcal{I}(\mathcal{G})$ -- Independence Statements implied by $\mathcal{G}$

two DAGs $\mathcal{G}_1$, $\mathcal{G}_2$ are Markov Equivalent if
$\mathcal{I}(\mathcal{G}_1) = \mathcal{I}(\mathcal{G}_2)$



\subparagraph{Active Conditioning}\label{sec:active_conditioning}\hfill

(Wasserman04, \S17.08)

\emph{Passive Conditioning} -- Conditioning by Observation

\emph{Active Conditioning} -- Conditioning by Intervention



\subparagraph{Structural Equation Modeling (SEM)}\label{sec:sem}\hfill

%FIXME: move section ?

Confirmatory Factor Analysis, Confirmatory Composite Analysis, Path Analysis,
Partial Least Squares Path Modeling, Latent Growth Modeling



\subparagraph{Pairwise Markov Graph}\label{sec:pairwise_markov_graph}\hfill

(Wasserman04, \S18.2)

Undirected Graph (\S\ref{sec:undirected_graph})

encodes a Set of Pairwise Conditional Independence Relations
(\S\ref{sec:independence})

Global Markov Property



% ------------------------------------------------------------------------------
\subsection{Fiducial Inference}\label{sec:fiducial_inference}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Topological Inference}\label{sec:topological_inference}
% ------------------------------------------------------------------------------

Wasserman14 - \emph{Robust Topological Inference}

TDA (R package)



% ==============================================================================
\section{Multivariate Statistics}\label{sec:multivariate_statistics}
% ==============================================================================

\emph{simultaneous} Observation (\S\ref{sec:observation}) and Analysis of more
than one Outcome Variable (\emph{Multivariate Random Variables} or \emph{Random
  Vectors} \S\ref{sec:random_vector})

\begin{itemize}
  \item Multivariate Analysis (\S\ref{sec:multivariate_analysis})
  \item Statistical Classification (\S\ref{sec:statistical_classification})
    -- Discrete Response Variable
  \item Regression Analysis (\S\ref{sec:regression_analysis}) -- Estimating
    (\S\ref{sec:estimation_theory}) the Relation between Variables in
    Multivariate Data; note that this is different from Multivariate Analysis in
    that only the Univariate Conditional Distribution of a single Outcome
    Variable is considered; cf. Multivariate Regression
    (\S\ref{sec:multivariate_regression})
  \item Cluster Analysis (\S\ref{sec:cluster_analysis}) --
    ``Unsupervised Learning''
  \item Artificial Neural Networks (\S\ref{sec:ann}) -- extends Regression and
    Clustering to Non-linear Multivariate Models
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Multivariate Analysis}\label{sec:multivariate_analysis}
% ------------------------------------------------------------------------------

\subsubsection{Ordination}\label{sec:ordination}

or \emph{Gradient Analysis}

cf. Gradient (Vector Calculus \S\ref{sec:gradient})

cf. Clustering (\S\ref{sec:cluster_analysis})



\paragraph{Principal Components Analysis}\label{sec:pca}\hfill

cf. Factor Analysis (\S\ref{sec:factor_analysis})



\paragraph{Multidimensional Scaling}\label{sec:multidimensional_scaling}\hfill

\paragraph{Correspondence Analysis}\label{sec:correspondence_analysis}\hfill

\subparagraph{Detrended Correspondence Analysis}
\label{sec:detrended_correspondence}\hfill

\subparagraph{Canonical Correspondence Analysis}
\label{sec:canonical_correspondence}\hfill



\paragraph{Bray-Curtis Ordination}\label{sec:bray_curtis_ordination}\hfill

\paragraph{Redundancy Analysis}\label{sec:redundancy_analysis}\hfill



\subsubsection{Factor Analysis}\label{sec:factor_analysis}

cf. PCA (\S\ref{sec:pca})



\subsubsection{Multivariate Analysis of Variance (MANOVA)}\label{sec:manova}

Variance Analysis (ANOVA \S\ref{sec:variance_analysis})



\subsubsection{Discriminant Analysis}\label{sec:discriminant_analysis}



% ------------------------------------------------------------------------------
\subsection{Statistical Classification}\label{sec:statistical_classification}
% ------------------------------------------------------------------------------

(wiki):

Statistical Inference where the Response Variable is \emph{Discrete}

an Algorithm (\S\ref{sec:algorithm}) that implements Classification is called a
\emph{Classifier}

often done with Logistic Regression (\S\ref{sec:logistic_regression})

\emph{Features} (Properties of Observations \S\ref{sec:observation} or
\emph{Instances}) are \emph{Explanatory Variables} (Regressors
\S\ref{sec:independent_variable}) and possible values of the Dependent Variable
(\S\ref{sec:dependent_variable}) are prediction categories (or \emph{Classes})
called \emph{Outcomes}

example of Pattern Recognition (assignment of some Output Value to a given Input
Value), other examples are Regression Analysis (\S\ref{sec:regression_analysis})
and Cluster Analysis (\S\ref{sec:cluster_analysis})



\subsubsection{Feature Vector}\label{sec:feature_vector}

\subsubsection{Linear Classifier}\label{sec:linear_classifier}

a \emph{Linear Predictor Function} assigns a ``score'' to each possible category
$k$ by taking the Dot Product of the Feature Vector with a Vector of
\emph{Weights}

\begin{itemize}
\item Logistic Regression (\S\ref{sec:logistic_regression})
\item Probit Regression (TODO: xref)
\item Perceptron Algorithm
\item ...
\end{itemize}



\subsubsection{Probabilistic Classification}
\label{sec:probabilistic_classification}

use of Statistical Inference (\S\ref{sec:statistical_inference})



% ------------------------------------------------------------------------------
\subsection{Regression Analysis}\label{sec:regression_analysis}
% ------------------------------------------------------------------------------

\emph{Regression} (or \emph{Curve Estimation}) is the Estimation
(\S\ref{sec:estimation_theory}) of \emph{Relations} (Dependencies
\S\ref{sec:dependence}) in Multivariate Data (\S\ref{sec:random_vector}).

Note that Regression Analysis is different from Multivariate Analysis
(\S\ref{sec:multivariate_analysis}) in that only the Univariate Conditional
Distribution of a single Outcome Variable is considered (cf. Multivariate
Regression \S\ref{sec:multivariate_regression}).

specifically, an Estimation of the \emph{Regression Function}
$r(x) = E(Y | X = x)$.

commonly this is an Estimate of the Conditional Expectation
(\S\ref{sec:conditional_expectation}) of a Dependent Variable for a given
Independent Variable; also the Quantile (\S\ref{sec:quantile}) or other Location
Parameter

\fist cf. Curve Fitting (\S\ref{sec:curve_fitting})

\emph{Regression Variable}, ``Regressor'', ``Predictor'', ``Feature'', or
``Explanatory Variable'' -- \emph{Independent Variable}
(\S\ref{sec:independent_variable}); Covariate

\emph{Response Variable}, ``Regressand'', ``Outcome'', or ``Explained Variable''
-- \emph{Dependent Variable} (\S\ref{sec:dependent_variable}); Criterion

\emph{Regression Function} -- the Function of the Independent Variables to be
Estimated (\S\ref{sec:estimation_theory}):
\[
  r(x) = E(Y | X = x) = \int y f(y|x) dy
\]
that is, the Expected Value of the Response Variable given that the Regression
Variable takes a specific value, where $r \in \mathcal{F}$ is specified by
choice of (Regression) Model Parameters (\S\ref{sec:statistical_model}) $\theta$

\fist cf. Predictive Inference (\S\ref{sec:predictive_inference}),
Prediction Interval (\S\ref{sec:prediction_interval})

Regression Analysis is also concerned with characterizing the \emph{variation}
of the Dependent Variable $X$ around the \emph{Prediction}
(\S\ref{sec:prediction}) $Y$ of the Regression Function using a Probability
Distribution

cf. ``Predictive Analytics''

example of \emph{Pattern Recognition} (assignment of some Output Value to a
given Input Value), other examples are Statistical Classification
(\S\ref{sec:statistical_classification})--when the Response Variable is
Discrete--and Cluster Analysis (\S\ref{sec:cluster_analysis})

cf. Numerical Analysis (\S\ref{sec:numerical_analysis}): Interpolation
(\S\ref{sec:interpolation}), Extrapolation (TODO)

\fist Artificial Neural Networks (ANNs \S\ref{sec:ann}) generalize Regression
and Clustering (\S\ref{sec:cluster_analysis}) to Non-linear Multivariate Models

\emph{Statistical Assumptions} (\S\ref{sec:statistical_assumption}):
\begin{itemize}
  \item the Sample is ``representative'' of the Population for the Inference
    Prediction
  \item the Error is a Random Variable with Mean $0$ Conditional on the
    Regressor(s)
  \item the Regressors are Measured (Observed) with no Error (cf. Measurement
    Error Models \S\ref{sec:measurement_error_model})
  \item the Regressors are Linearly Independent
  \item the Errors are Uncorrelated (\S\ref{sec:correlation})
  \item (\emph{Homoscedasticity} \S\ref{sec:homoscedasticity}) the Variance of
    the Error is Constant accross Observations (cf. Weighted Least Squares
    \S\ref{sec:weighted_least_squares})
\end{itemize}
at are sufficient for the Least-squares Estimator (\S\ref{sec:least_squares}) to
be Unbiased (\S\ref{sec:unbiased_estimate}), Consistent
(\S\ref{sec:consistent_estimator}), and Efficient
(\S\ref{sec:efficient_estimate}) in the Class of \emph{Linear Unbiased
  Estimators} (TODO: xref)

(Wasserman04, Ch.13)

Estimate the Regression Function $r(x)$ from Sample Data (\S\ref{sec:sample}) of
the form:
\[
  (Y_1,X_1), \ldots, (Y_n,X_n) \sim F_{X,Y}
\]

Estimate $\hat{r}(x)$

\emph{Predicted (Fitted) Values}:
\[
  \hat{Y}_i = \hat{r}(X_i)
\]

\emph{Residuals} (\S\ref{sec:regression_residual}):
\[
  \hat{\epsilon}_i = Y_i - \hat{Y}_i
\]

the \emph{Residual Sum of Squares} (SSR \S\ref{sec:ssr}) is a measure of how
well the Estimated Regression Function ``Fit'' the Data:
\[
  \sum_{i=1}^n \hat{\epsilon}_i^2
\]
the Regression Parameters that miminize SSR are caled \emph{Least Squares
  Estimates} (\S\ref{sec:least_squares})



\subsubsection{Regression Error}\label{sec:regression_error}

\fist cf. Statistical Error (\S\ref{sec:error})

Mean Squared Error (MSE) or Mean Squared Deviation (MSD)



\subsubsection{Regression Residual}\label{sec:regression_residual}

\fist cf. Residual (\S\ref{sec:residual})



\subsubsection{Regression Model}\label{sec:regression_model}

a \emph{Statistical Model} (\S\ref{sec:statistical_model}) which makes some
assumption about the Relations (Dependences \S\ref{sec:dependence}) among
Multivariate Data (\S\ref{sec:random_vector})

\emph{Regression Model}:
\begin{itemize}
  \item \emph{Unknown Parameters} ($\beta$)
  \item \emph{Independent Variables} ($X$) -- ``Regression Variable'',
    ``Regressor'', ``Covariate'', ``Explanatory Variable''
  \item \emph{Dependent Variable} ($Y$) -- ``Response Variable'',
    ``Regressand'', ``Criterion'', ``Explained Variable''; variable whose values
    are to be ``explained'' in terms of the Independent Variable
\end{itemize}

the Regression Parameters that miminize Residual Sums of Squares (SSR
\S\ref{sec:ssr}) are caled \emph{Least Squares Estimates}
(\S\ref{sec:least_squares}); under assumption of Normality, the Least Squares
Estimator is also the Maximum Likelihood Estimator (MLE \S\ref{sec:mle})

(Wasserman04 \S13.6)

Model Selection

\emph{Prediction Risk}, \emph{Training Error}

\emph{Mallows's $C_p$}, AIC (\S\ref{sec:aic})

Leave-one-out Cross-validation (\S\ref{sec:cross_validation}),
$k$-fold Cross-validation

Bayesian Information Criterion (BIC) %TODO: xref

Zheng-Loh Model Selection Method

Linear Regression Models (\S\ref{sec:linear_regression})

...



\paragraph{Measurement Error Model}\label{sec:measurement_error_model}\hfill

accounts for Observational (Measurement) Error (\S\ref{sec:observational_error})



\subsubsection{Non-parametric Regression}\label{sec:nonparametric_regression}

Regression Function is chosen from an Infinite-dimensional Family of Functions



\subsubsection{Linear Regression}\label{sec:linear_regression}

\emph{Linear Regression Model}

Relationships are modeled using \emph{Linear Predictor Functions}
(\S\ref{sec:linear_predictor}) which are Linear Functions of a Set of
Coefficients and Explanatory (Independent) Variables:
\[
  Y_i = \beta_0 + \beta_1\psi_1(X_{i1}) + \cdots +
    \beta_p\phi_p(X_{ip}) + \varepsilon_i
\]
for $i \in \{1, \ldots, n\}$

Assuming $\varepsilon_i | X_i \sim N(0, \sigma^2)$ is the same as Assuming
$Y_i | X_i \sim N(\mu_i, \sigma^2)$

cf. \emph{Correlation} (\S\ref{sec:correlation}) -- measure of how close two
Random Variables are to having a \emph{Linear Relationship}

Fit using Estimators:
\begin{itemize}
  \item Linear Least Squares (\S\ref{sec:lls}): if Errors are
    \emph{Normally Distributed}, Least Squares ($2$-norm Best Fit) should be
    used
  \begin{itemize}
    \item Ordinary Least Squares (\S\ref{sec:ols}): if Errors are
      \emph{Normally Distributed}, Least Squares ($2$-norm Best Fit) should be
      used
  \end{itemize}
  \item Generalized Least Squares (\S\ref{sec:gls}): if
    there is a degree of Correlation between Residuals (Fitting Deviations
    \S\ref{sec:residual})
  \item ...
\end{itemize}

\textbf{Gauss-Markov Theorem} \emph{
  In a Linear Model (\S\ref{sec:linear_regression}) where Errors are
  Uncorrelated, have Mean Zero, and equal Variances, the Best Linear Unbiased
  Estimator (BLUE \S\ref{sec:blue}) of the Coefficients is given by the Ordinary
  Least-Squares (OLS \S\ref{sec:ols}) Estimator.
}

\fist cf. Gradient Descent (\S\ref{sec:gradient_descent})

\fist cf. Convex Optimization (\S\ref{sec:convex_optimization}) -- for Linear
Regression, a Mean-Square Error Loss Function is always \emph{Convex} (example
\url{https://towardsdatascience.com/introduction-to-machine-learning-algorithms-linear-regression-14c4e325882a}

\fist cf. Linear Programming (\S\ref{sec:linear_programming})
-- article: \emph{Linear Programming for Linear Regression};
\url{https://lazyprogrammer.me/linear-programming-for-linear-regression/}



\paragraph{Simple Linear Regression}\label{sec:simple_linear_regression}\hfill

single (One-dimensional) Regressor (Independent Variable)

Regression Coefficients

Error Term $\varepsilon$

$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$

for the $i$th Observation (\S\ref{sec:observation})

assuming that $Y$ can be Approximated by a Linear Function of $X$ and the IID
Distribution of the $\varepsilon_i$s is Normal with Mean Zero, the
\emph{Regression Model} (\S\ref{sec:statistical_model}) has three Parameters--
$\beta_0$, $\beta_1$, and the Variance $\sigma^2$ of $\varepsilon$:
\[
  \theta = (\beta_0, \beta_1, \sigma^2)
\]
and each possible value of $\theta$ determines a Distribution $P_\theta$ on the
Sample Space (\S\ref{sec:sample_space}) $S$ of all possible $(Y, X)$ pairs

(Wasserman04 \S13.1)

Least Squares Estimates (\S\ref{sec:least_squares}): TODO



\paragraph{Multivariate Regression}
\label{sec:multivariate_regression}\hfill

\emph{Multivariate Regression Model} or \emph{General Linear Model}

\fist not to be confused with Generalized Linear Models
(\S\ref{sec:generalized_linear_model})

multiple Correlated Dependent Variables

cf. Multivariate Statistics (\S\ref{sec:multivariate_statistics})

cf. Multiple Linear Regression (\S\ref{sec:multiple_linear_regression})
-- multiple Correlated Independent Variables

\fist Artificial Neural Networks (ANNs \S\ref{sec:ann}) generalize Regression
and Clustering (\S\ref{sec:cluster_analysis}) to Non-linear Multivariate Models



\paragraph{Multiple Linear Regression}
\label{sec:multiple_linear_regression}\hfill

Multiple Regression (\S\ref{sec:multiple_regression})

multiple Correlated Independent Variables

(wiki) $p$ Independent Variables:
\[
  y_i = \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} +
    \varepsilon_i
\]
where $x_{ij}$ is the $i$-th Observation (\S\ref{sec:observation}) of the $j$-th
Independent Variable

cf. Multivariate (Linear) Regression (General Linear Regression
\S\ref{sec:multivariate_linear_regression}) -- multiple Correlated Dependent
Variables



\paragraph{Orthogonal Regression}\label{sec:orthogonal_regression}\hfill

\subparagraph{Deming Regression}\label{sec:deming_regression}\hfill

accounts for Error in $X$ and $Y$ Observations (cf. Simple Linear Regression
which only accounts for Vertical Errors)



\paragraph{Generalized Linear Model}\label{sec:generalized_linear_model}\hfill

generalization of ordinary Linear Regression allowing Response Variables to have
Error Distributions other than the Normal Distribution

not to be confused with General Linear Models (Multivariate Regression Models
\S\ref{sec:multivariate_regression})

(wiki):

Least-squares Estimate (\S\ref{sec:least_squares}) may be used to fit a
Generalized Linear Model by iteratively applying the Local Quadratic
Approximation (FIXME: explain)



\subparagraph{Log-linear Model}\label{sec:log_linear}\hfill

\emph{Poisson Regression}

fitting Discrete Data to a Graphical Model (\S\ref{sec:graphical_model})

Pairwise Markov Graph (\S\ref{sec:pairwise_markov_graph})



\subsubsection{Logistic Regression}\label{sec:logistic_regression}

or \emph{Logit Regression}

cf. Statistical Classification (\S\ref{sec:statistical_classification})

\emph{Logistic Model}: uses a Logistic Function (\S\ref{sec:logistic_function})
to Model a \emph{Binary Dependent Variable} $Y_i \in \{ 0, 1 \}$

Logistic Function $e^x / (1 + e^x)$

for a $k$-dimensional Covariate $X$:
\[
  p_i \equiv P(Y_i = 1 | X = x) = \frac{
    e^{\sum_{j=1}^k \beta_j x_{ij}}
  }{
    1 + e^{\sum_{j=1}^k \beta_j x_{ij}}
  }
\]

\[
  logit(p_i) = \sum_{j=1}^k \beta_j x_{ij}
\]
where:
\[
  logit(p) = log\Big(\frac{p}{1-p}\Big)
\]
(FIXME: explain)

\[
  Y_i | X_i = x_i \sim Bernoulli(p_i)
\]

Conditional Likelihood:
\[
  \mathcal{L}(\beta) = \prod_{i=1}^n p_i(\beta)^{Y_i} (1 - p_i(\beta))^{1-Y_i}
\]

the Maximum Likelihood Estimate can be obtained by maximizing $\mathcal{L}(B)$
numerically using Re-weighted Least Squares
(\S\ref{sec:reweighted_least_squares}):

choose starting $\hat{\beta}^0 = (\hat{\beta}_1^0, \ldots, \hat{\beta}_k^0)$
and compute $p_i^0$ for $i = 1, \ldots, n$, and iterate from $s = 0$:
\begin{enumerate}
  \item set
    \[
      Z_i = logit(p_i^s) + \frac{Y_i - p_i^s}{p_i^s(1 - p_i^s)}
    \]
  \item let $W$ be a Diagonal Matrix with $(i,i)$ equal to $p_i^s(1 - p_i^s)$
  \item set
    \[
      \hat{\beta}^s = (X^T W X)^{-1} X^T W Z
    \]
  corresponding to doing a Weighted Linear Regression of $Z$ on $X$
\end{enumerate}



\paragraph{Binomial Regression}\label{sec:binomial_regression}\hfill

essentially the same as Binary Choice Models (\S\ref{sec:binary_choice_model})



\paragraph{Multinomial Regression}\label{sec:multinomial_regression}\hfill

\paragraph{Ordinal Regression}\label{sec:ordinal_regression}\hfill

\emph{Ranking Learning}



\subsubsection{Probit Regression}\label{sec:probit_regression}

\subsubsection{Multiple Regression}\label{sec:multiple_regression}

Definite Quadratic Forms (\S\ref{sec:definite_quadratic})

Multiple Linear Regression (\S\ref{sec:multiple_linear_regression})

note that adding more Covariates, the Bias of the Predictions descreases and the
Variance increases

\emph{Underfitting} -- too few Covariates, high Bias

\emph{Overfitting} -- too many Covariates, high Variance

(wiki): uses Additive Logic (FIXME: xref ???); cf. Necessary Condition Analysis
(NCA \S\ref{sec:nca}) -- uses Necessary Logic (\S\ref{sec:alethic_logic})



\subsubsection{Gaussian Process Regression}
\label{sec:gaussian_process_regression}

\emph{Kriging} or \emph{Wiener-Komogorov Prediction}

under ``suitable assumptions'' on the Priors, Kriging gives the \emph{Best
  Linear Unbiased Prediction} (BLUP \S\ref{sec:blup}) of the intermediate values

\fist Spatial Analysis (\S\ref{sec:spatial_analysis})



\subsubsection{Necessary Condition Analysis (NCA)}\label{sec:nca}

(wiki): uses Necessity Logic (\S\ref{sec:alethic_logic});
cf. Multiple Regression (\S\ref{sec:multiple_regression}) -- uses Additive Logic
(FIXME: xref ???)



% ------------------------------------------------------------------------------
\subsection{Cluster Analysis}\label{sec:cluster_analysis}
% ------------------------------------------------------------------------------

Unsupervised Learning

example of Pattern Recognition (assignment of some Output Value to a given Input
Value), other examples are Statistical Classification
(\S\ref{sec:statistical_classification}) and Regression Analysis
(\S\ref{sec:regression_analysis})

Artificial Neural Networks (ANNs \S\ref{sec:ann}) generalize Regression
(\S\ref{sec:regression_analysis}) and Clustering to Non-linear Multivariate
Models



\subsubsection{Hierarchical Clustering}\label{sec:hierarchical_clustering}



% ------------------------------------------------------------------------------
\subsection{Artificial Neural Network (ANN)}\label{sec:ann}
% ------------------------------------------------------------------------------

%FIXME: move section ?

extends Regression (\S\ref{sec:regression_analysis}) and Clustering
(\S\ref{sec:cluster_analysis}) to Non-linear Multivariate Models



% ==============================================================================
\section{Computational Learning Theory}\label{sec:computational_learning_theory}
% ==============================================================================

%FIXME start new document ???



% ------------------------------------------------------------------------------
\subsection{Algorithmic Learning Theory}\label{sec:algorithmic_learning}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Vapnik-Chervonenkis Theory}\label{sec:vc_theory}
% ------------------------------------------------------------------------------

\emph{VC Theory}



% ==============================================================================
\section{Statistical Randomness}\label{sec:statistical_randomness}
% ==============================================================================

cf. \emph{Algorithmic Randomness} (\S\ref{sec:algorithmic_randomness}) --
Universal Test, Universal Sequential Test (Martin-L\"of66)

\emph{Subsequence Selection Criterion} (\S\ref{sec:random_sequence}) --
\emph{Mises-Church Randomness}: any Recursive Function which having read the
first $N$ elements of the Sequence decides if it wants to select element $N+1$

cf. Quasi-random Sequences (\S\ref{sec:low_discrepancy})

Tests (\S\ref{sec:hypothesis_testing}):
\begin{itemize}
  \item Frequency test
  \item Serial Test
  \item Poker Test
  \item Gap Test
  \item ...
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Randomization}\label{sec:randomization}
% ------------------------------------------------------------------------------

\begin{itemize}
  \item Random Experiments (\S\ref{sec:experiment}), cf. Observation
    (\S\ref{sec:observation}), Sampling (\S\ref{sec:random_sample})
  \item Survey Sampling
  \item Resampling (\S\ref{sec:resampling})
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Pseudorandom Process}\label{sec:pseudorandom_process}
% ------------------------------------------------------------------------------

Deterministic System (\S\ref{sec:deterministic_system}) exhibiting Statistical
Randomness

cf. \emph{Stochastic Process} (\S\ref{sec:stochastic_process})

\emph{Hash Functions} can create ``Random Numbers'' solely based on an Input
with no dependency on previous queries

2015 -
\url{http://blog.runevision.com/2015/01/primer-on-repeatable-random-numbers.html}
- \emph{Primer on Repeatable Random Numbers}



% ==============================================================================
\section{Stochastic Process}\label{sec:stochastic_process}
% ==============================================================================

or \emph{Random Process}

%FIXME: move section ???

a \emph{Random Sequence} (\S\ref{sec:random_sequence}) is a special case of
Stochastic Process where the Index Set is some Subset of the Integers

\fist cf. Data Generating Process (\S\ref{sec:data_generating_process})

\fist a \emph{Pseudorandom Process} (\S\ref{sec:pseudorandom_process}) is a
Determinstic Process exhibiting Statistical Randomness
(\S\ref{sec:statistical_randomness})

\fist Stochastic Calculus (\S\ref{sec:stochastic_calculus}):
\begin{itemize}
  \item Predictable Process (\S\ref{sec:predictable_process}) -- Process whose
    value is knowable at a prior time; smallest Class of Processes that is
    Closed under taking limits of Sequences (FIXME: clarify)
  \item Adapted Proces (Non-anticipative Process \S\ref{sec:adapted_process}) --
    cannot be Predicted into the Future (FIXME: clarify)
\end{itemize}

cf. Harmonic Functions (\S\ref{sec:harmonic_function})

\fist cf. Stochastic Optimization (\S\ref{sec:stochastic_optimization})

\fist cf. Non-deterministic Dynamical Systems
(\S\ref{sec:nondeterministic_dynamical_system})

\fist Stochastic Differential Equations (SDEs \S\ref{sec:sde}) -- a Differential
Equation in which one or more Terms is a Stochastic Process

First-hitting-time Model



% ------------------------------------------------------------------------------
\subsection{Stochastic Convergence}\label{sec:stochastic_convergence}
% ------------------------------------------------------------------------------

Convergence of Sequences (\S\ref{sec:convergent_sequence}) of Random Variables
(\S\ref{sec:random_variable}) to a Limit Random Variable

\fist Asymptotic Theory (Large Sample Theory \S\ref{sec:asymptotic_theory})

\fist cf. Measure Convergence (\S\ref{sec:measure_convergence})

Wasserman04 Ch.5

\textbf{Modes of Convergence}
For a Sequence of Random Variables $X_1, X_2, \ldots$, and Random Variable $X$,
with $F_{X_n}$ the CDF (\S\ref{sec:cdf}) of $X_n$ and $F_X$ the CDF of $X$:
\begin{itemize}
  \item \emph{Convergence in Distribution} (\emph{Weak Convergence}) --
    $X_n \rightsquigarrow X$ if for all $x$ at which $F_X$ is Continuous:
    \[
      \lim_{n\rightarrow\infty} F_{X_n}(x) = F_X(x)
    \]
  \item \emph{Convergence in Probability} -- $X_n \xrightarrow{P} X$ if for
    every $\epsilon > 0$:
    \[
      \lim_{n\rightarrow\infty}P(|X_n - X| > \epsilon) = 0
    \]
  \item \emph{Almost Sure (Everywhere) Convergence} (\emph{Strong Convergence})
    -- $X_n \xrightarrow{as} X$ if:
    \[
      P(\lim_{n\rightarrow\infty}X_n = X) = 1
    \]
  \item \emph{Sure (Everywhere) Convergence} (\emph{Pointwise Convergence})
  \item \emph{Convergence in the $r$th Mean} or \emph{$L^r$-norm}
    (\S\ref{sec:lp_space})
    \begin{itemize}
      \item \emph{Convergence in Quadratic Mean ($L^2$)} --
        $X_n \xrightarrow{qm} X$ if:
        \[
          \lim_{n\rightarrow\infty} E(X_n - X)^2 = 0
        \]
      \item \emph{Convergence in $L^1$} -- $X_n \xrightarrow{L^1} X$ if:
        \[
          \lim_{n\rightarrow\infty} E(|X_n - X|) = 0
        \]
    \end{itemize}
\end{itemize}

\textbf{Thm.}
\begin{itemize}
  \item $X_n \xrightarrow{qm} X \Rightarrow X_n \xrightarrow{L^1} X$
  \item $X_n \xrightarrow{L^1} X \Rightarrow X_n \xrightarrow{P} X$
  \item $X_n \xrightarrow{as} X \Rightarrow X_n \xrightarrow{P} X$
  \item $X_n \xrightarrow{P} X \Rightarrow X_n \rightsquigarrow X$
  \item $X \rightsquigarrow X \wedge \exists c : P(X = c) = 1 \Rightarrow
    X_n \xrightarrow{P} X$
\end{itemize}

\emph{Slutsky's Theorem}



% ------------------------------------------------------------------------------
\subsection{Statistical Fluctuation}\label{sec:statistical_fluctuation}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Random Measure}\label{sec:random_measure}
% ------------------------------------------------------------------------------

a Measure-valued Random Element (\S\ref{sec:random_variable})

definition as Transition Kernels

\begin{itemize}
  \item $P_n(A) = \frac{1}{n}\sum_{i=1}^n \delta_{X_i}(A)$ --
    Empirical Measure (\S\ref{sec:empirical_measure})
  \item $\mu = \sum_{n=1}^N \delta_{X_n}$ -- Point Process
    (\S\ref{sec:point_process})
\end{itemize}



\subsubsection{Empirical Measure}\label{sec:empirical_measure}

$P_n(A) = \frac{1}{n}\sum_{i=1}^n \delta_{X_i}(A)$

where $\delta$ is the Dirac Measure (\S\ref{sec:dirac_measure})

the CDF (\S\ref{sec:cdf}) associated with the Empirical Measure of a Sample
(\S\ref{sec:sample}) is the \emph{Empirical Distribution Function}
(\S\ref{sec:empirical_distribution})



% ------------------------------------------------------------------------------
\subsection{Random Walk}\label{sec:random_walk}
% ------------------------------------------------------------------------------

\subsubsection{Law of Iterated Logarithm}\label{sec:iterated_logarithm}

describes magnitude of Fluctuations of a Random Walk

cf. Law of Large Numbers (\S\ref{sec:large_numbers})



% ------------------------------------------------------------------------------
\subsection{Random Field}\label{sec:random_field}
% ------------------------------------------------------------------------------

(wiki): for a Probability Space $(\Omega, \mathcal{F}, P)$, an \emph{$X$-valued
  Random Field}, $F$, is a collection of $X$-valued Random Variables indexed by
elements in a Topological Space $T$:
\[
  F = \{ F_t : t \in T \}
\]
where each $F_t$ is an $X$-valued Random Variable

Tensor-valued Random Fields



\subsubsection{Markov Random Field}\label{sec:markov_random_field}

(MRF)



\subsubsection{Gibbs Random Field}\label{sec:gibbs_random_field}

\subsubsection{Conditional Random Field}\label{sec:conditional_random_field}

Machine Learning: Sequence MOdelling



\subsubsection{Gaussian Random Field}\label{sec:gaussian_random_field}

(GRF)

a 1D GRF is a Gaussian Process (\S\ref{sec:gaussian_process})



% ------------------------------------------------------------------------------
\subsection{Point Process}\label{sec:point_process}
% ------------------------------------------------------------------------------

a \emph{Point Process} is a Random Measure (\S\ref{sec:random_measure}) of the
form:
\[
  \mu = \sum_{n=1}^N \delta_{X_n}
\]
where $\delta$ is the Dirac Measure (\S\ref{sec:dirac_measure})



\subsubsection{Poisson Process}\label{sec:poisson_process}

Memory-less

Poisson Distribution (\S\ref{sec:poisson_distribution})



\subsubsection{Binomial Process}\label{sec:binomial_process}

cf. \emph{Bernoulli Process} (\S\ref{sec:bernoulli_process})



% ------------------------------------------------------------------------------
\subsection{Markov Process}\label{sec:markov_process}
% ------------------------------------------------------------------------------

(or \emph{Markov Chain})

Markov Property (``Memorylessness'')

can be seen as a special case of Petri Nets (\S\ref{sec:petri_net})
where every Transition has a single Input and a single Output



% ------------------------------------------------------------------------------
\subsection{Discrete-time Stochastic Process}\label{sec:discretetime_stochastic}
% ------------------------------------------------------------------------------

\subsubsection{Bernoulli Process}\label{sec:bernoulli_process}

Mathematical Formalization of \emph{Binomial (Bernoulli) Trials}
(\S\ref{sec:binomial_trial})

Stochastic Computing

cf. \emph{Binomial Process} (Point Process \S\ref{sec:binomial_process})



\paragraph{Bernoulli Sequence}\label{sec:bernoulli_sequence}\hfill

Random Sequence (\S\ref{sec:random_sequence})

\emph{Infinite Bernoulli Sequences} -- cf. \emph{Collectives} (Von Mises57); a
solution to the ``Reference Class Problem'' of Frequentist Probability Theory;
cf. (Martin-L\"of66)



\subsubsection{Martingale}\label{sec:martingale}

\begin{itemize}
  \item Stopped Brownian Motion
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Continuous-time Stochastic Process}\label{sec:continuous_stochastic}
% ------------------------------------------------------------------------------

\subsubsection{Gaussian Process}\label{sec:gaussian_process}

a 1D Gaussian Random Field (\S\ref{sec:gaussian_random_field})

can be seen as the Infinite-dimensional generalization of Multivariate Normal
Distributions (\S\ref{sec:normal_distribution})

the Distribution of a Gaussian Process is the Joint Distribution of infinitely
many Random Variables, i.e. it is a Distribution over Functions with a
Continuous Domain

Machine Learning: Lazy Learning (1D Gaussian Distributions)

Gaussain Process Regression (Kriging \S\ref{sec:gaussian_process_regression})



\paragraph{Fractional Brownian Motion}\label{sec:fractional_brownian}\hfill

(\emph{fBm})

$H \in (0,1) \subset \reals$ -- Hurst index

$H = 1/2$ -- Wiener Process (Brownian Motion \S\ref{sec:wiener_process})

for $H > 1/2$, increments of the process are Positively Correlated, and exhibits
Long-range dependence

for $H < 1/2$, increments of the process are Negatively Correlated

Hausdorff and Box Dimension of $2 - H$

\fist Multifractals (\S\ref{sec:multifractal_system}): generalized framework of
Fractional Brownian Motions



\subparagraph{Wiener Process}\label{sec:wiener_process}\hfill

or \emph{Brownian Motion}

$H = 1/2$



% ------------------------------------------------------------------------------
\subsection{Stationary Process}\label{sec:stationary_process}
% ------------------------------------------------------------------------------

Stochastic Process for which the Unconditional Joint Probability Distribution
(\S\ref{sec:joint_probability}) does not change when shiften in Time (TODO:
xref)



% ------------------------------------------------------------------------------
\subsection{Empirical Process}\label{sec:empirical_process}
% ------------------------------------------------------------------------------

Empirical Measure (\S\ref{sec:empirical_measure}):

Empirical Distribution Function (\S\ref{sec:empirical_distribution}):

$P_n(A) = \frac{1}{n}\sum_{i=1}^n \delta_{X_i}(A)$

where $\delta$ is the Dirac Measure (\S\ref{sec:dirac_measure})



% ------------------------------------------------------------------------------
\subsection{Stochastic Simulation}\label{sec:stochastic_simulation}
% ------------------------------------------------------------------------------

\subsubsection{Monte Carlo Simulation}\label{sec:monte_carlo}



% ------------------------------------------------------------------------------
\subsection{Probability Monad}\label{sec:probability_monad}
% ------------------------------------------------------------------------------

1980 - Giry - \emph{A Categorical Approach to Probability Theory}

collapsing a Probability Distribution (Measure) of Probability Distrubtions to a
Probability Distribution is called the ``Giry Monad'' (TODO)

\url{https://ncatlab.org/nlab/show/Giry+monad}

assigns to a Space of Outcomes $X$ a new Space $P X$ containing Random Outcomes
of $X$



\subsection{Kantorovich Monad}\label{sec:kantorovich_monad}

(Breugel)

\url{https://golem.ph.utexas.edu/category/2019/03/the_kantorovich_monad.html}

Probability Monad on the Category of Metric Spaces; can be described purely in
terms of Combinatorics of Finite Sequences of Elements

2017 - Fritz, Perrone - \emph{A Probability Monad as the Colimit of Spaces of
  Finite Samples}



% ==============================================================================
\section{Statistical Mechanics}\label{sec:statistical_mechanics}
% ==============================================================================

Thermodynamics, ``Irreversibility''

Jarzynski Equality

Crooks' Fluctuation Theorem



% ------------------------------------------------------------------------------
\subsection{Non-equilibrium Statistical Mechanics}
\label{sec:nonequilibrium_statistical_mechanics}
% ------------------------------------------------------------------------------

Jarzynski



% ------------------------------------------------------------------------------
\subsection{Statistical Ensemble}\label{sec:statistical_ensemble}
% ------------------------------------------------------------------------------

a Probability Distribution (\S\ref{sec:probability_distribution}) for the state
of a Physical System



\subsubsection{Thermodynamic Ensemble}\label{sec:thermodynamic_ensemble}



% ==============================================================================
\section{Geometric Probability}\label{sec:geometric_probability}
% ==============================================================================

``\emph{Continuous Combinatorics}'': analogies between \emph{Counting} and
\emph{Measure} (\S\ref{sec:measure}) \fist Combinatorics (Part
\ref{part:combinatorics}), Measure Theory (Part \ref{part:measure_theory})



% ------------------------------------------------------------------------------
\subsection{Integral Geometry}\label{sec:integral_geometry}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Stochastic Geometry}\label{sec:stochastic_geometry}
% ------------------------------------------------------------------------------



% ==============================================================================
\section{Information Geometry}\label{sec:information_geometry}
% ==============================================================================

Harper09 - \emph{The Replicator Equation as an Inference Dynamic}

Harper09 - \emph{Information Geometry and Evolutionary Game Theory}

\url{http://math.ucr.edu/home/baez/information/}

\url{https://johncarlosbaez.wordpress.com/2017/01/31/biology-as-information-dynamics/}

application of Differential Geometry
(\S\ref{sec:differential_geometry}) techniques to Probability Theory



% ------------------------------------------------------------------------------
\subsection{Statistical Manifold}\label{sec:statistical_manifold}
% ------------------------------------------------------------------------------

Riemannian Manifold (\S\ref{sec:riemannian_manifold}) with the
\emph{Fisher Information Metric} as the Riemannian Metric
(\S\ref{sec:riemannian_metric})



\subsubsection{Fisher Information Metric}\label{sec:fisher_metric}

$I$

Riemannian Metric (\S\ref{sec:riemannian_metric}) for a Statistical Manifold

Score Function (\S\ref{sec:score})

Fisher Information Matrix

Jeffrey's Prior (\S\ref{sec:prior_distribution})

\fist \textbf{Fisher's Fundamental Theorem of Natural Selection},
Quasi-linkage Equilibrium: approximation in the case of Weak Selection
and Weak Epistasis -- Evolutionary Optimization
(\S\ref{sec:evolutionary_optimization}) %FIXME

\url{https://golem.ph.utexas.edu/category/2018/05/the_fisher_metric_will_not_be.html}
