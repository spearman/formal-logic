%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Probability Theory}\label{part:probability_theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\fist Measure Theory (Part \ref{part:measure_theory})

\fist Probabilistic Logic (\S\ref{sec:probabilistic_logic}) --
2013 - \emph{Logic and Probability} -
\url{https://plato.stanford.edu/entries/logic-probability/} (Stanford
Encyclopedia of Philosophy)

\fist Decision Theory (\S\ref{sec:decision_theory}) --
(wiki): Probabilistic Decision Theory is Sensitive
(\S\ref{sec:sensitivity_analysis}) to \emph{Assumptions} about Probabilities of
Events; Non-probabilistic Decision Rules (\S\ref{sec:decision_rule}), such as
Minimax (\S\ref{sec:minimax}), are \emph{Robust} (\S\ref{sec:robust_statistics})
in that they don't make such Assumptions (FIXME: clarify)

2018 - \emph{A Categorical Look at Random Variables} -
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html} (article):

$\cat{Prob}$ -- Category with Objects as Probability Spaces
(\S\ref{sec:probability_space}) and Morphisms are ``Almost-everywhere-equality
Equivalence Classes'' of Measure-preserving Maps

``Probability Theory is \emph{not} about the Category $\cat{Prob}$, in the sense
that Group Theory or Topology might be said (however incompletely) to be about
the Categories $\cat{Grp}$ or $\cat{Top}$''

\emph{Isomorphic Objects} in $\cat{Prob}$ are \emph{not} the same from the point
of view of \emph{Probability Theory}

example: the Distributions (\S\ref{sec:probability_distribution}) of a Uniform
Random Variable in an Interval, an Infinite Sequence of independent ``coin
flips'', and Brownian Motion $\{B_t : t \geq 0\}$ are \emph{different} things in
Probability Theory, but are Isomorphic in $\cat{Prob}$

the fundamental ``objects'' in Probability Theory are the Morphisms of
$\cat{Prob}$ and those Morphisms are \emph{Random Variables}
(\S\ref{sec:random_variable})

TODO: Giry Monads (Probability Monads) -
\url{https://ncatlab.org/nlab/show/Giry+monad}


\asterism

1933 - Kolmogorov - \emph{Foundations of the Theory of Probability}

\emph{Field of Probabilities} (\emph{$\sigma$-algebra}
(\S\ref{sec:sigma_algebra})



% ====================================================================
\section{Observation}\label{sec:observation}
% ====================================================================

\emph{``data point''}

\fist Curve Fitting (\S\ref{sec:curve_fitting}): the process of constructing a
Curve (or Function) that has the ``best Fit'' to a Series of data points
(Observations), possibly subject to constraints

(FIXME: cf. Event ???)



% ====================================================================
\section{Population}\label{sec:population}
% ====================================================================

``Totality of Observations''

Observation: Value of a Random Variable $X$ having some Probability
Distribution $f(x)$

Paired Observation (Dependent) (???)

(wiki):

\emph{Statistical Population} -- a Set of ``similar items'' or Events
(\S\ref{sec:probability_event}) of interest

Descriptive Statistics (\S\ref{sec:descriptive_statistics}): a Subset of the
Population is a \emph{Statistical Sample} (\S\ref{sec:statistical_sample})



% --------------------------------------------------------------------
\subsection{Population Parameter}\label{sec:population_parameter}
% --------------------------------------------------------------------

or \emph{Statistical Parameter}

(wiki): a ``quantity'' that indexes a Family of Probability Distributions
(\S\ref{sec:probability_distribution})

can be regarded as a ``numerical characteristic'' of a Population or a
Statistical Model (\S\ref{sec:statistical_model}) \fist cf. Parametric
Statistical Models (\S\ref{sec:parametric_model})

example: the Family of Normal Distributions (\S\ref{sec:normal_distribution})
are Parameterized by the Mean and Standard Deviation

$\mu$, $\sigma$

\fist \emph{Estimation Theory} (\S\ref{sec:estimation_theory}) deals with
``\emph{Estimating}'' the values of Statistical Parameters
based on data that has a ``\emph{random component}'' (FIXME: clarify)



% --------------------------------------------------------------------
\subsection{Sample}\label{sec:sample}
% --------------------------------------------------------------------

Subset of a Population

Statistical Sample (Descriptive Statistics \S\ref{sec:statistical_sample})



\subsubsection{Random Sample}\label{sec:random_sample}

Statistical Sample (Descriptive Statistics \S\ref{sec:statistical_sample})



\paragraph{Simple Random Sample}\label{sec:simple_random_sample}\hfill

\paragraph{Stratified Random Sample}\label{sec:stratified_random_sample}\hfill



% --------------------------------------------------------------------
\subsection{Statistic}\label{sec:statistic}
% --------------------------------------------------------------------

Function of the Random Variable (\S\ref{sec:random_variable}) constituting a
Random Sample (\S\ref{sec:random_sample})

$\overline{x}$, $\sigma^2$

The Probability Distribution (\S\ref{sec:probability_distribution}) of
a Statistic is a Sampling Distribution
(\S\ref{sec:sampling_distribution})

Estimator (\S\ref{sec:estimator})



\subsubsection{Robust Statistic}\label{sec:robust_statistic}

\fist Info-gap Decision Theory (\S\ref{sec:info_gap}) -- Non-probabilistic
Decision Theory seeking to optimize Robustness to ``failure'' under severe
Uncertainty (\S\ref{sec:uncertainty_analysis})



% ====================================================================
\section{Probability Space}\label{sec:probability_space}
% ====================================================================

$(\Omega, \Sigma, P)$

A \emph{Probability Space} is a Measure Space
(\S\ref{sec:measure_space}) with a Probability Measure
(\S\ref{sec:probability_measure}).

\fist Measure-preserving Dynamical Systems
(\S\ref{sec:measure_preserving_system})

$\cat{Prob}$ -- Category with Objects as Probability Spaces and Morphisms are
``Almost-everywhere-equality Equivalence Classes'' of Measure-preserving Maps
--
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html}:
``Probability Theory is not about the Category $\cat{Prob}$''

$\cat{Prob}$ -- Category with Objects as Probability Spaces and Morphisms are
``Almost-everywhere-equality Equivalence Classes'' of Measure-preserving Maps
(\S\ref{sec:measure_preserving_map})

the fundamental ``objects'' of Probability Theory are the \emph{Morphisms} of
$\cat{Prob}$ and these Morphisms are \emph{Random Variables}
(\S\ref{sec:random_variable})



% ------------------------------------------------------------------------------
\subsection{Probability Measure}\label{sec:probability_measure}
% ------------------------------------------------------------------------------

A \emph{Probability Measure} is a Measure (\S\ref{sec:measure}) that assigns the
Value $1$ to the entire Measure Space (making it a Probability Space).

cf. \emph{Probability} (\S\ref{sec:probability})



\subsubsection{Probability Measure Function}
\label{sec:probability_measure_function}



% --------------------------------------------------------------------
\subsection{Sample Space}\label{sec:sample_space}
% --------------------------------------------------------------------

or \emph{Event Space}

$S$

an Event (\S\ref{sec:probability_event}) is a Subset of a Sample Space

Set of all possible outcomes of Statistical Experiment

the Probability (\S\ref{sec:probability}) $P$ of an Event $E$ is usually
defined such that $P$ satisfies the Kolmogorov Axioms
(\S\ref{sec:probability_axioms}) \fist \emph{Unit Measure Axiom}: the
total Probability of the Sample Space is $1 = P(S)$

Random Variable (\S\ref{sec:random_variable}): Function on a Sample
Space

a Statistical Model (\S\ref{sec:statistical_model}) $(S,\mathcal{P})$ is a
Sample Space $S$ together with a Set of Probability Distributions
(\S\ref{sec:probability_distribution}) $\mathcal{P}$ on $S$



\subsubsection{Experiment}\label{sec:experiment}

Sample Space (\S\ref{sec:sample_space}): Set of all possible Outcomes of
Statistical Experiment

if an Outcome is inside an Event (\S\ref{sec:probability_event}), i.e. a Subset
of the Sample Space, it is said to have ``\emph{Occurred}''



\paragraph{Binomial Trial}\label{sec:binomial_trial}\hfill

or \emph{Bernoulli Trial}

Binomial Distribution (\S\ref{sec:binomial_distribution}); special case:
Bernoulli Distribution (\S\ref{sec:bernoulli_distribution})

Mathematical Formalization: Bernoulli Process (\S\ref{sec:bernoulli_process})

\begin{enumerate}
  \item repeated Trials
  \item each Trial results in an Outcome
  \item Probability of Success is Constant
  \item each Trial is Independent
\end{enumerate}

Number of Successes in $n$ Bernoulli Trials is a \emph{Binomial Random
  Variable} (\S\ref{sec:binomial_random_variable})



% --------------------------------------------------------------------
\subsection{Event}\label{sec:probability_event}
% --------------------------------------------------------------------

Subset of a \emph{Event Space} (Sample Space \S\ref{sec:sample_space})

if an Outcome is inside an Event (Subset), it is said to have
``\emph{Occurred}''

\emph{Probability} (\S\ref{sec:probability})

(Kolmogorov33) analogy between the \emph{Measure} (\S\ref{sec:measure}) of a Set
and the Probability of an Event

(FIXME: cf. Observation \S\ref{sec:observation})



\subsubsection{Elementary Event}\label{sec:elementary_event}

or \emph{Atomic Event} or \emph{Simple Event} is an Event which contains only a
\emph{single Outcome} in the Sample Space, i.e. it is a Singleton Subset of the
Sample Space

the Unitarity Axiom (\S\ref{sec:probability_axioms}) states that the
Probability that at least one of the Elementary Events in the Entire Sample
Space will Occur is $1$



\subsubsection{Mutually Exclusive Event}\label{sec:mutually_exclusive}

$\sigma$-additivity Axiom (\S\ref{sec:probability_axioms}): the Probability of
a Countable Sequence of Disjoint Sets is equal to the Sum of the individual
Probabilities

a Quasiprobability Distribution (\S\ref{sec:quasiprobability_distribution})
violates the $\sigma$-additivity Axiom by not representing Probabilities of
Mutually Exclusive States



\subsubsection{Independent Event}\label{sec:independent_event}

\fist cf. Independence (\S\ref{sec:independence})

$P(B|A) = P(B)$ or $P(A|B) = P(A)$ -- note that this is only defined when the
Conditioning Event has Non-zero Probability

Independent if and only if $P(A \cap B) = P(A) P(B)$

$n$ Events are Independent if:
\[
  P(A_i \cap A_j \cap \cdots \cap A_g) = P(A_i)P(A_j) \cdots P(A_g)
\]
for any distinct Events $i,j,\ldots,g$

Pairwise Independence does not imply $n$-way Independence

$P(A \cap B | C) = P(A|C)P(B|C)$

\fist Conditional Independence (\S\ref{sec:conditional_independence})

note that two Events may be Independent, but not \emph{Conditionally}
Independent, i.e. the Intersection of each Independent Event $A$ and $B$ with
the Conditioning Event $C$ may be Disjoint, making them \emph{Dependent}



% --------------------------------------------------------------------
\subsection{Random Variable}\label{sec:random_variable}
% --------------------------------------------------------------------

Function on a Sample Space (\S\ref{sec:sample_space}) mapping Outcomes in the
Sample Space to some other Set of Values

$X : \Omega \rightarrow E$

Discrete Random Variable (\S\ref{sec:discrete_random_variable})

Continuous Random Variable (\S\ref{sec:continuous_random_variable})

a \emph{Dependence} (Association \S\ref{sec:association}) between two Random
Variables (``Bivariate Data'') is any ``Statistical Relationship'' (which may
or may not be Causal) --
Random Variables are \emph{Dependent} if they do not Satisfy the Property of
\emph{Probabilistic Independence} (\S\ref{sec:independence})

\fist Relative Entropy (\S\ref{sec:relative_entropy}), Mutual Information
(\S\ref{sec:mutual_information})

***

\emph{A Categorical Look at Random Variables} -
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html}:

$\cat{Prob}$ -- Category with Objects as Probability Spaces
(\S\ref{sec:probability_space}) and Morphisms are ``Almost-everywhere-equality
Equivalence Classes'' of Measure-preserving Maps
(\S\ref{sec:measure_preserving_map})

the fundamental ``objects'' of Probability Theory are the \emph{Morphisms} of
$\cat{Prob}$ and these Morphisms are \emph{Random Variables}

a Random Variable is defined as a Measurable Map
(\S\ref{sec:measurable_function}):
\[
  X : \Omega \rightarrow E
\]
where $(\Omega,\mathbb{P})$ is a Probability Space and $E$ is an arbitrary
Measurable Space

***

MIT 6.041SC Lec. 5 - \url{https://www.youtube.com/watch?v=3MOahpLxj6A}:

Functions of Random Variables are also Random Variables

Probability Mass Function (\S\ref{sec:probability_mass}) $p_X$ assigns
Probabilities to Elements of $x \in E$:
\[
  p_X(x) = P(X = x)
\]

$p_X(x) \geq 1$

$\sum_x p_X(x) = 1$

Expected Value (\S\ref{sec:expected_value}) of a Random Variable is a kind of
``average'' where Probabilities are treated like ``frequencies'':
\[
  E[X] = \sum_x xp_X(x)
\]
for a Function of a Random Variable $Y = g(X)$:
\[
  E[Y] = \sum_x g(x)p_X(x)
\]

for a PMF that is Symmetric around a certain point, that point is the Expected
Value




\subsubsection{Characteristic}\label{sec:characteristic}

Function associating a Real Number to each Element in the Sample
Space.



\subsubsection{Discrete Random Variable}
\label{sec:discrete_random_variable}

\subsubsection{Continuous Random Variable}
\label{sec:continuous_random_variable}

has Probability $0$ of assuming a particular Value



\subsubsection{Expected Value}\label{sec:expected_value}

Expected Value of a Random Variable is a kind of ``average'' where
Probabilities are treated like ``frequencies''

(Kolmogorov33) analogy between the \emph{Expectation} of a Random Variable, and
\emph{Lebesgue Integration} (\S\ref{sec:lebesgue_integral})

for a Probability Mass Function (\S\ref{sec:probability_mass}) that is
Symmetric around a certain point, that point is the Expected Value

For Random Variable $X$ with Probability Distribution $f(x)$, the
\emph{Expected Value} (or \emph{Mean}) of $X$ is (Discrete):
\[
  \mu = E[X] = \sum_{i=1}^\infty x_i f(x_i)
\]
(Continuous):
\[
  \mu = E[X] = \int\limits_{-\infty}^{\infty} x_i f(x_i) dx
\]

for a Function of a Random Variable $Y = g(X)$:
\[
  E[Y] = \sum_x g(x)p_X(x)
\]

for \emph{Linear Function} $g$:
\[
  E[g(X)] = g(E[X])
\]

Expectations of Constants (i.e. as ``degenerate'' Random Variables) are just
the Constants themselves: $E[a] = a$

Expectations of Random Variables multiplied by Constant is the Constant
multiplied by the Expectation of the Random Variable:
\[
  E[aX] = aE[X]
\]

Expectation of a Random Variable with the addition of a Constant is the
Constant added to the Expectation of the Random Variable:
\[
  E[X + b] = E[X] + b
\]

Law of Large Numbers (\S\ref{sec:large_numbers})

For Random Variable $X$ with Probability Distribution $f(x)$, the
Expected Value of a Measurable Function
(\S\ref{sec:measurable_function}) of $X$, $g(X)$, is:
\[
  \mu_{g(X)} = E[g(X)] = \int\limits_{-\infty}^{\infty} g(x) f(x) dx
\]

For Joint Probability Density Function:
\[
  E[X Y] = \int\int x y j(x,y) dx dy
\]
\fist Note that $E[X Y]$ is not necessarily equal to $E[X]
E[Y]$, see Covariance (\S\ref{sec:covariance}).

For $X$ and $Y$ Independent (\S\ref{sec:independence}), then $E[X,Y] = E[X]
E[Y]$

If $a$ and $b$ are Constants, then $E[aX +b] = a E[X] + b$

$E [g(X) \pm h(X)] = E[g(X)] \pm E[h(X)]$

$E [g(X,Y) \pm h(X,Y)] = E[g(X,Y)] \pm E[h(X,Y)]$

the Variance (Expected Value of the Squared Deviation \S\ref{sec:variance}) of
a Random Variable $X$ is equal to:
\begin{align*}
  Var(X) & = E[(x - E[X])^2] \\
         & = E[X^2] - (E[X])^2 \\
\end{align*}



\subsubsection{Variance}\label{sec:variance}

the \emph{Variance} is the Expected Value of the Squared Deviation of a Random
Variable

Variances are always Non-negative

the Variance of a Random Variable $X$ is equal to:
\begin{align*}
  Var(X) & = E[(x - E[X])^2] \\
         & = E[X^2] - (E[X])^2 \\
\end{align*}
where $E[\cdot]$ is the Expected Value (\S\ref{sec:expected_value}) of a
Random Variable

Discrete Random Variable $X$:
\[
  Var(X) = \sigma_X^2 = \sum_{i=1}^n f(x_i) (x_i - \mu)^2 = \sum_{i=1}^n
  f(x_i) x_i^2 - \mu^2
\]
where $\mu = \sum_{i=1}^n f(x_i) x_i$

Continuous Random Variable $X$:
\[
  Var(X) = \sigma_X^2 = \int (x - \mu)^2 f(x) dx = \int x^2 f(x) dx -
  \mu^2
\]
where $\mu = \int x f(x) dx$

For Random Variables $X$, $Y$ with Joint Probability Distribution
$f(x,y)$ and $a$, $b$, $c$ are Constants, then:
\[
  \sigma^2_{a X + b Y + c} = a^2 \sigma^2_X + b^2 \sigma^2_Y + 2ab
  \sigma_{X Y}
\]



\subsubsection{Covariance}\label{sec:covariance}

$X$, $Y$, Joint Probability Distribution
(\S\ref{sec:joint_probability}) $f(x,y)$

Discrete:
\[
  \sigma_{xy} = E [(x - \mu_X)(y - \mu_Y)] = \sum_x \sum_y (x - \mu_X)
  (y - \mu_Y) f(x,y)
\]

Continuous:
\[
  \sigma_{xy} = E [(x - \mu_X)(y - \mu_Y)] =
  \int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty}
  (x - \mu_X) (y - \mu_Y) f(x,y) dx dy
\]



\paragraph{Covariance Matrix}\label{sec:covariance_matrix}\hfill

Positive semi-definite (\S\ref{sec:positive_semidefinite})



\subsubsection{Skewness}\label{sec:skewness}

Asymmetry %FiXME



\subsubsection{Kurtosis}\label{sec:kurtosis}

\subsubsection{Binomial Random Variable}\label{sec:binomial_random_variable}

Binomial (Bernoulli) Trial (\S\ref{sec:binomial_trial})

Binomial Distribution (\S\ref{sec:binomial_distribution})

$X \sim B(n,p)$

Probability Mass Function:
\[
  f(k,n,p) = P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}
\]
for $k = 0,1,2, \ldots, n$



\subsubsection{Correlation Coefficient}\label{sec:correlation_coefficient}

\fist Correlation (\S\ref{sec:correlation})

\emph{Pearson Product-moment Correlation Coefficient}

$\rho_{xy} = \frac{\sigma_{xy}}{\sigma_x \sigma_y}$



% --------------------------------------------------------------------
\subsection{Dependence}\label{sec:dependence}
% --------------------------------------------------------------------

or \emph{Dependence}

any ``\emph{Statistical Relationship}'' between two Random Variables
(``Bivariate Data'')

may or may not be Causal

Random Variables are \emph{Dependent} if they do not Satisfy the Property of
\emph{Probabilistic Independence} (\S\ref{sec:independence})



\subsubsection{Correlation}\label{sec:statistical_correlation}

measure of how close two Random Variables are to having a \emph{Linear
  Relationship}

\fist Correlation Coefficient (\S\ref{sec:correlation_coefficient})



% --------------------------------------------------------------------
\subsection{Independence}\label{sec:independence}
% --------------------------------------------------------------------

\emph{Property of Probabilistic Independence}

$P(A \cap B) = P(A)P(B)$

two Random Variables (\S\ref{sec:random_varible}) are \emph{Dependent}
(\S\ref{sec:dependence}) if they do not Satisfy the Property of
Probabilistic Independence

\fist cf. Independent Event (\S\ref{sec:independent_event})



\subsubsection{Conditional Independence}\label{sec:conditional_independence}

$P(A \cap B | C) = P(A|C)P(B|C)$

note that two Events may be Independent, but not \emph{Conditionally}
Independent, i.e. the Intersection of each Independent Event $A$ and $B$ with
the Conditioning Event $C$ may be Disjoint, making them \emph{Dependent}

\fist Conditional Probability (\S\ref{sec:conditional_probability})

\url{http://lesswrong.com/lw/pi/classical_configuration_spaces/}
-- ``Conditional Independence happens when the Joint Probability Distribution
is the Product of the individual Probability Distributions''



% --------------------------------------------------------------------
\subsection{Probability}\label{sec:probability}
% --------------------------------------------------------------------

cf. Uncertainty (\S\ref{sec:uncertainty})

Probability of an Event (\S\ref{sec:probability_event}) $A$, $P(A)$ is the Sum
of Weights of all Sample Points in $A$

the Probability $P$ of an Event $E$ is usually defined such that $P$ satisfies
the Kolmogorov Axioms (\S\ref{sec:probability_axioms})

(Kolmogorov33) analogy between the \emph{Measure} (\S\ref{sec:measure}) of a Set
and the Probability of an Event

$\frac{|A|}{|S|}$

$P(A \cup B) = P(A) + P(B) - P(A \cap B)$

$P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) -
P(B \cap C) + P(A \cap B \cap C)$

Corollary: for Disjoint $A_1, A_2, \ldots$:
\[
  P(A_1 \cup A_2 \cup \ldots) = P(A_1) + P(A_2) + \ldots
\]

$P(A_1 \cap A_2 \cap \ldots \cap A_k) = P(A_1) P(A_2 | A_1) P(A_3 |
A_1 \cap A_2) \ldots P(A_k | A_1 \cap A_2 \cap \ldots \cap A_{k-1})$

cf. \emph{Probability Measure} (\S\ref{sec:probability_measure}),
\emph{Probability Measure Function} (\S\ref{sec:probability_measure_function})

\emph{Probability, Knowledge, and Meta-probability}:
\url{https://www.lesswrong.com/posts/2xmKZu73gZLDEQw7c/probability-knowledge-and-meta-probability}



\subsubsection{Probability Axioms}\label{sec:probability_axioms}

\emph{Kolmogorov Axioms}

the Probability $P$ of an Event $E$ is usually defined such that $P$ satisfies
the Kolmogorov Axioms

\begin{enumerate}
  \item (\emph{Non-negativity}) The Probability of an Event is a Non-negative
    (Finite) Real Number
  \item (\emph{Unit Measure}) The Probability that at least one of the
    Elementary Events in the entire Sample Space will Occur is $1$
  \item (Countable \emph{$\sigma$-additivity}) Any Countable Sequence of
    Disjoint Sets (Mutually Exclusive Events) $E_1, E_2, \ldots$ satisfies:
    \[
      P (\bigcup_{i=1}^\infty = \sum_{i=1}^\infty P(E_i)
    \]
\end{enumerate}

\fist Unit Measure: cf. \emph{Unitarity} in Physics is used as a synonym for
``Consistency'', esp. the condition that the Hamiltonian is bounded from below,
i.e. there is a State of Minimal Energy (the \emph{Ground State} or
\emph{Vacuum State}), which is needed for the Third Law of Thermodynamics to
hold

the Third Axiom is relaxed in Quasiprobability Distributions
(\S\ref{sec:quasiprobability_distribution}); to compensate sometimes they are
allowed to have regions of Negative Probability
(\S\ref{sec:negative_probability}) Density

\fist cf. Probabilistic Logic (\S\ref{sec:probabilistic_logic})



\subsubsection{Law of Total Probability}\label{sec:total_probability}

For a Countably Inifinite Partition of a Sample Space
(\S\ref{sec:sample_space}), $\{ B_n : n = 1,2,3,\ldots \}$, with each
Event $B_n$ being Measurable (\S\ref{sec:measure}), then for any Event
$A$ in the same Probability Space (\S\ref{sec:probability_space}):
\[
  P(A) = \sum_n P(A \cap B_n)
\]
or equivalently:
\[
  P(A) = \sum_n P(A|B_n) P(B_n)
\]
where terms such that $P(B_n) = 0$ are omitted from the summation.



\subsubsection{Conditional Probability}
\label{sec:conditional_probability}

where Event $A$ is known to have occurred:

$P(B|A) = \frac{P(A \cap B)}{P(A)}$ when $P(A) > 0$

$P(A \cap B) = P(A) P(B|A)$ when $P(A) > 0$

$P(A|A) = 1$

note that Conditional Probability is only defined when the Conditioning Event
has a Non-zero (Positive) Probability

\fist Independent Event (\S\ref{sec:independent_event})

\fist Conditional Independence (\S\ref{sec:conditional_independence})

\fist Negative Probability (\S\ref{sec:negative_probability})

(Witten18): Quantum Information Theory doesn't have a good analog to defining a
Conditional Probability Distribution as in Classical Information Theory, but
does have an analog of \emph{Strong Subadditivity of Entropy}
(\S\ref{sec:entropy})



\subsubsection{Baye's Theorem}\label{sec:bayes_theorem}

or \emph{Bayes Rule}

\url{https://arbital.com/p/bayes_rule/?l=1zq}

\emph{Bayesian Inference} (\S\ref{sec:bayesian_inference})

\[
  P(A|B) = \frac{P(A)P(B|A)}{P(B)}
\]

\fist Relative Entropy (Kullback-Leibler Divergence
\S\ref{sec:relative_entropy})



\subsubsection{Law of Large Numbers}\label{sec:large_numbers}

\subsubsection{Central Limit Theorem}\label{sec:central_limit}

$z = \frac{\overline{x} - \mu}{\sfrac{\sigma}{\sqrt{n}}}$ as
$n \rightarrow \infty$ is $n(z; 0,1)$ %FIXME

\fist an instance of \emph{Renormalization} (\S\ref{sec:renormalization})

\fist origin of ``Multifractality'' (\S\ref{sec:multifractal_system}) in
Sequential (Time Series) data attributed to ``convergence effects'' related to
the Central Limit Theorem that have Foci of Convergence in the family of Tweedie
Exponential Dispersion Models (Probability Distributions
\S\ref{sec:tweedie_distribution})



\subsubsection{Negative Probability}\label{sec:negative_probability}

or \emph{Quasiprobability}

may apply to \emph{Unobservable Events} or \emph{Conditional Probability}
(\S\ref{sec:conditional_probability})

forbidden by the First Kolmogorov Axiom (\S\ref{sec:probability_axioms})

the Third Axiom ($\sigma$-additivity) is relaxed in Quasiprobability
Distributions (\S\ref{sec:quasiprobability_distribution}); to compensate
sometimes they are allowed to have regions of Negative Probability Density,
violating the First Law

Wigner Distribution in Phase Space (Quantum Corrections)



% --------------------------------------------------------------------
\subsection{Probability Distribution}
\label{sec:probability_distribution}
% --------------------------------------------------------------------

Mathematical Function providing the Probabilities (\S\ref{sec:probability}) of
Occurrence of ``Outcomes''

Probability Distribution Functions:
\begin{itemize}
  \item Probability Mass Function (\S\ref{sec:probability_mass})
  \item Probability Density Function (\S\ref{sec:probability_density})
  \item Cumulative Distribution Function (CDF \S\ref{sec:cdf})
\end{itemize}
See also Probability Measure Function
(\S\ref{sec:probability_measure_function}), Distribution Function (Measure
Theory \S\ref{sec:distribution_function}), Distribution (Analysis
\S\ref{sec:distribution})

a Statistical Model (\S\ref{sec:statistical_model}) $(S,\mathcal{P})$ is a
Sample Space (\S\ref{sec:sample_space}) $S$ together with a Set of Probability
Distributions $\mathcal{P}$ on $S$

\fist Random Graphs (\S\ref{sec:random_graph}) -- Probability Distribution over
a Graph

collapsing a Probability Distribution (Measure) of Probability Distrubtions to a
Probability Distribution is called the ``Giry Monad'' (TODO)

(wiki): a Statistical (or Population) Parameter
(\S\ref{sec:population_parameter}) is a ``quantity'' that indexes a Family of
Probability Distributions

the Entropy (\S\ref{sec:entropy}) of a Distribution is the Mean number
of Bits-per-symbols in an Optimal Encoding (\S\ref{sec:encoding}) --
\url{https://golem.ph.utexas.edu/category/2017/02/functional_equations_iii_expla.html}

Cross Entropy (\S\ref{sec:cross_entropy}) measures the average number of Bits
needed to identify an Event drawn from an underlying Set of Events under two
Probability Distributions $p$ and $q$, if the ``coding scheme'' is optimized for
an ``unnatural'' Distribution $q$ rather than a ``true'' Distribution $p$
%FIXME: clarify

\emph{Principle of Maximum Entropy}

(Witten18): Quantum Information Theory doesn't have a good analog to defining a
Conditional Probability Distribution (\S\ref{sec:conditional_probability}) as in
Classical Information Theory, but does have an analog of \emph{Strong
  Subadditivity of Entropy}

the Quantum analog of a Classical Probability Distribution is a \emph{Density
  Matrix} (\S\ref{sec:density_matrix}), a representation of the Linear
\emph{Density Operator} \S\ref{sec:density_operator})-- a Self-adjoint
(Hermitian), Positive Semi-definite, Trace One, and may be Infinite-dimensional
Matrix; every Matrix with these properties can be ``Purified'', meaning that it
is the Density Matrix of \emph{some} Pure State on some ``Bipartite'' System
$AB$; there is no ``classical analog'' for Purification, i.e. there is no way to
make Probability Distribution ``pure'' (one outcome with Probability $1$) by
adding more Variables



\subsubsection{Moment}\label{sec:moment}

(TODO)

Mean, Variance, Skewness



\subsubsection{Discrete Probability Distribution}
\label{sec:discrete_probability}

\paragraph{Binomial Distribution}\label{sec:binomial_distribution}\hfill

Random Variable $X$ with Binomial Distribution where $n \in \nats$ and
$p \in [0,1]$:
\[
  X \sim B(n,p)
\]

Probability of getting exactly $k$ ``successes'' in $n$ ``trials'' where the
Probability of ``success'' is $p$:
\[
  P(k,n,p) = \binom{n}{k}p^k(1-p)^{n-k}
\]

Binomial Random Variable (\S\ref{sec:binomial_random_variable})

Binomial (Bernoulli) Trial (\S\ref{sec:binomial_trial})

generalized as Multinomial Distributions (\S\ref{sec:multinomial_distribution})

Mean $\mu = n p$

Variance $\sigma^2 = n p q$

Sample Proportion %FIXME



\subparagraph{Bernoulli Distribution}\label{sec:bernoulli_distribution}\hfill

$n = 1$

generalization: Categorical Distribution (\S\ref{sec:categorical_distribution})



\subparagraph{Negative Binomial Distribution}\label{sec:negative_binomial}\hfill

$b^*(x; k,p) = \binom{x-1}{k-1} p^k 2^{k-k}$



\subparagraph{Normal Approximation}\label{sec:normal_approximation}\hfill

For Binomial Random Variable $X$ with Mean $\mu = np$ and Variance
$\sigma^2 = npq$, then:
\[
  Z = \frac{X - np}{\sqrt{npq}}
\]
as $n \rightarrow \infty$ is the Standard Normal Distribution
(\S\ref{sec:normal_distribution}) $n(Z;0,1)$



\paragraph{Multinomial Distribution}\label{sec:multinomial_distribution}\hfill

generalization of Binomial Distribution (\S\ref{sec:binomial_distribution})

$k$ Outcomes $E_1, E_2, \ldots, E_k$

Probabilities $p_1, p_2, \ldots, p_k$

Probability Distribution of $x_1, x_2, \ldots, x_k$ number of
Occurences for $E_1, E_2, \ldots, E_k$ in $n$ Independent Trials:
\[
  f(x_1, x_2, \ldots, x_k) = \binom{n}{x_1, x_2, \ldots, x_k} =
  p_1^{x_1} p_2^{x_2} \cdots p_k^{x_k}
\]
and $\sum_{i=1}^k x_i = n$ and $\sum_{i=1}^k {p_i} = 1$



\subparagraph{Categorical Distribution}\label{sec:categorical_distribution}
\hfill

generalization of Bernoulli Distribution (\S\ref{sec:bernoulli_distribution})



\subparagraph{Softmax Function}\label{sec:softmax}
\hfill

or \emph{Normalized Exponential Function}

generalization of Logistic Function (\S\ref{sec:softmax}); the Logistic Function
is the Derivative of Softplus --TODO

output can be used to represent a Categorical Distribution

often used as final layer of a Neural Network-based Classifier



\paragraph{Poisson Distribution}\label{sec:poisson_distribution}\hfill

Poisson Process (\S\ref{sec:poisson_process})

$P(x; \lambda t) = \frac{e^{-\lambda t} (\lambda t)^x}{x!}$
where $\lambda$ is the average number of outcomes per unit time



\paragraph{Geometric Distribution}\label{sec:geometric_distribution}
\hfill

\paragraph{Hypergeometric Distribution}\hfill
\label{sec:hypergeometric_distribution}

$h(x; N, n, k) = \frac{\binom{k}{x} \binom{N-k}{n-x}}{\binom{N}{n}}$

Mean $\mu = \frac{nk}{N}$

Variance $\sigma^2 = \frac{N-n}{N-1} n \frac{k}{N}(1 - \frac{k}{N})$



\subparagraph{Multivariate Hypergeometric Distribution}\hfill
\label{sec:multivariate_hypergeometric}



\paragraph{Parabolic Fractal Distribution}
\label{sec:parabolic_fractal_distribution}\hfill

\paragraph{Discrete Power Law Distribution}
\label{sec:discrete_power_law_distribution}\hfill

\fist Continuous Power Law Distributions
(\S\ref{sec:continuous_power_law_distribution})



\subparagraph{Zipf Distribution}\label{sec:zipf_distribution}\hfill

\subparagraph{Zeta Distribution}\label{sec:zeta_distribution}\hfill

Normalization of the Zipf Distribution

\subparagraph{Yule-Simon Distribution}
\label{sec:yule_simon_distribution}\hfill



\subsubsection{Continuous Probability Distribution}
\label{sec:continuous_probability}

\fist Discrete Power Law Distributions
(\S\ref{sec:discrete_power_law_distribution})



\paragraph{Normal Distribution}\label{sec:normal_distribution}\hfill

(or \emph{Gaussian Distribution})

\[
  n (x; \mu, \sigma) =
  \frac{1}{\sqrt{2\pi \sigma}} e^{-\frac{1}{2 \sigma^2}(x - \mu)^2}
\]

\fist Gaussian Processes (\S\ref{sec:gaussian_process}) can be seen as
Infinite-dimensional generalizations of Multivariate Normal Distributions

2018 - Eric Jang
- \emph{Normalizing Flows Tutorial}
- \url{https://blog.evjang.com/2018/01/nf1.html}



\subparagraph{Standard Normal Distribution}\label{sec:standard_normal}\hfill

Mean $\mu = 0$

Variance $\sigma^2 = 1$



\paragraph{Log-normal Distribution}\label{sec:lognormal_distribution}\hfill

\paragraph{Gamma Distribution}\label{sec:gamma_distribution}\hfill

Gamma Function (\S\ref{sec:gamma_function})

Continuous Random Variable $X$ with parameters $\alpha > 0$ and $\beta
> 0$:
\[
  f(x; \alpha, \beta) =
  \begin{cases}
  \frac{1}{\beta^\alpha \Gamma(\alpha)} x^{\alpha-1} e^{\sfrac{-x}{\beta}}     & \quad x > 0 \\
  0     & \quad\text{else} \\
  \end{cases}
\]

Mean $\mu = \alpha \beta$

Variance $\sigma^2 = \alpha \beta^2$



\subparagraph{Exponential Distribution}\label{sec:exponential_squared}\hfill

Continuous Random Variable $X$ with parameter $\beta > 0$:
\[
  f(x; \beta) =
  \begin{cases}
  \frac{1}{\beta} e^{\sfrac{-x}{\beta}}     & \quad x > 0 \\
  0     & \quad\text{else} \\
  \end{cases}
\]



\subparagraph{$\chi^2$ Distribution}\label{sec:chi_squared}\hfill

Non-symmetric

\[
  f(x; v) =
  \begin{cases}
  \frac{1}{2^{\sfrac{v}{2}}\Gamma(\sfrac{v}{2})} x^{\sfrac{v}{2-1}} e^{\sfrac{-x}{2}}     & \quad x > 0 \\
  0     & \quad\text{else} \\
  \end{cases}
\]



\paragraph{Continuous Power Law Distribution}
\label{sec:continuous_power_law_distribution}\hfill

Scale Invariance (\S\ref{sec:scale_invariance})



\subparagraph{Pareto Distribution}\label{sec:pareto_distribution}\hfill

prototypical Power Law Distribution



\paragraph{$t$-distribution}\label{sec:t_distribution}\hfill

(or \emph{Student's $t$-distribution})



\paragraph{Cauchy Distribution}\label{sec:cauchy_distribution}\hfill

or \emph{Cauchy-Lorentz Distribution}



\subsubsection{Symmetric Probability Distribution}
\label{sec:symmetric_probability}

\paragraph{Uniform Distribution}\label{sec:uniform_distribution}\hfill

a Uniform Distribution is defined by a rectangle formed on the interval Interval
$[min,max]$ such that the area is $1$



\subsubsection{Joint Probability Distribution}\label{sec:joint_probability}

$f(x,y,\ldots)$ for two or more Random Variables $X,Y,\ldots$

Discrete Random Variables:
\begin{enumerate}
  \item $f(x,y) \geq 0$
  \item $\sum_x \sum_y f(x,y) = 1$
  \item $P(X = x, Y = y) = f(x,y)$
\end{enumerate}

Continuous Random Variables:
\begin{enumerate}
  \item $\forall (x,y) \in X \times Y, f(x,y) \geq 0$
  \item $\int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty}
    f(x,y) dx dy = 1$
  \item $P[(X,Y) \in B] = \iint\limits_B f(x,y) dA$
\end{enumerate}

Conditional Independence (\S\ref{sec:conditional_independence}) happens when
the Joint Probability Distribution is the Product of the individual Probability
Distributions
--\url{http://lesswrong.com/lw/pi/classical_configuration_spaces/}

\fist a Stationary Process (\S\ref{sec:stationary_process}) is a Stochastic
Process whose Unconditional Joint Probability Distribution is unchanged in Time



\paragraph{Kalman Filter}\label{sec:kalman_filter}\hfill

a series of papers on ``Kalman Folding'':
\url{http://vixra.org/author/brian_beckman}



\subsubsection{Marginal Distribution}\label{sec:marginal_distribution}

\subsubsection{Conditional Distribution}
\label{sec:conditional_distribution}

\subsubsection{Asymptotic Distribution}
\label{sec:asymptotic_distribution}

\subsubsection{Sampling Distribution}\label{sec:sampling_distribution}

Probability Distribution of a Statistic (\S\ref{sec:statistic})

Statistical Inference (\S\ref{sec:statistical_inference})

Standard Error (\S\ref{sec:standard_error})



\subsubsection{Tweedie Distribution}\label{sec:tweedie_distribution}

(wiki): \emph{Tweedie Convergence Theorem}: describes the Convergence of certain
Statistical Processes towards the Family of Statistical Models known as
\emph{Tweedie Distributions}; Variance-to-Mean Power Law (TODO: xref); cf.
Taylor's Power Law, \emph{Fluctuation Scaling}; alternative paradigm to explain
Power Law manifestations attributed to ``Self-organized Criticality''
(SOC \S\ref{sec:soc})

Pink ($1/f$) Noise

\fist origin of ``Multifractality'' (\S\ref{sec:multifractal_system}) in
Sequential (Time Series) data attributed to ``convergence effects'' related to
the Central Limit Theorem (\S\ref{sec:central_limit}) that have Foci of
Convergence in the family of Tweedie Exponential Dispersion Models



\subsubsection{Quasiprobability Distribution}
\label{sec:quasiprobability_distribution}

relaxation of the Third Kolmogorov Axiom ($\sigma$-additivity
\S\ref{sec:probability_axioms})

to compensate some Quasiprobability Distributions have regions of Negative
Probability (\S\ref{sec:negative_probability}) Density, contradicting the First
Axiom

regions Integrated under them do not represent Probabilities of Mutually
Exclusive States (\S\ref{sec:mutually_exclusive})

cf. Phase Space (\S\ref{sec:phase_space}) Formulation of Quantum Mechanics:
Position and Momentum Variables on equal footing in Phase Space (cf.
Schr\"odinger formulation uses Position \emph{or} Momentum representations)

\fist Time-Frequency Analysis (\S\ref{sec:time_frequency_analysis}): analysis
of Signals with Time-varying Statistics (cf. Entropy \S\ref{sec:entropy}), e.g.
Transient Signals (\S\ref{sec:transient})



\subsubsection{Probability Mass Function}\label{sec:probability_mass}

(or \emph{Probability Function})

for a Discrete Random Variable (\S\ref{sec:discrete_random_variable})
$X$:
\begin{enumerate}
  \item $f(x) \geq 0$
  \item $\sum_x f(x) = 1$
  \item $P(X = x) = f(x)$
\end{enumerate}

for a Probability Mass Function that is Symmetric around a certain point, that
point is the Expected Value (\S\ref{sec:expected_value})



\subsubsection{Probability Density Function}
\label{sec:probability_density}

\emph{Probability Density Function} $f(x)$

for a Continuous Random Variable (\S\ref{sec:continuous_random_variable}) $X$:
\begin{enumerate}
  \item $\forall x \in \reals, f(x) \geq 0$
  \item $\int\limits_{-\infty}^{\infty} f(x) dx = 1$
  \item $P (a < X < b) = \int\limits_a^b f(x) dx$
\end{enumerate}



\subsubsection{Cumulative Distribution Function (CDF)}\label{sec:cdf}

Area under Probability Density Function

cf. Distribution Function (Measure Theory \S\ref{sec:distribution_function})

$\forall x \in \reals, F_X(x) = P(X \leq x) = \int\limits_{-\infty}^x
f(t) dt$



% --------------------------------------------------------------------
\subsection{Normalizing Constant}\label{sec:normalizing_constant}
% --------------------------------------------------------------------



% ====================================================================
\section{Conditioning}\label{sec:conditioning}
% ====================================================================

\fist not to be confused with Condition Numbers (Numerical Analysis
\S\ref{sec:condition_number})



% ====================================================================
\section{Inferential Statistics}\label{sec:inferential_statistics}
% ====================================================================

Probabilistic Inference
(\S\ref{sec:probabilistic_inference}),Inductive Inference
(\S\ref{sec:inductive_inference})

Random Variation: Sampling Variation, Observational Error

Wasserman04 - \emph{All of Statistics}



% --------------------------------------------------------------------
\subsection{Statistical Inference}\label{sec:statistical_inference}
% --------------------------------------------------------------------

Probabilistic Classification (\S\ref{sec:probabilistic_classification}) -- use
of Statistical Inference to solve a Statistical Classification
(\S\ref{sec:statistical_classification})



\subsubsection{Predictive Inference}\label{sec:predictive_inference}

\paragraph{Prediction Interval}\label{sec:prediction_interval}\hfill

Frequentist: Confidence Interval (\S\ref{sec:confidence_interval})

Bayesian: Credible Interval (\S\ref{sec:credible_interval})



\paragraph{Best Linear Unbiased Prediction (BLUP}}\label{sec:blup}\hfill

under ``suitable assumptions'' on the Priors, Gaussian Process Regression
(Kriging \S\ref{sec:gaussian_process_regression}) gives the best BLUP of the
intermediate values



\subsubsection{Proportion}\label{sec:statistical_proportion}

\paragraph{Lexis Ratio}\label{sec:lexis_ratio}\hfill



\subsubsection{Hypothesis Testing}\label{sec:hypothesis_testing}

\emph{Statistical Hypothesis}: Assertion or Conjecture concerning one
or more Populations (\S\ref{sec:population})

\url{https://github.com/puolival/multipy} -- Python library

Methodology

Confidence Intervals (\S\ref{sec:confidence_interval})

Null Hypothesis $H_0$ represents any Hypothesis

If $H_0$ is Rejected then Alternate Hypothesis $H_1$ is Accepted

$H_1$ usually represents the question to be answered

\begin{enumerate}
  \item Sufficient Evidence: Reject $H_0$ in favor of $H_1$
  \item Insufficient Evidence: fail to Reject $H_0$
\end{enumerate}

\emph{Test Statistic}

\emph{Critical Region}, \emph{Critical Value}

Type I Error: Rejection of $H_0$ when it is True

Type II Error: Non-Rejection of $H_0$ when it is False

\emph{Level of Significance} $\alpha$: Probability of committing a
Type I Error

$\beta$: Probability of committing a Type II Error

\emph{Power} $1 - \beta$: Probability of Rejecting $H_0$ given that a
specific alternative is True

Confidence Intervals (\S\ref{sec:confidence_interval})

One-tailed Test

Two-tailed Test

Test on a single Mean

Test on a single Sample

$P$-value: lowest Level of Significance at which the observed Value of
the Statistic is Significant



% --------------------------------------------------------------------
\subsection{Statistical Model}\label{sec:statistical_model}
% --------------------------------------------------------------------

or \emph{Probabilistic Model}

\emph{Statistical Population} (\S\ref{sec:population}) -- Set of ``similar
items'' or Events (\S\ref{sec:probability_event}) of interest

\fist Descriptive Statistics (\S\ref{sec:descriptive_statistics}): a Subset of
the Population is a \emph{Statistical Sample} (\S\ref{sec:statistical_sample})

Statistical Parameters (Population Parameters \S\ref{sec:population_parameter})

Data

Estimate (\S\ref{sec:estimation_theory}): Data $\rightarrow$ Parameters

\emph{Regression} (\S\ref{sec:regression_analysis}) is the Estimation of
Parameters of a Statistical Model

cf. Regression Model (\S\ref{sec:regression_model})

(wiki):

$(S, \mathcal{P})$

$S$ -- Sample Space

$\mathcal{P}$ -- Probability Distributions
(\S\ref{sec:probability_distribution}) on $S$

\emph{Regression} (\S\ref{sec:regression_analysis}) is the Estimation
(\S\ref{sec:estimation_theory}) of Parameters of a Statistical Model

\asterism

MIT 6.041SC - \emph{Probabilistic Systems Analysis and Applied Probability}

Probability Laws -- describes ``beliefs'' about which outcomes are more likely
than others; should obey Probability Axioms (\S\ref{sec:probability_axioms})

Sample Space (\S\ref{sec:sample_space}) $\Omega$ -- description of possible
outcomes

a ``list'' of Events should be Mutually Exclusive
(\S\ref{sec:mutually_exclusive}, for $\sigma$-additivity Axiom) and exhaustive
(for Unitarity Axiom)

\emph{Discrete Uniform Law} (\S\ref{sec:discrete_uniform_law}): all Outcomes are
equally likely

\emph{Continuous Uniform Law} (\S\ref{sec:continuous_uniform_law}): equal Areas
have equal Probabilities

Discrete Models

Continuous Models -- any individual outcome has Zero Probability (TODO: explain)

Models based on Conditional Probabilities (\S\ref{sec:conditional_probability})



\subsubsection{Discrete Uniform Law}\label{sec:discrete_uniform_law}

MIT 6.041SC Lec. 4 - \url{https://www.youtube.com/watch?v=6oV3pKLgW2I}

every possible Outcome has the same Probability of Occurring

Sample Space $\Omega$

the Probability of an Event $A$:
\[
  P(A) = \frac{|A|}{|\Omega|}
\]

for $|\Omega| = N$, every Element of $\Omega$ has Probability $\frac{1}{N}$

for a Subset $A$ with Cardinality $|A| = n$:
\[
  P(A) = n \frac{1}{N}
\]


Basic Counting Principles

for a Set with Cardinality $n$:
\begin{itemize}
  \item $n^\ell$ -- Possible Sequences of Length $\ell$ (with repetitions)
  \item $2^n$ -- Possible Subsets
  \item $\binom{n}{k}$ -- Possible Subsets of $k$ Elements
  \item $n!$ -- Possible Permutations (Orderings with no repetitions)
  \item $\frac{n!}{(n-k)!}$ -- Possible Permutations of $k$ Elements
  \item $n^2$ -- Possible Ordered Pairs
  \item $\frac{n(n-1)}{2}$ -- Possible Unique Pairings (Handshake problem)
\end{itemize}


Binomial Probabilities \fist Binomial Distribution
(\S\ref{sec:binomial_distribution}) -- Probability of getting exactly $k$
``successes'' in $n$ Trials where the Probability of ``success'' is $p$:
\[
  P(k,n,p) = \binom{n}{k}p^k(1-p)^{n-k}
\]
(FIXME: clarify)



\subsubsection{Continuous Uniform Law}\label{sec:continuous_uniform_law}

\subsubsection{Variational Bayesian Method}
\label{sec:variational_bayesian_method}

Free Energy Principle -- implicit Minimization of Variational Free Energy;
Active Inference (Friston)



\subsubsection{Model Selection}\label{sec:model_selection}

\paragraph{Optimality Criterion}\label{sec:optimality_criterion}\hfill

\fist Decision Rules (Decision Theory \S\ref{sec:decision_rule}): makes a
Choice using an Optimality Critereon



\subsubsection{Parametric Model}\label{sec:parametric_model}

\emph{Parametric Statistics}

assumes that Sample Data comes from a Population that follows a Probability
Distribution based on a fixed Set of \emph{Statistical Parameters}
(Population Parameters \S\ref{sec:population_parameter})

example: the Family of Normal Distributions (\S\ref{sec:normal_distribution})
are Parameterized by the Mean and Standard Deviation



\subsubsection{Non-parametric Model}\label{sec:nonparametric_model}

Parameter Set (or \emph{Feature Set} in Machine Learning) is not fixed, i.e. it
may increase or decrease as new relevant information is collected



\subsubsection{Graphical Model}\label{sec:graphical_model}

\paragraph{Bayesian Network}\label{sec:bayesian_network}\hfill

or \emph{Probabilistic Directed Acyclic Graphical Model}

DAG (\S\ref{sec:dag}) -- dependency structure

representation of Probability Distributions based on \emph{Causal Dependencies}

\emph{Causality} (Pearl 2009) -- counterfactual reasoning

\url{https://golem.ph.utexas.edu/category/2018/07/bayesian_networks.html}



\subsubsection{Generalized Linear Model}\label{sec:generalized_linear_model}

not to be confused with General Linear Models (Multivariate Regression Models
\S\ref{sec:multivariate_regression})



\subsubsection{Discrete Choice Model}\label{sec:discrete_choice_model}

\paragraph{Binary Choice Model}\label{sec:binary_choice}\hfill

essentially the same as Binomial Regression
(\S\ref{sec:binomial_regression}) Models



\subsubsection{Logistic Model}\label{sec:discrete_uniform_law}

or \emph{Logit Model}

uses a Logistic Function (\S\ref{sec:logistic_function}) to Model a Binary
Dependent Variable

Logistic Regression (\S\ref{sec:logistic_regression})



% --------------------------------------------------------------------
\subsection{Estimation Theory}\label{sec:estimation_theory}
% --------------------------------------------------------------------

deals with ``\emph{Estimating}'' the values of Statistical Parameters
(\S\ref{sec:population_parameter}) based on data that has a ``\emph{random
  component}'' (FIXME: clarify)

an \emph{Estimator} (\S\ref{sec:estimator}) attempts to approximate unknown
Statistical Parameters using ``measured data''

\emph{Regression} (\S\ref{sec:regression_analysis}) is the Estimation of
Parameters of a Statistical Model (\S\ref{sec:statistical_model})

approaches:
\begin{itemize}
  \item \emph{Probabilistic} -- assume the ``measured data'' is ``random'' with
    a Probability Distribution (\S\ref{sec:probability_distribution}) dependent
    on the Statistical Parameters of interest
  \item \emph{Set-membership} (\S\ref{sec:set_estimation}) -- 
\end{itemize}



\subsubsection{Estimator}\label{sec:estimator}

(wiki):

an \emph{Estimator} attempts to approximate unknown Statistical Parameters
(\S\ref{sec:statistical_paramaeter}) using ``measured data''

when the data consists of ``multiple variables'', Estimating the ``relation''
between them is \emph{Regression Analysis} (\S\ref{sec:regression_analysis})
--FIXME: clarify



\paragraph{Point Estimator}\label{sec:point_estimator}\hfill

\paragraph{Interval Estimator}\label{sec:interval_estimator}\hfill



\subsubsection{Error}\label{sec:error}

\emph{Statistical Error}

Mean Squared Error (MSE) or Mean Squared Deviation (MSD)



\subsubsection{Residual}\label{sec:residual}

or \emph{Fitting Deviation}

\fist Regression Residual (\S\ref{sec:regression_residual})



\subsubsection{Bias}\label{sec:bias}

\paragraph{Unbiased Estimate}\label{sec:unbiased_estimate}\hfill

\paragraph{Efficient Estimate}\label{sec:efficient_estimate}\hfill

Unbiased Estimator with Smallest Variance



\subsubsection{Standard Error}\label{sec:standard_error}

Sampling Distribution (\S\ref{sec:sampling_distribution})



\subsubsection{Pooled Estimate}\label{sec:pooled_estimate}

%FIXME



\subsubsection{Set Estimation}\label{sec:set_estimation}

Set-membership approach to Estimation Theory (cf. Probabilistic approach)



% --------------------------------------------------------------------
\subsection{Regression Analysis}\label{sec:regression_analysis}
% --------------------------------------------------------------------

\emph{Regression} is the Estimation (\S\ref{sec:estimation_theory}) of
Parameters of a Statistical Model

\fist cf. Curve Fitting (\S\ref{sec:curve_fitting})

Regression Variable, ``Regressor'', or ``Explanatory Variable'' -- Independent
Variable (\S\ref{sec:independent_variable}); Covariate

Response Variable, ``Regressand'', or ``Explained Variable'' -- Dependent
Variable (\S\ref{sec:dependent_variable}); Criterion

example of Pattern Recognition (assignment of some Output Value to a given Input
Value), other examples are Statistical Classification
(\S\ref{sec:statistical_classification}) and Cluster Analysis
(\S\ref{sec:cluster_analysis})

Statistical Classification: \emph{Features} (Properties of Observations
\S\ref{sec:observation} or \emph{Instances}) are Explanatory Variables
(Regressors) and possible values of the Dependent Variable are categories called
\emph{Outcomes}

Linear Regression, Ordinary Least Squares, Logistic Regression

cf. Numerical Analysis (\S\ref{sec:numerical_analysis}): Interpolation
(\S\ref{sec:interpolation}), Extrapolation (TODO)



\subsubsection{Regression Model}\label{sec:regression_model}

\emph{Regression Model}:
\begin{itemize}
  \item \emph{Unknown Parameters} ($\beta$) -- Statistical Parameters
    (\S\ref{sec:statistical_parameter})
  \item \emph{Independent Variables} ($X$) -- ``Regression Variable'',
    ``Regressor'', ``Covariate'', ``Explanatory Variable''
  \item \emph{Dependent Variable} ($Y$) -- ``Response Variable'',
    ``Regressand'', ``Criterion'', ``Explained Variable''; variable whose values
    are to be ``explained'' in terms of the Independent Variable
\end{itemize}

Linear Regression Models (\S\ref{sec:linear_regression})

...



\subsubsection{Regression Error}\label{sec:regression_error}

\fist cf. Statistical Error (Estimators \S\ref{sec:error})

Mean Squared Error (MSE) or Mean Squared Deviation (MSD)



\subsubsection{Regression Residual}\label{sec:regression_residual}

\fist cf. Residual (Estimators \S\ref{sec:residual})

Mean Squared Error (MSE) or Mean Squared Deviation (MSD)



\subsubsection{Fit}\label{sec:model_fit}

measures the discrepancy between Observed (\S\ref{sec:observation}) values and
Expected Values under the Statistical Model

%FIXME: move section ???

cf. Curve Fitting (\S\ref{sec:curve_fitting})



\subsubsection{Linear Regression}\label{sec:linear_regression}

\emph{Linear Regression Model}

Fit using:
\begin{itemize}
  \item Linear Least Squares (\S\ref{sec:linear_least_squares}): if errors are
    \emph{normally distributed}, Least Squares ($2$-norm Best Fit) should be
    used
  \item ...
\end{itemize}

Gradient Descent (\S\ref{sec:gradient_descent})

cf. Convex Optimization (\S\ref{sec:convex_optimization}) -- for Linear
Regression, a Mean-Square Error Loss Function is always \emph{Convex} (example
\url{https://towardsdatascience.com/introduction-to-machine-learning-algorithms-linear-regression-14c4e325882a}

cf. Linear Programming (\S\ref{sec:linear_programming})
-- article: \emph{Linear Programming for Linear Regression};
\url{https://lazyprogrammer.me/linear-programming-for-linear-regression/}

Simple Linear Regression -- single Regressor (Independent Variable)

Regression Coefficients

Error Term $\varepsilon$

$Y = \beta_0 + \beta_1 X + \varepsilon$



\subsubsection{Least Squares}\label{sec:least_squares}

$2$-norm Best Fit \fist cf. $1$-norm Best Fit (\S\ref{sec:1norm_best_fit}),
Chebyshev Approximation ($\infty$-norm Best Fit
\S\ref{sec:chebyshev_approximation})



\paragraph{Ordinary Least Squares}\label{sec:ordinary_least_squares}\hfill

estimating the Unknown Parameters of a Linear Regression Model
(\S\ref{sec:linear_regression})



\subparagraph{Linear Least Squares}\label{sec:linear_least_squares}\hfill

Overdetermined Systems (\S\ref{sec:overdetermined_system})

QR Decomposition (\S\ref{sec:qr_decomposition})



\subparagraph{Normal Equation}\label{sec:normal_equation}\hfill

UC Math 352 Lec. 7 \url{https://www.youtube.com/watch?v=ZWGIchXVbho}

$A\vec{x} = \vec{b}$

$\mathrm{min}_{\vec{x}} \|A_{\vec{x}} - \vec{b}\|$

\emph{Normal Equation}: $(A^TA)\vec{x} = A^T\vec{b}$ -- Condition Number
(\S\ref{sec:condition_number}) is $\kappa(A)^2$; see QR Factorization
(\S\ref{sec:qr_factorization}) for a better Conditioned solution

Project $\vec{b}$ onto the Column Space of $A$

\[
  \vec{x} = (A^TA)^{-1}A^T\vec{b}
\]

solve by Cholesky Factorization (\S\ref{sec:cholesky_decomposition}) ... TODO
\url{https://www.youtube.com/watch?v=VJ-04jOfu-E}



\subparagraph{QR Factorization}\label{sec:qr_factorization}\hfill

QR Decomposition (\S\ref{sec:qr_decomposition})

UC Math 352 Lec. 7 \url{https://www.youtube.com/watch?v=ZWGIchXVbho}

better Condition Number than Normal Equations (\S\ref{sec:normal_equation})

$A\vec{x} = \vec{b}$

$A = QR$ ($Q$ is Square, Orthogonal)

Residual $\vec{r} = A\vec{x} - \vec{b}$

\begin{align*}
     \vec{r} & = QR\vec{x} - \vec{b} \\
  Q^T\vec{r} & = R\vec{x} - Q^T\vec{b} \\
\end{align*}

because Orthogonal Matrices preserve Distances and $Q$ is Orthogonal:
\[
  \|Q^T\vec{r}\|_2 = \|\vec{r}\|_2
\]
minimizing $Q^T\vec{r} = \vec{\rho}$ is equivalent to minimizing $\vec{r}$

splitting $\vec{\rho}$ into:
\begin{enumerate}
  \item $\hat{\rho}   = \hat{R}\vec{x} - \hat{Q}^T\vec{b}$
  \item $\vec{\rho}_N = -Q_N^T\vec{b}$
\end{enumerate}
$\hat{rho}$ can be made Zero by solving $\hat{R}\vec{x} - \hat{Q}^T\vec{b}$ for
$\vec{x}$, which is an Upper Triangular Matrix that can be solved efficiently:
\[
  \vec{x} = \hat{R}^{-1}\hat{Q}^T\vec{b}
\]
and $\vec{rho}_N$ is independent of $\vec{x}$ so it is \emph{fixed}, so:
\[
  \|\vec{r}\|^2_2 = \|\hat{Q}_N^T\vec{b}\|_2^2
\]



\paragraph{Generalized Least Squares}\label{sec:generalized_least_squares}\hfill

\subparagraph{Weighted Least Squares}\label{sec:weighted_least_squares}\hfill



\paragraph{Non-linear Least Squares}\label{sec:nonlinear_least_squares}\hfill



\subsubsection{Multivariate Regression}\label{sec:multivariate_regression}

or \emph{General Linear Model}; not to be confused with Generalized Linear
Models (\S\ref{sec:generalized_linear_model})



\subsubsection{Binomial Regression}\label{sec:binomial_regression}

essentially the same as Binary Choice Models (\S\ref{sec:binary_choice_model})



\paragraph{Logistic Regression}\label{sec:logistic_regression}\hfill

or \emph{Logit Regression}

Logistic Model (\S\ref{sec:logistic_model}) -- uses a Logistic Function
(\S\ref{sec:logistic_function}) to Model a Binary Dependent Variable

Statistical Classification (\S\ref{sec:statistical_classification})



\subsubsection{Gaussian Process Regression}
\label{sec:gaussian_process_regression}

\emph{Kriging} or \emph{Wiener-Komogorov Prediction}

under ``suitable assumptions'' on the Priors, Kriging gives the \emph{Best
  Linear Unbiased Prediction} (BLUP \S\ref{sec:blup}) of the intermediate values

\fist Spatial Analysis (\S\ref{sec:spatial_analysis})



\subsubsection{Multiple Regression}\label{sec:multiple_regression}

Definite Quadratic Forms (\S\ref{sec:definite_quadratic})



% --------------------------------------------------------------------
\subsection{Uncertainty Analysis}\label{sec:uncertainty_analysis}
% --------------------------------------------------------------------

\fist Decision Theory (\S\ref{sec:decision_theory})

\fist Robust Statistics (\S\ref{sec:robust_statistic})



\subsubsection{Uncertainty}\label{sec:uncertainty}

cf. Probability (\S\ref{sec:probability})



\subsubsection{Sensitivity Analysis}\label{sec:sensitivity_analysis}

\fist Info-gap Decision Theory (\S\ref{sec:info_gap}): application of
Sensitivity Analysis of the Stability Radius (\S\ref{sec:stability_radius}) type
to Perturbations in the value of a given Estimate of a Parameter of interest
(FIXME: clarify)



\subsubsection{Evidince Theory}\label{sec:evidence_theory}

or \emph{Dempster-Shafer Theory (DST)} or \emph{Theory of Belief Functions}

Transferable Belief Model



\subsubsection{Possibility Theory}\label{sec:possibility_theory}

alternative to Probability Theory for dealing with certain types of Uncertainty



% --------------------------------------------------------------------
\subsection{Statistical Analysis}\label{sec:statistical_analysis}
% --------------------------------------------------------------------

%FIXME: move this section ?

Statistical Theory -- FIXME

Statistic (\S\ref{sec:statistic}) -- a Function of a Random Variable
(\S\ref{sec:random_variable}) constituting a Random Sample
(\S\ref{sec:random_sample})

Statistical Population (\S\ref{sec:population})

Statistical Parameter (\S\ref{sec:population_parameter})

Statistical Model (\S\ref{sec:statistical_model})

Statistical Inference (\S\ref{sec:statistical_inference})

Statistical Learning Theory (\S\ref{sec:statistical_learning_theory})



\subsubsection{Cluster Analysis}\label{sec:cluster_analysis}

Unsupervised Learning

example of Pattern Recognition (assignment of some Output Value to a given Input
Value), other examples are Statistical Classification
(\S\ref{sec:statistical_classification}) and Regression Analysis
(\S\ref{sec:regression_analysis})



\paragraph{Hierarchical Clustering}\label{sec:hierarchical_clustering}\hfill



% --------------------------------------------------------------------
\subsection{Frequentist Inference}\label{sec:frequentist_inference}
% --------------------------------------------------------------------

\subsubsection{Confidence Interval}\label{sec:confidence_interval}

Confidence Coefficient

Confidence Limit

Hypothesis Testing (\S\ref{sec:hypothesis_testing})

One-tail

Two-tail



% --------------------------------------------------------------------
\subsection{Bayesian Inference}\label{sec:bayesian_inference}
% --------------------------------------------------------------------

Conditional Probabilities (\S\ref{sec:conditional_probability}), Bayes' Rule
(\S\ref{sec:bayes_theorem})

\fist Bayesian Network (Probabilistic Directed Acyclic Graphical Model
\S\ref{sec:bayesian_network})

\fist Aumann1987 - \emph{Correlated Equilibrium as an Expression of Bayesian
  Rationality} -- \emph{Correlated Equilibrium}
(\S\ref{sec:correlated_equilibrium}) ``does away with'' the ``dichotomy usually
perceived'' between the \emph{Bayesian} and \emph{Game-theoretic} world-views



\subsubsection{Prior Distribution}\label{sec:prior_distribution}

\subsubsection{Posterior Distribution}\label{sec:posterior_distribution}

\subsubsection{Credible Interval}\label{sec:credible_interval}

\subsubsection{Linear Quadratic Estimation (LQE)}\label{sec:lqe}

dual of Linear Quadratic Regulation (LQR \S\ref{sec:lqr})



% --------------------------------------------------------------------
\subsection{Fiducial Inference}\label{sec:fiducial_inference}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Topological Inference}\label{sec:topological_inference}
% --------------------------------------------------------------------

Wasserman14 - \emph{Robust Topological Inference}

TDA (R package)



% --------------------------------------------------------------------
\subsection{Causal Inference}\label{sec:causal_inference}
% --------------------------------------------------------------------

\url{http://www.inference.vc/untitled/}



% ====================================================================
\section{Descriptive Statistics}\label{sec:descriptive_statistics}
% ====================================================================

Summary of Data: Mean, Median, Mode, Standard Deviation



% --------------------------------------------------------------------
\subsection{Statistical Sample}\label{sec:statistical_sample}
% --------------------------------------------------------------------

Random Sample (\S\ref{sec:random_sample})



\subsubsection{Order Statistic}\label{sec:order_statistic}



% --------------------------------------------------------------------
\subsection{Summary Statistics}\label{sec:summary_statistics}
% --------------------------------------------------------------------

\subsubsection{Measure of Location}\label{sec:location_measure}

\paragraph{Median}\label{sec:median}\hfill

\paragraph{Mode}\label{sec:mode}\hfill

cf. \emph{Unimodality}



\paragraph{Arithmetic Mean}\label{sec:arithmetic_mean}\hfill

\emph{Arithmetic Mean} $\overline{x} = \frac{1}{n}\sum_{i=1}^n x_i$



\paragraph{Geometric Mean}\label{sec:geometric_mean}\hfill

using the Product of Values instead of Sum as in Arithmetic Mean



\paragraph{Trimmed Mean}\label{sec:trimmed_mean}\hfill

\paragraph{Sample Median}\label{sec:median}\hfill



\subsubsection{Statistical Dispersion}\label{sec:statistical_dispersion}

cf. \emph{Uncertainty}

2018 - \emph{Uncertainty: a Tutorial} -
\url{https://blog.evjang.com/2018/12/uncertainty.html}



\paragraph{Sample Variance}\label{sec:variability}\hfill

$s^2$

Degrees of Freedom, Linear Independence, Biased/Unbiased Estimator
(\S\ref{sec:unbiased_estimate})

Unbiased Sample Variance:
\[
  s^2 = \frac{n}{n-1}\sigma^2_y =
  \frac{1}{n-1} \sum_{i=1}^n (y_i - \overline{y})^2
\]



\paragraph{Standard Deviation}\label{sec:standard_deviation}\hfill

Variance (\S\ref{sec:variance})

\emph{Uncorrected Standard Deviation}:
\[
  s_n = \sqrt{\frac{1}{n}\sum_{i=1}^n (x_i - \overline{x})^2}
\]

\emph{Corrected Standard Deviation}

\emph{Unbiased Standard Deviation}



\subparagraph{Chebyshev's Inequality}\label{sec:chebyshevs_inequality}
\hfill

Probability that a Random Variable $X$ will assume Value within $k$ Standard
Deviations

Random Variable $X$ with Finite Expected Value (\S\ref{sec:expected_value})
$\mu$ and Finite Non-zero Variance $\sigma^2$, for any $k \in \reals : k > 0$:
\[
  P(k\sigma \leq |X - \mu|) \leq \frac{1}{k^2}
\]



% --------------------------------------------------------------------
\subsection{Earthmover Distance}\label{sec:earthmover_distance}
% --------------------------------------------------------------------

%FIXME: does this section belong here?

a measure of ``nearness'' for Probability Distributions

\url{https://jeremykun.com/2018/03/05/earthmover-distance/}



% ====================================================================
\section{Large Deviations Theory}\label{sec:large_deviations_theory}
% ====================================================================

% ====================================================================
\section{Statistical Randomness}\label{sec:statistical_randomness}
% ====================================================================

% ====================================================================
\section{Pseudorandom Process}\label{sec:pseudorandom_process}
% ====================================================================

Deterministic System (\S\ref{sec:deterministic_system}) exhibiting Statistical
Randomness (\S\ref{sec:statistical_randomness})

\emph{Hash Functions} can create ``Random Numbers'' solely based on an Input
with no dependency on previous queries

2015 -
\url{http://blog.runevision.com/2015/01/primer-on-repeatable-random-numbers.html}
- \emph{Primer on Repeatable Random Numbers}



% ====================================================================
\section{Stochastic Process}\label{sec:stochastic_process}
% ====================================================================

%FIXME: move section ???

Harmonic Functions (\S\ref{sec:harmonic_function})

\fist Stochastic Calculus (\S\ref{sec:stochastic_calculus})

\fist cf. Stochastic Optimization (\S\ref{sec:stochastic_optimization})

\fist cf. Non-deterministic Dynamical Systems
(\S\ref{sec:nondeterministic_dynamical_system})

\fist Stochastic Differential Equations (SDEs \S\ref{sec:sde}) -- a Differential
Equation in which one or more Terms is a Stochastic Process

First-hitting-time Model



% --------------------------------------------------------------------
\subsection{Random Field}\label{sec:random_field}
% --------------------------------------------------------------------

(wiki): for a Probability Space $(\Omega, \mathcal{F}, P)$, an \emph{$X$-valued
  Random Field}, $F$, is a collection of $X$-valued Random Variables indexed by
elements in a Topological Space $T$:
\[
  F = \{ F_t : t \in T \}
\]
where each $F_t$ is an $X$-valued Random Variable

Tensor-valued Random Fields



\subsubsection{Markov Random Field}\label{sec:markov_random_field}

(MRF)



\subsubsection{Gibbs Random Field}\label{sec:gibbs_random_field}

\subsubsection{Conditional Random Field}\label{sec:conditional_random_field}

Machine Learning: Sequence MOdelling



\subsubsection{Gaussian Random Field}\label{sec:gaussian_random_field}

(GRF)

a 1D GRF is a Gaussian Process (\S\ref{sec:gaussian_process})



% --------------------------------------------------------------------
\subsection{Point Process}\label{sec:point_process}
% --------------------------------------------------------------------

\subsubsection{Poisson Process}\label{sec:poisson_process}

Memory-less

Poisson Distribution (\S\ref{sec:poisson_distribution})



\subsubsection{Binomial Process}\label{sec:binomial_process}

cf. \emph{Bernoulli Process} (\S\ref{sec:bernoulli_process})



% --------------------------------------------------------------------
\subsection{Markov Process}\label{sec:markov_process}
% --------------------------------------------------------------------

(or \emph{Markov Chain})

Markov Property (``Memorylessness'')

can be seen as a special case of Petri Nets (\S\ref{sec:petri_net})
where every Transition has a single Input and a single Output



% --------------------------------------------------------------------
\subsection{Discrete-time Stochastic Process}\label{sec:discretetime_stochastic}
% --------------------------------------------------------------------

\subsubsection{Bernoulli Process}\label{sec:bernoulli_process}

Mathematical Formalization of \emph{Binomial (Bernoulli) Trials}
(\S\ref{sec:binomial_trial})

Stochastic Computing

cf. \emph{Binomial Process} (Point Process \S\ref{sec:binomial_process})



% --------------------------------------------------------------------
\subsection{Continuous-time Stochastic Process}\label{sec:continuous_stochastic}
% --------------------------------------------------------------------

\subsubsection{Gaussian Process}\label{sec:gaussian_process}

a 1D Gaussian Random Field (\S\ref{sec:gaussian_random_field})

can be seen as the Infinite-dimensional generalization of Multivariate Normal
Distributions (\S\ref{sec:normal_distribution})

the Distribution of a Gaussian Process is the Joint Distribution of infinitely
many Random Variables, i.e. it is a Distribution over Functions with a
Continuous Domain

Machine Learning: Lazy Learning (1D Gaussian Distributions)

Gaussain Process Regression (Kriging \S\ref{sec:gaussian_process_regression})



\paragraph{Fractional Brownian Motion}\label{sec:fractional_brownian}\hfill

(\emph{fBm})

$H \in (0,1) \subset \reals$ -- Hurst index

$H = 1/2$ -- Wiener Process (Brownian Motion \S\ref{sec:wiener_process})

for $H > 1/2$, increments of the process are Positively Correlated, and exhibits
Long-range dependence

for $H < 1/2$, increments of the process are Negatively Correlated

Hausdorff and Box Dimension of $2 - H$

\fist Multifractals (\S\ref{sec:multifractal_system}): generalized framework of
Fractional Brownian Motions



\subparagraph{Wiener Process}\label{sec:wiener_process}\hfill

or \emph{Brownian Motion}

$H = 1/2$



% --------------------------------------------------------------------
\subsection{Stationary Process}\label{sec:stationary_process}
% --------------------------------------------------------------------

Stochastic Process for which the Unconditional Joint Probability Distribution
(\S\ref{sec:joint_probability}) does not change when shiften in Time (TODO:
xref)



% ====================================================================
\section{Multivariate Statistics}\label{sec:multivariate_statistics}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Multivariate Analysis}\label{sec:multivariate_analysis}
% --------------------------------------------------------------------

\subsubsection{Ordination}\label{sec:ordination}

\paragraph{Principal Components Analysis}
\label{sec:principal_components_analysis}\hfill

\paragraph{Multidimensional Scaling}\label{sec:multidimensional_scaling}\hfill

\paragraph{Correspondence Analysis}\label{sec:correspondence_analysis}\hfill

\subparagraph{Detrended Correspondence Analysis}
\label{sec:detrended_correspondence}\hfill

\subparagraph{Canonical Correspondence Analysis}
\label{sec:canonical_correspondence}\hfill



\paragraph{Bray-Curtis Ordination}\label{sec:bray_curtis_ordination}\hfill

\paragraph{Redundancy Analysis}\label{sec:redundancy_analysis}\hfill



% ====================================================================
\section{Statistical Mechanics}\label{sec:statistical_mechanics}
% ====================================================================

Thermodynamics, ``Irreversibility''

Jarzynski Equality

Crooks' Fluctuation Theorem



% --------------------------------------------------------------------
\subsection{Non-equilibrium Statistical Mechanics}
\label{sec:nonequilibrium_statistical_mechanics}
% --------------------------------------------------------------------

Jarzynski



% --------------------------------------------------------------------
\subsection{Statistical Ensemble}\label{sec:statistical_ensemble}
% --------------------------------------------------------------------

a Probability Distribution (\S\ref{sec:probability_distribution}) for the state
of a Physical System



\subsubsection{Thermodynamic Ensemble}\label{sec:thermodynamic_ensemble}



% ====================================================================
\section{Information Geometry}\label{sec:information_geometry}
% ====================================================================

Harper09 - \emph{The Replicator Equation as an Inference Dynamic}

Harper09 - \emph{Information Geometry and Evolutionary Game Theory}

\url{http://math.ucr.edu/home/baez/information/}

\url{https://johncarlosbaez.wordpress.com/2017/01/31/biology-as-information-dynamics/}

application of Differential Geometry
(\S\ref{sec:differential_geometry}) techniques to Probability Theory



% --------------------------------------------------------------------
\subsection{Statistical Manifold}\label{sec:statistical_manifold}
% --------------------------------------------------------------------

Riemannian Manifold (\S\ref{sec:riemannian_manifold}) with the
\emph{Fisher Information Metric} as the Riemannian Metric
(\S\ref{sec:riemannian_metric})



\subsubsection{Fisher Information Metric}\label{sec:fisher_metric}

Riemannian Metric (\S\ref{sec:riemannian_metric}) for a Statistical
Manifold

\fist \textbf{Fisher's Fundamental Theorem of Natural Selection},
Quasi-linkage Equilibrium: approximation in the case of Weak Selection
and Weak Epistasis -- Evolutionary Optimization
(\S\ref{sec:evolutionary_optimization}) %FIXME

\url{https://golem.ph.utexas.edu/category/2018/05/the_fisher_metric_will_not_be.html}



% ====================================================================
\section{Statistical Learning Theory}\label{sec:statistical_learning_theory}
% ====================================================================

%FIXME start new document ???



% --------------------------------------------------------------------
\subsection{Statistical Classification}\label{sec:statistical_classification}
% --------------------------------------------------------------------

(wiki): an Algorithm (\S\ref{sec:algorithm}) that implements Classification is
called a \emph{Classifier}

often done with Logistic Regression (\S\ref{sec:logistic_regression})

\emph{Features} (Properties of Observations \S\ref{sec:observation} or
\emph{Instances}) are \emph{Explanatory Variables} (Regressors
\S\ref{sec:independent_variable}) and possible values of the Dependent Variable
(\S\ref{sec:dependent_variable}) are prediction categories (or \emph{Classes})
called \emph{Outcomes}

example of Pattern Recognition (assignment of some Output Value to a given Input
Value), other examples are Regression Analysis (\S\ref{sec:regression_analysis})
and Cluster Analysis (\S\ref{sec:cluster_analysis})



\subsubsection{Feature Vector}\label{sec:feature_vector}

\subsubsection{Linear Classifier}\label{sec:linear_classifier}

a \emph{Linear Predictor Function} assigns a ``score'' to each possible category
$k$ by taking the Dot Product of the Feature Vector with a Vector of
\emph{Weights}

\begin{itemize}
\item Logistic Regression (\S\ref{sec:logistic_regression})
\item Probit Regression (TODO: xref)
\item Perceptron Algorithm
\item ...
\end{itemize}



\subsubsection{Probabilistic Classification}
\label{sec:probabilistic_classification}

use of Statistical Inference (\S\ref{sec:statistical_inference})



% ====================================================================
\section{Computational Learning Theory}\label{sec:computational_learning_theory}
% ====================================================================

%FIXME start new document ???



% --------------------------------------------------------------------
\subsection{Vapnik-Chervonenkis Theory}\label{sec:vc_theory}
% --------------------------------------------------------------------

\emph{VC Theory}



% ====================================================================
\section{Queueing Theory}\label{sec:queueing_theory}
% ====================================================================

\emph{Little's Law}

1993 - \emph{The Distributional Little's Law and its Applications} - Bertsimas,
Nakazato
