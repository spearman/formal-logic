%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Probability Theory}\label{part:probability_theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\fist Measure Theory (Part \ref{part:measure_theory})

\fist Probabilistic Logic (\S\ref{sec:probabilistic_logic}) --
2013 - \emph{Logic and Probability} -
\url{https://plato.stanford.edu/entries/logic-probability/} (Stanford
Encyclopedia of Philosophy)

\fist cf. Inductive Logic (\S\ref{sec:inductive_inference}) -- makes extensive
use of Probabilistic notions

\emph{Bayesian Epistemology}: Probability as a formal representation of Belief
(cf. Bayesian Inference \S\ref{sec:bayesian_inference})

\emph{Knowledge Representation}: Probability in Artificial Intelligence

\fist cf. Fuzzy Logic (\S\ref{sec:fuzzy_logic})

\fist Possibility Theory (\S\ref{sec:possibility_theory}) -- alternative to
Probability Theory for dealing with certain types of Uncertainty
(\S\ref{sec:uncertainty_analysis})

\fist Decision Theory (\S\ref{sec:decision_theory}) --
(wiki): Probabilistic Decision Theory is Sensitive
(\S\ref{sec:sensitivity_analysis}) to \emph{Assumptions} about Probabilities of
Events; Non-probabilistic Decision Rules (\S\ref{sec:decision_rule}), such as
Minimax (\S\ref{sec:minimax}), are \emph{Robust} (\S\ref{sec:robust_statistic})
in that they don't make such Assumptions (FIXME: clarify)

2018 - \emph{A Categorical Look at Random Variables} -
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html}
(article):

$\cat{Prob}$ -- Category with Objects as Probability Spaces
(\S\ref{sec:probability_space}) and Morphisms are ``Almost-everywhere-equality
Equivalence Classes'' of Measure-preserving Maps

``Probability Theory is \emph{not} about the Category $\cat{Prob}$, in the sense
that Group Theory or Topology might be said (however incompletely) to be about
the Categories $\cat{Grp}$ or $\cat{Top}$''

\emph{Isomorphic Objects} in $\cat{Prob}$ are \emph{not} the same from the point
of view of \emph{Probability Theory}

example: the Distributions (\S\ref{sec:probability_distribution}) of a Uniform
Random Variable in an Interval, an Infinite Sequence of independent ``coin
flips'', and Brownian Motion $\{B_t : t \geq 0\}$ are \emph{different} things in
Probability Theory, but are Isomorphic in $\cat{Prob}$

the fundamental ``objects'' in Probability Theory are the Morphisms of
$\cat{Prob}$ and those Morphisms are \emph{Random Variables}
(\S\ref{sec:random_variable})

\fist Giry Monads (Probability Monads \S\ref{sec:probability_monad})

\asterism

1933 - Kolmogorov - \emph{Foundations of the Theory of Probability}

\emph{Field of Probabilities} (\emph{$\sigma$-algebra}
\S\ref{sec:sigma_algebra})

\asterism

2003 - Jaynes - \emph{Probability Theory: The Logic of Science}



% ==============================================================================
\section{Experiment}\label{sec:experiment}
% ==============================================================================

(wiki): any ``procedure'' that can be infinitely repeated and has a well-defined
Set of possible \emph{Outcomes} (\S\ref{sec:outcome})

when an Experiment is ``performed'' (or ``conducted'') one and only one possible
Outcome ``results'', and any Events (\S\ref{sec:probability_event}), i.e.
Subsets of the Sample Space, containing that Outcome are said to have
``occurred''

a \emph{Random Experiment} has more than one possible Outcome; a Random
Experiment with exactly two possible (Mutually Exclusive) outcomes is called a
\emph{Binomial (Bernoulli) Trial} (\S\ref{sec:binomial_trial})

a \emph{Deterministic Experiment} has only a single possible Outcome

a number of repetitions of an Experiment is called a \emph{Composed Experiment},
and the individual repetitions are called ``\emph{Trials}'' (\S\ref{sec:trial})

after conducting many Trials of the same Experiment, the \emph{Relative
  Frequency} (Empirical Probability \S\ref{sec:relative_frequency}) of the
various Outcomes and Events can be assessed

\fist cf. Experimental Unit (Unit of Observation \S\ref{sec:observational_unit})
-- one Member of a Set of objects that are initially equivalent until each
object is subjected to an ``Exprimental Treatment''

\fist cf. Data Collection (Data Generating Process
\S\ref{sec:data_generating_process})

\fist cf. Replication (Sampling \S\ref{sec:replication})

\asterism


McCullagh02:

each \emph{Statistical Experiment} or ``Observational Study'' is built from:
\begin{enumerate}
  \item a Set $U$ of \emph{Statistical Units} (\S\ref{sec:statistical_unit})
  \item a \emph{Covariate Space} $\Omega$
  \item a \emph{Response Scale} $V$
\end{enumerate}



% ------------------------------------------------------------------------------
\subsection{Trial}\label{sec:trial}
% ------------------------------------------------------------------------------

an individual repetition of a Composed Experiment



\subsubsection{Binomial Trial}\label{sec:binomial_trial}

or \emph{Bernoulli Trial}

Binomial Distribution (\S\ref{sec:binomial_distribution}); special case:
Bernoulli Distribution (\S\ref{sec:bernoulli_distribution})

Mathematical Formalization: Bernoulli Process (\S\ref{sec:bernoulli_process})

\begin{enumerate}
  \item repeated Trials
  \item each Trial results in an Outcome
  \item Probability of Success is Constant
  \item each Trial is Independent
\end{enumerate}

Number of Successes in $n$ Bernoulli Trials is a \emph{Binomial Random
  Variable} (\S\ref{sec:binomial_variable})

\fist Statistical Odds (\S\ref{sec:odds}) -- Ratio of the Probability that an
Event will occur versus the Probability that it will not occur, i.e. a Binomial
Trial



% ------------------------------------------------------------------------------
\subsection{Outcome}\label{sec:outcome}
% ------------------------------------------------------------------------------

a possible result of an Experiment (or Trial)

a Subset of Outcomes in a Sample Space is called an \emph{Event}
(\S\ref{sec:probability_event})

if an actual Outcome is inside an Event, the Event is said to have
``\emph{occurred}''

\fist cf. \emph{Observation} (or \emph{Realization} \S\ref{sec:observation}):
the ``Outcome'' of a \emph{Random Variable} (\S\ref{sec:random_variable}) or
\emph{Random Process} (\S\ref{sec:stochastic_process}), i.e. the Member of the
Random Variable's State Space corresponding to an Outcome which occurred in the
Sample Space of a performed Experiment

\fist note sometimes ``\emph{Outcome}'' is used to refer to a Response Variable
(Regressor \S\ref{sec:regression_analysis}) or Classification Category
(\S\ref{sec:classification}) to be Predicted



% ------------------------------------------------------------------------------
\subsection{Sample Space}\label{sec:sample_space}
% ------------------------------------------------------------------------------

a.k.a. \emph{Possibility Space} or \emph{Event Space}

Set of all possible Outcomes of Statistical \emph{Experiment}
(\S\ref{sec:experiment})

$S$

an \emph{Event} (\S\ref{sec:probability_event}) is a Subset of a Sample Space

the Probability (\S\ref{sec:probability}) $P$ of an Event $E$ is usually defined
such that $P$ satisfies the Kolmogorov Axioms (\S\ref{sec:probability_axioms})
\fist \emph{Unit Measure Axiom}: the total Probability of the Sample Space is
$1 = P(S)$

Random Variable (\S\ref{sec:random_variable}): Function on a Sample Space to a
Measurable \emph{State Space}

a Statistical Model (\S\ref{sec:statistical_model}) $(S,\mathcal{P})$ is a
Sample Space $S$ together with a Set of Probability Distributions
(\S\ref{sec:probability_distribution}) $\mathcal{P}$ on $S$

\fist cf. \emph{Sample} (\S\ref{sec:sample}) -- a Subset of a Population
(\S\ref{sec:population})



% ------------------------------------------------------------------------------
\subsection{Event}\label{sec:probability_event}
% ------------------------------------------------------------------------------

Subset of a Sample Space (\S\ref{sec:sample_space})

if an actual Outcome is inside an Event (Subset), the Event is said to have
``\emph{occurred}''

\emph{Probability} (\S\ref{sec:probability})

(Kolmogorov33) analogy between the \emph{Measure} (\S\ref{sec:measure}) of a Set
and the Probability of an Event

(FIXME: cf. Observation \S\ref{sec:observation})

The \emph{Information Content} (\emph{Self-information} or \emph{Surprisal}
\S\ref{sec:information_content}) of a Sampled (\S\ref{sec:sample}) Random
Variable or Signal (\S\ref{sec:signal}) is the amount of Information
(\S\ref{sec:information}) ``gained'' by the Sample; this Information Content is
a Random Variable defined for any Event as the Negative Log-probability
(\S\ref{sec:log_probability}) of the Vent, regardless of whether a Random
Variable is being measured or not. (wiki)



\subsubsection{Elementary Event}\label{sec:elementary_event}

or \emph{Atomic Event} or \emph{Simple Event} is an Event which contains only a
\emph{single Outcome} in the Sample Space, i.e. it is a Singleton Subset of the
Sample Space

cf. Atom (\S\ref{sec:atom})

the Unitarity Axiom (\S\ref{sec:probability_axioms}) states that the
Probability that at least one of the Elementary Events in the Entire Sample
Space will Occur is $1$



\subsubsection{Mutually Exclusive Event}\label{sec:mutually_exclusive}

$\sigma$-additivity Axiom (\S\ref{sec:probability_axioms}): the Probability of
a Countable Sequence of Disjoint Sets is equal to the Sum of the individual
Probabilities

a Quasiprobability Distribution (\S\ref{sec:quasiprobability_distribution})
violates the $\sigma$-additivity Axiom by not representing Probabilities of
Mutually Exclusive States



\subsubsection{Independent Event}\label{sec:independent_event}

\fist cf. Independence (\S\ref{sec:independence})

Independent if and only if $P(A \cap B) = P(A) P(B)$, or in terms of Conditional
Probability (\S\ref{sec:conditional_probability}), $A$ and $B$ are Independent
if and only if $P(A|B) = P(A)$ or $P(B|A) = P(B)$

\fist two Events are Independent if and only if their Odds Ratio
(\S\ref{sec:odds_ratio}) equals $1$

an Event is Self-independent if and only if $P(A) = 0$ or $P(A) = 1$

$n$ Events are Independent if:
\[
  P(A_i \cap A_j \cap \cdots \cap A_g) = P(A_i)P(A_j) \cdots P(A_g)
\]
for any distinct Events $i,j,\ldots,g$

Pairwise Independence does not imply $n$-way Independence

$P(A \cap B | C) = P(A|C)P(B|C)$

\fist Conditional Independence (\S\ref{sec:conditional_independence})

note that two Events may be Independent, but not \emph{Conditionally}
Independent, i.e. the Intersection of each Independent Event $A$ and $B$ with
the Conditioning Event $C$ may be Disjoint, making them \emph{Dependent}



% ------------------------------------------------------------------------------
\subsection{Experimental Design}\label{sec:experimental_design}
% ------------------------------------------------------------------------------

%FIXME: move this section ???

Fisher 1926, 1935

\emph{Design of Experiments}

Treatment Effects

Variety Effects

Block Effects



% ==============================================================================
\section{Probability}\label{sec:probability}
% ==============================================================================

Probability of an Event (\S\ref{sec:probability_event}) $A$, $P(A)$ is the Sum
of Weights of all Sample Points in $A$

the Probability $P$ of an Event $E$ is usually defined such that $P$ satisfies
the Kolmogorov Axioms (\S\ref{sec:probability_axioms})

(Kolmogorov33) analogy between the \emph{Measure} (\S\ref{sec:measure}) of a Set
and the Probability of an Event

cf. Uncertainty (\S\ref{sec:uncertainty})

cf. \emph{Likelihood} (\S\ref{sec:likelihood}) -- a Probability refers to
variable ``Sample Data'' (\S\ref{sec:sample}) for a fixed Hypothesis
(\S\ref{sec:hypothesis_testing}), while a Likelihood refers to variable
Hypotheses for fixed Data

$\frac{|A|}{|S|}$

$P(A \cup B) = P(A) + P(B) - P(A \cap B)$

$P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) -
P(B \cap C) + P(A \cap B \cap C)$

Corollary: for Disjoint $A_1, A_2, \ldots$:
\[
  P(A_1 \cup A_2 \cup \ldots) = P(A_1) + P(A_2) + \ldots
\]

$P(A_1 \cap A_2 \cap \ldots \cap A_k) = P(A_1) P(A_2 | A_1) P(A_3 |
A_1 \cap A_2) \ldots P(A_k | A_1 \cap A_2 \cap \ldots \cap A_{k-1})$

\textbf{(Thm.) Continuity of Probabilities} \emph{If $A_n \to A$, then:}
\[
  P(A_n) \to P(A)
\]
\emph{as $n \to \infty$}.

cf. \emph{Probability Measure} (\S\ref{sec:probability_measure}),
\emph{Probability Measure Function} (\S\ref{sec:probability_measure_function})

\fist Algorithmic Probability (\S\ref{sec:algorithmic_probability})

(wiki):

two broad categories of \emph{Probability Interpretations}:
\begin{enumerate}
  \item \emph{Physical Probabilities} -- ``Objective'' or \emph{Frequency
    Probabilities} associated with ``Random'' Physical Systems
    \begin{enumerate}
      \item \emph{Frequentist Probability} (``Long-run Probability'') -- defines
        an Event's (\S\ref{sec:probability_event}) Probability as the Limit of
        its Relative Frequency (Empirical Probability
        \S\ref{sec:relative_frequency}) in a large number of Trials
        (\S\ref{sec:trial}); cf. Frequentist Inference
        (\S\ref{sec:frequentist_inference})
      \item \emph{Propensity Probability} (``Single-case Probability'') -- a
        Propensity (\S\ref{sec:propensity}) is not a Relative Frequency but a
        purported ``\emph{cause}'' or explanation of the observed stable
        Relative Frequencies; invokes the Law of Large Numbers
        (\S\ref{sec:large_numbers}) to explain stable \emph{long-run}
        Frequencies as a manifestation of invariant \emph{single-case}
        Probabilities
    \end{enumerate}
  \item \emph{Evidential Probabilities} -- \emph{Bayesian Probability};
    interpretation of Probability as ``reasonable'' \emph{Expectation}
    (\S\ref{sec:expected_value}) or ``degree of belief''; assigns Probability to
    Statements even when no Random Process (\S\ref{sec:stochastic_process}) is
    involved; assigns Probability to Hypotheses (\S\ref{sec:hypothesis}), unlike
    Frequentist Inference which Tests Hypotheses without assigning Probability
    \begin{enumerate}
      \item \emph{Classical Interpretation}
      \item \emph{Subjective Interpretation}
      \item \emph{Inductive (Epistemic) Interpretation}
      \item \emph{Logical Interpretation} -- Cox's Theorem
      \item \emph{Intersubjective Interpretation}
    \end{enumerate}
\end{enumerate}

2011 - \emph{Interpretations of Probability} -
\url{https://plato.stanford.edu/entries/probability-interpret/}:
\begin{itemize}
  \item \emph{Classical Probability} (Laplace) -- Probability shared equally
    among ``possible outcomes'' (cf. Keynes ``Principle of Indifference'');
    issues include Infinite Probability Spaces and the elimination of
    Irrational-valued Probabilities; extension to Countable Infinities by
    generalizing the Principle of Indifference to the ``Principle of Maximum
    Entropy'' (Jaynes)-- select from the family of all Probability Functions
    consistent with evidence the Function that maximizes Entropy; for
    difficulties with Uncountable Infinities cf. the \emph{Bertrand Paradox}--
    Probabilities may not be Well-defined if the method that produces the Random
    Variable is not Well-defined, cf. \emph{Invariance Condition} (Jaynes): two
    problems with the same evidence should assign the same Probabilities
  \item \emph{Logical Probability} (``Non-deductive Logic''
    \S\ref{sec:probabilistic_logic}) -- generalizes Classical Interpretation to
    assigning unequal weights to possibilities, and Probabilities may be
    computed from asymmetric evidence; generalizes Deductive Logic and its
    notion of Implication to a complete theory of Inference with a notion of
    ``\emph{Degree of Implication}'' that relates Evidence to Hypotheses;
    Deductive Logic is the case where the Confirmation Function takes values 0
    and 1; Carnap-- choice of Language and Confirmation Function are in a sense
    arbitrary
  \item \emph{Subjective Probability} (``Subjective Bayesianism'', cf.
    Subjective Logic \S\ref{sec:subjective_logic}) --
    Probability as a \emph{degree of ``belief''}, cf. Doxastic Logic
    (\S\ref{sec:doxastic_logic}); betting analysis (de Finetti): ``operational''
    definition of Probability as a measurement of belief as a basis of action
    (Ramsey); Utilities (``desirabilities'') of outcomes, Probabilities of
    outcomes, and ``rational Preferences'' can be derived from one another in
    different ways-- (Ramsey26) derives Utilities and Probabilities from
    Preferences alone (``Logic of Partial Belief''); see also ``Expected Utility
    Representation'' (Savage54, Jeffrey66) ``Decision Theory''
    (\S\ref{sec:decision_theory}) in which ``rational choice'' maximizes
    Expected Utility;
    these accounts presuppose a connection between ``desire-like states'' and
    ``belief-like states'' rendered explicit in the connections between
    Preferences and Probabilities;
    \emph{Orthodox Bayesianism}, Conditioning (\S\ref{sec:conditioning});
    compare also Probabilistic Coherence (Regularity)--only \emph{a priori}
    falsehoods are assigned Probability 0--to Consistency in ordinary Doxastic
    Logic; cf. Moore's Paradox
  \item \emph{Frequency Interpretations} -- Relative Frequency (Empirical
    Probability \S\ref{sec:relative_frequency}); identifies the Probability of
    an Outcome with the Frequency of the Outcome in a suitable Sequence of
    ``trials''; differs from the Classical Interpretation in counting only the
    \emph{actual} Outcomes instead of the \emph{possible} Outcomes; Finite
    Frequentism (Venn)-- dominant view in Statistics; problems handling
    single-cases and ``unrepeatable'' events; Hypothetical Frequentism:
    extension of Relative Frequencies of an actual Sequence of ``Trials'' to
    counterfactual, limiting Relative Frequencies in case of an Infinite number
    of Trials; Reference Class Problem: Relative Frequencies must be
    ``Relativised'' to a ``Reference Class'' (this problem may exist for other
    interpretations as well)-- solutions restrict to certain Sequences of
    Outcomes, e.g. (Infinite) ``\emph{Collectives}'' (Von Mises57)--cf. Infinite
    Bernoulli Sequences (\S\ref{sec:bernoulli_sequence})--where a
    \emph{Place-selection} is an effective method of selecting indices of
    Members of a Sequence such that the selection or not of Index $i$ depends
    \emph{at most} on the first $i-1$ Outcomes (``attributes''), with the Axioms
    of Convergence (the limiting Relative Frequency of any Outcome exists) and
    Randomness (the limiting Relative Frequency of each Outcome in a Collective
    $\omega$ is the same in any Infinite Subsequence of $\omega$ determined by
    Place-selection; note that trivial Sequences such as $H,H,H,\ldots$ satisfy
    this ``Randomness'' Axiom; cf. the Principle of Maximum Entropy in Classical
    Probability), Algorithmic Randomness (\S\ref{sec:algorithmic_randomness});
    issues with limiting Relative Frequencies are that they violate Countable
    Additivity and the Domain of Definition is not a Set-field or a
    $\sigma$-algebra (de Finetti72)
  \item \emph{Propensity Interpretations} (Pierce10, Popper57) -- Probability as
    a ``physical'' tendency or disposition of a given ``physical situation'' to
    yield an Outcome of a certain kind, or to yield long-run Relative Frequency
    of such an Outcome; motivated by ``single-case'' Probability attributions
    (e.g. radioactive decay); distinction between \emph{long-run} and
    \emph{single-case} Propensities (Gillies00); \emph{Humphreys' Paradox}:
    Propensities as measures of ``causal tendencies'' violates Bayes' Theorem
    which allows the reversal of a Conditional Probability-- cf. alternative
    ``Probabilistic Causal Calculus'' (Fetzer81)
  \item \emph{Best-system Interpretations} (Lewis94) -- a Theory of the
    ``Physical Laws'' of the Universe ``optimally balances'' simplicity,
    strength, and ``fit'' (assigning a higher Probability to the ``actual''
    history of the Universe
\end{itemize}

(\url{https://plato.stanford.edu/entries/logic-probability/}):

Probabilistic Semantics (\S\ref{sec:probabilistic_semantics}) for Logical
Consequence Relation yields \emph{Probability Preserving} (dually,
\emph{Uncertainty Propagating}) Deductive Validity (\S\ref{sec:validity}),
rather than Truth Preserving (\S\ref{sec:truth_preservation})

\emph{Probability, Knowledge, and Meta-probability}:
\url{https://www.lesswrong.com/posts/2xmKZu73gZLDEQw7c/probability-knowledge-and-meta-probability}



% ------------------------------------------------------------------------------
\subsection{Probability Axioms}\label{sec:probability_axioms}
% ------------------------------------------------------------------------------

\emph{Kolmogorov Axioms}

the Probability $P$ of an Event $E$ is usually defined such that $P$ satisfies
the Kolmogorov Axioms

\begin{enumerate}
  \item (\emph{Non-negativity}) The Probability of an Event is a Non-negative
    (Finite) Real Number
  \item (\emph{Unit Measure}) The Probability that at least one of the
    Elementary Events in the entire Sample Space will Occur is $1$
  \item (Countable \emph{$\sigma$-additivity}) Any Countable Sequence of
    Disjoint Sets (Mutually Exclusive Events) $E_1, E_2, \ldots$ satisfies:
    \[
      P (\bigcup_{i=1}^\infty = \sum_{i=1}^\infty P(E_i)
    \]
\end{enumerate}

\fist Unit Measure: cf. \emph{Unitarity} in Physics is used as a synonym for
``Consistency'', esp. the condition that the Hamiltonian is bounded from below,
i.e. there is a State of Minimal Energy (the \emph{Ground State} or
\emph{Vacuum State}), which is needed for the Third Law of Thermodynamics to
hold

the Third Axiom is relaxed in Quasiprobability Distributions
(\S\ref{sec:quasiprobability_distribution}); to compensate sometimes they are
allowed to have regions of Negative Probability
(\S\ref{sec:negative_probability}) Density

\fist cf. Probabilistic Logic (\S\ref{sec:probabilistic_logic})

(wiki): note that Axiomatic Probability Theory avoids definition of a
\emph{Random Sequence} (\S\ref{sec:random_sequence})



% ------------------------------------------------------------------------------
\subsection{Law of Total Probability}\label{sec:total_probability}
% ------------------------------------------------------------------------------

For a Countably Inifinite Partition of a Sample Space
(\S\ref{sec:sample_space}), $\{ B_n : n = 1,2,3,\ldots \}$, with each Event
$B_n$ being Measurable (\S\ref{sec:measure}), then for any Event $A$ in the same
Probability Space (\S\ref{sec:probability_space}):
\[
  P(A) = \sum_n P(A \cap B_n)
\]
or equivalently:
\[
  P(A) = \sum_n P(A|B_n) P(B_n)
\]
where terms such that $P(B_n) = 0$ are omitted from the summation.



% ------------------------------------------------------------------------------
\subsection{Log-probability}\label{sec:log_probability}
% ------------------------------------------------------------------------------

the \emph{Negative} of the Log Probability is the \emph{Information Content}
(\S\ref{sec:information_content}) of an Event (\S\ref{sec:probability_event})

cf. Log-likelihood (\S\ref{sec:log_likelihood})

(wiki): viewing Data as ``evidence'', Log-likelihood is the ``weight'' of
evidence or providing ``\emph{support}'' for a particular Model; the support of
a Model given an Event is the Negative of the Surprisal (Information Content),
i.e. the Log-probability, of the Event given the Model: a Model is supported by
an Event to the extent that the Event is ``\emph{unsurprising}'' given the Model



% ------------------------------------------------------------------------------
\subsection{Conditional Probability}\label{sec:conditional_probability}
% ------------------------------------------------------------------------------

where Event $A$ is known to have occurred:

$P(B|A) = \frac{P(A \cap B)}{P(A)}$ when $P(A) > 0$

$P(A \cap B) = P(A) P(B|A)$ when $P(A) > 0$

$P(A|A) = 1$

note that Conditional Probability is only defined when the Conditioning Event
has a Non-zero (Positive) Probability

$A$ and $B$ are Independent (\S\ref{sec:independent_event}) if and only if
$P(A|B) = P(A)$

General Product Rule (\S\ref{sec:general_product_rule}) -- calculate any member
of the Joint Distribution (\S\ref{sec:joint_probability}) of a Set of Random
Variables using only Conditional Probabilities

\fist Conditioning (\S\ref{sec:conditioning})

\fist Conditional Independence (\S\ref{sec:conditional_independence})

\fist Discriminative Models (Classification \S\ref{sec:discriminative_model})

\fist Negative Probability (\S\ref{sec:negative_probability})

\fist Conditional Event Algebra (\S\ref{sec:conditional_event_algebra})

(Witten18): Quantum Information Theory doesn't have a good analog to defining a
Conditional Probability Distribution as in Classical Information Theory, but
does have an analog of \emph{Strong Subadditivity of Entropy}
(\S\ref{sec:entropy})



% ------------------------------------------------------------------------------
\subsection{Baye's Theorem}\label{sec:bayes_theorem}
% ------------------------------------------------------------------------------

or \emph{Bayes Rule}

\fist Bayes Classifier (\S\ref{sec:bayes_classifier})

\url{https://arbital.com/p/bayes_rule/?l=1zq}

\emph{Bayesian Inference} (\S\ref{sec:bayesian_inference})

\[
  P(A|B) = \frac{P(A)P(B|A)}{P(B)}
\]

for a Partition $A_1, \ldots, A_k$ of $\Omega$ such that $P(A_i) > 0$ for all
$i$, if $P(B) > 0$ then for $i \in \{1, \ldots, k\}$:
\[
  P(A_i|B) = \frac{
    P(B|A_i)P(A_i)
  }{
    \sum_j P(B|A_j)P(A_j)
  }
\]
where $A_i$ is the \emph{Prior Probability} of $A$ and $P(A_i|B)$ is the
\emph{Posterior Probability} of $A$ (FIXME: what is $A$ here ???)

\fist Relative Entropy (Kullback-Leibler Divergence
\S\ref{sec:relative_entropy})



% ------------------------------------------------------------------------------
\subsection{Independence}\label{sec:independence}
% ------------------------------------------------------------------------------

\emph{Property of Probabilistic Independence}

$P(A \cap B) = P(A)P(B)$

for Dependent Events, $P(A) \neq P(A|B)$

two Random Variables (\S\ref{sec:random_variable}) are \emph{Dependent}
(\S\ref{sec:dependence}) if they do not Satisfy the Property of
Probabilistic Independence:
\[
  P(X \in A, Y \in B) = P(X \in A) P(Y \in B)
\]

\fist cf. Independent Event (\S\ref{sec:independent_event}) --
two Events are Independent if and only if their Odds Ratio
(\S\ref{sec:odds_ratio}) equals $1$

if $X$ and $Y$ are Independent and have Finite Second Moments, then they are
Uncorrelated (\S\ref{sec:statistical_correlation}); not all Uncorrelated
Variables are Independent

for Independent Random Variables, $Var(X + Y) = Var(X) + Var(Y)$ and
$Var(X - Y) = Var(X) + Var(Y)$

the Probability Distribution of the Sum of two Independent Random Variables is
the Convolution (\S\ref{sec:convolution}) of their individual Distributions

cf. Binomial Distribution (\S\ref{sec:binomial_distribution}) -- Sum of
Independent Trials; Sampling 10\% Rule (TODO)

Tests for Independence (Wasserman04, Ch.15) %TODO



\subsubsection{Conditional Independence}\label{sec:conditional_independence}

$P(A \cap B | C) = P(A|C)P(B|C)$

note that two Events may be Independent, but not \emph{Conditionally}
Independent, i.e. the Intersection of each Independent Event $A$ and $B$ with
the Conditioning Event $C$ may be Disjoint, making them \emph{Dependent}

\fist cf. Conditional Probability (\S\ref{sec:conditional_probability})

\fist Bayesian Networks (\S\ref{sec:bayes_network});
Markov Condition (\S\ref{sec:markov_condition}) -- every Node is Conditionally
Independent (\S\ref{sec:conditional_independence}) of its Non-descendents, given
its Parents

\fist Pairwise Markov Graph (\S\ref{sec:pairwise_markov}) -- encodes a Set
of Pairwise Conditional Independence Relations

\url{http://lesswrong.com/lw/pi/classical_configuration_spaces/}
-- ``Conditional Independence happens when the Joint Probability Distribution
is the Product of the individual Probability Distributions''



% ------------------------------------------------------------------------------
\subsection{Odds}\label{sec:odds}
% ------------------------------------------------------------------------------

for Probability $p$, the Odds are:
\[
  \frac{p}{1-p}
\]

the Odds can range in $[0, \infty)$

\fist Logit (Log-odds \S\ref{sec:logit}):
\[
  \ln \frac{p}{1-p}
\]
is the Inverse of the Logistic Function (\S\ref{sec:logistic_function}); the
Logistic Function can be used to convert a Log-odds into a Probability

an expression of Relative Probabilities: the Odds \emph{in favor} of an Event or
Proposition is the Ratio of the Probability that the Event will occur to the
Probability that it will not occur, i.e. a \emph{Binomial Trial}
(Bernoulli Trial \S\ref{sec:binomial_trial})



\subsubsection{Odds Ratio}\label{sec:odds_ratio}

Statistic (\S\ref{sec:statistic})

quantifies strength of Association (Dependence \S\ref{sec:dependence}) between
two Events

\fist cf. Risk Ratio (\S\ref{sec:risk_ratio}), Risk Difference
(\S\ref{sec:risk_difference})

two Events are Independent if and only if their Odds Ratio equals $1$

\url{https://www.youtube.com/watch?v=ckkiG-SDuV8}:

in Logistic Regression (\S\ref{sec:logistic_regression}), the Odds Ratio for an
Independent Variable represents how the Odds change with a 1 unit increase in
the Independent Variable, holding all other variables constant



\subsubsection{Log-odds}\label{sec:log_odds}

Logit (Log-odds \S\ref{sec:logit})

\[
  \ln \Big(\frac{p}{1 - p}\Big)
\]

(wiki) --
the difference between the Log-odds of two Probabilities is the Logarithm
of the Odds Ratio (\S\ref{sec:odds_ratio}), $R$:
\[
  logit(p_1) - logit(p_2) = \ln\Big(\frac{p_1/(1 - p_1)}{p_2/(1 - p_2)}\Big)
    = \ln R
\]



\subsubsection{Coherent Odds}\label{sec:coherent_odds}

``Dutch Book'' or ``Lock'' is a Set of Odds which are \emph{not} Coherent, i.e.
``Skewed''



% ------------------------------------------------------------------------------
\subsection{Negative Probability}\label{sec:negative_probability}
% ------------------------------------------------------------------------------

or \emph{Quasiprobability}

may apply to \emph{Unobservable Events} or \emph{Conditional Probability}
(\S\ref{sec:conditional_probability})

forbidden by the First Kolmogorov Axiom (\S\ref{sec:probability_axioms})

the Third Axiom ($\sigma$-additivity) is relaxed in Quasiprobability
Distributions (\S\ref{sec:quasiprobability_distribution}); to compensate
sometimes they are allowed to have regions of Negative Probability Density,
violating the First Law

Wigner Distribution in Phase Space (Quantum Corrections)



% ==============================================================================
\section{Probability Space}\label{sec:probability_space}
% ==============================================================================

$(\Omega, \Sigma, P)$

A \emph{Probability Space} is a Measure Space (\S\ref{sec:measure_space}) with a
\emph{Probability Measure} (\S\ref{sec:probability_measure}).

\fist cf. Measure-preserving Dynamical Systems
(\S\ref{sec:measure_preserving_system})

\fist \emph{Quantum Probability}: classical Probability Theory generalized to
Non-commutative Probability Spaces (\S\ref{sec:quantum_probability_space})

$\cat{Prob}$ -- Category with Objects as Probability Spaces and Morphisms are
``Almost-everywhere-equality Equivalence Classes'' of Measure-preserving Maps
--
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html}:
``Probability Theory is not about the Category $\cat{Prob}$''

$\cat{Prob}$ -- Category with Objects as Probability Spaces and Morphisms are
``Almost-everywhere-equality Equivalence Classes'' of Measure-preserving Maps
(\S\ref{sec:measure_preserving_map})

the fundamental ``objects'' of Probability Theory are the \emph{Morphisms} of
$\cat{Prob}$ and these Morphisms are \emph{Random Variables}
(\S\ref{sec:random_variable})



% ------------------------------------------------------------------------------
\subsection{Probability Measure}\label{sec:probability_measure}
% ------------------------------------------------------------------------------

A \emph{Probability Measure} is a Measure (\S\ref{sec:measure}) that assigns the
Value $1$ to the entire Measure Space (making it a Probability Space).

cf. \emph{Probability} (\S\ref{sec:probability})

\fist any \emph{Probability Distribution} (\S\ref{sec:probability_distribution})
defines a Probability Measure as the Pushforward Measure
(\S\ref{sec:pushforward_measure}) of a Random Variable
(\S\ref{sec:random_variable})

\emph{Choquet Simplex} (\S\ref{sec:choquet_theory}) -- any Point in a Choquet
Simplex is represented by a unique Probability Measure



\subsubsection{Probability Measure Function}
\label{sec:probability_measure_function}

\subsubsection{Kullback-Leibler Divergence}\label{sec:kullback_leibler}

can be used to characterize Relative Entropy (\S\ref{sec:relative_entropy}),
Randomness (\S\ref{sec:statistical_randomness})

defined between PDFs (\S\ref{sec:pdf})

can be used to show Consistency of MLE (\S\ref{sec:mle})



% ==============================================================================
\section{Random Variable}\label{sec:random_variable}
% ==============================================================================

A general \emph{Random Element} is a Measurable Function
(\S\ref{sec:measurable_function}) on a Sample Space (\S\ref{sec:sample_space})
mapping Outcomes (\S\ref{sec:outcome}) in the Sample Space to some other Set of
Values called the \emph{State Space}:
\[
  X : \Omega \to E
\]
The Type (\S\ref{sec:datatype}) of a State Space is called a \emph{Statistical
  Data Type} (\S\ref{sec:statistical_data_type}).

A Realization of a Random Element resulting from a specific Outcome is called an
\emph{Observation} (\S\ref{sec:observation}).

A \emph{Random Variable} is a Random Element where $E = \reals$ is the Real Line
(\S\ref{sec:real_line}).

other types of Random Elements:
\begin{itemize}
  \item Random Measure (\S\ref{sec:random_measure})
  \item ...
\end{itemize}

The \emph{Information Content} (\emph{Self-information} or \emph{Surprisal}
\S\ref{sec:information_content}) of a Sampled (\S\ref{sec:sample}) Random
Variable or Signal (\S\ref{sec:signal}) is the amount of Information
(\S\ref{sec:information}) ``gained'' by the Sample; this Information Content is
a Random Variable defined for any Event (\S\ref{sec:probability_event}) as the
Negative Log-probability (\S\ref{sec:log_probability}) of the Event,
regardless of whether a Random Variable is being measured or not. (wiki)

the Entropy of a Random Variable is the Expected Value of its Information
Content

\fist cf. \emph{Statistical Unit} (\S\ref{sec:statistical_unit}) -- one Member
of a Set of entities being analyzed, providing the ``material source'' for an
abstract Random Variable (wiki)

\fist a \emph{Statistic} (\S\ref{sec:statistic}) is an Observable Random
Variable defined as a Function of a Random Variable constituting a Random Sample
(IID \S\ref{sec:random_sample})

Discrete Random Variable (\S\ref{sec:discrete_random_variable})

Continuous Random Variable (\S\ref{sec:continuous_random_variable})

a \emph{Probability Distribution} (\S\ref{sec:probability_distribution})
is the Pushforward Measure (\S\ref{sec:pushforward_measure}) of $X$

such a distribution records all the individual Probabilities $P(X = x)$,
sometimes written $p_X(x)$

a \emph{Dependence} (Association \S\ref{sec:dependence}) between two Random
Variables (``Bivariate Data'' \S\ref{sec:bivariate_distribution}) is any
``Statistical Relationship'' (which may or may not be Causal)

Wasserman04 Ch.2

two Random Variables $X$ and $Y$ are \emph{Independent}, sometimes denoted
$X \coprod Y$, if they Satisfy the Property of \emph{Probabilistic Independence}
(\S\ref{sec:independence}):
\[
  P(X \in A, Y \in B) = P(X \in A) P(Y \in B)
\]
that is, for every $x$ and $y$, the Events $\{X \leq x\}$ and $\{Y \leq y\}$ are
Independent Events (\S\ref{sec:independent_event}); in terms of CDFs:
\[
  \forall x,y\ F_{X,Y}(x,y) = F_X(x)F_Y(y)
\]
or in terms of Probability Mass or Density Functions (if they exist):
\[
  \forall x,y\ f_{X,Y}(x,y) = f_X(x)f_Y(y)
\]

\textbf{Thm.} \emph{If the Range of Random Variables $X$ and $Y$ is a (possibly
  Infinite) Rectangle and $f_{X,Y}(x,y) = g(x)h(y)$ for arbitrary Functions $g$
  and $h$, then $X$ and $Y$ are Independent.}

\fist Relative Entropy (\S\ref{sec:relative_entropy}), Mutual Information
(\S\ref{sec:mutual_information})

cf. \emph{Statistical Randomness} (\S\ref{sec:statistical_randomness}),
\emph{Algorithmic Randomness} (\S\ref{sec:algorithmic_randomness})

a Discrete Random Variable $Y = r(X)$ that is a Transformation of a Discrete
Random Variable $X$, the Probability Mass Function is given by:
\[
  f_Y(y) = P(Y = y) = P(r(X) = y) = P(X \in r^{-1}(y))
\]
for Continuous Random Variables, the CDF is defined as the Integral of the PDF
$f_X(x)$ over the Set $A_y = \{x : r(x) \leq y\}$:
\[
  F_Y(y) = \int_{A_y} f_X(x) dx
\]
and the PDF can be defined as $f_Y(y) = F_Y'(y)$

for Continuous $X$ with CDF $F_X$, $Y = F_X(X)$ is called a \emph{Probability
  Integral Transform} (\S\ref{sec:probability_integral_transform}) and has a
Standard Uniform Distribution

Laplace Transform (\S\ref{sec:laplace_transform}) of a Random Variable $X$ with
PDF $f$:
\[
  \mathcal{L}\{f\}(s) = \expect(e^{-sX}))
\]
and replacing $s$ by $-t$ gives the Moment-generating Function
(\S\ref{sec:moment_generating_function}) of $X$

\asterism

\emph{A Categorical Look at Random Variables} -
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html}:

$\cat{Prob}$ -- Category with Objects as Probability Spaces
(\S\ref{sec:probability_space}) and Morphisms are ``Almost-everywhere-equality
Equivalence Classes'' of Measure-preserving Maps
(\S\ref{sec:measure_preserving_map})

the fundamental ``objects'' of Probability Theory are the \emph{Morphisms} of
$\cat{Prob}$ and these Morphisms are \emph{Random Variables}

a Random Variable is defined as a Measurable Map
(\S\ref{sec:measurable_function}):
\[
  X : \Omega \to E
\]
where $(\Omega,\mathbb{P})$ is a Probability Space and $E$ is an arbitrary
Measurable Space

\asterism

MIT 6.041SC Lec. 5 - \url{https://www.youtube.com/watch?v=3MOahpLxj6A}:

Functions of Random Variables are also Random Variables

Probability Mass Function (\S\ref{sec:pmf}) $p_X$ assigns
Probabilities to Elements of $x \in E$:
\[
  p_X(x) = P(X = x)
\]

$p_X(x) \geq 1$

$\sum_x p_X(x) = 1$

Expected Value (\S\ref{sec:expected_value}) of a Random Variable is a kind of
``average'' where Probabilities are treated like ``frequencies'':
\[
  E[X] = \sum_x xp_X(x)
\]
for a Function of a Random Variable $Y = g(X)$:
\[
  E[Y] = \sum_x g(x)p_X(x)
\]

for a PMF that is Symmetric around a certain point, that point is the Expected
Value



% ------------------------------------------------------------------------------
\subsection{Observation}\label{sec:observation}
% ------------------------------------------------------------------------------

An \emph{Observation} (\emph{Observed Value}, \emph{Measurement},
\emph{Realization}, or \emph{Random Variate}) is the Element of a Random
Variable's State Space corresponding to the actual Outcome (\S\ref{sec:outcome})
resulting from performing an Experiment (\S\ref{sec:experiment}).

in Statistics, it is commonly assumed that Observations are \emph{Independent
  and Identifcally Distributed} (\emph{IID} \S\ref{sec:iid})

\fist A \emph{Data Generating Process} (\S\ref{sec:data_generating_process})
is a possibly unspecified \emph{Probabilistic (Statistical) Model}
(\S\ref{sec:statistical_model}) governing the ``Generation'' of Observed Data.
The \emph{Level of Measurement} (\S\ref{sec:measurement_level}) is a
classification of the \emph{Statistical Data Type}
(\S\ref{sec:statistical_data_type}) of a State Space.

\fist A \emph{(Statistical) Population} (\S\ref{sec:population}) is a totality
of Observations. A \emph{Statistical Sample} (\S\ref{sec:sample}) is
a Subset of a Population selected by a definite \emph{Sampling Procedure}
(\S\ref{sec:sampling}). A \emph{``Data Point''} is an Observation of a
\emph{Statistical Unit} (\S\ref{sec:statistical_unit}) in the Statistical
Sample. A \emph{Statistic} (\S\ref{sec:statistic}) is an Observable Random
Variable defined as a Function of a Random Variable constituting a Random
Sample.

\fist \emph{Statistical Inference} (\S\ref{sec:inferential_statistics}) is the
use of Sample Data to \emph{Infer} (cf. Logical Inference
\S\ref{sec:logical_inference}, Inference Rules \S\ref{sec:inference_rule}) the
Distribution (\S\ref{sec:probability_distribution}) that \emph{Generated}
(\S\ref{sec:data_generating_process}) the Data.

\fist \emph{Observational Error} (\emph{Measurement Error}
\S\ref{sec:observational_error}) is the
difference between an Observed Value (Random Variate) and the ``true'' Value;
a \emph{Statistical Error} (\S\ref{sec:error}) is the difference between an
Observed Value and its \emph{Expected Value};
the \emph{Residual} (\S\ref{sec:residual}) of an Observed Value is the
difference between the Observed Value and the \emph{Estimated}
(\S\ref{sec:estimation_theory}) Value

\fist Multivariate Statistics (\S\ref{sec:multivariate_statistics}) --
\emph{simultaneous} Observation and Analysis of more than one Outcome Variable
(Random Vector \S\ref{sec:random_vector})

\fist Curve Fitting (\S\ref{sec:curve_fitting}), Regression Analysis
(\S\ref{sec:regression_analysis}): the process of constructing a Curve (or
Function) that has the ``best Fit'' to a Series of Data Points (Observations),
possibly subject to constraints

\fist cf. \emph{Observable} (\S\ref{sec:observable})



\subsubsection{Deviation}\label{sec:deviation}

A \emph{Deviation} is a Signed Difference (\S\ref{sec:subtraction}) between an
Observation and some other value, usually the Observed Random Variable's Mean
(Expected Value \S\ref{sec:expected_value}).

\begin{itemize}
  \item the \emph{Sampling Deviation} (\S\ref{sec:sampling_deviation}) is the
    difference between an Estimate on a Sample (Statistic) and the Expected
    Value of the Estimator
  \item an \emph{Error} (\S\ref{sec:error}) is a Deviation of an Observed value
    and an ideal (possibly theoretical) ``true'' value, e.g. Deviation from a
    Population Mean
  \item a \emph{Residual} (\S\ref{sec:residual}) is a Deviation of an Observed
    value from an \emph{Estimate} (\S\ref{sec:estimation_theory}) of a ``true''
    value, e.g. Deviation from a Sample Mean
\end{itemize}

\emph{Statistical Dispersion} (or ``Variability'' \S\ref{sec:dispersion}) is
measured by Population Parameters or Sample Statistics defined on the
\emph{Distribution of Deviations}:
\begin{itemize}
  \item Variation Ratio (Qualitative Variation, Deviation from the Mode
    \S\ref{sec:variation_ratio}) -- proportion of cases that are \emph{not} in
    the Mode (\S\ref{sec:mode})
  \item Mean Absolute Deviation (MAD \S\ref{sec:mad}) -- average of Absolute
    Deviations (\S\ref{sec:absolute_deviation}); the Median (\S\ref{sec:median})
    minimizes the MAD
  \item Standard Deviation (\S\ref{sec:standard_deviation}) -- average of
    Squared Deviations (\S\ref{sec:squared_deviation}); the Mean
    (\S\ref{sec:mean}) minimizes the Standard Deviation
  \item Maximum Absolute Deviation (\S\ref{sec:maximum_absolute_deviation}) --
    maximum of Absolute Deviations around a point; the Mid-range
    (\S\ref{sec:midrange}) minimizes the Maximum Absolute Deviation
\end{itemize}

see also:
\begin{itemize}
  \item Regression Error (\S\ref{sec:regression_error}) -- Deviation of a value
    Predicted by an Estimated Regression Function from the value Predicted by
    the ``true'' Prediction Function
  \item Regression Residual (\S\ref{sec:regression_residual}) -- Deviation of an
    Observed value from the value Predicted by an Estimated Regression Function
  \item Mean Signed Deviation (\S\ref{sec:mean_signed_deviation}) -- Average
    of Signed Error of the Estimated value (produced by an Estimator) from the
    ``true''  value
  \item Mean Squared Deviation (MSD \S\ref{sec:msd}) -- Average of the Squared
    Error of the Estimated value (produced by an Estimator) from the ``true''
    value; MSD is the Second Moment of the Error; for an Unbiased Estimator the
    MSD is the Variance of the Estimator
  \item Root-Mean-Square Deviation (RMSD \S\ref{sec:rmsd}) -- Square Root of the
    MSD (cf. Standard Deviation)
  \item Standard Error (\S\ref{sec:standard_error}) -- the Standard Deviation of
    a Sampling Distribution
  \item Mean Absolute Difference (\S\ref{sec:mean_absolute_difference}) --
    Average Absolute Difference of two IID Random Variables
  \item Mean Absolute Error (MAE \S\ref{sec:mae}) -- Average Absolute Difference
    between two Continuous Random Variables, i.e. the Average Vertical or
    Horizontal Difference between each Point (Pair) and the Identity Line
\end{itemize}



\paragraph{Absolute Deviation}\label{sec:absolute_deviation}\hfill

Absolute Error, Absolute Residual

\fist Mean Absolute Deviation (MAD \S\ref{sec:mad}) -- measure of Dispersion
(\S\ref{sec:dispersion}) associated with the $L^1$ Metric (Taxicab Norm
\S\ref{sec:p_norm}); corresponding Central Tendency
(\S\ref{sec:central_tendency}) is the Median (\S\ref{sec:median})

\fist Maximum Absolute Deviation (\S\ref{sec:maximum_absolute_deviation}) --
measure of Dispersion associated with the $L^{\infty}$ Metric (Max Norm
\S\ref{sec:p_norm}); corresponding Central Tendency is the Midrange
(\S\ref{sec:midrange})



\paragraph{Squared Deviation}\label{sec:squared_deviation}\hfill

\fist Variance (\S\ref{sec:variance}) is the Expected Value of the Squared
Deviation from the Mean (SDM \S\ref{sec:sdm})

\fist Loss Function for Regression (\S\ref{sec:regression_analysis}); cf.
Categorical Cross-entropy Loss Function for Classification

\begin{itemize}
  \item Sum of Squared Deviations (\S\ref{sec:sum_squared_deviation})
    \begin{itemize}
      \item Total Sum of Squares (\S\ref{sec:tss})
      \item Sum of Squared Residuals (\S\ref{sec:ssr})
      \item Explained Sum of Squares (\S\ref{sec:ess})
    \end{itemize}
  \item Mean Squared Deviation (MSD \S\ref{sec:msd})
  \item Squared Deviation from the Mean (\S\ref{sec:sdm})
\end{itemize}



\subsubsection{Observational Transformation}
\label{sec:observational_transformation}

(Mandelbrot97, Ch.3)

Mandelbrot 1963

\begin{itemize}
  \item Linear Aggregation -- simple addition of quantities in their ``common
    natural scale''; Central Limit Theorem (\S\ref{sec:central_limit}); cf.
    Autoregressive (\S\ref{sec:autoregressive_model}) schemes, Stable
    Distributions (\S\ref{sec:stable_distribution})
  \item Weighted Mixture -- Data Randomly Sampled from among a Set of possible
    basic Distributions
  \item Maximizing Choice -- selection of largest or smallest quantity in a Set
  \item ...
\end{itemize}

Invariances with respect to Observational Transformations

cf.:
\begin{itemize}
  \item Stable Distributions (\S\ref{sec:stable_distribution})
  \item Weak Scaling Distributions (\S\ref{sec:scaling_distribution}) --
    Invariance up to Scale holds \emph{Asymptotically} under Linear Aggregation,
    Weighted Mixture, and Maximizing Choice, as long as the ``parts'' themselves
    are Asymptotically Scaling
  \item Exponential Distributions (\S\ref{sec:exponential_distributions}) --
    Invariant under change of Location
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Expected Value}\label{sec:expected_value}
% ------------------------------------------------------------------------------

The \emph{Expected Value}, \emph{Expectation}, or \emph{Mean} (First Raw Moment
\S\ref{sec:moment}/Cumulant \S\ref{sec:cumulant}) of a Random Variable is a kind
of ``average'' where Probabilities are treated like ``frequencies''. (FIXME:
clarify)

\fist Mean (\S\ref{sec:mean}) -- Central Tendency (\S\ref{sec:central_tendency})
for Interval Measurement (\S\ref{sec:measurement_level}); associated with
minimizing the Standard Deviation (\S\ref{sec:standard_deviation}); cf. the
Median minimizes Absolute Deviation (\S\ref{sec:absolute_deviation})

as an Estimate (\S\ref{sec:estimation_theory}) of $X$, the Expected Value $E[X]$
minimizes Squared Error (\S\ref{sec:error})

note that $E(X + Y) = E(X) + E(Y)$, but not for $m(X+Y)$

\fist Sample Mean (Estimator \S\ref{sec:sample_mean}) -- minimizes Squares of
the Residuals;
by the Law of Large Numbers (\S\ref{sec:large_numbers}), the Arithmetic Mean
Converges to the Expected Value as the Sample Size gets larger

\fist Risk (\S\ref{sec:risk}) -- Expected Loss

(Kolmogorov33) analogy between the \emph{Expectation} of a Random Variable, and
\emph{Lebesgue Integration} (\S\ref{sec:lebesgue_integral})

For a Random Variable $X$ defined on Probability Space $(\Omega,\Sigma,P)$, the
Expected Value $\mu_X = E[X]$ of $X$ is defined as the Lebesgue Integral:
\[
  \mu_X = E[X] = \int_\Omega X(\omega) dP(\omega)
\]

In terms of the Cumulative Distribution Function (\S\ref{sec:cdf}) $F_X$ of $X$
and a Radon Integral (\S\ref{sec:radon_integral}):
\[
  \mu_X = E[X] = \int\limits_{-\infty}^{\infty} x dF_X(x)
\]

For Discrete Random Variable $X$ with Probability Mass Function
(\S\ref{sec:pmf}) $f_X(x)$, the Expected Value of $X$ is:
\[
  E[X] = \sum_x x f_X(x)
\]
For a PMF that is Symmetric around a certain point, that point is the Expected
Value.

For a Continuous Random Variable $X$ with Probability Density Function
(\S\ref{sec:pdf}) $f_X(x)$, the Expected Value of $X$ is:
\[
  E[X] = \int x f(x) dx
\]

note that some Distributions have no Expected Value, e.g. the Cauchy
Distribution (\S\ref{sec:cauchy_distribution})

for Linear Function $g$:
\[
  E[g(X)] = g(E[X])
\]

Expectations of Constants (i.e. as ``degenerate'' Random Variables) are just
the Constants themselves: $E[a] = a$

Expectations of Random Variables multiplied by Constant is the Constant
multiplied by the Expectation of the Random Variable:
\[
  E[aX] = aE[X]
\]

Expectation of a Random Variable with the addition of a Constant is the
Constant added to the Expectation of the Random Variable:
\[
  E[X + b] = E[X] + b
\]

for a Function of a Random Variable $Y = g(X)$:
\[
  E[Y] = \sum_x g(x) p_X(x)
\]
%FIXME: is this only for discrete random variables ???

For Random Variable $X$ with Probability Density Function $f(x)$, the
Expected Value of a Measurable Function
(\S\ref{sec:measurable_function}) of $X$, $g(X)$, is:
\[
  \mu_{g(X)} = E[g(X)] = \int\limits_{-\infty}^{\infty} g(x) f(x) dx
\]

For Joint Probability Density Function:
\[
  E[X Y] = \int\int x y j(x,y) dx dy
\]
\fist Note that $E[X Y]$ is not necessarily equal to $E[X] E[Y]$, see Covariance
(\S\ref{sec:covariance}).

For $X$ and $Y$ Independent (\S\ref{sec:independence}), $E[X,Y] = E[X] E[Y]$

If $a$ and $b$ are Constants, then $E[aX + b] = a E[X] + b$

$E [g(X) \pm h(X)] = E[g(X)] \pm E[h(X)]$

$E [g(X,Y) \pm h(X,Y)] = E[g(X,Y)] \pm E[h(X,Y)]$

Wasserman04 Ch.3

\textbf{Thm.} for $X_1, \ldots, X_n$ Random Variables and $a_1, \ldots, a_n$
Constants:
\[
  E\Big(\sum_i a_i X_i\Big) = \sum_i a_i E(X_i)
\]

\textbf{Thm.} for $X_1, \ldots, X_n$ Independent Random Variables:
\[
  E\Big(\prod_{i=1}^n X_i\Big) = \prod_i E(X_i)
\]

\emph{Conditional Expectation} -- $E(X|Y)$ is a Random Variable whose Value is
$E(X|Y = y)$ when $Y = y$

\textbf{Thm.} (Rule of Iterated Expectations) \emph{
  For Random Variables $X$ and $Y$, assuming Expectations exist, then:
  \[
    E(E(Y|X)) = E(Y) \quad\quad E(E(X|Y)) = E(X)
  \]
  or generally for any Function $r(x,y)$:
  \[
    E(E(r(X,Y)|X)) = E(r(X,Y))
  \]
}

Moment-generating Function (\S\ref{sec:moment_generating_function}):
$M_X(t) := E(e^{tX})$ for $t \in \reals$

the Variance (Expected Value of the Squared Deviation \S\ref{sec:deviation}) of
a Random Variable $X$ is equal to:
\begin{align*}
  \sigma^2 = V(X) & = E(X - E(X))^2   \\
                  & = E(X^2) - E(X)^2 \\
                  & = \int(x - E(X))^2 dF(x) \\
\end{align*}
assuming the Expectation exists

$V(Y) = E(V(Y|X)) + V(E(Y|X))$

\textbf{Thm.} \emph{Covariance (\S\ref{sec:covariance}) Satisfies:
  \[
    Cov(X,Y) = E(XY) - E(X)E(Y)
  \]
}

example of Probability as a special case of Expectation (Wasserman Ch. 3): for
Event $A$ with Indicator Function $I_A(x)$:
\[
  E(I_A(X)) = \int I_A(x)f_X(x)dx = \int_A f_X(x) dx = P(X \in A)
\]

the \emph{$k^{th}$ Moment} (\S\ref{sec:moment}) of $X$ is defined as $E(X^k)$
assuming that $E(|X|^k) < \infty$

\emph{Cauchy-Schwarz Inequality} (\S\ref{sec:cauchy_schwarz}):
\[
  E|XY|^2 \leq \sqrt{E(X^2)E(Y^2)}
\]
where $X$ and $Y$ have Finite Variances

\textbf{Thm.} (Jensen's Inequality) \emph{
  If $g$ is a Convex Function, then:
  \[
    E(g(X)) \geq g(E(X))
  \]
  and if $g$ is Concave, then:
  \[
    E(g(X)) \leq g(E(X))
  \]
}
examples: $E(X^2) \geq E(X)^2$; if $X$ is Positive, then $E(1/X) \geq 1/E(X)$;
since $\log$ is Concave $E(\log X) \leq \log E(X)$



\subsubsection{Law of Large Numbers}\label{sec:large_numbers}

the Sample Mean (\S\ref{sec:sample_mean})
$\overline{X}_n = \frac{1}{n}\sum_i X_i$ of a Sequence of Random Variables
$X_1, \ldots, X_n$ \emph{Converges in Probability}
(\S\ref{sec:stochastic_convergence}) to the Expectation
(\S\ref{sec:expected_value}) $\mu = E(X_i)$ as $n \to \infty$, i.e.
$\overline{X}_n$ is close to $\mu$ with high Probability

\textbf{Thm.} (Weak Law of Large Numbers) \emph{If $X_1, \ldots, X_n$ are IID
  (\S\ref{sec:iid}), then:
  \[
    \overline{X}_n \xrightarrow{P} \mu = E(X_1)
  \]
}
(note that since $X_i$ are IID, $\mu$ is identical for all $X_i$)

\textbf{Thm.} (Strong Law of Large Numbers) \emph{If $X_1, \ldots, X_n$ are IID,
  and $\mu = E(|X_1|) < \infty$, then $\overline{X}_n \xrightarrow{as} \mu$}

\fist cf. Law of Iterated Logarithm (\S\ref{sec:iterated_logarithm})

\fist \emph{Propensity Probability} (``Single-case Probability''
\S\ref{sec:propensity}) -- invokes the Law of Large Numbers to explain stable
\emph{long-run} Relative Frequencies (\S\ref{sec:relative_frequency}) as a
manifestation of invariant \emph{single-case} Probabilities

\fist cf. Asymptotic Theory (Large Sample Theory \S\ref{sec:asymptotic_theory})



\subsubsection{Markov's Inequality}\label{sec:markovs_inequality}

\textbf{Thm.} (Markov's Inequality) \emph{
  Given a Random Variable $X$ with Expectation $E(X)$, for any $t > 0$:
  \[
    P(X > t) \leq \frac{E(X)}{t}
  \]
}



\subsubsection{Conditional Expectation}\label{sec:conditional_expectation}

or \emph{Conditional Mean}

\fist Conditioning (\S\ref{sec:conditioning})

\fist Regression Analysis (\S\ref{sec:regression_analysis}) commonly Estimates
the Conditional Expectation of a Dependent Variable given an Independent
Variable

\fist Probability Monads (\S\ref{sec:probability_monad}): Partial Evaluations
(\S\ref{sec:partial_evaluation}) as Conditional Expectations
(\url{https://golem.ph.utexas.edu/category/2019/05/partial_evaluations.html},
Perrone 2018)



\paragraph{Law of Total Expectation}\label{sec:total_expectation}\hfill

$E(X) = E(E(X | Y))$

MIT 6.041SC, Lec. 6



\subsubsection{Law Of The Unconscious Statistician (LOTUS)}\label{sec:lotus}

calculation of the Expected Value of Function $g(X)$ of a Random Variable $X$
with a known Probability Distribution, but where the Probability Distribution of
$g(X)$ is unknown

Discrete PMF $f_X$:
\[
  \expect(g(X)) = \sum_x g(x) f_X(x)
\]

Continuous PDF $f_X$:
\[
  \expect(g(X)) = \int_{-\infty}^\infty g(x) f_X(x) \diffy{x}
\]

Continuous CDF $F_X$ (Real-valued $X$):
\[
  \expect(g(X)) = \int_{-\infty}^\infty g(x) \diffy{F_X(x)}
\]
(Riemann-Stieltjes Integral \S\ref{sec:riemann_stieltjes})



% ------------------------------------------------------------------------------
\subsection{Moment-generating Function}\label{sec:moment_generating_function}
% ------------------------------------------------------------------------------

$M_X(t) = E(e^{tX}) = \int e^{tx} dF(x)$ for $t \in \reals$

the Cauchy Distribution (\S\ref{sec:cauchy_distribution}) has no
Moment-generating Function

the Cumulant-generating Function (\S\ref{sec:cumulant_generating_function}) is
the Natural Logarithm of the Moment-generating Function

\fist Laplace Transform (\S\ref{sec:laplace_transform})
%FIXME: explain relation

cf. Characteristic Function (\S\ref{sec:characteristic_function}) --
if a Random Variable has a Moment-generating Function then the Characteristic
Function can be extended to the Complex Plane

every Distribution with a Moment-generating Function is a member of a Natural
Exponential Family (\S\ref{sec:nautral_exponential_family})

Laplace Transform (\S\ref{sec:laplace_transform}) of a Random Variable $X$ with
PDF $f$:
\[
  \mathcal{L}\{f\}(s) = \expect(e^{-sX}))
\]
and replacing $s$ by $-t$ gives the Moment-generating Function of $X$



% ------------------------------------------------------------------------------
\subsection{Cumulant-generating Function}
\label{sec:cumulant_generating_function}
% ------------------------------------------------------------------------------

Natural Logarithm of the Moment-generating Function



% ------------------------------------------------------------------------------
\subsection{Characteristic Function}\label{sec:characteristic_function}
% ------------------------------------------------------------------------------

for a Scalar Random Variable $X$, the \emph{Characteristic Function} is the
Expected Value of $e^{itX}$ where $i$ is the Imaginary Unit and $t \in \reals$
is the Argument of the ``Characteristic Function''
$\varphi_X : \reals \to \comps$:
\[
  \varphi_X(t) = E[e^{itX}] = \int_\reals e^{itx} dF_X(x)
\]
where $F_X$ is the Cumulative Distribution Function (\S\ref{sec:cdf}) of $X$ and
the Integral is a Riemann-Sieltjes Integral (TODO: xref)

like the Cumulative Distribution Function, the Characteristic Function
completely determines the behavior and properties of the Probability
Distribution

if the Random Variable admits a Probability Density Function then the
Characteristic Function is the \emph{Fourier Transform}
(\S\ref{sec:fourier_transform}) of the Probability Density Function and vice
versa

cf. Moment-generating Function (\S\ref{sec:moment_generating_function}) --
the Characteristic Function always exists even when the Moment-generating
Function and Probability Density Function (\S\ref{sec:pdf}) do not exist;
if a Random Variable has a Moment-generating Function then the Characteristic
Function can be extended to the Complex Plane

\fist cf. Indicator Functions (\S\ref{sec:indicator_function})

cf. Characteristic Function Form Games
(\S\ref{sec:characteristic_function_form})

\begin{itemize}
  \item the Characteristic Function of a (L\'evy) Symmetric $\alpha$-stable
    Distribution (\S\ref{sec:symmetric_alpha_stable}) is a Stretched Exponential
    Function (\S\ref{sec:stretched_exponential})
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Discrete Random Variable}\label{sec:discrete_random_variable}
% ------------------------------------------------------------------------------

State Space is a Countable Set

has a Cumulative Distribution Function (\S\ref{sec:cdf}) that is Piecewise
Constant (\S\ref{sec:step_function})

\fist Discrete Probability Distributions (\S\ref{sec:discrete_probability})



\subsubsection{Probability Mass Function (PMF)}\label{sec:pmf}

for a Discrete Random Variable $X$, the \emph{Probability Mass Function} is
defined as:
\[
  p_X(x) = P(X = x)
\]
and has the Properties:
\begin{enumerate}
  \item $p_X(x) \geq 0$
  \item $\sum_x p_X(x) = 1$
\end{enumerate}

characterizes a Discrete Probability Distribution
(\S\ref{sec:discrete_probability})

related to the CDF (\S\ref{sec:cdf}) $F_X$ of $X$ by:
\[
  F_X(x) = P(X \leq x) = \sum_{x_i \leq x} p_X(x_i)
\]

for a Probability Mass Function that is Symmetric around a certain point, that
point is the Expected Value (\S\ref{sec:expected_value})

\fist each Row in the Transition Matrix of a Markov Process
(\S\ref{sec:markov_process}) represents a Probability Mass Function



\paragraph{Probability Generating Function}
\label{sec:probability_generating_function}\hfill

(Ordinary) Generating Function (\S\ref{sec:generating_function})--i.e. Formal
Power Series representation--of the Probability Mass Function of a Discrete
Random Variable



\subsubsection{Binomial Random Variable}\label{sec:binomial_variable}

number of ``Successes'' in $n$ Independent Trials with Constant Success
Probability $p$

can be viewed as a Sum of a ``Bernoulli'' Random Variables, i.e. the Sum of $n$
Binomial Variables with $n = 1$

Binomial (Bernoulli) Trial (\S\ref{sec:binomial_trial})

Binomial Distribution (\S\ref{sec:binomial_distribution})

cf. Binomial Coefficients (\S\ref{sec:binomial_coefficient})

\fist cf. Geometric Distribution (\S\ref{sec:geometric_distribution}) -- number
of Trials until first Success

$X \sim B(n,p)$

Expected Value $E(X) = np$

Variance $\sigma^2 = np(1-p)$

Probability Mass Function:
\[
  f(k,n,p) = P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}
\]
for $k = 0,1,2, \ldots, n$



% ------------------------------------------------------------------------------
\subsection{Continuous Random Variable}\label{sec:continuous_random_variable}
% ------------------------------------------------------------------------------

has Probability $0$ of assuming a particular Value

\fist Continuous Probability Distributions (\S\ref{sec:continuous_probability})



\subsubsection{Probability Density Function (PDF)}\label{sec:pdf}

\emph{Probability Density Function} $f_X(x)$ of a Continuous Random Variable $X$
has the Properties:
\begin{enumerate}
  \item $\forall x \in \reals, f_X(x) \geq 0$
  \item $\int\limits_{-\infty}^{\infty} f_X(x) dx = 1$
  \item $\forall a \leq b, P (a < X < b) = \int\limits_a^b f(x) dx$
\end{enumerate}
the CDF (\S\ref{sec:cdf}) $F_X$ of $X$ can be defined in terms of $f_X$ as:
\[
  F_X(x) = \int_{-\infty}^x f_X(t)dt
\]
i.e. the CDF of a Continuous Random Variable gives the Area under the PDF from
$-\infty$ to $x$, and $f_X(x) = F'_X(x)$ at all Points $x$ at which $F_X$ is
Differentiable

\emph{Probability Densities} represent \emph{rates} at which Probabilities
``accumulate'' (cf. Discrete \emph{Probability Masses} (\S\ref{sec:pmf}) which
are actual Probabilities); cf. \emph{Likelihood} (\S\ref{sec:likelihood})

characterizes a Continuous Probability Distribution
(\S\ref{sec:continuous_probability})

for a Random Variable that admits a Probability Density Function, the
Characteristic Function (\S\ref{sec:characteristic_function}) of the Random
Variable is the Fourier Transform (\S\ref{sec:fourier_transform}) of its
Probability Density Function and vice versa

\fist Probability Amplitude (Quantum Systems \S\ref{sec:probability_amplitude}):
Complex Number with Modulus Squared representing a Probability Density

\fist Kullback-Leibler Divergence (\S\ref{sec:kullback_leibler})

Laplace Transform (\S\ref{sec:laplace_transform}) of a Random Variable $X$ with
PDF $f$:
\[
  \mathcal{L}\{f\}(s) = \expect(e^{-sX}))
\]
and replacing $s$ by $-t$ gives the Moment-generating Function
(\S\ref{sec:moment_generating_function}) of $X$



\paragraph{Normalizing Constant}\label{sec:normalizing_constant}\hfill

used to reduce any Probability Function to a Probability Density Function with
total Probability $1$

%FIXME: same concept as Normalizing Constant for bayesian inference ?



\subsubsection{Mean Absolute Error (MAE)}\label{sec:mae}

Average Absolute Difference between two Continous Random Variables, e.g.:
\begin{itemize}
  \item between \emph{Predicted} and \emph{Observed} (cf. Residual
    \S\ref{sec:residual})
  \item between \emph{Initial} and \emph{Subsequent Observations}
  \item between \emph{measurement techniques}
\end{itemize}

Expected Value of the Absolute Difference of two Continuous Random Variables

measures the Vertical or Horizontal Distance from the Identity Line

\fist not to be confused with \emph{Mean Absolute Deviation} (MAD
\S\ref{sec:mad})-- Average of Deviations around a central point, or \emph{Mean
  Absolute Difference} (\S\ref{sec:mean_absolute_difference})-- Average Absolute
Difference of two IID Random Variables



% ------------------------------------------------------------------------------
\subsection{Mixed Random Variable}\label{sec:mixed_random_variable}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Random Sequence}\label{sec:random_sequence}
% ------------------------------------------------------------------------------

(wiki):

a Random Sequence is a special case of \emph{Stochastic Process}
(\S\ref{sec:stochastic_process}) where the Index Set is some Subset of the
Integers

Stochastic Processes: Sequences of possibly \emph{Dependent}
(\S\ref{sec:dependence}) Random Variables:
\begin{itemize}
  \item Martingales (\S\ref{sec:martingale})
\end{itemize}
cf. IID Sequences (\S\ref{sec:iid})

cf. Random Vector (\S\ref{sec:random_vector})

note that Axiomatic Probability Theory (\S\ref{sec:probability_axioms})
avoids definition of a \emph{Random Sequence}

paradigms:
\begin{itemize}
  \item \emph{Frequency / Measure-theoretic} approach -- (Mises-Church); the
    Sets ``Coding'' Frequency-based Stochastic properties are special kinds of
    Null Sets (\S\ref{sec:null_set}) (Martin-L\"of)
  \item \emph{Complexity / Compressibility} approach -- (Kolmogorov-Chatin)
    Algorithmic (Kolmogorov) Complexity (\S\ref{sec:algorithmic_complexity})
  \item \emph{Predictability} approach -- (Schnorr) Constructive Martingales
    (\S\ref{sec:martingale})
\end{itemize}

Bernoulli Sequence (\S\ref{sec:bernoulli_sequence})

\emph{Subsequence Selection Criterion} -- \emph{Mises-Church Randomness}: any
Recursive Function which having read the first $N$ elements of the Sequence
decides if it wants to select element $N+1$; cf. Algorithmic Randomness
(\S\ref{sec:algorithmic_randomness})

\emph{Reference Class Problem}: Relative Frequencies must be ``Relativised'' to
a ``Reference Class'' (other interpretations of Probability may have this
problem as well)--

solutions restrict to certain Sequences of Outcomes, e.g. (Infinite)
``\emph{Collectives}'' (Von Mises57)--cf. Infinite Bernoulli Sequences --where a
\emph{Place-selection} is an effective method of selecting indices of Members of
a Sequence such that the selection or not of Index $i$ depends \emph{at most} on
the first $i-1$ Outcomes (``attributes''), with the Axioms of \emph{Convergence}
(the limiting Relative Frequency of any Outcome exists) and \emph{Randomness}
(the limiting Relative Frequency of each Outcome in a Collective $\omega$ is the
same in any Infinite Subsequence of $\omega$ determined by Place-selection; note
that trivial Sequences such as $H,H,H,\ldots$ satisfy this ``Randomness'' Axiom;
cf. the Principle of Maximum Entropy in Classical Probability), Algorithmic
Randomness (\S\ref{sec:algorithmic_randomness});
issues with limiting Relative Frequencies are that they violate Countable
Additivity and the Domain of Definition is not a Set-field or a $\sigma$-algebra
(de Finetti72)



% ------------------------------------------------------------------------------
\subsection{Multivariate Random Variable}\label{sec:random_vector}
% ------------------------------------------------------------------------------

or \emph{Random Vector}

$X = (X_1, \ldots, X_n)$

cf. Random Sequences (\S\ref{sec:random_sequence})

\fist cf. Stochastic Processes (\S\ref{sec:stochastic_process}) -- Sequences of
not necessarily IID (\S\ref{sec:iid}) Random Variables

\fist Multivariate Statistics (\S\ref{sec:multivariate_statistics}) --
\emph{simultaneous} Observation and Analysis of more than one Outcome Variable

Multinomial Distribution (\S\ref{sec:multinomial_distribution})

Multivariate Normal Distribution (\S\ref{sec:multivariate_normal})



\subsubsection{Independent and Identically Distributed (IID)}\label{sec:iid}

if $X_1, \ldots, X_n$ are Independent and each has the same Marginal
Distribution (\S\ref{sec:marginal_distribution}) with CDF $F$, then $X_1,
\ldots, X_n$ are said to be \emph{Independent and Identically Distributed
  (IID)}, writing:
\[
  X_1, \ldots, X_n \sim F
\]
and if $F$ has Density $f$, then:
\[
  X_1, \ldots, X_n \sim f
\]
$X_1, \ldots, X_n$ are then called a \emph{Random Sample of Size $n$ from $F$}
(\S\ref{sec:random_sample})

in Statistics it is commonly assumed that Observations (\S\ref{sec:observation})
are IID

(wiki):

in Signal Processing (\S\ref{sec:signal_processing}) terms, \emph{Identically
  Distributed} implies that the ``Signal Level must be Balanced'' (FIXME:
xref/clarify) and \emph{Independent} implies a White Noise Spectrum (flat)

a Sequence of IID Random Variables can be seen as a Discrete-time L\'evy Process
(\S\ref{sec:levy_process}): a Stochastic Process with Independent, Identically
Distributed displacements in pairaise Disjoint Time Intervals

many L\'evy Processes can be seen as \emph{Limits} of IID Variables (e.g. Wiener
Process as the Limit of the Simple Random Walk)

Stable Probability Distributions (\S\ref{sec:stable_distribution}) are
``Attractors'' for ``properly normed'' Sums of IID Random Variables-- Central
Limit Theorem (\S\ref{sec:central_limit_theorem}): the Normal Distribution is
the ``properly normed'' Sum of a Set of Random Variables with Finite Variance



\subsubsection{Homoscedasticity}\label{sec:homoscedasticity}

an Assumption in Regression Analysis (\S\ref{sec:regression_analysis}): Error is
Constant accross Observations



\subsubsection{Heteroscedasticity}\label{sec:heteroscedasticity}

Weighted Least Squares (WLS \S\ref{sec:wls})



% ==============================================================================
\section{Probability Distribution}\label{sec:probability_distribution}
% ==============================================================================

any Probability Distribution defines a Probability Measure
(\S\ref{sec:probability_measure}) as the Pushforward Measure
(\S\ref{sec:pushforward_measure}) of a Random Variable
(\S\ref{sec:random_variable})

a Probability Distribution is given by its Cumulative Distribution Function
(\S\ref{sec:cdf}), which is a Right-continuous Function; the Cardinality of the
Set of all such Functions is equal to the Cardinality of the Reals, $|\reals|$

\emph{Probability Distribution Function} of a Random Variable $X$ often means
the CDF $F_X$, but can also refer
to:
\begin{itemize}
  \item Probability Mass Function (\S\ref{sec:pmf}) -- Discrete Probability
    Distributions (\S\ref{sec:discrete_probability})
  \item Probability Density Function (\S\ref{sec:pdf}) -- Continuous Probability
    Distributions (\S\ref{sec:continuous_probability})
\end{itemize}

the \emph{Support} (\S\ref{sec:distribution_support}) of a Probability
Distribution is the smallest Closed Set whose Complement has Probability $0$

\fist cf. Probability Measure Function
(\S\ref{sec:probability_measure_function}), Distribution Function (Measure
Theory \S\ref{sec:distribution_function}), Distribution (Analysis
\S\ref{sec:distribution}), Frequency Distribution
(\S\ref{sec:frequency_distribution})

\fist \emph{Statistical Inference} (\S\ref{sec:inferential_statistics}) -- using
Sample Data (\S\ref{sec:sample}) to \emph{Infer} the Distribution that
\emph{Generated} (\S\ref{sec:data_generating_process}) the Data; a Statistical
Model (\S\ref{sec:statistical_model}) $(S,\mathcal{P})$ is a Sample Space
(\S\ref{sec:sample_space}) $S$ together with a Set of Probability Distributions
$\mathcal{P}$ on $S$

\fist Random Graphs (\S\ref{sec:random_graph}) -- Probability Distribution over
a Graph

collapsing a Probability Distribution (Measure) of Probability Distrubtions to a
Probability Distribution is called the ``Giry Monad'' (TODO)

(wiki): a Statistical (or Population) Parameter
(\S\ref{sec:population_parameter}) is a ``quantity'' that indexes a Family of
Probability Distributions

the Entropy (\S\ref{sec:entropy}) of a Distribution is the Mean number
of Bits-per-symbols in an Optimal Encoding (\S\ref{sec:encoding}) --
\url{https://golem.ph.utexas.edu/category/2017/02/functional_equations_iii_expla.html}

Cross Entropy (\S\ref{sec:cross_entropy}) measures the average number of Bits
needed to identify an Event drawn from an underlying Set of Events under two
Probability Distributions $p$ and $q$, if the ``coding scheme'' is optimized for
an ``unnatural'' Distribution $q$ rather than a ``true'' Distribution $p$
%FIXME: clarify

\emph{Principle of Maximum Entropy}; cf. Axiom of Randomness in Frequentist
Probability (Von Mises57)

(Witten18): Quantum Information Theory doesn't have a good analog to defining a
Conditional Probability Distribution (\S\ref{sec:conditional_probability}) as in
Classical Information Theory, but does have an analog of \emph{Strong
  Subadditivity of Entropy}

the Quantum analog of a Classical Probability Distribution is a \emph{Density
  Matrix} (\S\ref{sec:density_matrix}), a representation of the Linear
\emph{Density Operator} \S\ref{sec:density_operator})-- a Self-adjoint
(Hermitian), Positive Semi-definite, Trace One, and may be Infinite-dimensional
Matrix; every Matrix with these properties can be ``Purified'', meaning that it
is the Density Matrix of \emph{some} Pure State on some ``Bipartite'' System
$AB$; there is no ``classical analog'' for Purification, i.e. there is no way to
make Probability Distribution ``pure'' (one outcome with Probability $1$) by
adding more Variables



% ------------------------------------------------------------------------------
\subsection{Cumulative Distribution Function (CDF)}\label{sec:cdf}
% ------------------------------------------------------------------------------

MIT 6.041SC, Lec.8

CDF applies equally well to Discrete and Continuous Random Variables

(wiki):

the \emph{Cumulative Distribution Function (CDF)} of a Real-valued Random
Variable $X$ evaluated at $x$ is equal to the Probability that $X$ will take a
value less than or equal to $x$:
\[
  \forall x \in \reals, F_X(x) = \prob(X \leq x)
\]
every CDF is Non-decreasing and Right-continuous

special case of Distribution Function (Measure Theory
\S\ref{sec:distribution_function}) with the boundary conditions
$\lim_t\to\infty F_X(t) = 0$ and $\lim_{t\to\infty}F_X(t) = 1$

every Function with these four Properties is a CDF, i.e. for every such Function
a Random Variable can be defined such that the Function is a CDF of that Random
Variable

a Random Variable $X$ with CDF $F$ is indicated by the notation $X \sim F$, but
note that this does \emph{not} mean ``approximate equality''

the CDF $F_X$ of a Discrete Random Variable can be related to its Probability
Mass Function (\S\ref{sec:pmf}) $f_X$ by:
\[
  F_X(x) = P(X \leq x) = \sum_{x_i \leq x} f_X(x_i)
\]

the CDF of a Continuous Random Variable can be expressed as the Integral of its
Probability Density Function (\S\ref{sec:pdf}) $f_X$:
\[
  F_X(x) = \int\limits_{-\infty}^x f_X(t) dt
\]
i.e. the CDF of a Continuous Random Variable gives the Area under the PDF from
$-\infty$ to $x$

if $F_X$ is Absolutely Continuous (\S\ref{sec:absolute_continuity}), then there
exists a Lebesgue-integrable Function $f_X(x)$ such that:
\[
  F_X(b) - F_X(a) = P(a < X \leq b) = \int_a^b f_X(x) dx
\]
for all Real Numbers $a, b$ and $f_X$ is the PDF of the Distribution of $X$
and equals the Derivative of $F_X$ almost everywhere

\fist \emph{Empirical Distribution Function}
(\S\ref{sec:empirical_distribution}) -- an Unbiased Estimator for $F$ defined as
the CDF of the Empirical Measure (\S\ref{sec:empirical_measure}) of a Sample
(\S\ref{sec:sample})



\subsubsection{Complementary Cumulative Distribution Function}
\label{sec:complementary_cumulative}

or \emph{Tail Distribution}

$\prob(X > x)$

$\bar{F}(\cdot)$



\paragraph{Survival Function}\label{sec:survival_function}\hfill

$\bar{F}_X(x) = P(X > x) = 1 - F_X(x)$



\paragraph{Scaling Distribution}\label{sec:scaling_distribution}\hfill

\emph{Self-affine} (\S\ref{sec:self_affinity})

cf. Scale Parameter (\S\ref{sec:scale_parameter})

cf. Power-law (\S\ref{sec:power_law})

cf. Scaling (Homothety \S\ref{sec:scaling})

%FIXME: wikipedia links scaling distribution to power law

--FIXME: should this be considered equivalent to the Pareto Distribution
(\S\ref{sec:pareto_distribution}) with scale parameter $x_m = 1$ ???

Mandelbrot97:

Ch.1

\emph{Scaling under Conditioning} of a Positive Random Variable
$\prob(U > 0) = 1$

$\bar{F}_U(u) = c u^{-\alpha} = \frac{u}{\tilde{u}}^{-\alpha}$

the sole response to \emph{Conditioning} (\S\ref{sec:conditioning}) by $w$ is
change of \emph{Scale} from $\tilde{u}$ to $w$

is the \emph{only} Distribution that is Scaling under this particular
Conditioning

by Logarithmic Transformation $V = \ln U$, the Invariance Property (FIXME:
clarify) reduces to an Invariance Property of the Exponential Distribution
$\bar{F}_V(v) = e^{-\alpha(v - \tilde{v})}$, that Conditioning by $w$ is a
change of \emph{Location} rather than Scale

from an Exponentially Distributed (\S\ref{sec:exponential_distribution}) $V$, a
Scaling $U$ is obtained by $U = e^V$

\fist $L$-Stable Motion (LSM \S\ref{sec:lsm}) -- Integration of a Difference
Stationary Process of Independent and Scaling Random Variables

Process $Z(t)$ and Non-decreasing Function of Time $\theta(t)$ gives Compound
Process $\tilde{Z}(\theta(t))$ where $\tilde{Z}(\theta)$ and $\theta(t)$ are
taken to be Independent and Scaling

Ch.2

\emph{Scaling} in price changes: a short time interval resemble a scaled-down
version of price changes in longer intervals (\emph{Invariance with respect to
  Contractions})

practical limits in real price data:
\begin{itemize}
  \item \emph{inner cutoff}: very short time intervals contain few transactions
    and can't resemble longer records
  \item \emph{outer cutoff}: variations move from time scales dominated by
    ``speculation'' to longer scales dominated by fundamental economic effects
  \item \emph{crossover}: scaling models may change over time
\end{itemize}

Continuous for $\alpha = 2$

increasing Discontinuity as $\alpha \to 1$

\emph{Concentration} leads to Discontinuity -- the overall change over an
interval $T$ will be concentrated in smaller sub-intervals, and so-on when
considering each sub-interval in isolation, leading to Discontinuities as the
overall change becomes concentrated in smaller and smaller intervals

Lindy Effect: does not hold for Non-scaling Distributions

Ch.3

Mandelbrot 1963

\begin{quote}
  ... when the ``spontaneous activity'' of a system is governed by a Scaling
  rather than a Gaussian Process, the ``Causally Structural'' features of the
  system are more likely to be obscured by Noise. ... Scaling Noise generates a
  variety of ``patterns''; everyone agrees on their Form, but they have no
  Predictive value. ...
\end{quote}

\emph{Weak (Asymptotic) Scaling}

for $N$ Independent Random Variables $U_n(1 \leq n \leq N)$ with Weak Scaling
Distributions with the same Exponent $\alpha$:
\[
  \prob(U_n > u) \sim C_n u^{-\alpha}
\]
as $u \to \infty$

Invariance under Observational Transformation
(\S\ref{sec:observational_transformation}) -- Invariance up to Scale holds
\emph{Asymptotically} under Linear Aggregation, Weighted Mixture, and Maximizing
Choice, as long as the ``parts'' themselves are Asymptotically Scaling

under Infinite Aggregation, Scaling holds only for $\alpha < 2$

\begin{quote}
  ... one must rather say: ``It is true that incomes (or firm sizes) follow the
  scaling distribution; it is not true that the Distributions of income are very
  sensitive to the methods of reporting and of observation.''
\end{quote}

for $U_W$ a Weighted Mixture of the $U_n$ and $p_n$ denoting $\prob(U_W = U_n)$,
then $U_W$ is Asymptotically Scaling with Scale Parameter $C_W$ equal to the
Weighted Average $C_W = \sum p_n C_n$ separate Scale Coefficients $C_n$ and:
\[
  \prob(U_W > u) = C_W u^{-\alpha}
\]

if $U_M$ is the largest of the Realized $U_n$ (i.e. Maximizing Choice), then
$U_M$ is Asymptotically Scaling with Scale Parameter $C_M = \sum C_n$, and:
\[
  \prob(U_M < u) = \prod \prob(U_n \leq u)
\]
and:
\[
  \prob(U_M > u) \sim C_M u^{-a}
\]

for $U_A$ the Sum of the individual $U_n$ (i.e. Linear Aggregation), $U_A$ is
Asymptotically Scaling with Scaling Parameter is again the Sum $C_A = \sum C_n$,
implying that the Sum of the $U_n$ behaves like the largest $U_n$ as
$u \to \infty$

the Probability Densities of the following three ``Invariant Families'' of
Distributions differ through most of the Range of $u$, however for $0 < \alpha <
2$, their Asymptotic behavior coincides

Maximization -- the CDF of a Fr\'echet Distribution
(\S\ref{sec:frechet_distribution}) with $m = 0$ and $s = 1$:
\[
  F_M(u) = e^{-x^{-\alpha}}
\]
is Weakly Scaling

Mixing -- $F_W(u) = 1 - Cu^{-\alpha}$ is the ``Analytical Form'' of the Scaling
Distribution ``extended'' down to $u = 0$; has Infinite Probability unless $U$
is restricted to an Interval $0 < a \leq u \leq b$

Aggregation -- leads to Random Variables that are ``positive'' members of the
family of $L$-stable Distributions (``Scaling Sum Distribution'', i.e. with
$\alpha < 1$; only the L\'evy Distribution (\S\ref{sec:levy_distribution}) has
Density Function $dF_A(u)$ with Closed Analytic Form; $L$-stable Distributions
are the only Non-Gaussian Limits of Linearly Weighted Sums of Random Variables

\begin{quote}
  There are many reasons for believing that many scaling phenomena are related
  to ``accumulative'' processes similar to those encountered in coin-tossing.
\end{quote}

Ch.4

Limits of Limit Theorems in Probability Theory as \emph{Fixed
  Points} of Renormalization (\S\ref{sec:renormalization})

Ch.5

(Mandelbrot97E) Randomness (\S\ref{sec:statistical_randomness}): ``mild''
(Gaussian), ``slow'' (Log-normal), ``wild'' (Scaling with Infinite Variance,
i.e. $\alpha < 2$)

Scaling Variables with $\alpha < 2$ satisfy $\expect(U^2) < \infty$ but are
\emph{not} Pre-Gaussian

\emph{Tail Preservation Relation} -- $\overline{F}_N(u) \sim N \overline{F}(u)$

for $U_n$ ($1 \leq n \leq N$) IID with Tail Probability $\overline{F}(u)$, and
$\tilde{F}_N(u)$ the Tail Probability of $\tilde{U}_N = \max(U_n)$, then:
\[
  1 - \tilde{F}_N(u) = F(u)^N
\]
in the Tail where $\overline{F}(u) \ll 1$ and $\tilde{F}(u) \ll 1$, in
\emph{all} cases: $\tilde{F}(u) \sim N \overline{F}$

cf. Extreme Value Analysis (\S\ref{sec:eva})

Wild Randomness is characterized by the fact that the largest of many addends is
of the same order of magnitude as their sum

Ch.6

Self-affinity (\S\ref{sec:self_affinity}): Linear Scaling behavior in the Graph
(\S\ref{sec:relation_graph}) of a Function

cf. Self-similarity (\S\ref{sec:self_similarity}) -- defined by an Isotropic
Reduction (Homothety \S\ref{sec:homothety}), a Rotation, and a Translation



\subparagraph{Multiscaling}\label{sec:multiscaling}\hfill

(Mandelbrot97E)

model of price variation

the Distribution $L(t, T) = \ln Z(t + T) - \ln Z(t)$ (cf. $L$-stable Motion
\S\ref{sec:lsm}) is observed to be increasingly ``sharp peaked'' and Long-tailed
as $T \to 0$

\emph{alternative explanation for drift}: Long-term Dependence and
``clustering'' of large changes of $L(t, T)$ means that changes of small $p$ are
unlikely to be observed in a finite sample as $T$ becomes large, reducing the
Histograms Tail

``Scale Factors'' $\sigma(q) = \Big(\expect(L^q(t, T))\Big)^{\frac{1}{q}}$

\emph{Uniscaling} (Fractal) -- $q < \alpha$ are Powers of $T$ with Exponent
\emph{independent} of $q$ (FIXME: define $\alpha$); i.e. Scale Factors based on
Moments (\S\ref{sec:moment}) satisfy:
\[
  \Big(E(B_H(t + T) - B_H(t)^q)\Big)^{\frac{1}{q}} = c T^H
\]
for all Powers $q > -1$ where $c$ is some Constant (Ch.6)

\emph{Multiscaling} (Multifractal) -- the (Exponent of the) $q$th Scale Factor
\emph{depends} on $q$

\fist Conditional Stationarity (\S\ref{sec:conditional_stationarity})

\fist Sporadic Processes (\S\ref{sec:sporadic_process})



\subsubsection{Quantile Function}\label{sec:quantile_function}

\emph{Inverse CDF} $F^{-1}$

$F^{-1}(0.25)$ -- \emph{First Quartile}

$F^{-1}(0.5)$ -- \emph{Median} (or \emph{Second Quartile})

$F^{-1}(0.75)$ -- \emph{Third Quartile}

Location Parameter



\paragraph{Qantile}\label{sec:quantile}\hfill

\paragraph{Probit}\label{sec:probit}\hfill

Quantile Function of the Normal Distribution



\subsubsection{Statistical Functional}\label{sec:statistical_functional}

(Wasserman04 Example 6.05):

a Function of a CDF is called a \emph{Statistical Functional}

can be used to compute various Summary Statistics
(\S\ref{sec:summary_statistic}):
\begin{itemize}
  \item $\mu = T(F) = \int x dF(x)$
    -- Mean (Expectation \S\ref{sec:expected_value})
  \item $\sigma^2 = T(F) = \int (x - \mu)^2 dF(x)$
    -- Variance (\S\ref{sec:variance})
  \item $m = T(F) = F^{-1}(0.5)$
    -- Median (\S\ref{sec:median})
\end{itemize}

Non-parametric Inference (\S\ref{sec:nonparametric_model})

the \emph{Plug-in Estimator} (\S\ref{sec:plugin_principle}) for a Functional
$\theta = T(F)$ is:
\[
  \hat{\theta} = T(\hat{F}_n)
\]
where $\hat{F}_n$ is the Empirical Distribution Function
(\S\ref{sec:empirical_distribution})



\paragraph{Linear Functional}\label{sec:linear_functional}\hfill

a Functional of the form:
\[
  T(F) = \int r(x) dF(x)
\]
for some Function $r(x)$

called ``Linear'' because in this case $T$ satisfies
$T(aF + bG) = aT(F) + bT(G)$, i.e. $T$ is Linear in all arguments

the Plug-in Estimator (\S\ref{sec:plugin_principle}) for a Linear Functional:
\[
  T(\hat{F}_n) = \frac{1}{n}\sum_{i=1}^n r(X_i)
\]
where $\hat{F}_n$ is the Empirical Distribution Function
(\S\ref{sec:empirical_distribution})



\subsubsection{Cumulative Frequency Analysis}
\label{sec:cumulative_frequency_analysis}



% ------------------------------------------------------------------------------
\subsection{Moment}\label{sec:moment}
% ------------------------------------------------------------------------------

the \emph{$k^{th}$ Moment} of $X$ is defined as $E(X^k) = \int x^k dF(x)$
assuming that $E(|X|^k) < \infty$, where $F$ is the CDF (\S\ref{sec:cdf}) of $X$

the \emph{$k^{th}$ Sample Moment} of a Sample (\S\ref{sec:sample}) $X_1, \ldots,
X_n$ is:
\[
  \frac{1}{n}\sum_{i=1}^n X^k_{i}
\]

\fist Cumulants (\S\ref{sec:cumulant}) -- Moments determine Cumulants and vice
versa

\textbf{Thm.} \emph{If $j < k$ and the $k$th Moment Exists, then the $j$th
  moment exists.}

Mean (Expected Value \S\ref{sec:expected_value}) -- First Raw Moment; Sample
Mean (\S\ref{sec:sample_mean})

Variance (\S\ref{sec:variance}) -- Second Central Moment

Skewness (\S\ref{sec:skewness}) -- Third Central Moment; ``lopsided-ness''

Kurtosis (\S\ref{sec:kurtosis}) -- Fourth Central Moment; Measure of the
``heaviness'' of the tail of a Distribution

Fourth and higher-order Cumulants are not equal to Central Moments

\emph{Hausdorff Moment Problem}: for a Probability Distribution on a Bounded
Interval, the collection of all Moments (of all Orders from $0$ to $\infty$)
\emph{uniquely} determines the Distribution

\emph{Stieltjes Moment Problem}, \emph{Hamburger Moment Problem}: there may be
infinitely many Distributions on an Unbounded Interval for a given Sequence of
Moments; under some conditions the Distribution may be uniquely determined

\fist Moment-generating Function (\S\ref{sec:moment_generating_function})

\fist Method of Moments (\S\ref{sec:moments_method}) -- Estimator of Statistical
Model Parameters

\fist Mean Squared Deviation or Mean Squared Error (MSE \S\ref{sec:msd}) of an
Estimator (\S\ref{sec:estimator}) is the Average of the Squared Error of the
Estimated value (produced by an Estimator) from the ``true'' value; MSD is
the Second Moment of the Error; for an Unbiased Estimator the MSD is the
Variance of the Estimator



\subsubsection{Standardized Moment}\label{sec:standardized_moment}

a \emph{Normalized} Moment, usually by division by an expression of the Standard
Deviation rendering the Moment \emph{Scale Invariant}
(\S\ref{sec:scale_invariance})



% ------------------------------------------------------------------------------
\subsection{Cumulant}\label{sec:cumulant}
% ------------------------------------------------------------------------------

\fist Moments (\S\ref{sec:moment}) -- Cumulants determine Moments and vice
versa

Mean (Expected Value \S\ref{sec:expected_value}) -- First Cumulant

Variance (\S\ref{sec:variance}) -- Second Cumulant

Skewness (\S\ref{sec:skewness}) -- Third Cumulant; ``lopsided-ness''

Fourth and higher-order Cumulants are not equal to Central Moments

when two or more Random Variables are Statistically Independent, the $n$th-order
Cumulant of their sum is the sum of their $n$th-order Cumulants

the Normal Distribution is the only Distribution with the property that the
third and higher-order Cumulants are Zero

\fist Cumulant-generating Function (\S\ref{sec:cumulant_generating_function})

cf. ``Extensive Quantities'' -- Quantities that are proportional to Volume or
size of a given System (i.e. the sum of quantities associated with Independent
regions)



% ------------------------------------------------------------------------------
\subsection{Degenerate Distribution}\label{sec:degenerate_distribution}
% ------------------------------------------------------------------------------

(wiki):

a \emph{Degenerate Distribution} is a Probability Distribution in a Space with
Support (\S\ref{sec:support}) only on a Space of lower Dimension

for a Univariate Distribution, it is a \emph{Deterministic Distribution} that
takes only a single value (FIXME: clarify)

Infinitely Divisible (\S\ref{sec:infinitely_divisible})



% ------------------------------------------------------------------------------
\subsection{Joint Probability Distribution}\label{sec:joint_probability}
% ------------------------------------------------------------------------------

$f(x,y,\ldots)$ for two or more Random Variables $X,Y,\ldots$

\fist Generative Models (Classification \S\ref{sec:generative_model})

Discrete Random Variables:
\begin{enumerate}
  \item $f(x,y) \geq 0$
  \item $\sum_x \sum_y f(x,y) = 1$
  \item $P(X = x, Y = y) = f(x,y)$
\end{enumerate}

Continuous Random Variables:
\begin{enumerate}
  \item $\forall (x,y) \in X \times Y, f(x,y) \geq 0$
  \item $\int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty}
    f(x,y) dx dy = 1$
  \item $P[(X,Y) \in B] = \iint\limits_B f(x,y) dA$
\end{enumerate}

(Wasserman04, \S23.1):

for Random Variables $X_1, \ldots, X_n$, the Joint Density $f(x_1, \ldots, x_n)$
is:
\begin{flalign*}
  f(x_1, \ldots, x_n)
    & = f(x_1) f(x_2 | x_1) \cdots f(x_n | x_1, \ldots, x_{n-1}) \\
    & = \prod_{i=1}^n f(x_i | x_1, \ldots, x_{i-1}) \\
\end{flalign*}
for a Markov Process (\S\ref{sec:markov_process}), this simplifies to:
\[
  f(x_0, \ldots, x_t) = f(x_1)f(x_2|x_1)f(x_3|x_2) \cdots f(x_t|x_{t-1})
\]

\asterism

\fist \emph{Cross-variation Assumptions} -- Model-based Statistical Assumptions
(\S\ref{sec:statistical_assumption}) involving Joint Probability Distributions
of either Observations or Random Errors in a Model; simple Models may Assume
that Observations or Errors are Statistically Independent
(\S\ref{sec:independence})

Conditional Independence (\S\ref{sec:conditional_independence}) happens when
the Joint Probability Distribution is the Product of the individual Probability
Distributions
--\url{http://lesswrong.com/lw/pi/classical_configuration_spaces/}

\fist a Stationary Process (\S\ref{sec:stationary_process}) is a Stochastic
Process whose Unconditional Joint Probability Distribution is unchanged in Time



\subsubsection{General Product Rule}\label{sec:general_product_rule}

or \emph{Probability Chain Rule}

calculate any member of the Joint Distribution of a Set of Random Variables
using only Conditional Probabilities (\S\ref{sec:conditional_probability})

for two Random Events $A, B$:
\[
  \prob(A \cap B) = \prob(B | A) \prob(A)
\]
for $n$ Events $A_1, \ldots, A_n$:
\[
  \prob(A_n \cap \cdots \cap A_1) =
    \prod_{k=1}^n \prob\Big(A_k | \bigcap_{j=1}^{k-1} A_j \Big)
\]

for two Random Variables $X, Y$:
\[
  \prob(X, Y) = \prob(X | Y) \prob(Y)
\]

for $n$ Random Variables $X_1, \ldots, X_n$:
\[
  \prob\Big(\bigcap_{k=1}^n X_k\Big) =
    \prod_{k=1}^n \prob\Big(X_k | \bigcap_{j=1}^{k-1} X_j\Big)
\]



\subsubsection{Bivariate Distribution}\label{sec:bivariate_distribution}

$P(X = x, Y = y)$



\subsubsection{Kalman Filter}\label{sec:kalman_filter}

a series of papers on ``Kalman Folding'':
\url{http://vixra.org/author/brian_beckman}

Linear Quadratic Estimation (LQE \S\ref{sec:lqe})

cf. Linear-Quadratic Regulator (LQR \S\ref{sec:lqr})

\fist Dynamic Bayesian Networks (\S\ref{sec:dynamic_bayes_network})



% ------------------------------------------------------------------------------
\subsection{Conditional Distribution}\label{sec:conditional_distribution}
% ------------------------------------------------------------------------------

cf. ``Unconditional Distribution'' (Marginal Distribution
\S\ref{sec:marginal_distribution})

cf. \emph{Discriminative Models} (Classification
\S\ref{sec:discriminative_model})

for Discrete Random Variables $X$, $Y$:

\[
  P(X = x | Y = y) = P(X = x, Y = y)/P(Y = y)
\]
the Conditional Probability Mass Function, assuming $f_Y(y) > 0$:
\[
  f_{X|Y}(x|y) = P(X = x|Y = y) =
    \frac{P(X = x, Y = y)}{P(Y = y)} =
    \frac{f_{X,Y}(x,y)}{f_Y(y)}
\]

for Continuous Random Variables $X$, $Y$, the Conditional Probability Density
Function:
\[
  f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}
\]
and:
\[
  P(X \in A| Y = y) = \int_A f_{X|Y}(x|y) dx
\]

\fist Conditioning (\S\ref{sec:conditioning})

cf. \emph{Borel-Kolmogorov Paradox} -- the concept of a Conditional Probability
with regard to an isolated given Hypothesis whose Probability equals $0$ is
``\emph{inadmissable}'' (Kolmogorov33); Conditional Probability Density
Functions need not be Invariant under Coordinate Transformations



% ------------------------------------------------------------------------------
\subsection{Marginal Distribution}\label{sec:marginal_distribution}
% ------------------------------------------------------------------------------

``Un-conditional Distribution''

Marginal Probability Mass Functions:

$f_X(x) = P(X = x) = \sum_y P(X = x, Y = y) = \sum_y P(X = x | Y = y) P(Y = y)$

$f_Y(y) = P(Y = y) = \sum_x P(X = x, Y = y) = \sum_x P(Y = y | X = x) P(X = x)$

Marginal Probability Density Functions:

$f_X(x) = \int f_{X,Y}(x,y) dy$

$f_Y(y) = \int f_{X,Y}(x,y) dx$



% ------------------------------------------------------------------------------
\subsection{Product Distribution}\label{sec:product_distribution}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Quotient Distribution}\label{sec:quotient_distribution}
% ------------------------------------------------------------------------------

or \emph{Ratio Distribution}

\begin{itemize}
  \item Cauchy Distribution (Normal Ratio Distribution
    \S\ref{sec:cauchy_distribution}) -- Ratio of two Normally Distributed Random
    Variables
  \item $t$-distribution (\S\ref{sec:t_distribution}) -- Gaussian Random
    Variable Divided by an Independent $\chi$-distributed
    (\S\ref{sec:chi_distribution}) Random Variable
  \item $F$-distribution (\S\ref{sec:f_distribution}) -- Ratio of two
    Independent $\chi$-squared (\S\ref{sec:chi_squared}) Random Variables
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Infinitely Divisible Distribution}
\label{sec:infinitely_divisible}
% ------------------------------------------------------------------------------

can be expressed as the Probability Distribution as the Sum of an arbitrary
number of IID Random Variables

\begin{itemize}
  \item Stable Distributions (\S\ref{sec:stable_distribution})
  \item Degenerate Distribution (\S\ref{sec:degenerate_distribution})
  \item $t$-distribution (\S\ref{sec:t_distribution})
  \item Poisson Distribution (\S\ref{sec:poisson_distribution})
  \item Negative Binomial Distribution (\S\ref{sec:negative_binomial})
  \item Gamma Distribution (\S\ref{sec:gamma_distribution})
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Asymptotic Distribution}\label{sec:asymptotic_distribution}
% ------------------------------------------------------------------------------

\fist cf. Asymptotic Theory (Large Sample Theory \S\ref{sec:asymptotic_theory})

(Mandelbrot63) Limits of Limit Theorems in Probability Theory as \emph{Fixed
  Points} of Renormalization (\S\ref{sec:renormalization}); cf. Scaling
Distributions (\S\ref{sec:scaling_distribution})



\subsubsection{Central Limit Theorem}\label{sec:central_limit}

``the Distribution of a Sum of Independent Random Variables can be approximated
by a Normal Distribution''

\fist Sampling Distribution (\S\ref{sec:sampling_distribution})

for a Sequence of Random Variables (\S\ref{sec:random_variable})
$X_i, \ldots, X_n$ with Sample Mean (\S\ref{sec:sample_mean})
$\overline{X}_n$, $\sqrt{n}(\overline{X}_n - \mu)$
\emph{Converges in Distribution} to a Normal Distribution
(\S\ref{sec:normal_distribution}) as $n \to \infty$, i.e. the Sample
Mean has approximately a Normal Distribution for large $n$

\textbf{Thm.} (Central Limit Theorem) \emph{For IID (\S\ref{sec:iid}) Random
  Variables $X_1, \ldots, X_n$ with Mean $\mu$ and Variance $\sigma^2$, then:
  \[
    Z_n \equiv \frac{\overline{X}_n - \mu}{\sqrt{V(\overline{X}_n)}} =
      \frac{\sqrt{n}(\overline{X}_n - \mu)}{\sigma} \to Z \sim N(0,1)
  \]
  i.e:
  \[
    \lim_{n\to\infty} P(Z_n \leq z) = \Phi(z) =
      \int_{-\infty}^z \frac{1}{\sqrt{2\pi}}e^{-x^2/2} dx
  \]
}

\fist if the Random Variables do not have Finite Variance then the Limit may be
a Stable Distribution (\S\ref{sec:stable_distribution}) that is not Normal

(Mandelbrot63) Linear Aggregation (\S\ref{sec:observational_transformation});
cf. Stable Distributions, Autoregressive Models
(\S\ref{sec:autoregressive_model})

\emph{Berry-Ess\'een Inequality}

\emph{Multivariate Central Limit Theorem}

generalization: \emph{Local Asymptotic Normality}

as a consequence of the Central Limit Theorem, Random Errors
(\S\ref{sec:random_error}) tend to be Normally Distributed

\fist Convergence to a ``Universal DIstribution'' independent of starting
Distributions; cf. Universality Class (Renormalization
(\S\ref{sec:universality_class})

\fist Mean-Field Theory (MFT \S\ref{sec:mft}) -- Limit Theorems generalize the
Central Limit Theorem for Empirical Measures (\S\ref{sec:empirical_measure})

\fist origin of ``Multifractality'' (\S\ref{sec:multifractal_system}) in
Sequential (Time Series) data attributed to ``convergence effects'' related to
the Central Limit Theorem that have Foci of Convergence in the family of Tweedie
Exponential Dispersion Models (Probability Distributions
\S\ref{sec:tweedie_distribution})

(Mandelbrot97E)

the Domain of ``Universality of Attraction'' to the Gaussian includes \emph{all}
$U$ satisfying $\expect(U^2) < \infty$ and also some cases where $\expect(U^2)$
Diverges ``slowly enough''



% ------------------------------------------------------------------------------
\subsection{Symmetric Probability Distribution}
\label{sec:symmetric_probability}
% ------------------------------------------------------------------------------

\subsubsection{Uniform Distribution}\label{sec:uniform_distribution}

for a Finite Sample Space $\Omega$:
\[
  P(A) = \frac{\|A\|}{\|\Omega\|}
\]

a Uniform Distribution is defined by a rectangle formed on the interval Interval
$[min,max]$ such that the area is $1$

$Uniform(0,1)$ -- \emph{Standard Uniform Distribution}

\url{https://stats.stackexchange.com/questions/232967/what-makes-the-mean-of-some-distributions-undefined/233950#233950}:
the Cauchy Distribution (\S\ref{sec:cauchy_distribution}) is a ``disguised''
form of the Uniform Distribution on a Circle



\paragraph{Probability Integral Transform}
\label{sec:probability_integral_transform}\hfill

for Continuous $X$ with CDF $F_X$, $Y = F_X(X)$ is called a \emph{Probability
  Integral Transform} and has a Standard Uniform Distribution

\emph{Universal Random Number Generator} (Wasserman04 Ch.2 Exercise 15) -- TODO



\subsubsection{Tukey Lambda Distribution}\label{sec:tukey_lambda_distribution}

\paragraph{Logistic Distribution}\label{sec:logistic_distribution}\hfill

\fist Logistic Regression (\S\ref{sec:logistic_regression})



% ------------------------------------------------------------------------------
\subsection{Location-scale Family}\label{sec:location_scale}
% ------------------------------------------------------------------------------

\begin{itemize}
  \item Uniform Continuous and Discrete Distributions
  \item Normal Distributions
  \item Elliptical Distributions
  \item Cauchy Distributions
  \item Logistic Distributions
  \item Double Exponential (Laplace) Distributions
  \item Student's $t$-distributions
  \item Generalized Extreme Value (GEV) Distributions
\end{itemize}


\fist cf. Location Parameter (\S\ref{sec:location_parameter}), Scale Parameter
(\S\ref{sec:scale_parameter})



% ------------------------------------------------------------------------------
\subsection{Maximum Entropy Probability Distribution}\label{sec:maximum_entropy}
% ------------------------------------------------------------------------------

Entropy (\S\ref{sec:entropy})

(wiki):

\emph{Maximum Entropy Principle}: the \emph{Maximum Entropy Distribution} for a
certain Class of Probability Distributions minimizes the amount of Prior
Information (\S\ref{sec:prior_distribution}) built into the Distribution

\begin{itemize}
  \item the Log-normal Distribution (\S\ref{sec:lognormal_distribution}) is the
    Maximum Entropy Probability Distribution for a Random Variable $X$ for which
    the Mean and Variance of $\ln X$ are specified
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Memoryless Distribution}\label{sec:memoryless_distribution}
% ------------------------------------------------------------------------------

cf. Long-range Dependence (\S\ref{sec:long_range_dependence})

\begin{enumerate}
  \item Geometric Distributions (Discrete \S\ref{sec:geometric_distribution})
  \item Exponential Distributions (Continuous
    \S\ref{sec:exponential_distribution})
\end{enumerate}

cf. Markov Property



% ------------------------------------------------------------------------------
\subsection{Compound Probability Distribution}
\label{sec:compound_probability}
% ------------------------------------------------------------------------------

or \emph{Contagious Distribution}

cf. Doubly Stochastic Model (\S\ref{sec:doubly_stochastic})



\subsubsection{Mixture Distribution}\label{sec:mixture_distribution}

a Distribution realized by randomly selecting a Random Variable from a
collection of other Random Variables and then taking the Realization of the
selected Random Variable

a standard Cauchy Random Variable (\S\ref{sec:cauchy_distribution}) can be
viewed as a Mixture of Gaussian Random Variables with Zero Mean and Variance
drawn from a standard L\'evy Distribution (\S\ref{sec:levy_distribution})



\paragraph{Scale Mixture}\label{sec:scale_mixture}\hfill

selection Parameter is a Scale Parameter



% ------------------------------------------------------------------------------
\subsection{Tweedie Distribution}\label{sec:tweedie_distribution}
% ------------------------------------------------------------------------------

(wiki): \emph{Tweedie Convergence Theorem}: describes the Convergence of certain
Statistical Processes towards the Family of Statistical Models known as
\emph{Tweedie Distributions}; Variance-to-Mean Power Law (TODO: xref); cf.
Taylor's Power Law, \emph{Fluctuation Scaling}; alternative paradigm to explain
Power Law manifestations attributed to ``Self-organized Criticality''
(SOC \S\ref{sec:soc})

Pink ($1/f$) Noise

Normal Distribution (\S\ref{sec:normal_distribution}) is a member of the family
of Tweedie Exponential Dispersion Models (\S\ref{sec:exponential_dispersion})

\fist origin of ``Multifractality'' (\S\ref{sec:multifractal_system}) in
Sequential (Time Series) data attributed to ``convergence effects'' related to
the Central Limit Theorem (\S\ref{sec:central_limit}) that have Foci of
Convergence in the family of Tweedie Exponential Dispersion Models



% ------------------------------------------------------------------------------
\subsection{Quasiprobability Distribution}
\label{sec:quasiprobability_distribution}
% ------------------------------------------------------------------------------

relaxation of the Third Kolmogorov Axiom ($\sigma$-additivity
\S\ref{sec:probability_axioms})

to compensate some Quasiprobability Distributions have regions of Negative
Probability (\S\ref{sec:negative_probability}) Density, contradicting the First
Axiom

regions Integrated under them do not represent Probabilities of Mutually
Exclusive States (\S\ref{sec:mutually_exclusive})

cf. Phase Space (\S\ref{sec:phase_space}) Formulation of Quantum Mechanics:
Position and Momentum Variables on equal footing in Phase Space (cf.
Schr\"odinger formulation uses Position \emph{or} Momentum representations)

\fist Time-Frequency Analysis (\S\ref{sec:time_frequency_analysis}): analysis
of Signals with Time-varying Statistics (cf. Entropy \S\ref{sec:entropy}), e.g.
Transient Signals (\S\ref{sec:transient})



% ==============================================================================
\section{Discrete Probability Distribution}\label{sec:discrete_probability}
% ==============================================================================

Probability Distribution of a Discrete Random Variable
(\S\ref{sec:discrete_random_variable})

characterized by a Probability Mass Function (\S\ref{sec:pmf})

Cumulative Distribution Function (\S\ref{sec:cdf}) increases only by Jump
Discontinuities

\begin{itemize}
  \item \emph{Point Mass Distribution} -- $X \sim \delta_a$ has CDF:
    \[
      F_X(x) = \begin{cases}
        0 & x <    a \\
        1 & x \geq a \\
      \end{cases}
    \]
    and PMF:
    \[
      f_X(x) = \begin{cases}
        1 & x = a \\
        0 & \text{otherwise} \\
      \end{cases}
    \]
  \item \emph{Discrete Uniform Distribution} (\S\ref{sec:uniform_distribution})
  \item \emph{Multinomial Distribution} (\S\ref{sec:multinomial_distribution})
    -- $X \sim Multinomial_k(n,p)$
  \begin{itemize}
    \item \emph{Bernoulli Distribution} (\S\ref{sec:bernoulli_distribution}) --
      $X \sim Bernoulli(p)$
    \item \emph{Binomial Distribution} (\S\ref{sec:binomial_distribution}) --
      $X \sim Binomial(n,p)$
    \item \emph{Categorical Distribution} (\S\ref{sec:categorical_distribution})
      -- $X \sim Categorical(k,p)$
  \end{itemize}
  \item \emph{Geometric Distribution} (\S\ref{sec:geometric_distribution}) --
    $X \sim Geom(p)$
  \item \emph{Poisson Distribution} (\S\ref{sec:poisson_distribution}) --
    $X \sim Poisson(\lambda)$
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Multinomial Distribution}\label{sec:multinomial_distribution}
% ------------------------------------------------------------------------------

$n$ Trials

$k$ Outcomes or ``\emph{Categories}''

$k$ Outcomes $E_1, E_2, \ldots, E_k$

Probabilities $p_1, p_2, \ldots, p_k$

Probability Distribution of $x_1, x_2, \ldots, x_k$ number of
Occurences for $E_1, E_2, \ldots, E_k$ in $n$ Independent Trials:
\[
  f(x_1, x_2, \ldots, x_k) = \binom{n}{x_1, x_2, \ldots, x_k} =
    p_1^{x_1} p_2^{x_2} \cdots p_k^{x_k}
\]
and $\sum_{i=1}^k x_i = n$ and $\sum_{i=1}^k {p_i} = 1$

for $X = (X_1, \ldots, X_k) \sim Multinomial_k(n, p)$ and
$p = (p_1, \ldots, p_k)$, the Marginal Distribution
(\S\ref{sec:marginal_distribution}) of $X_j$ is $Binomial (n, p_j)$

\begin{itemize}
  \item Bernoulli Distribution (\S\ref{sec:bernoulli_distribution}) -- $k = 2$,
    $n = 1$
  \item Binomial Distribution (\S\ref{sec:binomial_distribution}) -- $k = 2$,
    $n > 1$
  \item Categorical Distribution (\S\ref{sec:categorical_distribution}) --
    $k > 2$, $n = 1$
\end{itemize}



\subsubsection{Bernoulli Distribution}\label{sec:bernoulli_distribution}

$k = 2$, $n = 1$

for a Random Variable $X$ representing a Binary Outcome:
\begin{itemize}
  \item $P(X=1) = p$
  \item $P(X=0) = 1-p$
\end{itemize}
for some $p \in [0,1]$

Mean:
\[
  \mu = p
\]
Variance:
\[
  \sigma^2 = p(1-p)
\]
PMF:
\[
  f(x) = p^x(1-p)^{1-x}
\]
or equivalently:
\[
  f(x) = \begin{cases}
    p   & x = 1 \\
    1-p & x = 0 \\
  \end{cases}
\]
for $x \in \{0, 1\}$

\fist cf. Logistic Regression (\S\ref{sec:logistic_regression}) -- Model with
Binary Data $Y_i$, the Conditional Distribution $y | x$ is Bernoulli
Distributed:
\[
  Y_i | X_i = x_i \sim Bernoulli(p_i)
\]
(cf. Linear Regression where the Conditional Distribution is Normally
Distributed)

generalization: Categorical Distribution (\S\ref{sec:categorical_distribution})



\subsubsection{Binomial Distribution}\label{sec:binomial_distribution}

Sum of Independent Trials; cf. Normal Distribution
(\S\ref{sec:normal_distribution})

Binomial (Bernoulli) Trial (\S\ref{sec:binomial_trial})

Binomial Random Variable (\S\ref{sec:binomial_variable})

$k = 2$ , $n > 1$

cf. Binomial Coefficients (\S\ref{sec:binomial_coefficient})

Random Variable $X$ with Binomial Distribution where $n \in \nats$ and
$p \in [0,1]$:
\[
  X \sim B(n,p)
\]
describes the Probability of getting exactly $x$ ``Successes'' in $n$ Trials
where the Probability of Success is $p$:
\[
  P(x,n,p) = \binom{n}{x}p^x(1-p)^{n-x}
\]

\fist Poisson Distribution (\S\ref{sec:poisson_distribution}) -- Limit of the
Binomial Distribution as number of Trials $n \to \infty$

Expected Value $E(X) = np$

Mean $\mu = n p$

Variance $\sigma^2 = n p (1-p)$

Sample Proportion %FIXME



\paragraph{Negative Binomial Distribution}\label{sec:negative_binomial}\hfill

$b^*(x; k,p) = \binom{x-1}{k-1} p^k 2^{k-k}$

Infinitely Divisible (\S\ref{sec:infinitely_divisible})



\subparagraph{Geometric Distribution}\label{sec:geometric_distribution}\hfill

$P(X = k) = p(1-p)^{k-1}$ for $k \in \{1, 2, 3, \ldots\}$

where $X$ is the number of Independent Trials with Constant Probability of
``Success'' until the first Success

\emph{Memoryless} (\S\ref{sec:memoryless_distribution})

\fist Continuous analogue: Exponetial Distribution
(\S\ref{sec:exponential_distribution})

cf. Geometric Series (\S\ref{sec:geometric_series})

Expected Value $E(X) = 1 + (1-p) + (1-p)^2 + \cdots = \frac{1}{p}$



\paragraph{Normal Approximation}\label{sec:normal_approximation}\hfill

For Binomial Random Variable $X$ with Mean $\mu = np$ and Variance
$\sigma^2 = npq$, then:
\[
  Z = \frac{X - np}{\sqrt{npq}}
\]
as $n \to \infty$ is the Standard Normal Distribution
(\S\ref{sec:normal_distribution}) $n(Z;0,1)$



\subsubsection{Categorical Distribution}\label{sec:categorical_distribution}

$k > 2$, $n = 1$

Standard (Probability) Simplex (\S\ref{sec:simplex})



\subsubsection{Softmax Function}\label{sec:softmax}

or \emph{Normalized Exponential Function}

generalization of Logistic Function (\S\ref{sec:logistic_function}); the
Logistic Function is the Derivative of Softplus --TODO

output can be used to represent a Categorical Distribution

often used as final layer of a Neural Network-based Classifier


% ------------------------------------------------------------------------------
\subsection{Poisson Distribution}\label{sec:poisson_distribution}
% ------------------------------------------------------------------------------

$P(x; \lambda t) = \frac{e^{-\lambda t} (\lambda t)^x}{x!}$
where $\lambda$ is the average number of outcomes per unit time

Expected Value is the Limit of the Binomial Distribution as number of Trials
$n \to \infty$:
\begin{flalign*}
  E(X) & = \lambda \\
  V(X) & = \lambda \\
  P(X = k) & = \lim_{n\to\infty}
               \binom{n}{k}(\frac{\lambda}{n})^k(1-\frac{\lambda}{n})^{n-k} \\
           & = \frac{\lambda^k e^{-\lambda}}{k!} \\
\end{flalign*}

events occur with a Constant known \emph{Mean Rate}, Independently of the time
since the last event; cf. Exponential Distribution
(\S\ref{sec:exponential_distribution})

models counts of rare events, e.g. radioactive decay, traffic accidents (cf.
Propensity Interpretation of Probability)

Infinitely Divisible (\S\ref{sec:infinitely_divisible})

cf. Poisson Processes (\S\ref{sec:poisson_process})

\fist Poisson Noise (Shot Noise): Statistical Fluctuations
(\S\ref{sec:statistical_fluctuation})

for Independent Random Variables $X \sim Poisson(\lambda)$ and
$Y \sim Poisson(\nu)$:
\[
  X + Y \sim Poisson(\lambda + \nu)
\]

if $N \sim Poisson(\lambda)$ and $Y | N = n \sim Binomial(n,p)$, then the
Marginal Distribution of $Y$ is $Y \sim Poisson(\lambda p)$
(Wasserman04 \S 23.3)



% ------------------------------------------------------------------------------
\subsection{Hypergeometric Distribution}
\label{sec:hypergeometric_distribution}
% ------------------------------------------------------------------------------

$h(x; N, n, k) = \frac{\binom{k}{x} \binom{N-k}{n-x}}{\binom{N}{n}}$

Mean $\mu = \frac{nk}{N}$

Variance $\sigma^2 = \frac{N-n}{N-1} n \frac{k}{N}(1 - \frac{k}{N})$



\subsubsection{Multivariate Hypergeometric Distribution}
\label{sec:multivariate_hypergeometric}



% ------------------------------------------------------------------------------
\subsection{Parabolic Fractal Distribution}
\label{sec:parabolic_fractal_distribution}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Discrete Power Law Distribution}\label{sec:discrete_power_law}
% ------------------------------------------------------------------------------

\fist Continuous Power Law Distributions (\S\ref{sec:continuous_power_law})

Slowly Varying Function (\S\ref{sec:slowly_varying})



\subsubsection{Zipf Distribution}\label{sec:zipf_distribution}

\subsubsection{Zeta Distribution}\label{sec:zeta_distribution}

Normalization of the Zipf Distribution



\subsubsection{Yule-Simon Distribution}\label{sec:yule_simon_distribution}



% ==============================================================================
\section{Continuous Probability Distribution}\label{sec:continuous_probability}
% ==============================================================================

Probability Distribution of a Continuous Random Variable
(\S\ref{sec:continuous_random_variable})

characterized by a Probability Density Function (\S\ref{sec:pdf})

has a Continuous Cumulative Distribution Function (\S\ref{sec:cdf})

\fist Discrete Power Law Distributions
(\S\ref{sec:discrete_power_law})

\begin{itemize}
  \item \emph{Uniform Distribution} (\S\ref{sec:uniform_distribution}) --
    $X \sim Uniform(a,b)$
  \item \emph{Normal (Gaussian) Distribution} (\S\ref{sec:normal_distribution})
    -- $X \sim N(\mu, \sigma^2)$
  \item \emph{Exponential Distribution} (\S\ref{sec:exponential_distribution})
    -- $X \sim Exp(\beta) = Gamma(1, \beta)$
  \item \emph{Gamma Distribution} (\S\ref{sec:gamma_distribution})
    -- $X \sim Gamma(\alpha, \beta)$
  \item \emph{Beta Distribution} (\S\ref{sec:beta_distribution})
    -- $X \sim Beta(\alpha, \beta)$
  \item \emph{$t$-distribution} (\S\ref{sec:t_distribution})
    -- $X \sim t_\nu$
  \item \emph{Cauchy-Lorenz Distribution} (\S\ref{sec:cauchy_distribution})
    -- $X \sim t_\nu=1$
  \item \emph{$\chi^2$-distribution} (\S\ref{sec:chi_squared})
    -- $X \sim \chi^2_p$
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Generalized Hyperbolic Distribution}
\label{sec:generalized_hyperbolic}
% ------------------------------------------------------------------------------

closed under Affine Transformations (\S\ref{sec:affine_transformation})



\subsubsection{$t$-distribution}\label{sec:t_distribution}

(or \emph{Student's $t$-distribution})

$\nu$ -- Degrees of Freedom

a Quotient Distribution (\S\ref{sec:quotient_distribution}) of a Gaussian Random
Variable and a Chi-distributed (\S\ref{sec:chi_distribution}) Random Variable

\begin{itemize}
  \item $\nu = 1$ -- Cauchy Distribution (\S\ref{sec:cauchy_distribution})
  \item $\nu = \infty$ -- Normal Distribution (\S\ref{sec:normal_distribution})
\end{itemize}

Sampling Distribution (\S\ref{sec:sampling_distribution}) for low Sample Size

Fat-tailed Distribution (\S\ref{sec:fat_tailed})

$t$-statistic (\S\ref{sec:t_statistic})

$t$-test (\S\ref{sec:t_test})

Infinitely Divisible (\S\ref{sec:infinitely_divisible})



\paragraph{Cauchy Distribution}\label{sec:cauchy_distribution}\hfill

\emph{Cauchy-Lorentz Distribution} or \emph{Normal Ratio Distribution}

$\nu = 1$

the Ratio (Quotient Distribution \S\ref{sec:quotient_distribution}) $X_1/X_2$ of
two Normally Distributed Independent Random Variables $X_1, X_2 \sim N(0,1)$

Expected Value (\S\ref{sec:expected_value}) and Variance (\S\ref{sec:variance})
are \emph{undefined}

a Stable Distribution (\S\ref{sec:stable_distribution}): a Linear Combination of
two Independent Cauchy-distributed Random Variables is also a Cauchy
Distribution

a standard Cauchy Random Variable can be viewed as a Mixture
(\S\ref{sec:mixture_distribution}) of Gaussian Random Variables with Zero Mean
and Variance drawn from a standard L\'evy Distribution
(\S\ref{sec:levy_distribution})

the ``average'' of $n$ Independent Cauchy Random Variables with $x_0 = 0$
\emph{does not} Converge to $0$ as $n \to \infty$ with Probability $1$-- ``it''
stays a Cauchy Distribution of the same size; however $0$ is the \emph{Median}
and \emph{Mode} (FIXME: clarify)
--\url{https://stats.stackexchange.com/questions/36027/why-does-the-cauchy-distribution-have-no-mean}

\url{https://stats.stackexchange.com/questions/232967/what-makes-the-mean-of-some-distributions-undefined/233950#233950}:
the Cauchy Distribution is a ``disguised'' form of the Uniform Distribution on a
Circle

has no Moment-generating Function (\S\ref{sec:moment_generating_function})

Cauchy Flight (\S\ref{sec:cauchy_flight}) -- Random Walk with step lengths
distributed according to a Cauchy Distribution



\subparagraph{Log-Cauchy Distribution}\label{sec:log_cauchy}\hfill

Heavy-tailed (\S\ref{sec:heavy_tailed})

``Extreme'' Randomness

Logarithmically decaying Tail



\paragraph{Normal Distribution}\label{sec:normal_distribution}\hfill

(or \emph{Gaussian Distribution})

member of the family of Tweedie (\S\ref{sec:tweedie_distribution}) Exponential
Dispersion Models (\S\ref{sec:exponential_dispersion})

a Stable Distribution (\S\ref{sec:stable_distribution}): a Linear Combination of
two Independent Normally-distributed Random Variables is also a Normal
Distribution

\[
  n (x; \mu, \sigma) =
  \frac{1}{\sqrt{2\pi \sigma}} e^{-\frac{1}{2 \sigma^2}(x - \mu)^2}
\]

cf. Binomial Distribution (Discrete \S\ref{sec:binomial_distribution})
-- Sum of Independent Trials

\emph{Additive Phenomena}; cf. \emph{Multiplicative Phenomena} (Log-normal)

a Normal Distribution corresponds to a $t$-distribution
(\S\ref{sec:t_distribution}) with $\nu = \infty$ Degrees of Freedom

the Ratio $X_1/X_2$ of two Normally Distributed Independent Random Variables
$X_1, X_2 \sim N(0,1)$ is a Cauchy Distribution
(\S\ref{sec:cauchy_distribution})

\fist a Generalized Normal Distribution adds a Shape Parameter
(\S\ref{sec:shape_parameter}) to the Normal Distribution

if $X$ is Normally Distributed, then the Process $Y = e^X$ has a
\emph{Log-normal Distribution} (\S\ref{sec:lognormal_distribution}), i.e. $\ln Y
= X$ is Normally Distributed

\emph{Central Limit Thoerem} (\S\ref{sec:central_limit}) -- ``the Distribution
of a Sum of Independent Random Variables can be approximated by a Normal
Distribution'';
for a Sequence of Random Variables (\S\ref{sec:random_variable})
$X_i, \ldots, X_n$ with Sample Mean (\S\ref{sec:sample_mean})
$\overline{X}_n$, $\sqrt{n}(\overline{X}_n - \mu)$
\emph{Converges in Distribution} to a Normal Distribution
(\S\ref{sec:normal_distribution}) as $n \to \infty$, i.e. the Sample
Mean has approximately a Normal Distribution for large $n$

as a consequence of the Central Limit Theorem, Random Errors
(\S\ref{sec:random_error}) tend to be Normally Distributed

cf. Heavy-tailed Distributions (\S\ref{sec:heavy_tailed}) --
Distributions with Tails ``heavier'' than the Normal Distribution

cf. Sub-gaussian Distributions (Short-tailed Distributions
\S\ref{sec:sub_gaussian}) -- Tails ``lighter'' than the Normal Distribution

\fist Gaussian Processes (\S\ref{sec:gaussian_process}) can be seen as
Infinite-dimensional generalizations of Multivariate Normal Distributions

\fist Gaussian Random Walk (\S\ref{sec:gaussian_random_walk}): Random Walk in
which the step size varies according to a Normal Distribution

(Mandelbrot97E) Randomness: ``mild'' (Gaussian), ``slow'' (Log-normal), ``wild''
(Scaling with Infinite Variance, i.e. $\alpha < 2$)

\emph{Empirical Rule} 68-95-99.7 Rule -- 68\% within 1 Standard Deviation of the
Mean, 95\% within 2 Standard Deviations, 99.7\% within 3 Standard Deviations

MIT 6.041SC, Lec.8

Linear Functions of Normal Variables are Normal--
for $X \sim N(\mu, \sigma^2)$ and $Y = aX + b$:
\[
  Y \sim N(a \mu + b, a^2 \sigma^2)
\]

\emph{Standardizing} -- for $X \sim N(\mu, \sigma^2)$:
\[
  \frac{X - \mu}{\sigma} \sim N(0, 1)
\]
where $(X - \mu)/\sigma$ is the \emph{Standard Score}
($z$-score \S\ref{sec:standard_score})

2018 - Eric Jang
- \emph{Normalizing Flows Tutorial}
- \url{https://blog.evjang.com/2018/01/nf1.html}



\subparagraph{Mill's Inequality}\label{sec:mills_inequality}\hfill

\textbf{Thm.} (Mill's Inequality) \emph{
  For $Z \sim N(0,1)$:
  \[
    P(|Z| > t) \leq \sqrt{\frac{2}{\pi}}\frac{e^{-t^2/2}}{t}
  \]
}



\subparagraph{Standard Normal Distribution}\label{sec:standard_normal}\hfill

Mean $\mu = 0$

Variance $\sigma^2 = 1$

by convention Standard Normal Random Variables are denoted by $Z$, PDF by
$\phi(z)$ and CDF by $\Phi(z)$

there is no Closed-form Expression (\S\ref{sec:closed_form_expression}) for
$\Phi$ (requires use of the Error Function \S\ref{sec:error_function})



\subparagraph{Truncated Normal Distribution}\label{sec:truncated_normal}\hfill

\subparagraph{Multivariate Normal Distribution}\label{sec:multivariate_normal}
\hfill

Multivariate Random Variable (\S\ref{sec:random_vector})



\subparagraph{Elliptical Distribution}\label{sec:elliptical_distribution}
\hfill

generalization of Multivariate Normal Distribution



\paragraph{Folded Normal Distribution}\label{sec:folded_normal}\hfill

\subparagraph{Half-normal Distribution}\label{sec:half_normal}\hfill



\subsubsection{Hyperbolic Distribution}\label{sec:hyperbolic_distribution}

\subsubsection{Generalized Normal Distribution}\label{sec:generalized_normal}

adds a Shape Parameter (\S\ref{sec:shape_parameter}) to the Normal Distribution
(\S\ref{sec:normal_distribution})



\paragraph{Exponential Power Distribution}\label{sec:exponential_power}\hfill

or \emph{Generalized Error Distribution}



\subparagraph{Laplace Distribution}\label{sec:laplace_distribution}\hfill



\paragraph{Log-normal Distribution}\label{sec:lognormal_distribution}\hfill

or \emph{Galton Distribution}

if $X$ is Normally Distributed (\S\ref{sec:normal_distribution}), then the
Process $Y = e^X$ has a \emph{Log-normal} Distribution, i.e. $\ln Y = X$ is
Normally Distributed

\emph{Multiplicative Phenomena}; cf. \emph{Additive Phenomena} (Gaussian)

the Log-normal Distribution is the Maximum Entropy Probability Distribution
(\S\ref{sec:maximum_entropy}) for a Random Variable $X$ for which the Mean and
Variance of $\ln X$ are specified

assumed by Black-Scholes Model as changes in prices, rates, indices etc.; cf.
Log-L\'evy Distribution (\S\ref{sec:log_levy})

(Mandelbrot97E) Randomness: ``mild'' (Gaussian), ``slow'' (Log-normal), ``wild''
(Scaling with Infinite Variance, i.e. $\alpha < 2$)

\begin{quote}
  Slow randomness is a complex intermediate state between two states of greater
  simplicity.
\end{quote}



% ------------------------------------------------------------------------------
\subsection{Inverse Gaussian Distribution}\label{sec:inverse_gaussian}
% ------------------------------------------------------------------------------

(or \emph{Wald Distribution})



\subsubsection{Generalized Inverse Gaussian Distribution}
\label{sec:generalized_inverse_gaussian}



% ------------------------------------------------------------------------------
\subsection{Gamma Distribution}\label{sec:gamma_distribution}
% ------------------------------------------------------------------------------

Gamma Function (\S\ref{sec:gamma_function})

Continuous Random Variable $X$ with parameters $\alpha > 0$ and $\beta
> 0$:
\[
  f(x; \alpha, \beta) =
  \begin{cases}
    \frac{1}{\beta^\alpha \Gamma(\alpha)} x^{\alpha-1} e^{\sfrac{-x}{\beta}}
      & \quad x > 0 \\
    0 & \quad\text{else} \\
  \end{cases}
\]

Mean $\mu = \alpha \beta$

Variance $\sigma^2 = \alpha \beta^2$

Infinitely Divisible (\S\ref{sec:infinitely_divisible})



\subsubsection{Exponential Distribution}\label{sec:exponential_distribution}

a $Gamma(1, \beta)$ Distribution

Probability Distribution of the Time between Events in a Poisson Point Process
(\S\ref{sec:point_poisson})

Continuous Random Variable $X$ with parameter $\beta > 0$:
\[
  f(x; \beta) =
  \begin{cases}
  \frac{1}{\beta} e^{\sfrac{-x}{\beta}}     & \quad x > 0 \\
  0     & \quad\text{else} \\
  \end{cases}
\]

models lifetimes of electronic components, wait times between rare events

\emph{Memoryless} (\S\ref{sec:memoryless_distribution})

\fist Discrete analogue: Geometric Distribution
(\S\ref{sec:geometric_distribution})

cf. \emph{Fat-tailed Distributions} (\S\ref{sec:fat_tailed}) -- Tails are
\emph{not} Exponentially Bounded

(Mandelbrot97E)

Invariant under change of \emph{Location}; the time since the last event has no
effect on the expected wait time until the next event (cf. Poisson Distribution
\S\ref{sec:poisson_distribution})

from an Exponentially Distributed $V$, a Scaling
(\S\ref{sec:scaling_distribution}) $U$ is obtained by $U = e^V$, is Invariant
under change of \emph{Scale}



\paragraph{Double Exponential Distribution}\label{sec:double_exponential}\hfill

or \emph{Laplace Distribution}



\subsubsection{$\chi^2$ Distribution}\label{sec:chi_squared}

Non-symmetric

Sums of Squared IID Normally-distributed Random Variables, where the number of
Variables is the ``Degrees of Freedom''

\[
  f(x; v) =
  \begin{cases}
    \frac{1}{2^{\sfrac{v}{2}}\Gamma(\sfrac{v}{2})}
      x^{\sfrac{v}{2-1}} e^{\sfrac{-x}{2}}
          & \quad x > 0 \\
    0     & \quad\text{else} \\
  \end{cases}
\]

Goodness-of-fit (\S\ref{sec:model_fit})

Chi-squared Statistic -- Randomness Condition, Large Counts Condition ($>5$
expected), Independence Condition

\fist Chi-squared Test (\S\ref{sec:chi_squared_test})

Logistic Regression

the $F$-distribution (\S\ref{sec:f_distribution}) is a Quotient Distribution
(\S\ref{sec:quotient_distribution}) defined as the Ratio of two Independent
$\chi$-squared Distributed Random Variables



\paragraph{$\chi$ Distribution}\label{sec:chi_distribution}\hfill

Distribution of Positive Square Roots of a Chi-squared Distributed Random
Variable

the $t$-distribution (\S\ref{sec:t_distribution}) is a Quotient Distribution
(\S\ref{sec:quotient_distribution}) defined as the Ratio of a Gaussian Random
Variable and an Independent $\chi$-distributed Random Variable



\subparagraph{Rayleigh Distribution}\label{sec:rayleigh_distribution}\hfill

Chi Distribution with $2$ Degrees of Freedom

Asymptotic Function for Two-dimensional Random Walk (\S\ref{sec:random_walk})



\paragraph{$F$-distribution}\label{sec:f_distribution}\hfill

(Fisher)

a Quotient Distribution (\S\ref{sec:quotient_distribution}) defined as the Ratio
of two Independent $\chi$-squared Distributed Random Variables

can be seen as a Ratio of Chi-squared Distributions with not necessarily the
same DoFs

$F$-statistic (\S\ref{sec:f_statistic})

$F$-test (\S\ref{sec:f_test})

$F = \frac{\text{between-group variability}}{\text{within-group variability}}$

$F = \frac{\frac{SSB}{DoF_B}}{\frac{SSW}{DoF_W}}$

ANOVA (\S\ref{sec:variance_analysis}), Linear Regression



\subsubsection{Wishart Distribution}\label{sec:wishart_distribution}



% ------------------------------------------------------------------------------
\subsection{Gompertz Distribution}\label{sec:gompertz_distribution}
% ------------------------------------------------------------------------------

Distribution of Walk Length of Random Self-avoiding Walks
(\S\ref{sec:selfavoiding_walk}) in the Erdos-R\'enyi Model
(\S\ref{sec:erdos_renyi_model})



% ------------------------------------------------------------------------------
\subsection{Fat-tailed Distribution}\label{sec:fat_tailed}
% ------------------------------------------------------------------------------

Tails are \emph{not} Exponentially Bounded (cf. Exponential Distributions
\S\ref{sec:exponential_distribution})

\fist Self-similar Processes (\S\ref{sec:self_similar}), Long-range Dependence
(\S\ref{sec:long_range_dependence}), Power Law Distributions
(\S\ref{sec:power_law})

\begin{itemize}
  \item Cauchy Distribution (\S\ref{sec:cauchy_distribution})
  \item Log-normal Distribution (\S\ref{sec:lognormal_distribution})
  \item ...
\end{itemize}

(Taleb 2020):

``Thick-tailed Distributions'' -- higher Kurtosis than Gaussian

``Fat-tailed Distributions'' -- ``extreme'' Thick Tails, or membership of a
Power-law Class



\subsubsection{Heavy-tailed Distribution}\label{sec:heavy_tailed}

Tails that are ``heavier'' than the Normal Distribution
(\S\ref{sec:normal_distribution})

Leptokurtic (Positive Kurtosis)

Log-cauchy (\S\ref{sec:log_cauchy}) -- Logarithmically decaying Tail;
``Extreme'' Randomness



\subsubsection{Long-tailed Distribution}\label{sec:long_tailed}

``Tail-preserving'' (Mandelbrot97E)



\subsubsection{Subexponential Distribution}
\label{sec:subexponential_distribution}

\subsubsection{Continuous Power Law Distribution}
\label{sec:continuous_power_law}

Scale Invariance (\S\ref{sec:scale_invariance})

Slowly Varying Function (\S\ref{sec:slowly_varying})



\paragraph{Pareto Distribution}\label{sec:pareto_distribution}\hfill

prototypical Power Law (\S\ref{sec:power_law}) Distribution

Scale Invariance (\S\ref{sec:scale_invariance})

$x_m > 0$ -- Scale Parameter

$\alpha > 0$ -- Shape Parameter

Mean:
\[
  \expect(X) = \begin{cases}
    \infty                      & \alpha \leq 1 \\
    \frac{\alpha x_m}{\alpha-1} & \alpha > 1 \\
  \end{cases}
\]

PDF: $\frac{\alpha x_m^\alpha}{x^{\alpha+1}}$

CDF: $1 - \Big(\frac{x_m}{x}\Big)^\alpha$

approaches $\delta(x - x_m)$ as $\alpha \to \infty$ where $\delta$ is the Dirac
Delta (\S\ref{sec:dirac_delta})

the step lengths in a L\'evy Staircase (\S\ref{sec:levy_staircase}) are
distributed according to a Pareto Distribution with Scale $x_m = 1$

--FIXME: is the Pareto Distribution with scale parameter $x_m = 1$ the same
thing as a Scaling Distribution (\S\ref{sec:scaling_distribution}) ???

Mandelbrot 1963



\subsubsection{Inverse Gamma Distribution}\label{sec:inverse_gamma}

%FIXME: are all inverse gamma distributions fat-tailed ???



\paragraph{L\'evy Distribution}\label{sec:levy_distribution}\hfill

L\'evy Flight (\S\ref{sec:levy_flight}) -- Random Walk with step length varying
according to a L\'evy Distribution

a Stable Distribution (\S\ref{sec:stable_distribution}): a Linear Combination of
two Independent L\'evy-distributed Random Variables is also a L\'evy
Distribution

a standard Cauchy Random Variable (\S\ref{sec:cauchy_distribution}) can be
viewed as a Mixture (\S\ref{sec:mixture_distribution}) of Gaussian Random
Variables with Zero Mean and Variance drawn from a standard L\'evy Distribution

a Cauchy Process (\S\ref{sec:cauchy_process}) can be seen as a Brownian Motion
Subordinated (\S\ref{sec:compound_process}) to a Process associated with a L\'evy
Distribution



\subparagraph{Log-L\'evy Distribution}\label{sec:log_levy}\hfill

Finance: Distribution of changes in rates, prices, indices, etc. (Mandelbrot);
cf. Black-Scholes changes are assumed to be Log-normal
(\S\ref{sec:lognormal_distribution})



% ------------------------------------------------------------------------------
\subsection{Stable Distribution}\label{sec:stable_distribution}
% ------------------------------------------------------------------------------

A \emph{Stable Distribution} (or \emph{L\'evy Alpha-stable Distribution} or
\emph{Stable Paretian Distribution}) has the Property that a Linear Combination
of two Independent Random Variables within the Distribution has the same
Distribution up to Location and Scale Parameters.

\emph{Stability Parameter} -- $\alpha \in (0, 2]$

\emph{Skewness Parameter} -- $\beta \in [-1, 1]$; note that the actual Skewness
of the resulting Distribution is not well defined for $\alpha < 2$

\emph{Scale Parameter} -- $c = (0, \infty)$

\emph{Location Parameter} -- $\mu \in (-\infty, \infty)$

\begin{itemize}
  \item Normal Distribution (\S\ref{sec:normal_distribution}) -- $\alpha = 2$
    ($\beta$ has no effect); has Variance $\sigma^2 = 2c^2$ and Mean $\mu$
  \item Cauchy Distribution (\S\ref{sec:cauchy_distribution}) --
    $\alpha = 1, \beta = 0$
  \item L\'evy Distribution (\S\ref{sec:levy_distribution}) --
    $\alpha = 1/2, \beta = 1$
\end{itemize}

a standard Cauchy Random Variable can be viewed as a Mixture
(\S\ref{sec:mixture_distribution}) of Gaussian Random Variables with Zero Mean
and Variance drawn from a standard L\'evy Distribution

Stable Distributions are Infinitely Divisible (\S\ref{sec:infinitely_divisible})

Stable Distributions are Closed under Convolution (FIXME: clarify)

All Stable Distributions except the Normal Distribution (i.e. $\alpha < 2$ are
Fat-tailed Distributions (\S\ref{sec:fat_tailed}) with undefined (Infinite)
Variance

any Non-degenerate Stable Distribution has a Smooth (Infinitely Differentiable)
Probability Density Function

``$L$-stable Distribution'', ``Scaling Sum Distribution'' (Mandelbrot 1963)
%FIXME: is l-stable distribution synonymous with stable distribution ???

$L$-stable Distributions are the only Non-Gaussian Limits of Linearly Weighted
Sums of Random Variables

(Mandelbrot63) Invariance under Linear Aggregation
(S\ref{sec:observational_transformation}), Central Limite Theorem; cf.
Autoregressive Models (\S\ref{sec:autoregressive_model})

a Stable Process (\S\ref{sec:stable_process}) is a Stochastic Process for which
associated Probability Distributions (FIXME: clarify) are Stable Distributions;
cf. $L$-Stable Motion (LSM \S\ref{sec:lsm})

Stable Probability Distributions are ``Attractors'' for ``properly normed'' Sums
of IID Random Variables (\S\ref{sec:iid})-- Central Limit Theorem
(\S\ref{sec:central_limit_theorem}): the Normal Distribution is the ``properly
normed'' Sum of a Set of Random Variables with Finite Variance



\subsubsection{Symmetric $\alpha$-stable Distribution}
\label{sec:symmetric_alpha_stable}

the Characteristic Function of a (L\'evy) Symmetric $\alpha$-stable Distribution
is a Stretched Exponential Function (\S\ref{sec:stretched_exponential})



\subsubsection{One-sided Stable Distribution}\label{sec:onesided_stable}

$\beta = 1$

$\alpha < 1$

the Stable Count Distribution (\S\ref{sec:stable_count}) is the Conjugate Prior
(\S\ref{sec:conjugate_prior}) of a One-sided Stable Distribution



\subsubsection{Max-stable Distribution}\label{sec:max_stable}

\emph{Maximum Stability Postulate}

Fr\'echet Distribution (\S\ref{sec:frechet_distribution})



% ------------------------------------------------------------------------------
\subsection{Dirichlet Distribution}\label{sec:dirichlet_distribution}
% ------------------------------------------------------------------------------

or \emph{Multivariate Beta Distribution (MBD)}

commonly used as Prior Distributions (\S\ref{sec:prior_distribution}) in
Bayesian Statistics



\subsubsection{Symmetric Dirichlet Distribution}\label{sec:symmetric_dirichlet}

\subsubsection{Beta Distribution}\label{sec:beta_distribution}

Gamma Function (\S\ref{sec:gamma_function})



% ------------------------------------------------------------------------------
\subsection{Phase-type Distribution}\label{sec:phasetype_distribution}
% ------------------------------------------------------------------------------

\begin{itemize}
  \item Degenerate Distribution (TODO) -- 0
    Phases
  \item Exponential Distribution (\S\ref{sec:exponential_distribution}) -- 1
    Phase
  \item Erlang Distribution (TODO) -- 2 or more identical Phases in sequence
  \item ...
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Generalized Extreme Value (GEV) Distribution}\label{sec:gev}
% ------------------------------------------------------------------------------

Extreme Value Theory (\S\ref{sec:eva})

by the Extreme Value Theorem, the GEV Distribution is the only \emph{possible}
Limit Distribution of Normalized Maxima of a Sequence of IID Random Variables,
but such a Limit Distribution does not necessarily exist, requiring
\emph{Regularity Conditions} on the Tail of the Distribution



\subsubsection{Gumbel Distribution}\label{sec:gumbel_distribution}

\subsubsection{Fr\'echet Distribution}\label{sec:frechet_distribution}

Max-stable (\S\ref{sec:max_stable})

the CDF with $m = 0$ and $s = 1$:
\[
  e^{-x^{-\alpha}}
\]
is Weakly Scaling (\S\ref{sec:scaling_distribution})



\subsubsection{Weibull Distribution}\label{sec:weibull_distribution}

the Complementary Cumulative (\S\ref{sec:complementary_cumulative}) Weibull
Distribution is given by a Stretched Exponential
(\S\ref{sec:stretched_exponential})

first applied to describe a Particle Size Distribution



% ------------------------------------------------------------------------------
\subsection{Sub-gaussian Distribution}\label{sec:sub_gaussian}
% ------------------------------------------------------------------------------

or \emph{Short-tailed Distribution}

``Platykurtic'' (Negative Kurtosis)

cf. Heavy-tailed Distribution (\S\ref{sec:heavy_tailed})

Uniform Distribution

Raised Cosine Distribution

Sub-gaussian Distributions



% ==============================================================================
\section{Singular Probability Distribution}\label{sec:singular_distribution}
% ==============================================================================

a Distribution ``concentrated'' on a Set of Lebesgue Measure Zero where
the Probability of each Point in the Set is Zero

CDFs are Singular (\S\ref{sec:singular_function}) and Continuous
(\S\ref{sec:real_continuous})



% ------------------------------------------------------------------------------
\subsection{Cantor Distribution}\label{sec:cantor_distribution}
% ------------------------------------------------------------------------------

CDF: Cantor's Staircase Function (\S\ref{sec:cantor_staircase})



% ==============================================================================
\section{Statistical Analysis}\label{sec:statistical_analysis}
% ==============================================================================

Statistical Theory -- FIXME

Statistical Population (\S\ref{sec:population})

Statistical Sample (\S\ref{sec:sample})

Statistic (\S\ref{sec:statistic}) -- a Function of a Random Variable
(\S\ref{sec:random_variable}) constituting a Random Sample

Descriptive Statistics (\S\ref{sec:descriptive_statistics})

Statistical Parameter (\S\ref{sec:population_parameter})

Statistical Model (\S\ref{sec:statistical_model})

Statistical Inference (\S\ref{sec:inferential_statistics})

Statistical Learning Theory (\S\ref{sec:statistical_learning_theory})

\emph{Statistical Studies}:
\begin{itemize}
  \item Sample Study -- Population Parameter Estimate (Statistic)
  \item Observational Study -- Explanatory, Explained Variables (Correlation)
  \item Experimental Study -- Control, Treatment (Causality)
\end{itemize}

1981 - Cox, Snell - \emph{Applied Statistics: Principles and Examples}



% ------------------------------------------------------------------------------
\subsection{Population}\label{sec:population}
% ------------------------------------------------------------------------------

\emph{Statistical Population}

totality of Observations (\S\ref{sec:observation})

Value of a Random Variable $X$ having some Probability Distribution $f(x)$

Paired Observation (Dependent), Unpaired Observation (Independent) (TODO: xref)

(wiki):

\emph{Statistical Population} -- a Set of ``similar items'' or Events
(\S\ref{sec:probability_event}) of interest

\fist cf. Data Generating Process (\S\ref{sec:data_generating_process}), Data
Collection (\S\ref{sec:data_collection})

A Subset of the Population is a \emph{Statistical Sample} (\S\ref{sec:sample}).
A \emph{Statistical Model} (\S\ref{sec:statistical_model}) is a Set of
Statistical Assumptions (\S\ref{sec:statistical_assumption}) concerning the
Generation (\S\ref{sec:data_generating_process}) of Sample Data.

A \emph{Statistical Hypothesis} is a Conjecture (\S\ref{sec:conjecture})
concerning one or more Populations.



% ------------------------------------------------------------------------------
\subsection{Data Generating Process}\label{sec:data_generating_process}
% ------------------------------------------------------------------------------

(wiki):

\begin{itemize}
  \item \emph{Data Collection} (\S\ref{sec:data_collection})
  \item a ``notional'', \emph{non-specific} Probabilistic Model
    that would include all of the ``Random influences'' that lead to individual
    Observations (\S\ref{sec:observation})
  \item a \emph{specific} \emph{Statistical Model}
    (\S\ref{sec:statistical_model}) used to represent Random Variations in
    Observations
\end{itemize}

\fist \emph{Model Validation} (\S\ref{sec:model_validation}) is the process of
confirming that the ``outputs'' of a Statistical Model are ``acceptable'' with
respect to the ``real'' Data Generating Process

\fist cf. Sample Data (Statistical Sample \S\ref{sec:sample}), Sampling
(\S\ref{sec:sampling})

\fist cf. Stochastic Process (\S\ref{sec:stochastic_process})



% ------------------------------------------------------------------------------
\subsection{Level of Measurement}\label{sec:measurement_level}
% ------------------------------------------------------------------------------

\begin{itemize}
  \item \emph{Nominal} -- Dispersion: Variation Ratio
    (\S\ref{sec:variation_ratio}); Central Tendency: Mode (\S\ref{sec:mode})
  \item \emph{Ordinal} -- Central Tendency: Median (\S\ref{sec:median})
  \item \emph{Interval} -- Central Tendency: Mean (\S\ref{sec:arithmetic_mean}),
    Deviation (\S\ref{sec:deviation})
  \item \emph{Ratio} -- Central Tendency: Geometric Mean
    (\S\ref{sec:geometric_mean}), Variation Coefficient (TODO);
    cf. Normalization Ratios (\S\ref{sec:normalizing_ratio})
\end{itemize}



\subsubsection{Statistical Data Type}\label{sec:statistical_data_type}

\fist cf. \emph{Datatype}

cf. Statistical Unit (\S\ref{sec:statistical_unit})

\emph{Simple Data Types}:
\begin{itemize}
  \item Binary
  \item Categorical
    \fist Statistical Classification (\S\ref{sec:classification})
  \item Ordinal
  \item Binomial
  \item Count
  \item Real
  \item Positive Real
  \item ...
\end{itemize}

\emph{Multivariate Data Types}:
\begin{itemize}
  \item Random Vector
  \item Random Sequence
  \item Bayes Networks
  \item Random Process
  \item Random Field
  \item ...
\end{itemize}

(TODO: xrefs)



% ------------------------------------------------------------------------------
\subsection{Population Parameter}\label{sec:population_parameter}
% ------------------------------------------------------------------------------

or \emph{Statistical Parameter}

(wiki): a ``quantity'' that indexes a Family of Probability Distributions
(\S\ref{sec:probability_distribution}), i.e. a ``numerical characteristic'' of a
\emph{Statistical Model} (\S\ref{sec:statistical_model})

Parametric Models (\S\ref{sec:parametric_model}) have a Finite Set of Parameters

example: the Family of Normal Distributions (\S\ref{sec:normal_distribution})
are Parameterized by the Mean and Standard Deviation

Non-parametric models (\S\ref{sec:nonparametric_model}) have an Infinite Set of
Parameters

a \emph{Parameter} is to a \emph{Population} as a \emph{Statistic}
(\S\ref{sec:statistic}) is to a \emph{Sample} (\S\ref{sec:sample})

\fist an \emph{Estimator} (\S\ref{sec:estimator}) is a Statistic used to
Estimate a Population Parameter:
\begin{itemize}
  \item Maximum Likelihood Estimation (MLE \S\ref{sec:mle})
  \item Method of Moments (\S\ref{sec:moments_method})
  \item ...
\end{itemize}

\fist Hyperparameters (Learning Algorithms \S\ref{sec:hyperparameter})

$\mu$, $\sigma$

\begin{itemize}
  \item Dispersion (Scale) Parameter (\S\ref{sec:scale_parameter})
  \item Location Parameter (\S\ref{sec:location_parameter}) -- Quantile
  \item Shape Parameter (\S\ref{sec:shape_parameter})
  \item Concentration Parameter (\S\ref{sec:concentration_parameter})
  \item Regression Coefficient (\S\ref{sec:correlation_coefficient})
\end{itemize}



\subsubsection{Population Proportion}\label{sec:proportion}

Population Parameter $p$ describing a percentage value associated with a
Population

\fist Confidence Interval (\S\ref{sec:confidence_interval})

$z$-statistic (\S\ref{sec:z_statistic}) -- used for Estimating Population
Proportion



\paragraph{Lexis Ratio}\label{sec:lexis_ratio}\hfill



% ------------------------------------------------------------------------------
\subsection{Statistical Sample}\label{sec:sample}
% ------------------------------------------------------------------------------

A \emph{Statistical Sample} (or \emph{Data Sample}) is a Subset of a Statistical
Population, selected by a definite procedure (\emph{Sampling Procedure}
\S\ref{sec:sampling}).

\fist A \emph{Data Point} (\S\ref{sec:data_point}) is an Observation (Random
Variate \S\ref{sec:observation}) of a Statistical Unit
(\S\ref{sec:statistical_unit}) in a Statistical Sample.

The \emph{Information Content} (\emph{Self-information} or \emph{Surprisal}
\S\ref{sec:information_content}) of a Sampled Random Variable or Signal
(\S\ref{sec:signal}) is the amount of Information (\S\ref{sec:information})
``gained'' by the Sample; this Information Content is a Random Variable defined
for any Event (\S\ref{sec:probability_event}) as the Negative Log-probability
(\S\ref{sec:log_probability}), regardless of whether a Random Variable is being
measured or not. (wiki)

\fist cf. \emph{Data} (\S\ref{sec:data}), \emph{Data Generating Process}
(\S\ref{sec:data_generating_process}), \emph{Dataset} (\S\ref{sec:dataset}),
\emph{Training Set} (\S\ref{sec:training_dataset})

\fist cf. Frequency Distribution (\S\ref{sec:frequency_distribution})

\fist a Statistical Model (\S\ref{sec:statistical_model}) ``embodies'' the Set
of Statistical Assumptions that concern the \emph{Generation}
(\S\ref{sec:data_generating_process}) of Sample Data

Binomial Distribution (\S\ref{sec:binomial_distribution}) -- Independence
Assumption: Sampling 10\% Rule (TODO)



% ------------------------------------------------------------------------------
\subsection{Statistical Unit}\label{sec:statistical_unit}
% ------------------------------------------------------------------------------

one of a Member of a Set of entities being analyzed, providing the ``material
source'' for abstract Random Variables (\S\ref{sec:random_variable})

cf. Statistical Data Type (\S\ref{sec:statistical_data_type})

\fist A \emph{Data Point} is an Observation (Random Variate
\S\ref{sec:observation}) of a Statistical Unit in a Statistical Sample
(\S\ref{sec:sample}).



\subsubsection{Unit of Observation}\label{sec:observational_unit}

\emph{Unit of Observation} or \emph{Unit of Collection}

\begin{itemize}
  \item \emph{Experimental Unit} -- a Member of a Set of objects that are
    initially equivalent until each object is subjected to an ``Experimental
    Treatment'' (\S\ref{sec:experiment})
  \item \emph{Sampling Unit} -- an object that has been Sampled
    (\S\ref{sec:sample}) from a Statistical Population (\S\ref{sec:population})
\end{itemize}

\fist Observation (Random Variate \S\ref{sec:observation})



\subsubsection{Unit of Analysis}\label{sec:analysis_unit}

the entity that frames what is being ``analyzed'' in a ``study'' (cf. Experiment
\S\ref{sec:experiment})



% ------------------------------------------------------------------------------
\subsection{Data Point}\label{sec:data_point}
% ------------------------------------------------------------------------------

A \emph{Data Point} is an Observation (Random Variate \S\ref{sec:observation})
of a Statistical Unit (\S\ref{sec:statistical_unit}) in a Statistical Sample
(\S\ref{sec:sample}).

cf. Data Item (\S\ref{sec:data_item})



% ------------------------------------------------------------------------------
\subsection{Data Transformation}\label{sec:dataset_transformation}
% ------------------------------------------------------------------------------

application of a Deterministic Transformation to each Data Point in a Dataset
(\S\ref{sec:dataset})

\fist cf. Database Transformation (\S\ref{sec:data_transformation})



\subsubsection{Power Transform}\label{sec:power_transform}

used to create a Monotonic Transformation of Data using Power Functions
(\S\ref{sec:power_function})



\paragraph{Box-Cox Transformation}\label{sec:boxcox_transformation}\hfill

1964 - Box, Cox - \emph{An Analysis of Transformations}



% ------------------------------------------------------------------------------
\subsection{Sampling}\label{sec:sampling}
% ------------------------------------------------------------------------------

\emph{Sampling} is the \emph{selection} of a Subset (Statistical Sample) from
within a Statistical Population

\fist cf. \emph{Data Collection} (\S\ref{sec:data_collection}), Data Generating
Process (\S\ref{sec:data_generating_process})

\fist \emph{Sampling Unit} (Unit of Observation \S\ref{sec:observational_unit})
-- an object that has been Sampled from a Population

\fist \emph{Sampling Error} (\S\ref{sec:sampling_error}) -- Statistical Error
arising from the Estimation of Statistical characteristics of a Population from
a Subset (Sample)

\fist \emph{Design-based Assumptions} -- Statistical Assumptions
(\S\ref{sec:statistical_assumption}) of the way Observations have been made,
e.g. Assumption of Randomization during Sampling (\S\ref{sec:random_sample})

\emph{Empirical Distribution Function} (\S\ref{sec:empirical_distribution}) --
an Unbiased Estimator for the CDF (\S\ref{sec:cdf}) associated with the
Empirical Measure (\S\ref{sec:empirical_measure}) of a Sample



\subsubsection{Sample Size}\label{sec:sample_size}

\emph{Sample Size Determination} -- choosing the number of Observations
(\S\ref{sec:observation}) or Replicates (\S\ref{sec:replication}) to include in
a Statistical Sample

\fist Asymptotic Theory (Large Sample Theory \S\ref{sec:asymptotic_theory}):
evaluates properties of Estimators (\S\ref{sec:estimator}) and Statistical Tests
(\S\ref{sec:hypothesis_testing}) as Sample Size $n \to \infty$



\subsubsection{Replication}\label{sec:sampling_replication}

%FIXME: move this section ???

cf. Experiment (\S\ref{sec:experiment})



\subsubsection{Observational Error}\label{sec:observational_error}

\emph{Observational Error} (or \emph{Measurement Error}) is the difference
between an Observed Value (Random Variate \S\ref{sec:observation}) of a
``quantity'' and its ``true'' Value

cf. \emph{Statistical Error} (\S\ref{sec:error})



\paragraph{Random Error}\label{sec:random_error}\hfill

or \emph{Random Variation}

inconsistency of repeated Observations (Measurements) of a Constant attribute or
quantity

usually Normally Distributed due to the Central Limit Theorem
(\S\ref{sec:central_limit})

\fist a \emph{Distributional Assumption} is a Model-baesd Statistical Assumption
(\S\ref{sec:statistical_assumption}) about the Probability Distribution of
Random Errors



\subparagraph{Precision}\label{sec:precision}\hfill

cf. Accuracy (Systematic Errors \S\ref{sec:accuracy})



\paragraph{Systematic Error}\label{sec:systematic_error}\hfill

or \emph{Statistical Bias}

cf. \emph{Sampling Bias} (\S\ref{sec:nonrandom_sample})

inaccuracy inherent to Observation (Measurement) process



\subparagraph{Accuracy}\label{sec:accuracy}\hfill

cf. Precision (Random Errors \S\ref{sec:precision})

\fist Root-Mean-Square Deviation (RMSD \S\ref{sec:rmsd})



\subparagraph{Specification Error}\label{sec:specification_error}\hfill

%FIXME: does this belong under its own heading ?

error due to the choice of Independent Variables in the Model Specification
(\S\ref{sec:model_specification})



% ------------------------------------------------------------------------------
\subsection{Pseudo-random Number Sampling}\label{sec:pseudorandom_sampling}
% ------------------------------------------------------------------------------

or \emph{Non-uniform Pseudo-random Variate Generation}

Monte-carlo Simulation (\S\ref{sec:monte_carlo})

cf. Pseudo-random Process (\S\ref{sec:pseudorandom_process})



% ------------------------------------------------------------------------------
\subsection{Random Sample}\label{sec:random_sample}
% ------------------------------------------------------------------------------

A \emph{Random Sample} (or \emph{Probability Sample}) is a Sample where each
individual Member of the Population has a known Non-zero Probability of being
selected as part of the Sample.

A Random Vector (Multivariate Random Variable \S\ref{sec:random_vector}) of IID
(\S\ref{sec:iid}) Random Variables $X_1, \ldots, X_n \sim F$ is called a
\emph{Random Sample of Size $n$ from $F$} -- in Statistics it is commonly
assumed that Observations are IID

 a Random Sequence (\S\ref{sec:random_sequence}) of IID Observations is a
 special case of a Stochastic Process (\S\ref{sec:stochastic_process})

\fist cf. \emph{Statistical Randomness} (\S\ref{sec:statistical_randomness}),
\emph{Algorithmic Randomness} (\S\ref{sec:algorithmic_randomness})

\fist Monte Carlo Simulation (\S\ref{sec:monte_carlo}) -- Computational
Algorithms using repeated Random Sampling

\fist Random Assignment (Counterfactual Causal Inference
\S\ref{sec:counterfactual})



\subsubsection{Simple Random Sample}\label{sec:simple_random_sample}

every individual in the Population equally likely to be included



\subsubsection{Systematic Sample}\label{sec:systematic_sample}

\subsubsection{Stratified Random Sample}\label{sec:stratified_sample}

cf. Benchmarking (``\emph{Post-stratification}'' \S\ref{sec:benchmarking})

Horvitz-Thompson Estimator (\S\ref{sec:horvitz_thompson})



\subsubsection{Cluster Sample}\label{sec:cluster_sample}



% ------------------------------------------------------------------------------
\subsection{Non-random Sample}\label{sec:nonrandom_sample}
% ------------------------------------------------------------------------------

(or \emph{Non-probability Sample} or \emph{Biased Sample})

cf. Statistical Bias (\S\ref{sec:bias})

Voluntary Sampling, Response Bias

\emph{Accidental Sample} (\emph{Convenience Sample})

\emph{Consecutive Sample}

\emph{Snowball Sample}

\emph{Purposive Sample} (\emph{Judgemental Sample})

\emph{Quota Sample}

\emph{Quadrature Nodes} (Quasi-Monte Carlo Methods) %FIXME: xref



% ------------------------------------------------------------------------------
\subsection{Statistic}\label{sec:statistic}
% ------------------------------------------------------------------------------

cf. Sample Study

(wiki):

or \emph{Sample Statistic}

Computed by applying a Function (Statistical Algorithm) to Sample Data, i.e. a
Statistic is a Function of the Random Variable (\S\ref{sec:random_variable})
constituting a Random Sample, therefore a Statistic itself is an
\emph{Observable} Random Variable:
\[
  T_n = g(X_1, \ldots, X_n)
\]

the term \emph{Statistic} may be used both for the Function and for the value of
the Function on a given Sample

the Probability Distribution (\S\ref{sec:probability_distribution}) of a
Statistic is a \emph{Sampling Distribution} (\S\ref{sec:sampling_distribution})

a \emph{Statistic} is to a \emph{Sample} as a \emph{Parameter}
(\S\ref{sec:population_parameter}) is to a Population (\S\ref{sec:population})

Confidence Interval (\S\ref{sec:confidence_interval})

\fist an \emph{Estimator} (\S\ref{sec:estimator}) is a Statistic used to
Estimate a Population Parameter

\fist Resampling (\S\ref{sec:resampling}) is a method of Estimating the
precision of a Sample Statistic

$\overline{x}$, $\sigma^2$

\begin{itemize}
  \item Descriptive Statistics (\S\ref{sec:descriptive_statistics}) --
    Descriptive (Summary) Statistic (\S\ref{sec:summary_statistic}) used to
    describe Data
  \item Estimation Theory (\S\ref{sec:estimation_theory}) -- Estimator used to
    describe Population Parameter
  \item Hypothesis Testing (\S\ref{sec:hypothesis_testing}) -- Test Statistic
    (\S\ref{sec:test_statistic}) used to Test a Hypothesis
\end{itemize}

Low-order Statistics -- Functions of the First or Second Power of a Sample (cf.
Location \S\ref{sec:location_parameter}, Scale \S\ref{sec:scale_parameter}
Parameters):
\begin{itemize}
  \item Mean (\S\ref{sec:sample_mean}) -- First Raw Moment
  \item Variance (\S\ref{sec:sample_variance}) -- Second Central Moment
\end{itemize}

Higher-Order Statistics (HOS) -- Functions of Third or higher Power of a Sample
(cf. Shape Parameters \S\ref{sec:shape_parameter}):
\begin{itemize}
  \item Skewness (\S\ref{sec:skewness}) -- Third Standardized Moment
  \item Kurtosis (\S\ref{sec:kurtosis}) -- Fourth Standardized Moment
\end{itemize}

\asterism

\begin{itemize}
  \item $z$-score (Standard Score or $z$-statistic \S\ref{sec:z_statistic})
    -- Estimation of Population Proportion (\S\ref{sec:proportion})
  \item $t$-statistic (\S\ref{sec:t_statistic}) -- Estimation of Population Mean
    (\S\ref{sec:expected_value}) from a Sampling Distribution where the Sample
    Means of the Population Standard Deviation is unknown, or for other
    Parameters or when $n$ is too small
\end{itemize}

\asterism

\begin{itemize}
  \item Signal Coherence (\S\ref{sec:signal_coherence})
  \item ...
\end{itemize}

\asterism

(Wasserman04 \S9.13.2) a Statistic induces a \emph{Partition} on the Set of
Outcomes (FIXME: clarify)



\subsubsection{Sampling Distribution}\label{sec:sampling_distribution}

Probability Distribution of a Statistic (\S\ref{sec:statistic})

\fist Central Limit Theorem (\S\ref{sec:central_limit})

Conditions for Normal (\S\ref{sec:sampling_distribution}) Sampling Distribution:
\begin{enumerate}
  \item Randomness Condition
  \item Normality Condition
  \item Independence Condition
\end{enumerate}

Statistical Inference (\S\ref{sec:inferential_statistics})

the Standard Deviation (\S\ref{sec:standard_deviation}) of a Sampling
Distribution is called the \emph{Standard Error} (\S\ref{sec:standard_error})

$t$-distribution (\S\ref{sec:t_distribution}) -- Sampling Distribution for small
Sample Size

(Wasserman04 \S6.3.1):
the Distribution of a Point Estimator (\S\ref{sec:point_estimator})
$\hat{\theta}_n = g(X_1,\ldots,X_n)$



\subsubsection{Robust Statistic}\label{sec:robust_statistic}

\fist Info-gap Decision Theory (\S\ref{sec:info_gap}) -- Non-probabilistic
Decision Theory seeking to optimize Robustness to ``failure'' under severe
Uncertainty (\S\ref{sec:uncertainty_analysis})



\subsubsection{Sufficient Statistic}\label{sec:sufficient_statistic}

a \emph{Sufficient Statistic} is a Statistic that contains all the
Information (\S\ref{sec:information}) in the Data

(Wasserman04 \S9.13.2):

a Statistic if Sufficient if the Likelihood Function (\S\ref{sec:likelihood})
can be computed knowing only $T(X^n)$,
\emph{or}: a Statistic is Sufficient if the Distribution of $X^n$ given
$T(X^n) = t$ does not depend on Model Paramters $\theta$

a Statistic is \emph{Minimal Sufficient} if it is Sufficient and is a Function
of every other Sufficient Statistic

\emph{Factorization Theorem}

\emph{Rao-Blackwell Theorem} -- an Estimator (\S\ref{sec:estimator}) that does
not depend on a Sufficient Statistic is sub-optimal

for Exponential Family Distributions (\S\ref{sec:exponential_family}) which have
PDFs of the form:
\[
  f(x; \theta) = h(x) e^{\eta(\theta)T(x) - B(\theta)}
\]
$T$ is called the \emph{Natural Sufficient Statistic}



\subsubsection{Degrees of Freedom}\label{sec:statistical_freedom}

\subsubsection{$z$-statistic}\label{sec:z_statistic}

Standard Score ($z$-score \S\ref{sec:standard_score})

cf. $t$-statistic (\S\ref{sec:t_statistic})



\subsubsection{$t$-statistic}\label{sec:t_statistic}

$t$-distribution (\S\ref{sec:t_distribution})

$t$-test (\S\ref{sec:t_test})

cf. $z$-statistic (\S\ref{sec:z_statistic})

can be used for small $n$ ($t$-distribution has fatter tails)

conditions:
\begin{itemize}
  \item Sample is Random
  \item Normal Condition -- $n \geq 30$, or else original Distribution is Normal
    or Symmetric around Mean
  \item Observations are Independent
\end{itemize}

Margin of Error (\S\ref{sec:margin_of_error})

Degree of Freedom (\S\ref{sec:statistical_freedom}) -- Sample Size minus $1$;
different $t$-distribution depending on the Sample Size



\subsubsection{$F$-statistic}\label{sec:f_statistic}

(Fisher)

$F$-distribution (\S\ref{sec:f_distribution}) -- can be seen as a Ratio of
$\chi^2$-distributions with differing DoF

$F$-test (\S\ref{sec:f_test})

ANOVA (\S\ref{sec:variance_analysis})

$F = \frac{\text{between-group variability}}{\text{within-group variability}}$

Linear Regression



% ------------------------------------------------------------------------------
\subsection{Error}\label{sec:error}
% ------------------------------------------------------------------------------

\emph{Statistical Error} or \emph{Disturbance}

Deviation (Signed Difference \S\ref{sec:deviation}) of an Observation
(\S\ref{sec:observation}) \emph{or} of an Estimate
(\S\ref{sec:estimation_theory}) from an ideal (possibly theoretical) ``true''
value, usually the Observed (Estimated) Random Variable's Expected Value
(\S\ref{sec:expected_value})

\fist cf. \emph{Observational Error} (Measurement Error
\S\ref{sec:observational_error}), \emph{Standard Error}
  (\S\ref{sec:standard_error})

Absolute Error -- Median minimizes Absolute Error

Squared Error -- Mean (Expected Value) minimizes Squared Error

cf. \emph{Variance} (\S\ref{sec:variance}) -- Expected Squared Error

\fist Mean Squared Deviation or Mean Squared Error (MSE \S\ref{sec:msd}) of an
Estimator (\S\ref{sec:estimator}) is the Average of the Squared Error of the
Estimated value (produced by an Estimator) from the ``true'' value; MSD is
the Second Moment of the Error; for an Unbiased Estimator the MSD is the
Variance of the Estimator

cf. Residual (\S\ref{sec:residual}) -- Deviation of an Observed Value from an
\emph{Estimated} (\S\ref{sec:estimation_theory}) Expected Value

\fist Regression Error (\S\ref{sec:regression_error})

\fist Classification Error (\S\ref{sec:classification_error})

(wiki):

example for Sample (\S\ref{sec:sample}) of IID Normally Distributed Random
Variables, $X_1, \ldots, X_n \sim N(\mu, \sigma^2)$, the Sample Mean
(\S\ref{sec:sample_mean}):
\[
  \overline{X} = \frac{X_1 + \cdots + X_n}{n}
\]
is a Random Variable with Normal Distribution:
\[
  \overline{X} = N(\mu, \frac{\sigma^2}{n})
\]
and the \emph{Statistical Errors} are:
\[
  e_i = X_i - \mu
\]
and the \emph{Residuals} (\S\ref{sec:residual}) are:
\[
  r_i = X_i - \overline{X}
\]



\subsubsection{Sampling Error}\label{sec:sampling_error}

\subsubsection{Non-sampling Error}\label{sec:nonsampling_error}

Coverage Errors

Response Errors



% ------------------------------------------------------------------------------
\subsection{Kernel}\label{sec:distribution_kernel}
% ------------------------------------------------------------------------------

Window Function (\S\ref{sec:window_function})

Normalized, Symmetric

\fist Integral Kernel (\S\ref{sec:integral_kernel})

\fist Kernel Density Estimation (\S\ref{sec:kde})

\fist sometimes a Covariance Function (\S\ref{sec:covariance_function}) is
called a ``Kernel''



% ------------------------------------------------------------------------------
\subsection{Variance Analysis}\label{sec:variance_analysis}
% ------------------------------------------------------------------------------

ANalysis Of VAriance (ANOVA)

repeated Measures (Observations \S\ref{sec:observation})

General Linear (Multivariate) Regression (\S\ref{sec:multivariate_regression})

cf. Mixed Models (\S\ref{sec:mixed_model})

Analysis of the the differences among ``group means'' (FIXME: clarify) in a
Sample (\S\ref{sec:sample})

$F$-statistic (\S\ref{sec:f_statistic}):
$F = \frac{\text{between-group variability}}{\text{within-group variability}}$

generalizes $t$-test (\S\ref{sec:t_test}) to more than two groups

compare three or more ``group means'' for Significance
(\S\ref{sec:statistical_significance})

\fist Multivariate Analysis of Variance (MANOVA \S\ref{sec:manova})



\subsubsection{Squared Deviation from Mean (SDM)}\label{sec:sdm}

\fist Squared Deviation (\S\ref{sec:squared_deviation})

cf. Mean Squared Deviation (MSD \S\ref{sec:msd}), Sum of Squared
Deviations (\S\ref{sec:sum_squared_deviation})

\emph{Variance} (\S\ref{sec:variance}) is defined as either:
\begin{itemize}
  \item the \emph{Expected Value of the SDM} when considering a
    \emph{theoretical Distribution}
\end{itemize}
or:
\begin{itemize}
  \item the Sample Variance (\S\ref{sec:sample_variance}) of some Data
    (\S\ref{sec:sample})
\end{itemize}

cf. Least Squares (\S\ref{sec:least_squares}), Regression
(\S\ref{sec:regression_analysis})



\subsubsection{Sum of Squared Deviation}\label{sec:sum_squared_deviation}

\fist Squared Deviation (\S\ref{sec:squared_deviation})

cf. Mean Squared Deviation (MSD \S\ref{sec:msd}), Sum of Squared
Deviations (\S\ref{sec:sum_squared_deviation})

\fist cf. Least Squares (\S\ref{sec:least_squares})

unscaled measure of \emph{Dispersion} (Variability \S\ref{sec:dispersion})

Estimates the Variance (\S\ref{sec:variance}) when scaled for the number of
\emph{Degrees of Freedom} (\S\ref{sec:statistical_freedom})



\paragraph{Total Sum of Squares (TSS)}\label{sec:tss}\hfill

or \emph{SST}

\[
  TSS = \sum_{i=1}^n (y_i - \overline{y})^2
\]

the numerator when calculating the Variance

equal to SSR + ESS

SSW -- Sum of Squares \emph{Within} a Sample

SSB -- Sum of Squares \emph{Between} Samples

$SST = SSW + SSB$

ANOVA (\S\ref{sec:variance_analysis}) --
$F$-statistic (\S\ref{sec:f_statistic}):
$F = \frac{\text{between-group variability}}{\text{within-group variability}}$

$F = \frac{\frac{SSB}{DoF_B}}{\frac{SSW}{DoF_W}}$

Determination Coefficient (\S\ref{sec:determination_coefficient}):
\[
  r^2 = 1 - \frac{
    ESS_{\hat{y}}
  }{
    TSS_{\overline{y}}
  }
\]



\paragraph{Sum of Squared Residuals (SSR)}\label{sec:ssr}\hfill

or \emph{SSE} or \emph{SSR}

$SSE = \sum(Y_i - \hat{Y_i})^2$

Residuals (\S\ref{sec:residual})

\fist a \emph{Least Square Estimate} (\S\ref{sec:least_squares}) is an
approximate solution of an Overdetermined System that minimizes the Sum of
Squared Residuals (SSR)

the SSR is a measure of how well an Estimated Regression Function
(\S\ref{sec:regression_analysis}) $\hat{r}(x)$ ``Fits'' the Data; Regression
Parameters that minimize SSR are called \emph{Least Squares Estimates}

\[
  \sum_{i=1}^n \hat{\epsilon}_i^2
\]



\paragraph{Explained Sum of Squares (ESS)}\label{sec:ess}\hfill

Expected Deviation from Mean: $SSR = \sum(\hat{Y}_i - \overline{Y})^2$

Determination Coefficient (\S\ref{sec:determination_coefficient}):
\[
  r^2 = 1 - \frac{
    ESS_{\hat{y}}
  }{
    TSS_{\overline{y}}
  }
\]



\subsubsection{Partition of Sum of Squares}\label{sec:partition_squares}

TODO



\subsubsection{Contrast}\label{sec:contrast}



% ------------------------------------------------------------------------------
\subsection{Scale Analysis}\label{sec:statistical_scale}
% ------------------------------------------------------------------------------

Scale Parameter (\S\ref{sec:scale_parameter})

Scale Estimator (\S\ref{sec:scale_estimator})

cf. Scaling (\S\ref{sec:scaling}), Scale Invariance
(\S\ref{sec:scale_invariance})

\fist cf. Scale (Order-of-magnitude) Analysis (Approximation Theory
\S\ref{sec:scale_analysis}), Multi-scale Analysis (Perturbation Theory
\S\ref{sec:multiscale_analysis})

cf. Multidimensional Scaling (\S\ref{sec:multidimensional_scaling})



% ------------------------------------------------------------------------------
\subsection{Spatial Analysis}\label{sec:spatial_analysis}
% ------------------------------------------------------------------------------

Random Fields (\S\ref{sec:random_field})

% FIXME

Kriging (Gaussian Process Regression \S\ref{sec:gaussian_process_regression})



\subsubsection{Variogram}\label{sec:variogram}

\subsubsection{Boundary Problem}\label{sec:boundary_problem}



% ------------------------------------------------------------------------------
\subsection{Extreme Value Analysis (EVA)}\label{sec:eva}
% ------------------------------------------------------------------------------

or \emph{Extreme Value Theory}

Generalized Extreme Value (GEV \S\ref{sec:gev}) Distributions:

\begin{itemize}
  \item Gumbel (\S\ref{sec:gumbel_distribution})
  \item Fr\'echet (\S\ref{sec:frechet_distribution})
  \item Weibull (\S\ref{sec:weibull_distribution})
\end{itemize}

\textbf{Fisher-Tippett-Gnedenko Theorem} -- ``Extreme Value Theorem''; not to be
confused with the \emph{Extreme Value Theorem} (Analysis
\S\ref{sec:extreme_value}); Order Statistics (Non-parametric Statistics
\S\ref{sec:order_statistic})

by the Extreme Value Theorem, the GEV Distribution is the only \emph{possible}
Limit Distribution of Normalized Maxima of a Sequence of IID Random Variables,
but such a Limit Distribution does not necessarily exist, requiring
\emph{Regularity Conditions} on the Tail of the Distribution

(Mandelbrot97E)

\emph{Tail Preservation Relation} -- $\overline{F}_N(u) \sim N \overline{F}(u)$;
cf. Lognormal Distributions, Scaling Distributions

for $U_n$ ($1 \leq n \leq N$) IID with Tail Probability $\overline{F}(u)$, and
$\tilde{F}_N(u)$ the Tail Probability of $\tilde{U}_N = \max(U_n)$, then:
\[
  1 - \tilde{F}_N(u) = F(u)^N
\]
in the Tail where $\overline{F}(u) \ll 1$ and $\tilde{F}(u) \ll 1$, in
\emph{all} cases: $\tilde{F}(u) \sim N \overline{F}$



% ==============================================================================
\section{Descriptive Statistics}\label{sec:descriptive_statistics}
% ==============================================================================

\emph{Descriptive Measures}

Summary of Data: Mean, Median, Mode, Standard Deviation

cf. Test Statistics (\S\ref{sec:test_statistic})

Descriptive Statistics are often Non-parametric
(\S\ref{sec:nonparametric_model})



% ------------------------------------------------------------------------------
\subsection{Summary Statistic}\label{sec:summary_statistic}
% ------------------------------------------------------------------------------

% FIXME: many of the below concepts apply to *population parameters* as well as
% *sample statistics*; can they be distinguished/moved elsewhere ???

\begin{itemize}
  \item Dispersion (\S\ref{sec:dispersion})
  \item Central Tendency (\S\ref{sec:central_tendency})
  \item Shape (\S\ref{sec:distribution_shape})
  \item Dependence (\S\ref{sec:dependence})
\end{itemize}

various Summary Statistics can be computed by Statistical Functionals
(\S\ref{sec:statistical_functional}), i.e. Functions of the CDF
(\S\ref{sec:cdf}):
\begin{itemize}
  \item $\mu = T(F) = \int x dF(x)$
    -- Mean (Expectation \S\ref{sec:expected_value})
  \item $\sigma^2 = T(F) = \int (x - \mu)^2 dF(x)$
    -- Variance (\S\ref{sec:variance})
  \item $m = T(F) = F^{-1}(0.5)$
    -- Median (\S\ref{sec:median})
\end{itemize}



\subsubsection{Statistical Dispersion}\label{sec:dispersion}

\emph{Variability} or \emph{Spread}

Estimated by Statistics on the Distribution of Deviations
(\S\ref{sec:deviation})

quantified by Standard Deviation (\S\ref{sec:standard_deviation})

\fist a \emph{Scale Parameter} (\S\ref{sec:scale_parameter}) determines the
Dispersion in a Parameteric Model

\begin{itemize}
  \item Range (\S\ref{sec:range}) -- difference between largest and smallest
    values
  \item InterQuartile Range (IQR \S\ref{sec:iqr}) -- difference between 75th and
    25th Percentiles
  \item ... TODO
\end{itemize}

Overdispersion (\S\ref{sec:overdispersion}) -- presence of greater Dispersion
than would be expected based on a given Statistical Model

``Volatility'' (Finance) -- Statistical Measure of Dispersion around the
``average'' of any Random Variable

(wiki): ``Dispersion precedes Location'' --

given a measure of Statistical Dispersion, measures of Central Tendency
(\S\ref{sec:central_tendency}) can be characterized as \emph{Minimizing
  Variation} (\S\ref{sec:variational_calculus}) such that the Center is
minimal among all possible choices of Center (may or may not be unique); in the
sense of $L^p$-norms (\S\ref{sec:p_norm}):
\begin{tabular}{l l l}
  $L^p$ & Dispersion & Central Tendency \\
  $L^0$ & Variation Ratio (Qualitative Variation \S\ref{sec:variation_ratio})
    & Mode (\S\ref{sec:mode}) \\
  $L^1$ & Mean Absolute Deviation (\S\ref{sec:mad})
    & Median (\S\ref{sec:median}),
      Geometric Median (\S\ref{sec:geometric_median}) \\
  $L^2$ & Standard Deviation (\S\ref{sec:standard_deviation})
    & Mean (\S\ref{sec:mean}) \\
  $L^\infty$
    & Maximum Absolute Deviation (\S\ref{sec:maximum_absolute_deviation})
    & Mid-range (\S\ref{sec:midrange})
\end{tabular}

\fist Sum of Squared Deviations (\S\ref{sec:sum_squared_deviation}) -- unscaled
measure of Dispersion

cf. \emph{Uncertainty}

2018 - \emph{Uncertainty: a Tutorial} -
\url{https://blog.evjang.com/2018/12/uncertainty.html}



\paragraph{Range}\label{sec:range}\hfill

\subparagraph{InterQuartile Range (IQR)}\label{sec:iqr}\hfill

Outliers:  $Q1 - 1.5 \times IQR$, $Q3 + 1.5 \times IQR$



\subparagraph{Rescaled Range}\label{sec:rescaled_range}\hfill

\fist the Hurst Exponent (``Index of Long-range Dependence''
\S\ref{sec:hurst_exponent}) is defined in terms of the Asymptotic behavior of
the Rescaled Range as a function of the ``time span'' of a Time Series

\emph{R/S Analysis}

Estimation of Hurst Exponent

Range $R(n)$

Standard Deviation $S(n)$

Rescaled Range $R(n) / S(n)$

(Mandelbrot97E)

robust with respect to Infinite Variance

cf. ``Market Efficiency''-- Dependence ($J > 0.5$) implies exogenous factors



\paragraph{Covariance Matrix}\label{sec:covariance_matrix}\hfill

\emph{Variance-Covariance Matrix} or \emph{Dispersion Matrix}

Symmetric Matrix (\S\ref{sec:symmetric_matrix}) where the $i,j$th entry is the
Covariance between the $i$th and $j$th entries of a Random Vector

Positive Semi-definite (\S\ref{sec:positive_semidefinite})

the Inverse of the Covariance Matrix is called the \emph{Precision Matrix}



\paragraph{Qualitative Variation}\label{sec:qualitative_variation}\hfill

measure of Statistical Dispersion for \emph{Nominal Distributions}
(Measurement Level \S\ref{sec:measurement_level})

Deviation from the Mode (\S\ref{sec:mode})



\subparagraph{Coefficient of Variation}\label{sec:variation_coefficient}\hfill

or \emph{Relative Standard Deviation (RSD)}



\subparagraph{Variation Ratio}\label{sec:variation_ratio}\hfill

Dispersion associated with the $L^0$ Metric (Counting ``Norm''-- not really a
Norm \S\ref{sec:p_norm}); the corresponding Central Tendency is the \emph{Mode}
(\S\ref{sec:mode})

equal to the overall proportion of cases that are \emph{not} in the Mode:
\[
  v \defeq 1 - \frac{n_{\text{mode}}}{N}
\]
where $n_{\text{mode}}$ are the number of cases in the Mode and $N$ is the total
number of cases



\paragraph{Mean Absolute Deviation (MAD)}\label{sec:mad}\hfill

or \emph{Average of Absolute Deviations} (\S\ref{sec:absolute_deviation}), i.e.
Errors or Residuals, to a central point

Dispersion measure associated with the $L^1$ Metric (Taxicab Norm
\S\ref{sec:p_norm}); the corresponding Central Tendency which minimizes the MAD
is the \emph{Median} (\S\ref{sec:median}) or \emph{Geometric Median}
(\S\ref{sec:geometric_median})

\fist not to be confused with \emph{Mean Absolute Error} (MAE \S\ref{sec:mae})
-- Average difference between two Continuous Random Variables,
or \emph{Mean Absolute Difference} (\S\ref{sec:mean_absolute_difference}) --
Average Absolute Difference between two IID Random Variables

cf. Mean Squared Deviation (MSD \S\ref{sec:msd})



\subparagraph{Mean Absolute Difference}
\label{sec:mean_absolute_difference}\hfill

\emph{Absolute Mean Difference} or \emph{Gini Mean Difference (GMD)}

$MD$

Average Absolute Difference (\S\ref{sec:absolute_difference}) between two IID
Random Variables, i.e. the Expected Value of the Absolute Difference of two IID
Random Variables



\subparagraph{Relative Mean Absolute Difference}
\label{sec:relative_mean_absolute_difference}\hfill

Mean Absolute Difference divided by the Arithmetic Mean
(\S\ref{sec:arithmetic_mean})



\paragraph{Standard Deviation}\label{sec:standard_deviation}\hfill

$\sigma$

Dispersion measure associated with the $L^2$ Metric (Euclidean Norm
\S\ref{sec:p_norm}); the corresponding Central Tendency which minimizes the
Standard Deviation is the \emph{Mean} (\S\ref{sec:mean})

Deviation (\S\ref{sec:deviation})

Square Root of the Variance (\S\ref{sec:variance}) $\sqrt{V(X)}$

cf. Root Mean Squared Deviation (RMSD \S\ref{sec:rmsd}) -- Square Root of the
Mean Squared Deviation (MSD \S\ref{sec:msd})

the Standard Deviation of a Sampling Distribution
(\S\ref{sec:sampling_distribution}) is called the \emph{Standard Error}
(\S\ref{sec:standard_error})

the Standard Error equals the Standard Deviation divided by the square root of
the Sample Size, i.e. the Standard Error of the Mean is a measure of
``Dispersion'' of Sample Means around the Population Mean

cf. Confidence Interval (\S\ref{sec:confidence_interval})

see also: Relative Standard Deviation (Coefficient of Variation
\S\ref{sec:variation_coefficient})

$S$ -- Standard Deviation of Regression Residuals
(\S\ref{sec:regression_residual})

\emph{Uncorrected Standard Deviation}:
\[
  s_n = \sqrt{\frac{1}{n}\sum_{i=1}^n (x_i - \overline{x})^2}
\]

\emph{Corrected Standard Deviation}

\emph{Unbiased Standard Deviation}



\subparagraph{Standard Score}\label{sec:standard_score}\hfill

or \emph{$z$-score}

$z$-statistic (\S\ref{sec:z_statistic}) -- used for Estimating Population
Proportion (\S\ref{sec:proportion})

cf. $t$-statistic (\S\ref{sec:t_statistic}) -- used for Estimating Population
Mean and other Parameters, and for small $n$

(wiki): signed fractional number of Standard Deviations by which an Observation
or Data Point is \emph{above} the Mean:
\[
  z = \frac{x - \mu}{\sigma}
\]

$z$-statistic for a Proportion Statistic $\hat{p}$ with Sample Size $n$:
\[
  z = \frac{\hat{p} - p}{\sqrt{\frac{p(1-p)}{n}}}
\]
where the Denominator is the Standard Deviation of the Sampling Distribution of
the Sample Proportion (i.e. the Standard Error of the Statistic
\S\ref{sec:standard_error})

MIT 6.041SC, Lec.8

\emph{Standardizing} a Normal Random Variable (\S\ref{sec:normal_distribution})
-- for $X \sim N(\mu, \sigma^2)$:
\[
  \frac{X - \mu}{\sigma} \sim N(0, 1)
\]
where $(X - \mu)/\sigma$ is the Standard Score



\subparagraph{Mahalanobis Distance}\label{sec:mahalanobis_distance}\hfill

Multi-dimensional generalization of Standard Deviation

Generalized Least Squares (GLS \S\ref{sec:gls})



\subparagraph{Variance}\label{sec:variance}\hfill

the \emph{Variance} is the Expected Value of the Squared Deviation
(\S\ref{sec:sdm}) of a Random Variable

$\sigma_X^2 = Cov(X,X)$ (\S\ref{sec:covariance})

this is either equal to the Expected Value of the Square Deviation from the
Mean of a theoretical Distribution, or as the Squared Deviations from the Sample
Mean (Sample Variance \S\ref{sec:sample_variance})

the \emph{Sum of Squared Deviations} (\S\ref{sec:sum_squared_deviation})
Estimates (\S\ref{sec:estimation_theory}) the Variance when scaled for the
number of \emph{Degrees of Freedom} (\S\ref{sec:statistical_freedom})

\fist Mean Squared Deviation or Mean Squared Error (MSE \S\ref{sec:msd}) of an
Estimator (\S\ref{sec:estimator}) is the Average of the Squared Error of the
Estimated value (produced by an Estimator) from the ``true'' value; MSD is
the Second Moment of the Error; for an Unbiased Estimator the MSD is the
Variance of the Estimator

\emph{Overfitting} (Multiple Regression \S\ref{sec:multiple_regression}) -- too
many Covariates, high Variance

\fist ANalaysis Of VAriance (ANOVA \S\ref{sec:variance_analysis}) --
Variance is defined as either the Expected Value of the
Squared Deviation from the Mean (SDM \S\ref{sec:sdm}), considering a theoretical
Distribution, or its Sample Mean (\S\ref{sec:sample_mean})

\emph{Mean Square} (\S\ref{sec:mean_square}) $\expect(X^2)$ -- Second Central
Moment (\S\ref{sec:moment})/Second Cumulant (\S\ref{sec:cumulant})

Variances are always Non-negative

the Variance of a Random Variable $X$ is equal to:
\begin{align*}
  \sigma^2 = V(X) & = E(X - E(X))^2   \\
                  & = E(X^2) - E(X)^2 \\
                  & = \int(x - E(X))^2 dF(x) \\
\end{align*}
assuming the Expected Value (\S\ref{sec:expected_value}) $E(\cdot)$ exists

Discrete Random Variable $X$:
\[
  Var(X) = \sigma_X^2 = \sum_{i=1}^n f(x_i) (x_i - \mu)^2 = \sum_{i=1}^n
  f(x_i) x_i^2 - \mu^2
\]
where $\mu = \sum_{i=1}^n f(x_i) x_i$

Continuous Random Variable $X$:
\[
  Var(X) = \sigma_X^2 = \int (x - \mu)^2 f(x) dx = \int x^2 f(x) dx -
  \mu^2
\]
where $\mu = \int x f(x) dx$

For Random Variables $X$, $Y$ with Joint Probability Distribution
$f(x,y)$ and $a$, $b$, $c$ are Constants, then:
\[
  \sigma^2_{a X + b Y + c} = a^2 \sigma^2_X + b^2 \sigma^2_Y + 2ab
  \sigma_{X Y}
\]

\fist Estimator: Sample Variance (\S\ref{sec:sample_variance})

for Independent Random Variables, $Var(X + Y) = Var(X) + Var(Y)$ and
$Var(X - Y) = Var(X) + Var(Y)$

\emph{Conditional Variance} $V(X|Y)$

$V(Y) = E(V(Y|X)) + V(E(Y|X))$

Variance reduction methods:
\begin{itemize}
  \item Bootstrap Aggregation (Bagging \S\ref{sec:bootstrap_aggregation})
\end{itemize}



\subparagraph{Chebyshev's Inequality}\label{sec:chebyshevs_inequality}\hfill

Probability that a Random Variable $X$ will assume Value within $k$ Standard
Deviations

Random Variable $X$ with Finite Expected Value (\S\ref{sec:expected_value})
$\mu$ and Finite Non-zero Variance $\sigma^2$, for any $k \in \reals : k > 0$:
\[
  P(k\sigma \leq |X - \mu|) \leq \frac{1}{k^2}
\]



\paragraph{Maximum Absolute Deviation}
\label{sec:maximum_absolute_deviation}\hfill

Dispersion measure associated with the $L^\infty$ Metric (Max Norm
\S\ref{sec:p_norm}); the corresponding Central Tendency which minimizes the
Maximum Absolute Deviation is the \emph{Mid-range} (\S\ref{sec:midrange})



\subsubsection{Central Tendency}\label{sec:central_tendency}

or \emph{Location} or ``\emph{Average}''

\fist Location Parameter (\S\ref{sec:location_parameter})

(wiki): ``Dispersion precedes Location'' --

given a measure of Statistical Dispersion (\S\ref{sec:dispersion}), measures of
Central Tendency can be characterized as \emph{Minimizing Variation}
(\S\ref{sec:variational_calculus}) such that the Center is minimal among all
possible choices of Center (may or may not be unique); in the sense of
$L^p$-norms (\S\ref{sec:p_norm}):
\begin{tabular}{l l l}
  $L^p$ & Dispersion & Central Tendency \\
  $L^0$ & Variation Ratio (Qualitative Variation \S\ref{sec:variation_ratio})
    & Mode (\S\ref{sec:mode}) \\
  $L^1$ & Mean Absolute Deviation (\S\ref{sec:mad})
    & Median (\S\ref{sec:median}),
      Geometric Median (\S\ref{sec:geometric_median}) \\
  $L^2$ & Standard Deviation (\S\ref{sec:standard_deviation})
    & Mean (\S\ref{sec:mean}) \\
  $L^\infty$
    & Maximum Absolute Deviation (\S\ref{sec:maximum_absolute_deviation})
    & Mid-range (\S\ref{sec:midrange})
\end{tabular}



\paragraph{Mode}\label{sec:mode}\hfill

Central Tendency for Nominal Measurement (\S\ref{sec:measurement_level})

\fist Variation Ratio (Qualitative Variation, Deviation from the Mode
\S\ref{sec:variation_ratio}) -- the Dispersion measure associated with the $L^0$
Metric (Counting ``Norm''-- not really a Norm \S\ref{sec:p_norm}) for which the
Mode is the corresponding Central Tendency

cf. \emph{Unimodality}, \emph{Multimodality} -- Global/Local Maxima



\paragraph{Median}\label{sec:median}\hfill

Central Tendency for Ordinal Measurement (\S\ref{sec:measurement_level})

\fist Mean Absolute Deviation (MAD \S\ref{sec:mad}) -- Dispersion measure
associated with the $L^1$ Metric (Taxicab Norm \S\ref{sec:p_norm}) for which the
Median is the corresponding measure of Central Tendency

i.e. as an Estimate (\S\ref{sec:estimation_theory}) for $X$, the Median $m[X]$
minimizes Absolute Deviation (Absolute Errors or Absolute Residuals)

cf. the \emph{Mean} (Expected Value \S\ref{sec:mean}) minimizes Squared Error

note that $E(X + Y) = E(X) + E(Y)$, but not for $m(X+Y)$



\subparagraph{Geometric Median}\label{sec:geometric_median}\hfill

\subparagraph{Sample Median}\label{sec:sample_median}\hfill



\paragraph{Mean}\label{sec:mean}\hfill

Central Tendency for Interval Measurement (\S\ref{sec:measurement_level})

\fist Expected Value (\S\ref{sec:expected_value})



\subparagraph{Arithmetic Mean}\label{sec:arithmetic_mean}\hfill

\emph{Arithmetic Mean} $\overline{x} = \frac{1}{n}\sum_{i=1}^n x_i$

by the Law of Large Numbers (\S\ref{sec:large_numbers}), the Arithmetic Mean
Converges to the Mean (Expected Value \S\ref{sec:expected_value}) as the Sample
Size gets larger

Central Tendency for Interval Measurement (\S\ref{sec:measurement_level})

\begin{itemize}
  \item Relative Mean Absolute Difference
    (\S\ref{sec:relative_mean_absolute_difference}) -- Mean Absolute Difference
    divided by the Arithmetic Mean
\end{itemize}



\subparagraph{Weighted Arithmetic Mean}\label{sec:weighted_mean}\hfill

\emph{Weight Function}

\emph{Weighted Sum} or \emph{Weighted Average}

\fist Benchmarking (\S\ref{sec:benchmarking})

Simpson's Paradox



\subparagraph{Geometric Mean}\label{sec:geometric_mean}\hfill

using the Product of Values instead of Sum as in Arithmetic Mean

Central Tendency for Ratio Measurement (\S\ref{sec:measurement_level})



\subparagraph{Mean Square}\label{sec:mean_square}\hfill

Arithmetic Mean of the Squares of a Set of Numbers or Random Variable

Second Moment (\S\ref{sec:variance}) $\expect(X^2)$ of a Random Variable

\fist Mean Square Deviation (\S\ref{sec:msd})



\paragraph{Trimmed Mean}\label{sec:trimmed_mean}\hfill



\paragraph{Midrange}\label{sec:midrange}\hfill

Average (Arithmetic Mean) of Max and Min, i.e. the Midpoint of the Range
(\S\ref{sec:range})

Central Tendency minimizing the Maximum Absolute Deviation
(\S\ref{sec:maximum_absolute_deviation})



\subparagraph{Midhinge}\label{sec:midhinge}\hfill

Average of First and Third Quartiles; minimizes Median Absolute Deviation and
Maximum Absolute Deviation of the Distribution of the 2nd and 3rd Quartiles

Trimmed $L^\infty$ Norm Statistic



\subsubsection{Shape}\label{sec:distribution_shape}

\fist Shape Parameter (\S\ref{sec:shape_parameter}) -- any Parameter of a
Probability Distribution that is not a Location or Scale (Dispersion) Parameter



\paragraph{Skewness}\label{sec:skewness}\hfill

Asymmetry %FiXME

``lopsided-ness''

Third Central Moment (\S\ref{sec:moment})/Third Cumulant (\S\ref{sec:cumulant})

cf. Gyration



\paragraph{Kurtosis}\label{sec:kurtosis}\hfill

Fourth Central Moment (\S\ref{sec:moment})

Measure of the ``heaviness'' of the tail of a Distribution:

\begin{itemize}
  \item Leptokurtic -- ``Heavy-tailed'' (\S\ref{sec:heavy_tailed})
  \item Platykurtic -- ``Thin-tailed'' (Sub-gaussian \S\ref{sec:sub_gaussian})
\end{itemize}



\subsubsection{Dependence}\label{sec:dependence}

or \emph{Association}

any ``\emph{Statistical Relationship}'' between two Random Variables
(``Bivariate Data'')

may or may not be Causal -- (wiki): the main difference between
\emph{Causal Inference} (\S\ref{sec:causal_inference}) and an Inference of
\emph{Association} is that the former analyzes the ``response'' of the ``effect
variable'' when the Cause is changed

Random Variables are \emph{Dependent} if they do not Satisfy the Property of
\emph{Probabilistic Independence} (\S\ref{sec:independence})

Stochastic Processes (\S\ref{sec:stochastic_process}): Sequences of Dependent
Random Variables

note that a Signal may have a ``White'' Frequency Spectrum but still be Serially
Dependent (Mandelbrot97E)

\fist Regression Analysis (\S\ref{sec:regression_analysis}) -- Estimation
(\S\ref{sec:estimation_theory}) of Relations in Multivariate Data
(\S\ref{sec:random_vector})

\fist a \emph{Structural Assumption} is a Model-baesd Statistical Assumption
(\S\ref{sec:statistical_assumption}) about the Functional Dependence between
Variables in a Statistical Model



\paragraph{Covariance}\label{sec:covariance}\hfill

a measure of the ``Joint Variability'' of two Random Variables; the sign of the
Covariance shows the tendency of a Linear Relation between the Variables, and
the Normalized version of the Covariance is the \emph{Correlation Coefficient}
(\S\ref{sec:correlation_coefficient}) which gives the \emph{magnitude} of the
Linear Relation

Correlation (\S\ref{sec:statistical_correlation}) is Dimensionless, while
Covariance is in units resulting from multiplying the two Variables

$Cov(X,Y) = E [(X - \mu_X)(Y - \mu_Y)]$

$Cov(X,X)$ -- Variance (\S\ref{sec:variance})

\fist cf. Causation (\S\ref{sec:causation})

$n$ Discrete Samples:
\[
  \sigma_{X,Y} = Cov(X,Y) = E [(X - \mu_X)(Y - \mu_Y)] =
    \frac{1}{n} \sum_{i=1}^n (x_i - \mu_X) (y_i - \mu_Y)
\]

Continuous:
\[
  Cov(X,Y) = E [(X - \mu_X)(Y - \mu_Y)] =
  \int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty}
  (x - \mu_X) (y - \mu_Y) f(x,y) dx dy
\]
where $f(x,y)$ is the Joint Probability Distribution
(\S\ref{sec:joint_probability}) of $X$, $Y$

\fist Sample Covariance (\S\ref{sec:sample_covariance})

\textbf{Thm.} \emph{Covariance Satisfies:
  \[
    Cov(X,Y) = E(XY) - E(X)E(Y)
  \]
}

the Correlation (\S\ref{sec:statistical_correlation}) is defined in terms of the
Covariance:
\[
  \rho_{X,Y} = \frac{Cov(X,Y)}{\sigma_X \sigma_Y}
\]
if $X$ and $Y$ are Independent (\S\ref{sec:dependence}), then
$Cov(X,Y) = \rho = 0$

\fist Covariance Function (Stochastic Processes \S\ref{sec:covariance_function})



\paragraph{Correlation}\label{sec:statistical_correlation}\hfill

$\rho$

measure of how close two Random Variables are to having a \emph{Linear
  Relationship}

Normalized \emph{Covariance} (\S\ref{sec:covariance})

Correlation is Dimensionless, while Covariance is in units resulting from
multiplying the two Variables

completely Un-correlated Variables may be called \emph{Orthogonal}
(\S\ref{sec:orthogonality}); cf. White Frequency Spectrum
(\S\ref{sec:frequency_spectrum})

\fist cf. Cross-correlation (\S\ref{sec:cross_correlation}), Autocorrelation
(\S\ref{sec:autocorrelation})

\fist cf. Linear Regression (\S\ref{sec:linear_regression})

cf. Observational Studies

\[
  \rho_{X,Y} = \frac{Cov(X,Y)}{\sigma_X \sigma_Y}
\]
where $Cov(X,Y)$ is the Covariance (\S\ref{sec:covariance})

if $X$ and $Y$ are Independent (\S\ref{sec:dependence}) and have Finite Second
Moments, then they are Uncorrelated; not all Uncorrelated Variables are
Independent

if $X$ and $Y$ are Independent, then $Cov(X,Y) = \rho = 0$

\url{https://terrytao.wordpress.com/2014/06/05/when-is-correlation-transitive/}:
given two Unit Vectors $v$, $w$ in a Real Inner Product Space
(\S\ref{sec:inner_product}), the \emph{Correlation} between the Vectors is the
Inner Product $\langle{v,w}\rangle$; the Correlation of two non-constant
Square-integrable Real-valued Random Variables $X$ and $Y$ is the same as the
Correlation between two Unit Vectors $v$, $w$ in the Hilbert Space $L^2(\Omega)$
of Square-integrable Random Variables, where $v$ is the Normalization of $X$
defined by subtracting the Mean (Expected Value) $E[X]$ and dividing by the
Standard Deviation of $X$, and similarly for $w$ and $Y$



\subparagraph{Correlation Coefficient}\label{sec:correlation_coefficient}\hfill

\emph{Bivariate Correlation} or \emph{Pearson Product-moment Correlation
  Coefficient}

$\rho_{xy} = \frac{\sigma_{xy}}{\sigma_x \sigma_y}$

Sample Correlation Coefficient $-1 \leq r \leq 1$:
\[
  r = \frac{1}{n-1} \sum_{i=1}^n
    \Big(\frac{x_i - \overline{x}}{s_x}\Big)
    \Big(\frac{y_i - \overline{y}}{s_y}\Big)
\]
where $s_x$ and $s_y$ are the Sample Standard Deviations of $x$ and $y$

\fist cf. $r^2$ -- Coefficient of
Determination (\S\ref{sec:determination_coefficient})



\paragraph{Long-range Dependence}\label{sec:long_range_dependence}\hfill

\emph{Long Memory} or \emph{Long-range Persistence}

when Dependence decays more slowly than Exponential Decay
(\S\ref{sec:exponential_decay})

Spatial (\S\ref{sec:spatial_analysis}) and Time Series
(\S\ref{sec:time_series_analysis}) Data

\fist Fractional Brownian Motion (\S\ref{sec:fractional_brownian})

\fist ARFIMA (\S\ref{sec:arfima})

cf. ``Memoryless-ness'' (\S\ref{sec:memoryless_distribution})

cf. Short-term Dependence: Markov Processes (\S\ref{sec:markov_process}), ARMA,
ARCH

(Mandelbrot97E) Wild Randomness (\S\ref{sec:statistical_randomness}) is
characterized by presence of ``structure'' and Long-range Dependence



\subparagraph{Index of Long-range Dependence}\label{sec:hurst_exponent}\hfill

\emph{Rougness Exponent} or \emph{Hurst Exponent}

$H$

a measure of Long-term Memory in Time Series (\S\ref{sec:time_series})

relates to the Autocorrelations (\S\ref{sec:autocorrelation}) of Time Series and
the ``rate'' at which the Autocorrelations decrease as the lag between pairs of
values increases

defined in terms of the Asymptotic behavior of the Rescaled Range
(\S\ref{sec:rescaled_range}) as a function of the ``time span'' of a Time
Series:
\[
  \expect\big(\frac{R(n)}{S(n)}\big) = Cn^H
\]
as the time span $n \to \infty$ where $C$ is a Constant and $R(n)$ is the Range
of the first $n$ Cumulative Deviations from the Mean (FIXME: clarify) and $S(n)$
is their Standard Deviation

Fractional Brownian Motion (\S\ref{sec:fractional_brownian})

Fractal Co-dimension (\S\ref{sec:fractal_codimension}) -- Hurst Exponent
represents structure over asymptotically longer periods, Fractal Dimension
(\S\ref{sec:fractal_dimension}) represents structure over asymptotically shorter
periods

Rescaled Range (R/S) Analysis -- Estimation of Hurst Exponent

Range $R(n)$

Standard Deviation $S(n)$

Rescaled Range $R(n) / S(n)$

(Mandelbrot97E)

robust with respect to Infinite Variance

cf. ``Market Efficiency''-- Dependence ($J > 0.5$) implies exogenous factors



\subparagraph{Generalized Index of Long-range Dependence}
\label{sec:generalized_hurst}\hfill

$H(q)$

when $H(q)$ is a Non-linear Function of $q$, the Time Series is a Multifractal
System (\S\ref{sec:multifractal_system})



% ------------------------------------------------------------------------------
\subsection{Normalizing Ratio}\label{sec:normalizing_ratio}
% ------------------------------------------------------------------------------

Non-dimensional (\emph{Scale Invariant} \S\ref{sec:scale_invariance}) Ratios of
Errors, Residuals, Means, and Standard Deviations

only makes sense at the Ratio Measurement Level (\S\ref{sec:measurement_level})

Standard Score

Student's $t$-statistic

Studentized Residual

Standardized Moment

Coefficient of Variation

Min-max Feature Scaling (\S\ref{sec:minmax_normalization})



% ------------------------------------------------------------------------------
\subsection{Earthmover Distance}\label{sec:earthmover_distance}
% ------------------------------------------------------------------------------

%FIXME: does this section belong here?

a measure of ``nearness'' for Probability Distributions

\url{https://jeremykun.com/2018/03/05/earthmover-distance/}



% ==============================================================================
\section{Inferential Statistics}\label{sec:inferential_statistics}
% ==============================================================================

\emph{Statistical Inference} (or ``\emph{Learning}'' in Computer Science) --
using \emph{Sample Data} (\S\ref{sec:sample}) to \emph{Infer} (cf. Logical
Inference \S\ref{sec:logical_inference}, Inference Rules
\S\ref{sec:inference_rule}) the Distribution
(\S\ref{sec:probability_distribution}) that ``generated'' the Data

\fist cf. Statistical Learning Theory (\S\ref{sec:statistical_learning_theory})

\fist cf. Probabilistic Inference
(\S\ref{sec:probabilistic_inference}), Inductive Inference
(\S\ref{sec:inductive_inference})

\fist Probabilistic Classification (\S\ref{sec:probabilistic_classification}) --
use of Statistical Inference to solve a Statistical Classification
(\S\ref{sec:classification}) problem

(wiki)

two approaches to Statistical Inference, both relying on some \emph{Statistical
  Model} (\S\ref{sec:statistical_model}) to represent a ``Data-generating
Process'' (cf. Stochastic Process \S\ref{sec:stochastic_process}):
\begin{enumerate}
  \item \emph{Model-based Inference} -- the Model is taken to be initially
    unknown and the goal is to \emph{Select} (\S\ref{sec:model_selection}) a
    Model for Inference
  \item \emph{Design-based Inference} -- the Model is taken to be known and the
    goal is to ensure Sample Data is selected \emph{Randomly}
    (\S\ref{sec:random_sample}) enough for Inference
\end{enumerate}
the Statistical Assumptions (\S\ref{sec:statistical_assumption}) made by a
Statistical Model depends on the approach taken

Wasserman04 - \emph{All of Statistics}, Part II \emph{Models, Statistical
  Inference and Learning}

McCullagh02 - \emph{What is a Statistical Model?} -- Inference is concerned with
``natural extension'' of a Statistical Model



% ------------------------------------------------------------------------------
\subsection{Statistical Assumption}\label{sec:statistical_assumption}
% ------------------------------------------------------------------------------

(wiki):

\emph{Informally}, a Statistical Model (\S\ref{sec:statistical_model}) can be
thought of as a Set of Statistical Assumptions that allow the calculation of the
Probability of any Event (\S\ref{sec:event}), i.e. the Statistical Model
``embodies'' the Set of Statistical Assumptions that concern the
\emph{Generation} (\S\ref{sec:data_generating_process}) of Sample Data
(\S\ref{sec:sample}).

\emph{Classes of Assumptions} depend on which approach to Statistical Inference
is used (Model-based Inference or Design-based Inference):
\begin{enumerate}
  \item \emph{Model-based Assumptions}:
    \begin{itemize}
      \item \emph{Distributional Assumptions} -- Assumptions about the
        Probability Distribution of Random Errors (\S\ref{sec:random_error})
      \item \emph{Structural Assumptions} -- Assumptions about the form of a
        Statistical Relationship (Dependence \S\ref{sec:dependence}) between
        Variables, e.g. as in Linear Regression (\S\ref{sec:linear_regression})
      \item \emph{Cross-variation Assumptions} -- Assumptions involving Joint
        Probability Distributions (\S\ref{sec:joint_probability}) of either
        Observations or Random Errors in a Model; simple Models may Assume that
        Observations or Errors are Statistically Independent
        (\S\ref{sec:independence})
    \end{itemize}
  \item \emph{Design-based Assumptions} -- Assumptions of the way Observations
    have been made, e.g. Assumption of Randomization during Sampling
    (\S\ref{sec:random_sample})
\end{enumerate}

cf. Statistical Hypothesis (\S\ref{sec:hypothesis})

\fist Assumption (Proof Theory \S\ref{sec:antecedent})



% ------------------------------------------------------------------------------
\subsection{Statistical Model}\label{sec:statistical_model}
% ------------------------------------------------------------------------------

A \emph{Statistical Model} (or \emph{Probabilistic Model})
$\mathfrak{F} = (S,\mathcal{P})$ is a Sample Space (\S\ref{sec:sample_space}),
$S$, together with a Set of Probability Distributions
(\S\ref{sec:probability_distribution}) $\mathcal{P}$ on $S$

(wiki): \emph{Informally}, a Statistical Model can be thought of as a Set of
Statistical Assumptions (\S\ref{sec:statistical_assumption}) that allow the
calculation of the Probability of any Event (\S\ref{sec:event}), i.e. the
Statistical Model ``embodies'' the Set of Statistical Assumptions that concern
the \emph{Generation} (\S\ref{sec:data_generating_process}) of Sample Data
(\S\ref{sec:sample}).

\begin{itemize}
  \item \emph{Parametric Models} (\S\ref{sec:parametric_model}) -- Distributions
    are Parameterized by a Finite number of \emph{Statistical Parameters}
    (Population Parameters \S\ref{sec:population_parameter})
  \item \emph{Non-parametric Models} (\S\ref{sec:nonparametric_model})
    -- has an Infinite-dimensional Parameter Space
  \item \emph{Semi-parametric Models} (\S\ref{sec:semiparametric_model}) -- has
    Finite-dimensional Parameters and Infinite-dimensional
    ``Nuisance Parameters''
  \item \emph{Semi-nonparametric Models} (\S\ref{sec:seminonparametric_model})
    -- has both Finite-dimensional and Infinite-dimensional unknown Parameters
    of interest
\end{itemize}

\emph{Parameter Estimation} (\S\ref{sec:estimation_theory}): Data $\to$
Parameters

\emph{Prediction} (\S\ref{sec:prediction})

\emph{Hypothesis Testing} (\S\ref{sec:hypothesis_testing})

\fist a \emph{Regression Model} (\S\ref{sec:regression_model}) makes some
assumption about the Relations (Dependences \S\ref{sec:dependence}) among
Multivariate Data (\S\ref{sec:random_vector})

\fist \emph{Classification Model} (\S\ref{sec:classification_model})

\fist Markov Models (Stochastic Processes \S\ref{sec:markov_model})

VC Dimension (Model Complexity \S\ref{sec:vc_dimension})

(wiki):

$\mathfrak{F} = (S, \mathcal{P})$

$S$ -- ``Sample Space''

$\mathcal{P}$ -- Set of Probability Distributions
(\S\ref{sec:probability_distribution}) on $S$

Wasserman04, Ch.6

\asterism

MIT 6.041SC - \emph{Probabilistic Systems Analysis and Applied Probability}

Probability Laws -- describes ``beliefs'' about which outcomes are more likely
than others; should obey Probability Axioms (\S\ref{sec:probability_axioms})

Sample Space $\Omega$ -- description of possible outcomes

a ``list'' of Events should be Mutually Exclusive
(\S\ref{sec:mutually_exclusive}, for $\sigma$-additivity Axiom) and exhaustive
(for Unitarity Axiom)

\emph{Discrete Uniform Law} (\S\ref{sec:discrete_uniform_law}): all Outcomes are
equally likely

\emph{Continuous Uniform Law} (\S\ref{sec:continuous_uniform_law}): equal Areas
have equal Probabilities

Discrete Models

Continuous Models -- any individual outcome has Zero Probability (TODO: explain)

Models based on Conditional Probabilities (\S\ref{sec:conditional_probability})

\asterism

2002 - McCullagh - \emph{What is a Statistical Model?}

\emph{Inference} on the basis of a Model is not possible unless the Model admits
a ``natural extension'' that includes the Domain for which Inference is
required, i.e. Prediction requires that the Domain includes all future Units,
subjects, or ``time points''

certain Parameter Functions are ``natural'' and others are not; Inference is
only \emph{meaningful} for ``natural'' Parameters

to a Statistical Model as a Function $P : \Theta \to \mathcal{P}(S)$
from Parameters to Distributions on $S$, there is an associated Set of
Distributions $P \Theta \subset \mathcal{P}(S)$

a Bayesian Model adds a Prior Distribution on $\Theta$

a Parameterization is \emph{Identifiable} if distinct Parameter values yield
distinct Distributions, i.e. $P_\theta = P_\theta' \implies \theta = \theta'$;
it follows that a Parameterization is Identifiable if and only if
$P : \Theta \to \mathcal{P}(S)$ is Injective

each \emph{Statistical Experiment} or ``Observational Study'' (cf. Experiment
\S\ref{sec:experiment}) is built from:
\begin{enumerate}
  \item a Set $U$ of \emph{Statistical Units} (\S\ref{sec:statistical_unit})
  \item a \emph{Covariate Space} $\Omega$
  \item a \emph{Response Scale} $V$
\end{enumerate}

the ``\emph{Design}'' is a Function $x : U \to \Omega$ that associates with each
Statistical Unit $i \in U$ a Point $x_i$ in the Covariate Space; may be
represented as a Design Matrix $X$

the Set $D = \Omega^U$ of all Design Functions is the \emph{Design Space}

the \emph{Response} is a Function $y : U \to V$ associating a Response Value
$y_i \in V$ to each Statistical Unit $i$

the Set $S = V^U$ of all Response Functions is called the \emph{Sample Space}
(\S\ref{sec:sample_space})

a \emph{Statistical Model} consists of a Design $x : U \to \Omega$, a Sample
Space $S = V^U$, and a Family of \emph{Distributions} on $S$

a Parameterized Model $P : \Theta \to \mathcal{P}(S)$ associates to each
Parameter Value $\theta$ a Distribution $P\theta$ on $S$

the Parameterized Model additionally depends on the Design, so to each Design
$x : U \to \Omega$ there corresponds a map $P_x : \Theta \to \mathcal{P}(S)$
such that $P_x\theta$ is a Probability Distribution on $S$

for Statistical Inference to be valid, the \emph{dependence} of $P_x$ on
$x \in D$ cannot be \emph{arbitrary}

before a Model can be discussed, it is necessary to establish a
``\emph{Inferential Universe}'' of Statistical Units

the purpose of such a trial is to draw conclusions regarding Covariate values
for comparable but otherwise unobserved Units; it should also be possible to
draw conclusions about Subsets of Covariate values

universe of interchangeable \emph{Response Scales}, e.g. mph, km/s, m/s, with
Transformations between them and for Multivariate Response Scales it should be
possible to make Inferential Statements about each in Isolation

every ``logically defensible'' Statistical Model has a ``natural'' extension
from the Set of Observed Units, Observed Covariates, or Observed Responses to
Unobserved Units, Unobserved Covariates, or Unobserved Responses

the ``logic'' of every Statistical Model is founded on \emph{Categories of
  Morphisms} of the relevant spaces

\emph{Category of Statistical Designs}

$\cat{U}$ -- Category of Statistical Units; Objects are all possible Sets of
Statistical Units, possibly with temporal, spatial, or other structure;
Morphisms are structure-preserving maps $\varphi : U \to U'$, including all
insertion maps such that $\varphi u = u$ whenever $U \subset U'$; in typical
Regression problems, $\cat{u}$ is identified with the generic Category of
Injective maps on Finite Sets, i.e. maps preserving distinctness of Units

$\cat{V}$ -- Category of Response Scales; e.g. for temperature Response, there
would be one Object for each scale $\degree C$, $\degree F$, $\degree K$; for
each Ordered Pair of Response Scales $(V, V')$ there is a Surjective Morphism
$V \to V'$

$\cat{O}$ -- Category of Covariate Spaces; Morphisms are ordinarily
Injective maps between Covariates Spaces; when there are different measurement
scales for a Quantitative Covariate, the Objects of $\cat{O}$ are some or
all Subsets of each measurement scale, and Morphisms are generated by
composition of Subset Insertion maps and measurement-scale Transformations; for
Un-ordered Qualitative Covariates, $\cat{O}$ may be identified with the
Category of Injective maps on Finite Sets; for Ordered Qualitative Covariates,
$\cat{O}$ may be identified with the Subcategory of Order-preserving
Injective maps; in ``Factorial Designs'' where the Design has several
``factors'', then $\cat{O}$ is a Category where each Object is a Product
Set $\Omega = \Omega_1 \times \cdots \times \Omega_k$ and the Category of
Morphisms is usually the Product Category with one component Category for each
factor

(Cox, Snell 1981)

``\emph{Intensive Response Variables}'' -- Functions on Units that does not have
a ``Physically Additive'' interpretation; e.g. the sum of two measurements of
blood pressure does not have have a direct physical interpretation;
(Kingman 1984): cf. Random Process as an Indexed Family of Random Variables
$X_t$

``\emph{Extensive Response Variables}'' -- (``Physically'') Additive Set
Functions; e.g. yield, count, time interval; Mean is of interest, but Log
or other Non-linear Transformations are generally not of interest;
(Kingman 1984): cf. Point Process as the Number of Points in an Interval
$X_t - X_s$ or Subset of a Multi-dimensional Space; cf. Cumulants
(\S\ref{sec:cumulant})

\emph{Statistical Model}:
\begin{enumerate}
  \item $\cat{U}$
  \item $\cat{O}$
  \item $\cat{V}$
\end{enumerate}

\emph{Design Category} $\cat{D}$ -- Objects $x : U \to \Omega$ with
$U \in \cat{U}$ and $\Omega \in \cat{O}$ (or Design Matrices $X$ with labelled
rows and columns), and Morphisms $\varphi : x \to x'$ may be associated with a
pair of Injective maps $\varphi_d : U \to U'$ in $\cat{U}$ and
$\varphi_c : \Omega \to \Omega'$ in $\cat{O}$, such that
$\varphi_c \circ x = x' \circ \varphi_d$

for each Injective Morphism $\varphi : U \rightarrowtail U'$ in $\cat{U}$, there
is a corresponding ``Coordinate Projection Map'', $\varphi^* : V^{U'} \to V^{U}$

\emph{Sample Space Category} $\cat{S}$

for $f \in V^{U'}$, the Pullback Map defined by Function Composition
$\varphi^* (f) = f \circ \varphi$ is a $V$-valued Function on $U$; therefore
$(V, *)$ is a \emph{Functor} on $\cat{U} \to \cat{S}$ associating each $U$ with
the Sample Space $V^U$ and with each Morphism $\varphi : U \to U'$ the map
$varphi^* : V^{U'} \to V^U$ by Function Composition; by Functoriality of
$(V, *)$, the Identity $U \to U$ is mapped to the Identity $V^U \to V^U$ and the
Composite map $\psi\varphi : U \to U''$ to the Composite
$\varphi^*\psi^* : V^{U''} \to V^U$

in $\cat{S}$ Objects $V^U$ (with $V \in \cat{V}$
and $U \in \cat{U}$) and Morphisms $V^{U'} \to V'^{U}$ are Compositions
$\gamma_U(\varphi_V^*) = \varphi_{V'}^*(\gamma_{U'})$ where $\gamma : V \to V'$
is a Morphism of the Codomain and $\varphi^*$ is a  Functional Composition with
the Domain Morphism $\varphi : U \to U'$, i.e. the Category of Morphisms on
Sample Spaces is built from a Category of Injective Morphisms on Units and a
Category of Morphisms on Response Scales

$\cat{S}$ is Isomorphic with the Product Category $\cat{V} \times \cat{U}^{op}$

\emph{Example: Linear Model}

``skeletal description'':

$V$ is a Vector Space and Sample Space $V^U$ is also a Vector Space; a
\emph{Linear Model} is a Subspace of $V^U$ ``suitably related'' to the Design,
determined by a ``\emph{Subrepresentation}'' $\Theta_\Omega \subset V^{\Omega}$
together with a \emph{Design Pullback} map $\psi^*$

(TODO: commutative diagrams)

a Subrepresentation $\Theta$ in the standard Representation (FIXME: clarify
``standard representation'') $V^{\Omega}$ is a
Sequence of Subspaces $\{ \Theta_\Omega \subset V^\Omega \}$ Indexed by the
Objects in $\cat{O}$ such that for each map $\varphi_c : \Omega \to \Omega'$ in
$\cat{O}$, the Linear Transformation $\varphi_c^* : V^{\Omega'} \to V^\Omega$
also satisfies $\varphi_c^* \Theta_{\Omega'} = \Theta_\Omega$

in the usual complete formulation, the Parameter Space is extended to
$\Theta \times \reals^+$ by the inclusion of a Dispersion Parameter $\sigma^2$
and for the Design $\psi : U \to \Omega$, the Sample Space is $V^U$, and the
full Normal-theory Linear Model is the Set of Normal Distributions with Mean
Vector in the Subspace $\psi^*\Theta_\Omega$, and the Variance Matrix is
``Proportional to the Identity'' (FIXME: clarify)

the skeletal description is shared by Non-normal Linear Models, certain
Non-linear Models, and all Generalized Linear Models by modification of the step
by which the Representation $\Theta$ determines a Family of Distributions on
$S = V^U$ by the Linear Predictor $\eta = \psi^*\theta$ from $\Theta \to V^U$
and an Invertible Link Function $\eta = g(\mu)$ that is also a ``Natural''
Componentwise Transformation $V^U \to V^U$ together with a suitable Error
Distribution with independent components

``general construction'':

for each fixed $V$, the Parameter $(\Theta, *)$ is a Contravariant Functor
$\cat{O} \to \cat{K}$, associating each Covariate Set $\Omega$ with a Parameter
Set $\Theta_\Omega$, and each Injective Covariate Morphism
$\varphi_c : \Omega \to \Omega'$ with a Surjective Parameter map
$\varphi_c^* : \Theta_{\Omega'} \to \Theta_\Omega$; when $\cat{K}$ is the
Category of Surjective Linear Transformations on Vector Spaces, $\Theta$ is
called a \emph{Representation} (\S\ref{sec:representation}) of $\cat{O}$

\emph{Model Category} $\cat{M}$

\emph{Distribution Category} $\cat{F}$

a \emph{Statistical Model} is then a Functor on the Design Category
$\cat{D} \to \cat{M}$ associating with each Design Object $\psi : U \to \Omega$
a \emph{Model Object} that is a map $P_\psi : \Theta_\Omega \to \mathcal{P}(S)$
such that $P_\psi\theta$ is a Probability Distribution on $S$, and to each
Morphism $(\varphi_d,\varphi_c) : \psi \to \psi'$ in $\cat{D}$ is associated a
map $(\varphi_d^\dagger, \varphi_c^*) : P_{\psi'} \to P_\psi$; the Set of
Distributions generated is $\mathcal{F}_\psi = P_\psi \Theta_\Omega$

as a result of this definition:
\begin{enumerate}
  \item (\emph{Commutativity Condition}) the Sample-space Transformation
    $\varphi_d^* : S' \to S$ also carries each Distribution $F$ on $S'$ to a
    transformed Distribution $\varphi_d^\dagger F = F \circ \varphi^{*-1}_d$ on
    $S$,
  \item (\emph{Consistency Condition}) by Commutativity,
    \[
      P_\psi\varphi_c^* =
        \varphi_d^\dagger P_{\psi'} : \Theta_{\Omega'} \to \mathcal{P}(S)
    \]
    that is,
    \[
      \theta \in \Theta_{\Omega'}, P_\psi \varphi_c^* \theta =
        \varphi_d^\dagger P_{\psi'} \theta
    \]
\end{enumerate}
(1.) ensures that the Family of Distributions on $S$ is ``\emph{suitably
embedded}'' in the Family of Distributions on $S'$-- the maps
$\varphi_d^* : S' \to S$ that define the embedding depend on the Category of
Morphisms on Units; for $\varphi_c$ equal to the Identity on $\Omega$, and
therefore $\varphi_c^*$ equal to the Identity on $\Theta_\Omega$, the
Consistency Condition (2.) asserts that the Distribution $P_\psi\theta$ on
$S$ is \emph{the same} as the Marginal Distribution of $P_{\psi'}\theta$ on $S'$
by the embedding map $\varphi_d^* : S' \to S$ (FIXME: clarify)

these statements ensure that a Statistical model is a Natural Transformation
$P : \Theta \to \mathcal{P}(S)$

the association $U \mapsto V^U$, $\varphi_d \mapsto \varphi_d^*$ determines the
``structure'' of the Sample Spaces as a Functor $\cat{U} \to \cat{S}$ (FIXME:
this is the same functor as $(V, *)$ ???), and therefore as a Functor on
$\cat{D}$ (FIXME: explain)

the Set of Morphisms of Sample Spaces is a Category Isomorphic to
$\cat{U}^{op}$, and likewise the association $U \mapsto \mathcal{P}(V^U)$,
$\varphi_d \mapsto \varphi_d^\dagger$ is a Functor $\cat{U} \to \cat{F}$,
with Image Isomorphic to $\cat{U}^{op}$

the mapping $S \to \mathcal{P}(S)$, $\varphi_d^* \mapsto \varphi_d^\dagger$ is
an Isomorphism $\cat{S} \cong \cat{F}$

the Parameter $\Theta$ is a Functor on $\cat{O}$ and therefore on $\cat{D}$
(FIXME: explain)

therefore the Model $P : \Theta \to \mathcal{P}(S)$ is a \emph{Natural
  Transformation} of Functors $\cat{D}$ (FIXME: is this
$(\Theta, *) \implies (V, *)$ ???)

the Set of Models $\Theta \to \mathcal{P}(S)$ is Convex

``\emph{sense}'' of a Model, ``\emph{meaning}'' of a Parameter

the definition of $\varphi_d^\dagger$ and Consistency Condition (2.) above
ensures that the \emph{meaning} of the Parameter is \emph{retained} for families
on different Sample Spaces and different Designs

Parameter Sets $\Theta_\Omega$, maps $P$ and $\varphi_c^*$ are not otherwise
prescribed allowing variation in construction of specific Models

Vector Space $Vect(S)$ of Formal Linear Combinations
$\alpha_1 s_1 + \alpha_2 s_2 + \cdots$ of Elements of $S$; restricting to Formal
Convex Combinations in which $\alpha_i \geq 0$ and $\Sigma \alpha_i = 1$ obtains
the Subset $\mathcal{P}(S) \subset Vect(S)$ of Probability Distributions on $S$

if $S$ is Coutnable, then each Formal Convex Combination can be interpreted as
an ``\emph{Operation}'' in which an Element fo $S$ is chosen according to the
Probability Distribution; then each Function $h : S \to T$ determines a Linear
Transformation $h^* : Vect(S) \to Vect(t)$ where:
\[
  h^*(\alpha_1 s_1 + \alpha_2 s_2 + \cdots) =
    \alpha_1 h(s_1) + \alpha_2 h(s_2) + \cdots
\]
given $h : S \to T$, Formal Linearity determines
$h : \mathcal{P}(S) \to \mathcal{P}(T)$

to each Model Object $P_\psi : \Theta_\Omega \to \mathcal{P}(S)$ there
corresponds a map
$P_\psi : \mathcal{P}(\Theta_\Omega) \to \mathcal{P}(\Theta_\Omega \times S)$
assocaiating each Prior Distribution $F$ on $\Theta_\Omega$ a Joint Distribution
$P_\psi F$ on $\Theta \times S$ by Formal Convex Combinations, and the Marginal
Distribution on $S$ is obtained by Integration over $\Theta_\Omega$, i.e. by
treating the Formal Lineawr Combination $F$ as an ``actual'' Lineawr Combination

\emph{Hierarchical Models} -- ``chain'' $\Theta^1, \Theta^2, \ldots, \Theta^k$
of Parameter Functors with a ``chain'' of Natural Transformations:
\[
  P_1:\Theta^1 \to \mathcal{P}(\Theta^2),
  P_2:\Theta^2 \to \mathcal{P}(\Theta^3), \ldots,
  P_k:\Theta^k \to \mathcal{P}(S)
\]
and by the compositional operation above:
\[
  (P_k P_{k-1} \cdots P_1):
    \Theta^1 \to \mathcal{P}(\Theta^2 \times \cdots \times \Theta^k \times S)
\]
this is not a Statistical Model according to the definition, but it can be
converted into one by the Natural Transformation of \emph{Integration} in which
Formal Linear Combination $P_{k-1} \cdots P_1$ is interpreted as an ``actual''
Linear Combination:
\[
  \Theta^1 \xrightarrow{P_k \cdots P_1}
    \mathcal{P}(\Theta^2 \times \cdots ;\times \Theta^k \times S) \to
    \mathcal{P}(S)
\]
(FIXME: clarify)

a \emph{Bayesian Model} (Bayes Network \S\ref{sec:bayes_network}) is a
Hierarchical Model in which $k > 1$ and $\Theta^1 = \{0\}$ is the Trivial
Functor, a one-point Set with Identity Map (FIXME: clarify)

\url{https://statmodeling.stat.columbia.edu/2019/05/21/neural-nets-vs-statistical-models/}
-- some comments on Hierarchical Models as related to Neural Networks:
\begin{quote}
  Neural nets are a special case of Statistical Models, typically Bayesian
  Hierarchical Logistic Regression with latent Parameters. But Neural Nets are
  typically Estimated in a different way: the resulting Posterior Distributions
  will generally be Multimodal, so rather than try the hopeless task of
  traversing the whole Posterior Distribution, we’ll use various approximate
  methods, which then are evaluated using predictive accuracy.
\end{quote}

\emph{Submodels}

\emph{Subparameters} -- the notion that only certain Fuctions on Parameters
``make sense'' is understood and formalized to some extent by Dimensional
Analysis in Physics

a \emph{Natural Subparameter} is a Natural Transformation $g : \Theta \to \Xi$
of Functors on $\cat{D}$

Complementary Subparameters

Identifiable Subparameters

\emph{Response-scale Morphisms} -- $\gamma : V \to V'$

for each Response Scale $V \in \cat{V}$, the Sample Space is a Contravariant
Functor on $\cat{U}$ and the Model is a Contravariant Functor on the Design
Category; to each $\gamma : V \to V'$ in $\cat{V}$ there corresponds a Natural
Transformation of Sample Spaces (TODO: commutative diagram)

$\cat{S}$ is built up from a Category of Injective Morphisms on Units and a
Category of Morphisms on Response Scales, and $\cat{S}$ is Isomorphic to the
Product Category $\cat{V} \times \cat{U}^{op}$

the ``logical structure'' of a Statistical Model is given by the following
Functor ``sequences'':
\begin{flalign*}
  & \cat{V} \times \cat{D}^{op} \to \cat{V} \times \cat{U}^{op}
      \cong \cat{S} \cong \mathcal{P}(S) \\
  & \cat{V} \times \cat{D}^{op} \to \cat{V} \times \cat{O}^{op}
      \xrightarrow{\Theta} \cat{K} \\
  & P : \Theta \to \mathcal{P}(S)
\end{flalign*}

a Model is a Natural Transforamtion $P : \Theta \to \mathcal{P}(S)$ associating
each pair $(V, \psi : U \to \Omega)$ a map
$P_\psi : \Theta \to \mathcal{P}(V^U)$ satisfying Property (1.) above

``in the absence of Covariate effects'' (FIXME: does this just mean keeping a
fixed covariate set ???), the Commutative Diagram of a Statistical Model takes
a form in which the Model $P : \Theta \to \mathcal{P}(S)$ is indexed by Sample
Spaces $S, S', \ldots$; the Parameter Space $(\Theta, \dagger)$ is a Covariant
Functor on $\cat{V}$ associating each Response Scale $V$ with a Parameter Set
$\Theta_V$ and with each Morphism $\gamma : V \to V'$ a Parameter Morphism
$\gamma^\dagger : \Theta_V \to \Theta_V'$; also to each Morphism of Sample
Spaces $\gamma \varphi^* : V^{U'}\to V^{U}$, the Transformation on the Model is
described by a Commutative Diagram (TODO); implies
$P : \Theta \to \mathcal{P}(S)$ is a Natural Transformation of Functors

the statement that a Statistical Model is a Natural Transformation of Functors
is a Consistency Condition ensuring that different ways of computing the
Probability of equivalent Events gives \emph{the same answer}, and as a
consequence, equivalent Events determine the same Likelihood

\emph{Kolmogorov Consistency} (\S\ref{sec:kolmogorov_extension}) -- Insertion
Maps, $\cat{O} = \{ 0 \}$, $V = \reals$; the Consistency Condition (2.) above
is equivalent to the statement taht the Kolmogorov Existence Condition for a
Stochastic Process is satisfied at \emph{each Parameter Point}

\emph{Interference} -- Insertion Maps, $V = \reals$,
$\varphi_c = id_\Omega : \Omega \to \Omega$;
$P_\psi(E; \theta) = P_\psi'(E'; \theta)$;
assumption of \emph{Lack of Interference}; if $\cat{O}$ includes Insertion Maps,
then $\varphi_c : \Omega \to \Omega$ need not be the Identity Map, in which case
the Commutativity Condition (1.) above implies that Lack of Interference holds
for each family $P_\psi : \Theta_\Omega \to \mathcal{P}(\reals^U)$ and also for
$\Omega \neq \Omega'$ the Distributions in each family are related ``in a
natural way''; for each $\theta'$ such that $\varphi_c^* \theta' = \theta$,
$P_\psi(E; \theta) = P_{\psi'}(E'; \theta')$

\emph{(Infinite) Exchangeability} (\S\ref{sec:infinitely_exchangeable}) --
$\cat{U} = \cat{FinSet}_\rightarrowtail$ Category of Injective Maps on Finite
Sets, $V = \reals$, $\cat{O} = \{ 0 \}$; to each Injective Map
$\varphi : U \rightarrowtail U'$ in $\cat{FinSet}_\rightarrowtail$ the standard
(Contravariant) Representation associates the Surjective Linear Map
$\varphi^* : \reals^{U'} \twoheadrightarrow \reals^{U}$; for $U = U'$,
$\varphi^*$ Permutes Coordinates, or more generally $\varphi^*$ is a
Coordinate-projection Map; the Commutativity Condition (1.) is the statement
that for each $P_U\theta$ on $\reals^U$, $\theta \in \Theta$, the Distribution
$P_U \theta$ is Invariant under Coordinate Permutation, and for each Injection
$\varphi : U \rightarrowtail U'$, the Coordinate-projection map $\varphi^*$
carries the Distribution $P_U'\theta$ on $\reals^{U'}$ to $P_U\theta$ on
$\reals^U$-- i.e. for each $\theta \in \Theta$ there corresponds a Sequence
$\{ P_U\theta \}$ that is the Distribution of an \emph{Infinitely} Exchangeable
Sequence of Random Variables, and the Set
$Inv_{\cat{FinSet}_\rightarrowtail}(\reals^U)$ of all Natural Transformations
$\{0\} \to \mathcal{P}(\reals^U)$ is the Set of all Infinitely Exchangeable
Probability Models on the standard Representation

\emph{Partial Exchangeability} -- $\cat{FinSet}_\rightarrowtail^2$, assume
$\Theta = \{0\}$ (TODO: more preliminaries); by the Commutativity Condition
(1.), for each rectangular index array
$\{1, \ldots, m\} \times \{1, \ldots n\}$, there corresponds a Distribution
$P_{mn}$ on $\reals^{mn}$ such that for $m' \geq m$ and $n' \geq n$, $P_{mn}$ is
the Marginal Distribution of $P_{m'n'}$ under all Coordinate-projection Maps
$(\varphi_1, \varphi_2)^*$ in the standard Representation and $P_{mn}$ is
Invariant under row Permutation and column Permutation; i.e. $P$ is the
Distribution of an Infinite Partially Exchangeable Array (Aldous81); conversely
each Infinite Partially Exchangeable Array of Random Variables has a
Distribution corresponding to a $\cat{FinSet}_\rightarrowtail^2$-invariant
Distribution and a Model is therefore a Set of such Distributions indexed by
$\Theta$; the Set $Inv_{\cat{FinSet}_\rightarrowtail^2}(S)$ of all
$\cat{FinSet}_\rightarrowtail^2$-natural Transformations
$\{0\} \to \mathcal{P}(S)$ is the Set of all Invariant Probability Models on the
standard $\cat{FinSet}_\rightarrowtail^2$-representation

\emph{Completely Randomized Design} -- $\cat{U} = \cat{FinSet}_\rightarrowtail$
Implies that the Units are Infinitely Exchangeable; ... MORE

\emph{Block Designs}

\emph{Causality}, \emph{Non-specific Effects} -- Random Effects Models
(\S\ref{sec:random_effect}); Non-specific Factors (Blocks, temporal structure,
spatial structure) for which no ``level-specific'' Inferences are ``required''
can be best regarded as a \emph{Property} defining the structure of the Unit;
Specific Factors (Treatment, Variety, Age, etc.) for which ``level-specific''
Features may be ``required'' must be regarded as Objects in $\cat{O}$;
``level-specific'' Effects may be ascribed to Specific Factors (``intrinsic'' or
not), but \emph{Causal} Effects are not ``ordinarily'' ascribed to ``intrinsic''
Factors (FIXME: clarify);
Causal mechanisms are necessarily \emph{context dependent} in ways that
Categories and Morphisms are not;
a given Model arising in different fields may be capable of numerous
``mechanistic'' interpretations, and Models exist for which \emph{no}
mechanistic interpretation is ``readily'' available or else are in conflict
with accepted ``scientific'' laws, but such alternative Models are
\emph{necessary} in order to test scientific laws

\emph{Location-scale Models} -- Models with IID Scalar Responses are determined
by their $1$-dimensional Marginal Distributions on the Response Scale (ignores
$\cat{U}$ and $\cat{O}$); \emph{Transformations} of the Response Scale, i.e.
Morphisms in $\cat{V}$; (MORE: preliminaries); in an example Location-scale
Model $(\theta_1, \theta_2) \mapsto N(\theta_1, \theta_2^2)$, $\theta_1$ and
$\theta_2$ are Natural Subparameters, but the Coefficient of Variation
(\S\ref{sec:variation_coefficient}) $\tau = \theta_1 / \theta_2$ is not
a Natural Subparameter because
$(\theta_1, \theta_2) \mapsto \theta_1 / \theta_2$ is not Natural for the
Category of Location-scale Transformations, \emph{but} for the Subcategory
$(0, b)$ of Component-wise Non-zero Scalar Multiplication, the Coefficient of
Variation \emph{is} a Natural Subparameter with induced Transformation
$\tau \mapsto sign(b) \tau$

\emph{Regression}, \emph{Correlation} -- $\sigma^2_\psi$ is not Invariant under
selection of Units so the Correlation Coefficient $\rho$ is not a Natural
Transformation-- any Inferential statement about $\rho$ must be interpreted
relative to a ``suitable'' Model and Categor for which $\rho$ \emph{is} a
Natural Tranformation of Functors, e.g. by regarding $(y, x)$ as a
\emph{Bivariate} Response on the Units, then $\Omega = \{ 0 \}$ and $\rho$ is a
Natural Subparameter

\emph{Splines}, \emph{Curve Estimation}

\emph{Contingency-table Models} (\S\ref{sec:contingency_table})

\emph{Embeddability}, \emph{Stochastic Processes}

in particular applications, the Category of Morphisms on Samples Spaces should
be established at the outset and must not be determined by the chosen
Family of Distributions, but by the ``\emph{context}''

\emph{Box-Cox Model}

\emph{Extensive Response Variables}

\emph{Spatial Aggregation}, \emph{Measure Processes} -- Borel Measure Space on a
fixed Domain $D$ in the Plane; Process as Random Variable $Y$ or Probability
Model $P$ satisfying Kolmogorov Consistency Condition; \emph{Point Process} is a
Process for which each ``Outcome'' is a Countable Set of Points in $D$, i.e. a
Point Process is a Non-negative Integer-valued Random Measure such that with
Probability $1$, $Y$ has Countable Support and no ``Multiple Points'' (FIXME:
xref)

\emph{Domain Morphisms} -- an \emph{Invariant Probability Model} is a Natural
Transformation $\{0\} \to \mathcal{P}(S)$ associating each Object $D$ with a
Process $P_D$ on $Meas(D)$ such for that each Domain Morphism
$\varphi : D \to D'$, the Sample Space map $\varphi^* : S_{D'} \to S_D$
satisfies $P_D = P_{D'} \circ \varphi^{*-1}$, e.g. the Poisson Process with
constant Unit Intensity Function is Invariant under Translation and Rotation of
Domains; for many Categories of Domain Morphisms, Invariant Processes do not
exist, e.g. there are no non-trivial Processes that are Invariant under
Translation and Scalar Multiplication, however the \emph{family} of Poisson
Processes with constant Intensity Function is closed under Similarity
Transformation, and likewise the family of Stationary Gaussian Processes with
constant Intensity and Isotropic Covariance Density

a Statistical Model $P : \Xi \to \mathcal{P}(S)$ is a Natural Transformation of
Functors on $\cat{D}$, e.g. for $\cat{D}$ the Group of Similarity
Transformations acting on $\reals^2$ one may take $\Xi_D = \reals^+$ and
$\varphi'$ are equal to the Jacobian of $\varphi$; if $P_D \xi$ is the
Homogeneous Poisson Process on $D$ with Intensity $\xi$, ``the Diagram
Commutes'' (FIXME: clarify)

generally for $\Xi_D$ the Set of Non-negative Measures on $D$, for each
$\varphi : D \to D'$, the induced map $\varphi'$ on Measures is given by
$(\varphi' \mu)(A) = \mu(\varphi A)$ for $\mu \in \Xi_D'$ and $A \subset D$; if
$\mu$ is Non-atomic, so is $\varphi' \mu$, and the Set of Non-atomic Measures is
a Sub-functor of $\Xi$; if $P_{D'}\mu$ is a Poisson Process on $D'$ with
Non-atomic Mean Measure $\mu$, the induced Process
$\varphi^\dagger P_{D'}\mu$ on $D$ is Poisson with Non-atomic Mean Measure
$\varphi'\mu$, and ``the Diagram Commutes'' (FIXME: clarify); an arbitrary
Measure $\mu$ with Atoms gives rise to a Process in which multiple Events occur
with non-zero Probability at a single Point; although $P_D\mu$ is a Poisson
Process it is not a Point Process according to the usual definition; further
Sub-models exist if $\cat{D}$ is restricted to Continuous Maps

\emph{Covariate Effects in Spatial Processes}

\emph{Conformal Models} -- a \emph{Conformal Model} is a Natural Transforations
of Functors in which $\cat{D}$ is the Category of Conformal Maps acting on
Domains in the Plane (preserves local Euclidean structure); if
$\varphi : D \to D'$ is Conformal, then $\log J : D \to reals$ is Harmonic
(where $J(x) = |\partial\varphi(x) / \partial x|$ is the Jacobian of $\varphi$

\emph{Conformal Models with Covariates}

\emph{Lattice Approximation}

Br{\o}ns - \emph{Discussion} -- the Category of Designs $\cat{D}$ constructed by
McCullagh is the Comma Category:
\[
  \cat{D} = (U_\cat{U} \downarrow U_\cat{O})
\]
of $\cat{V}$-valued Functors, and the Category of Sample Spaces:
\[
  \cat{S} = \cat{V} \times \cat{U}^{op}
\]
and the ``basic Category'' (FIXME: model category ???) is the Product Category:
\[
  \cat{V} \times \cat{D}^{op}
\]
both $\cat{D}$ and $\cat{S}$ can be derived from the ``basic Category''

$\mathcal{P} : \cat{MeasSet} \to \cat{Set}$

$\Theta : \cat{O}^{op} \to \cat{K}$

Model as a Natural Transformation $P$:
\[
  P : U_\cat{K} \circ \Theta \circ \pi_{\cat{D}^{op}} \circ \pi_{\cat{U}^{op}}
    \to \mathcal{P} \circ \Theta \circ (1_{\cat{V}} \times \pi_{\cat{U}^{op}}
    : \cat{V} \times \cat{D}^{op} \to \cat{Set}
\]
(MORE: details)

simplest Parameterized Statistical Models are triples $(\Theta, S, P)$
consisting of a Parameter Set, Sample Space, and map
$P : \Theta \to \mathcal{P}(S)$

defining an Arrow (Morphism) between these Models as a pair $(\phi, t)$ of map
$\phi : \Theta \to \Theta'$ and Measurable map $t : S \to \S'$ such that
$\mathcal{P}(t) \circ P = P' \circ \theta$ Commutes, creating a Category
$\cat{StatMod}$ of Statistical Models which is the Comma Category
$(1_\cat{Set} \downarrow \mathcal{P})$

the Natural Transformation:
\[
  P : 1_{\cat{Set}} \circ U_\cat{K} \circ \Theta \circ \pi_{\cat{D}^{op}}
      \circ \pi_{\cat{U}^{op}}
    \to \mathcal{P} \circ \Theta \circ (1_{\cat{V}} \times \pi_{\cat{U}^{op}})
    : \cat{V} \to \cat{D}^{op} \to \cat{Set}
\]
is equivalent to a Functor:
\[
  P : \cat{V} \times \cat{D}^{op} \to (1_\cat{Set} \downarrow \mathcal{P})
\]
or a ``Diagram'' over the ``basic Category'' in $\cat{StatMod}$

the Diagrams in $\cat{StatMod}$ should be over Monoidal Categories and should be
Monoidal Functors, etc. (TODO: more details)

\emph{Rejoinder} -- \emph{Extension and Embedding} Self-consistency forces the
condition that $P_m\theta$ be the Marginal Distribution of $P_n\theta$ when $m$
isa  Subobject of $n$, but some systems are excepted from this condition, e.g.
``a Subset of a litter of pigs does not constitute a litter'' (Besag)



\subsubsection{Model Specification}\label{sec:model_specification}

\fist Specification Error (\S\ref{sec:specification_error})



\subsubsection{Model Validation}\label{sec:model_validation}

(wiki):

confirming that the ``outputs'' of a Statistical Model are ``acceptable'' with
respect to the ``real'' Data Generating Process
(\S\ref{sec:data_generating_process})

can be based on two types of Sample Data (\S\ref{sec:sample}):
\begin{enumerate}
  \item Data that was used in the \emph{construction} of the Model -- usually
    involves analyzing the \emph{Fit} (\S\ref{sec:model_fit}) or \emph{Residual
      Diagnostics} (\S\ref{sec:residual})
  \item Data that was \emph{not} used in the construction of the Model --
    usually involves analyzing whether the Model's ``\emph{Predictive
      Performance}'' (\S\ref{sec:prediction_interval}) holds up when applied to
    new Data
\end{enumerate}



\paragraph{Fit}\label{sec:model_fit}\hfill

\emph{Goodness-of-Fit}

measures the discrepancy between Observed (\S\ref{sec:observation}) values and
Predicted (\S\ref{sec:prediction}) values under the Statistical Model

$\chi^2$ Distributions (\S\ref{sec:chi_squared});
Chi Squared Test (\S\ref{sec:chi_squared_test})

\fist analysis of Residuals (Fitting Deviation \S\ref{sec:residual})

cf. Regression Analysis (\S\ref{sec:regression_analysis}), Curve Fitting
(\S\ref{sec:curve_fitting})

\fist cf. Learning Algorithms (\S\ref{sec:learning_algorithm});
Parameter Estimation (\S\ref{sec:estimation_theory}), Feature Selection
(\S\ref{sec:feature_selection})

Likelihood-Ratio (LR) Test (\S\ref{sec:lr_test})



\paragraph{Cross-validation}\label{sec:cross_validation}\hfill

or \emph{Rotation Estimation} or \emph{Out-of-sample Testing}

Predictive Models (\S\ref{sec:predictive_model})

Cross-validation Estimation of Fit

Cross-validation Estimator of Risk (Density Estimation
\S\ref{sec:density_estimation})

\emph{Holdout Dataset} -- Test Dataset that has not been used in Training

(wiki):

\begin{itemize}
  \item Model with one or more Unknown Parameters
  \item Dataset to which the Model can be "Fit" (Training Dataset)
  \item when taking an Independent sample of Validation Data as a Test Dataset,
    generally the Model does not Fit the Validation Dataset as well as the
    Training Dataset, and Cross-validation is a way to \emph{Estimate} the size
    of this effect
\end{itemize}

the \emph{In-sample Estimate} of Fit refers to the MSE of the Fit Model on the
Training Dataset

the \emph{Out-of-sample Estimate} of Fit refers to the MSE of the Fit Model on
the Validation Dataset

\begin{itemize}
  \item for a Linear Regression Model, the Expected Value of the MSE for the
    Training Dataset is $(n - p - 1) / (n + p + 1) < 1$ times the Expected Value
    of the MSE for the Validation Dataset where $n$ is the number of Samples in
    the Training Dataset and $p$ is the Dimensionality of the Covariate Vectors
  \item if the MSE of the Model in the Validation Dataset \emph{exceeds} the
    anticipated value then the Model has been \emph{Overfitted}
  \item in other types of Regression (e.g. Logistic Regression) there is no
    simple formula for the Expected Out-of-sample Fit, therefore
    Cross-validation is a generally applicable way to numerically Predict the
    performance of a Model on unavailable data
\end{itemize}

Holdout Method (TODO)



\subparagraph{Exhaustive Cross-validation}
\label{sec:exhaustive_cross_validation}\hfill

\subparagraph{Non-exhaustive Cross-validation}
\label{sec:nonexhaustive_cross_validation}\hfill

$k$-fold Cross-validation -- may be a source of lookahead bias ?



\subparagraph{Backtesting}\label{sec:backtesting}\hfill

Cross-validation applied to previous time periods

a type of \emph{Retrodiction} (\S\ref{sec:retrodiction})



\paragraph{Overdispersion}\label{sec:overdispersion}\hfill

%FIXME: move this section ???

Dispersion (\S\ref{sec:dispersion})



\subsubsection{Parametric Model}\label{sec:parametric_model}

\emph{Parametric Statistics}

A \emph{Parametric Model} or \emph{Finite-dimensional Model} assumes that Sample
Data (\S\ref{sec:sample}) comes from a Population that follows a Probability
Distribution based on a fixed Finite Set of \emph{Statistical Parameters}
(Population Parameters \S\ref{sec:population_parameter}).

A Parametric Model is defined by a collection of Probability Distributions,
$\mathfrak{F} = \{ F_\theta \ |\ \theta \in \Theta \}$, Indexed by a Finite Set
$\Theta$ called the \emph{Parameter Space}. For a Parametric Model with
Real-valued Parameters, $\Theta \subseteq \reals^k$ for some Positive Integer
$k$.

A Parametric Model consisting of Absolutely Continuous Distributions
can be specified in terms of corresponding Probability Density Functions:
\[
  \mathfrak{F} = \{ f(x; \theta) \ |\ \theta \in \Theta \}
\]

\emph{example}:
\begin{itemize}
  \item the Family of Normal Distributions (\S\ref{sec:normal_distribution}) are
    Parameterized by the Mean and Standard Deviation:
    \[
      \mathfrak{F} = \Big\{
        f(x; \mu, \sigma) =
          \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
        \ \Big|\ \mu \in \reals, \sigma > 0
      \Big\}
    \]
    where $f(x; \mu, \sigma)$ is the PDF of each Normal Distribution
    %FIXME: the above example is from wasserman04, 6.2; the pdf given differs
    % from that on wikipedia for a normal distribution
\end{itemize}

Parameter Estimation:
\begin{itemize}
  \item Method of Moments
  \item Maximum Likelihood Estimation (MLE \S\ref{sec:mle})
  \item ...
\end{itemize}
(TODO: xrefs)

``Parameters of Interest'', ``Nuisance Parameters''

\emph{Estimating Parameters in Chaotic Systems} -
\url{http://idontgetoutmuch.org/estimating-chaotic.htm} \fist Chaotic Systems
(\S\ref{sec:chaos_theory})



\paragraph{Exponential Family}\label{sec:exponential_family}\hfill

has PDFs of the form:
\[
  f(x; \theta) = h(x) e^{\eta(\theta)T(x) - B(\theta)}
\]
where $T$ is called the \emph{Natural Sufficient Statistic}
(\S\ref{sec:sufficient_statistic}) and $\eta$ is called the \emph{Natural
  Parameter}

includes:
\begin{itemize}
  \item Normal Distribution
  \item Exponential Distribution
  \item Gamma Distribution
  \item Wishart Distribution
  \item Chi-squared Distribution
  \item Beta Distribution
  \item Dirichlet Distribution
  \item Bernoulli Distribution
  \item Poisson Distribution
  \item Categorical Distribution
  \item Geometric Distribution
\end{itemize}
(TODO: xrefs)

when Observations come from an Exponential Family, under mild conditions the
Least-squares Estimates (\S\ref{sec:least_squares}) and Maximum-Likelihood
Estimates (\S\ref{sec:mle}) are identical



\subparagraph{Natural Exponential Family}
\label{sec:natural_exponential_family}\hfill

every Distribution with a Moment-generating Function
(\S\ref{sec:moment_generating_function}) is a member of a Natural
Exponential Family

Generalized Linear Models (\S\ref{sec:glm})



\subparagraph{Exponential Dispersion Model}
\label{sec:exponential_dispersion}\hfill

generalization of Natural Exponential Family

includes:
\begin{itemize}
  \item Tweedie Distribution (\S\ref{sec:tweedie_distribution})
\end{itemize}

Generalized Linear Models (\S\ref{sec:glm})



\paragraph{Scale Parameter}\label{sec:scale_parameter}\hfill

Parameter determining the \emph{Dispersion} (\S\ref{sec:dispersion}) of a
Parametric Family

\fist (Statistical) Scale Analysis (\S\ref{sec:statistical_scale})

\fist Scaling Limit (\S\ref{sec:scaling_limit})

\fist Scaling Distribution (\S\ref{sec:scaling_distribution})



\paragraph{Location Parameter}\label{sec:location_parameter}\hfill

cf. Central Tendency (\S\ref{sec:central_tendency})



\paragraph{Shape Parameter}\label{sec:shape_parameter}\hfill

any Parameter that is not a Location or Scale Parameter

\fist Shape (\S\ref{sec:distribution_shape})

Estimated in terms of higher Moments: Skewness (3rd Moment
\S\ref{sec:skewness}), Kurtosis (4th Moment \S\ref{sec:kurtosis})



\paragraph{Concentration Parameter}\label{sec:concentration_parameter}\hfill

tendency towards a Uniform Distribution (\S\ref{sec:uniform_distribution})

Dirichlet Distribution (\S\ref{sec:dirichlet_distribution})



\paragraph{Fixed Effects Model}\label{sec:fixed_effect}\hfill

\paragraph{Random Effects Model}\label{sec:random_effect}\hfill

type of Hierarchical Linear Model (Multilevel Model
\S\ref{sec:multilevel_model})

(McCullagh02)



\paragraph{Mixed Model}\label{sec:mixed_model}\hfill

both Fixed Effects and Random Effects

useful in settings where repeated Measurements (Observations
\S\ref{sec:observation}) are made ont he same Statistical Units
(\S\ref{sec:statistical_unit}), i.e. a ``Longitudinal Study'', or where
Measurements are made on \emph{clusters} of related Statistical Units

cf. ANOVA (Variance Analysis \S\ref{sec:variance_analysis})

BLUP (\S\ref{sec:blup})



\subsubsection{Non-parametric Model}\label{sec:nonparametric_model}

a Model that cannot be Parameterized by a Finite Parameter Set

e.g. the Model of \emph{all} Cumulative Distribution Functions (CDFs
\S\ref{sec:cdf}) is Non-parametric

Parameter Set (or \emph{Feature Set} in Machine Learning) is not fixed, i.e. it
may increase or decrease as new relevant information is collected

Descriptive Statistics (\S\ref{sec:descriptive_statistics}) are often
Non-parametric (\S\ref{sec:nonparametric_statistics})

\fist Non-parametric Inference (\S\ref{sec:nonparametric_inference})

\emph{Stein's Paradox} -- when three or more Parameters are Estimated
simultaneously, there exist combined Estimators more accurate on average (having
lower Expected MSE) than any method handling the Parameters Separately

Histogram (\S\ref{sec:histogram}), Kernel Density Estimation (\S\ref{sec:kde}),
Support Vector Machine



\paragraph{Order Statistic}\label{sec:order_statistic}\hfill

Extreme Value Theory (\S\ref{sec:eva})



\paragraph{Rank Statistic}\label{sec:rank_statistic}\hfill



\subsubsection{Semi-parametric Model}\label{sec:semiparametric_model}

\subsubsection{Semi-nonparametric Model}\label{sec:seminonparametric_model}

\subsubsection{Discrete Choice Model}\label{sec:discrete_choice_model}

\paragraph{Binary Choice Model}\label{sec:binary_choice}\hfill

essentially the same as Binomial Regression
(\S\ref{sec:binomial_regression}) Models



\subsubsection{Logistic Model}\label{sec:logistic_model}

or \emph{Logit Model}

Non-linear Model using a Logistic Function (\S\ref{sec:logistic_function}) to
Model a Binary Dependent Variable

Logit (\S\ref{sec:logit}) -- inverse of Logistic Function

Logistic Regression (\S\ref{sec:logistic_regression})



\subsubsection{Graphical Model}\label{sec:graphical_model}

(Whittaker 1990 - \emph{Graphical Models in Applied Multivariate Statistics}

\fist \emph{Log-linear Model} (Poisson Regression \S\ref{sec:log_linear}) --
Fitting a Graphical Model to Discrete Data \fist Pairwise Markov Graph
(Undirected Graph \S\ref{sec:pairwise_markov})

\begin{itemize}
  \item Variational AutoEncoders (VAEs \S\ref{sec:vae}) -- Directed
    Probabilistic Graphical Models (DPGM) with Posterior Distribution
    Approximated by a Neural Network
  \item Deep Belief Networks (DBNs \S\ref{sec:dbn}) -- Generative Models
    composed from Unsupervised Networks (RBMs or Autoencoders)
\end{itemize}



\paragraph{Markov Blanket}\label{sec:markov_blanket}\hfill

Markov Random Fields (\S\ref{sec:markov_random_field})



\paragraph{Bayes Network}\label{sec:bayes_network}\hfill

\emph{Bayesian Model} or \emph{Probabilistic Directed Acyclic Graphical Model}
(\S\ref{sec:graphical_model})

Bayesian Statistics (\S\ref{sec:bayesian_inference})

DAG (\S\ref{sec:dag}) -- Dependency structure

representation of Probability Distributions based on \emph{Causal Dependencies}
(\S\ref{sec:causal_graph})

\emph{Hierarchical Bayes Model}

McCullagh02: a \emph{Bayesian Model} is a Hierarchical Model
$\Theta^1, \Theta^2, \ldots, \Theta^k$ in which $k > 1$ and $\Theta^1 = \{0\}$
is the Trivial Functor, a one-point Set with Identity Map

\url{https://statmodeling.stat.columbia.edu/2019/05/21/neural-nets-vs-statistical-models/}
-- some comments on Hierarchical Models as related to Neural Networks:
\begin{quote}
  Neural nets are a special case of Statistical Models, typically Bayesian
  Hierarchical Logistic Regression with latent Parameters. But Neural Nets are
  typically Estimated in a different way: the resulting Posterior Distributions
  will generally be Multimodal, so rather than try the hopeless task of
  traversing the whole Posterior Distribution, we’ll use various approximate
  methods, which then are evaluated using predictive accuracy.
\end{quote}

\emph{Causality} (Pearl 2009) -- counterfactual reasoning

\url{https://golem.ph.utexas.edu/category/2018/07/bayesian_networks.html}



\subparagraph{Markov Condition}\label{sec:markov_condition}\hfill

every Node is Conditionally Independent (\S\ref{sec:conditional_independence})
of its Non-descendents, given its Parents

\emph{Causal Markov Condition}
--
Causal Graphs (\S\ref{sec:causal_graph})



\subparagraph{Directional Separation}\label{sec:directional_separation}\hfill

Directed Separation or $d$-separation



\subparagraph{Dynamic Bayes Network}\label{sec:dynamic_bayes_network}\hfill

simplest: Hidden Markov Model (\S\ref{sec:hmm})

Kalman Filters (\S\ref{sec:kalman_filter})



\subparagraph{Multilevel Model}\label{sec:multilevel_model}\hfill

or \emph{Hierarchical Linear Models}

Gibbs Sampling (\S\ref{sec:mcmc})

Random Effects Models (\S\ref{sec:random_effect})



\subparagraph{Random Tree}\label{sec:random_tree}\hfill



\subsubsection{Latent Variable Model}\label{sec:latent_variable_model}

\emph{Observable Variable} (\emph{Manifest Variable})

\emph{Latent Variable} (\emph{Hidden Variable})



\subsubsection{Discrete Uniform Law}\label{sec:discrete_uniform_law}

MIT 6.041SC Lec. 4 - \url{https://www.youtube.com/watch?v=6oV3pKLgW2I}

every possible Outcome has the same Probability of Occurring

Sample Space $\Omega$

the Probability of an Event $A$:
\[
  P(A) = \frac{|A|}{|\Omega|}
\]

for $|\Omega| = N$, every Element of $\Omega$ has Probability $\frac{1}{N}$

for a Subset $A$ with Cardinality $|A| = n$:
\[
  P(A) = n \frac{1}{N}
\]


Basic Counting Principles

for a Set with Cardinality $n$:
\begin{itemize}
  \item $n^\ell$ -- Possible Sequences of Length $\ell$ (with repetitions)
  \item $2^n$ -- Possible Subsets
  \item $\binom{n}{k}$ -- Possible Subsets of $k$ Elements
  \item $n!$ -- Possible Permutations (Orderings with no repetitions)
  \item $\frac{n!}{(n-k)!}$ -- Possible Permutations of $k$ Elements
  \item $n^2$ -- Possible Ordered Pairs
  \item $\frac{n(n-1)}{2}$ -- Possible Unique Pairings (Handshake problem)
\end{itemize}


Binomial Probabilities \fist Binomial Distribution
(\S\ref{sec:binomial_distribution}) -- Probability of getting exactly $k$
``successes'' in $n$ Trials where the Probability of ``success'' is $p$:
\[
  P(k,n,p) = \binom{n}{k}p^k(1-p)^{n-k}
\]
(FIXME: clarify)



\subsubsection{Continuous Uniform Law}\label{sec:continuous_uniform_law}

\subsubsection{Variational Bayesian Method}\label{sec:variational_bayesian}

Free Energy Principle -- implicit Minimization of Variational Free Energy;
Active Inference (Friston)

Variational AutoEncoders (VAEs \S\ref{sec:vae}) -- uses a Stochastic Gradient
Variational Bayes (SGVB) Estimator for the training algorithm



\subsubsection{Model Selection}\label{sec:model_selection}

\paragraph{Features Selection}\label{sec:feature_selection}\hfill

\paragraph{Optimality Criterion}\label{sec:optimality_criterion}\hfill

\fist Decision Rules (Decision Theory \S\ref{sec:decision_rule}): makes a
Choice using an Optimality Critereon



\paragraph{Akaike Information Criterion (AIC)}\label{sec:aic}\hfill

Likelihood minus number of Parameters

Mallows's $C_p$

\fist Information Theory (Part \ref{part:information_theory})



\paragraph{Bayesian Information Criterion (BIC)}\label{sec:bic}\hfill

Likelihood minus number of Parameters divided by two times the Log of Sample
Size



\paragraph{WAIC}\label{sec:waic}\hfill



\subsubsection{Statistical Language Model}
\label{sec:statistical_language_model}

Probability Distribution over Sequences of Words

Exponential Language Model

Continuous Space Language Model -- ANNs (\S\ref{sec:ann})

GPT-2: Unsupervised (Generative) Transformer Language Model
(\S\ref{sec:transformer})



\paragraph{Perplexity}\label{sec:perplexity}\hfill

measure of how well Distribution or Model predicts a Sample

%TODO: move section to informatio ntheory ?



\paragraph{$n$-gram Model}\label{sec:ngram_model}\hfill

Unigram Model -- can be treated as the combination of several One-state Finite
Automata

$n$-gram Model



% ------------------------------------------------------------------------------
\subsection{Power Law}\label{sec:power_law}
% ------------------------------------------------------------------------------

(or \emph{Scaling Law}) Functional Relation (cf. Statistical Dependence
\S\ref{sec:dependence}) as a Power Function (\S\ref{sec:power_function})

cf. Scaling Distributions (\S\ref{sec:scaling_distribution})

%FIXME: wikipedia links scaling distribution to power law

Scale Analysis (\S\ref{sec:statistical_scale}), Scale Invariance
(\S\ref{sec:scale_invariance})

\begin{itemize}
  \item Pareto Distribution (\S\ref{sec:pareto_distribution}) -- prototypical
    Power Law Distribution
  \item Discrete Power Law Distribution (\S\ref{sec:discrete_power_law})
  \item Continuous Power Law Distribution (\S\ref{sec:continuous_power_law})
\end{itemize}

\fist Fat-tailed Distributions (\S\ref{sec:fat_tailed})

\fist Regularly Varying Function (\S\ref{sec:regularly_varying}) -- Function of
a Real Variable with behavior at Infinity similar to the behavior of a Power Law
Function (cf. Polynomial \S\ref{sec:polynomial_function})



\subsubsection{Stretched Exponential Function}\label{sec:stretched_exponential}

$f_\beta(t) = e^{-t^\beta}$

Complementary Cumulative (\S\ref{sec:complementary_cumulative}) Weibull
Distribution (\S\ref{sec:weibull_distribution})

the Characteristic Function of a (L\'evy) Symmetric $\alpha$-stable Distribution
(\S\ref{sec:symmetric_alpha_stable}) is a Stretched Exponential Function



% ------------------------------------------------------------------------------
\subsection{Estimation Theory}\label{sec:estimation_theory}
% ------------------------------------------------------------------------------

deals with ``\emph{Estimating}'' the values of Statistical Parameters
(\S\ref{sec:population_parameter}) based on data that has a ``\emph{random
  component}'' (FIXME: clarify)

an \emph{Estimator} (\S\ref{sec:estimator}) attempts to approximate unknown
Statistical Parameters using ``measured data''

\fist Spectral Density Estimation (Statistical Signal Processing
\S\ref{sec:spectrum_analysis})

\fist cf. Decision Theory (\S\ref{sec:decision_theory}) -- choosing Estimators

\fist \emph{Supervised Learning}:
\begin{itemize}
  \item \emph{Classification} (\S\ref{sec:classification})
  \item \emph{Regression} (\S\ref{sec:regression_analysis}) is the Estimation of
    Dependencies (\S\ref{sec:dependence}) in Multivariate Data
    (\S\ref{sec:random_vector}), i.e. the Estimation of the \emph{Regression
      Function}; commonly this is the Estimate of the Conditional Expectation
    (\S\ref{sec:conditional_expectation}) of a Dependent Variable given an
    Independent Variable
\end{itemize}

approaches:
\begin{itemize}
  \item \emph{Probabilistic} -- assume the Sample Data is Random with a
    Probability Distribution (\S\ref{sec:probability_distribution}) dependent on
    the Statistical Parameters of interest
  \item \emph{Set-membership} (\S\ref{sec:set_estimation}) -- assumes the
    Sample Data belongs to a Set that depends on the Parameters
\end{itemize}

\fist cf. Approximation Theory (\S\ref{sec:approximation_theory})

Sample Distribution (Empirical Distribution \S\ref{sec:empirical_distribution})

Confidence Interval (\S\ref{sec:confidence_interval}), Margin of Error
(\S\ref{sec:margin_of_error})

Estimating:
\begin{itemize}
  \item Population Proportion (\S\ref{sec:proportion}) -- $z$-score (Standard
    Score \S\ref{sec:standard_score})
  \item Population Mean (\S\ref{sec:expected_value})
  \item ...
\end{itemize}

\emph{Estimating Parameters in Chaotic Systems} -
\url{http://idontgetoutmuch.org/estimating-chaotic.htm} \fist Chaotic Systems
(\S\ref{sec:chaos_theory})

\asterism

\emph{Optimizer's Curse} -
\url{https://confusopoly.com/2019/04/03/the-optimizers-curse-wrong-way-reductions/}
-- TODO



\subsubsection{Estimator}\label{sec:estimator}

\fist Decision Rule (Decision Theory \S\ref{sec:decision_rule})

(wiki):

an \emph{Estimator} attempts to approximate unknown Statistical (Population)
Parameters (\S\ref{sec:population_parameter}) using ``measured data''

when the Data consists of ``multiple variables'' (cf. Multivariate Statistics
\S\ref{sec:multivariate_statistics}), Estimating the ``relation'' between them
is \emph{Regression Analysis} (\S\ref{sec:regression_analysis})
--FIXME: clarify

\emph{Rao-Blackwell Theorem} -- an Estimator that does not depend on a
Sufficient Statistic (\S\ref{sec:sufficient_statistic}) is sub-optimal



\paragraph{Sampling Deviation}\label{sec:sampling_deviation}\hfill

difference between Estimate on a given Sample and the Expected Value of the
Estimator



\paragraph{Delta Method}\label{sec:delta_method}\hfill

(wiki): concerns the approximate Probability Distribution for a Function of an
Asymptotically Normal Estimator (e.g. MLE \S\ref{sec:mle}) from knowledge of the
limiting \emph{Variance} of the Estimator

\fist cf. Propagation of Error (\S\ref{sec:error_propagation})

\emph{Multivariate Delta Method}



\paragraph{Point Estimator}\label{sec:point_estimator}\hfill

\emph{Point Estimation} -- use of Sample Data to calculate a single value
(\emph{Point Estimate} or \emph{Statistic} \S\ref{sec:statistic}) to serve as an
Estimate of an unknown Population Parameter (\S\ref{sec:population_parameter})

\[
  \hat{\theta}_n = g(X_1, \ldots, X_n)
\]
where $X_1, \ldots, X_n$ are IID (\S\ref{sec:iid})

the Distribution of $\hat{\theta}_n$ is called a \emph{Sampling Distribution}
(\S\ref{sec:sampling_distribution}) and the Standard Deviation
(\S\ref{sec:standard_deviation}) of $\hat{\theta}_n$ is called the
\emph{Standard Error} (\S\ref{sec:standard_error})

\begin{itemize}
  \item Minimum-Variance Mean-Unbiased Estimator (MVUE)
  \item Best Linear Unbiased Estimator (BLUE)
  \item Minimum Mean Squared Error (MMSE)
  \item Median-Unbiased Estimator
  \item Maximum Likelihood Estimator (MLE \S\ref{sec:mle})
  \item Method of Moments (\S\ref{sec:moments_method})
\end{itemize}

Bayesian Point Estimation:
\begin{itemize}
  \item Posterior Mean
  \item Posterior Median
  \item Maximum A Posteriori (MAP)
\end{itemize}

(TODO: xrefs)



\subparagraph{Sample Mean}\label{sec:sample_mean}

Estimates the Population Mean (Expectation \S\ref{sec:expected_value})

for Random Variables (\S\ref{sec:random_variable}) $X_1, \ldots, X_n$:
\[
  \overline{X}_n = \frac{1}{n}\sum_i X_i
\]

\emph{Law of Large Numbers} (\S\ref{sec:large_numbers}): the Sample Mean
$\overline{X}_n = \frac{1}{n}\sum_i X_i$ \emph{Converges in Probability}
(\S\ref{sec:stochastic_convergence}) to the Expectation
(\S\ref{sec:expected_value}) $\mu = E(X_i)$ as $n \to \infty$, i.e.
$\overline{X}_n$ is close to $\mu$ with high Probability

\emph{Central Limit Theorem} (\S\ref{sec:central_limit}):
$\sqrt{n}(\overline{X}_n - \mu)$ \emph{Converges in Distribution} to a Normal
Distribution (\S\ref{sec:normal_distribution}) as $n \to \infty$, i.e.
the Sample Mean has approximately a Normal Distribution for large $n$

the \emph{Grand Mean} is the Mean of multiple Sample Means



\subparagraph{Sample Variance}\label{sec:sample_variance}\hfill

Estimates the Population Variance

$s^2$

Degrees of Freedom, Linear Independence, Biased/Unbiased Estimator
(\S\ref{sec:unbiased_estimate})

Unbiased Sample Variance:
\[
  s^2 = \frac{n}{n-1}\sigma^2_y =
  \frac{1}{n-1} \sum_{i=1}^n (y_i - \overline{y})^2
\]



\subparagraph{Sample Covariance}\label{sec:sample_covariance}\hfill

Estimates the Population Covariance



\subparagraph{Sample Standard Deviation}
\label{sec:sample_standard_deviation}\hfill

$\sqrt{s^2_{n-1}}$ -- Biased

\fist Root-Mean-Square Deviation (RMSD \S\ref{sec:rmsd}) -- Sample Standard
Deviation of Regression Residuals



\subparagraph{Sample Bias}\label{sec:sample_bias}\hfill

Bias (\S\ref{sec:bias})



\subparagraph{Maximum Likelihood Estimation}\label{sec:mle}\hfill

method of Estimating Population Parameters (\S\ref{sec:population_parameter})

$\hat{\theta}$ -- the value of $\theta$ that maximizes the Likilihood
(\S\ref{sec:likelihood}) $\mathcal{L}(\theta)$

under \emph{Regularity Conditions} (essentially Smoothness Conditions on
$f(x; \theta)$), MLE is Consistent, Equivariant, Asymptotically Normal, and
Asymptotically Optimal (or ``Efficient'' \S\ref{sec:efficiency})

\fist Delta Method (\S\ref{sec:delta_method})

cf. Backpropagation (\S\ref{sec:backpropagation}): the process of ``Training'' a
Regression Model (\S\ref{sec:regression_analysis})

when Observations come from an Exponential Family
(\S\ref{sec:exponential_family}), under mild conditions the Least-squares
Estimates (\S\ref{sec:least_squares}) and Maximum-Likelihood Estimates are
identical

whereas Least-squares is used to measure Fit of Linear Regression, MLE is used
to measure Fit in Logistic Regression (\S\ref{sec:logistic_regression}) \fist
Iteratively Re-weighted Least Squares (IRLS \S\ref{sec:irls})

the MLE Approximates (\S\ref{sec:approximation_theory}) the Bayes Estimator
(\S\ref{sec:bayes_estimator})

for Distributions satisfying ``Regularity Conditions'', e.g. Bernoulli and
Normal Distributions, Posterior Mean (\S\ref{sec:posterior_distribution}) is
generally close to the MLE

for Parametric Models satisfying ``Regularity Conditions'', MLE is approximately
Minimax (\S\ref{sec:minimax})

note that MLE is \emph{not} an optimal Estimator for high-dimensional problems,
e.g. when there are as many Parameters as there are Observations

$\hat{\theta} \pm 2\hat{S_E}$ is an approximate 95\% Confidence Interval, where
$S_E$ is the Standard Error

(Wasserman04 \S9.13.4) Numerical Approximations -- Iterative Method:
\begin{itemize}
  \item Newton-Raphson (Newton's Method \S\ref{sec:newtons_method})
  \item Expectation-Maximization (EM) Algorithm
\end{itemize}
produce a Sequence of values $\theta^0, \theta^1, \ldots$ that Converge to MLE
$\hat{\theta}$;
often the Method of Moments (\S\ref{sec:moments_method}) is a good starting
value of $\theta^0$

(Wasserman04 \S13.2):
 under assumption of Normality ($Y_i | X_i \sim N(\mu_i, \sigma^2)$), the Least
 Squares Estimator (\S\ref{sec:least_squares}) is also the MLE



\subparagraph{Method of Moments}\label{sec:moments_method}\hfill

method of Estimating Population Parameters (\S\ref{sec:population_parameter})

Moment (\S\ref{sec:moment})

for $k$ unknown Parameters $\theta_1, \theta_2, \ldots, \theta_k$ builds a
System of $k$ Equations with $k$ Unknowns:
\begin{flalign*}
  & \hat{\mu_1} & = \mu_1 (\hat{\theta}_n) \\
  & \hat{\mu_2} & = \mu_2 (\hat{\theta}_n) \\
  &             & \vdots \\
  & \hat{\mu_k} & = \mu_k (\hat{\theta}_n) \\
\end{flalign*}
where $\mu_j = E_\theta(X^j) = \int x^j dF_\theta(x)$ is the $j^{th}$ Moment and
$\hat{\mu_j} = \frac{1}{n}\sum_{i=1}^n X_j^i$ is the $j^{th}$ Sample Moment, and
$\hat{\theta}_n$ is the \emph{Method of Moments Estimator}

can be used to derive Least-squares (\S\ref{sec:least_squares}) Estimator



\subparagraph{Maximum A Posteriori (MAP) Estimation}
\label{sec:map_estimator}\hfill

Bayesian Estimation

cf. Bayes Estimator (\S\ref{sec:bayes_estimator})



\subparagraph{Scale Estimator}\label{sec:scale_estimator}

Scale Parameter (\S\ref{sec:scale_parameter})



\paragraph{Interval Estimator}\label{sec:interval_estimator}\hfill

Confidence Intervals (Frequentist Inference \S\ref{sec:confidence_interval})

$\forall \theta \in \Theta, P_\theta(a(X) < \theta < b(X)) = 1 - \alpha$

Credible Intervals (Bayesian Inference \S\ref{sec:credible_interval})

$P(a(x) < \Theta < b(x) | X = x) = 1 - \alpha$

Prediction Interval (Regression Analysis \S\ref{sec:prediction_interval})

$\forall \theta \in \Theta, P_\theta(a(X) < Y < b(X)) = 1 - \alpha$

Likelihood Intervals (TODO)

Fiducial Intervals (TODO)

Tolerance Interval (TODO)

Stochastic Asset/Investment Models



\paragraph{Horvitz-Thompson Estimator}\label{sec:horvitz_thompson}\hfill

method for Estimating Total and Mean of a Superpopulation in a Stratified Sample
(\S\ref{sec:stratified_sample})

cannot be derived from a Bayesian or Likelihood (\S\ref{sec:likelihood}) point
of view

Survey Analysis, Missing Data



\paragraph{Consistent Estimator}\label{sec:consistent_estimator}\hfill

or \emph{Asymptotically Consistent Estimator}

as the number of Data Points used increases, the resulting Sequence Converges in
Probability to the true value



\subsubsection{Mean Signed Deviation}\label{sec:mean_signed_deviation}

or \emph{Mean Signed Difference} or \emph{Mean Signed Error}

Average (Expected Value) of Estimation Error



\subsubsection{Mean Squared Deviation (MSD)}\label{sec:msd}

or \emph{Mean Squared Error (MSE)}

Average of the Squared Error of the Estimated value (produced by an Estimator)
from the ``true'' value; MSD is the Second Moment of the Error; for an Unbiased
Estimator the MSD is the \emph{Variance} (\S\ref{sec:variance}) of the Estimator

Expected Value of the Squared Errors

Squared Deviation (\S\ref{sec:squared_deviation})

cf. Mean Absolute Deviation (MAD \S\ref{sec:mad})

cf. Square Deviation from the Mean (SDM \S\ref{sec:sdm}), Sum of Squared
Deviations (\S\ref{sec:sum_squared_deviation})

\fist Decision Theory (\S\ref{sec:decision_theory}): when Loss Function
(\S\ref{sec:objective_function}) is Squared Error, the Risk (Average Loss
\S\ref{sec:risk}) is the MSE



\paragraph{Root-Mean-Square Deviation (RMSD)}\label{sec:rmsd}\hfill

or RMSE

Square Root of the MSD (cf. Standard Deviation \S\ref{sec:standard_deviation})

Sample Standard Deviation (\S\ref{sec:standard_deviation}) of Residuals

measure of Accuracy (\S\ref{sec:accuracy})



\subsubsection{Residual}\label{sec:residual}

or \emph{Fitting Deviation}

Deviation (Signed Difference \S\ref{sec:deviation}) of an Observed Value
(\S\ref{sec:observation}) from an Estimate of the ``true'' value

cf. Error (\S\ref{sec:error}), Sum of Squared Residuals (SSR \S\ref{sec:ssr})

\fist Regression Residual (\S\ref{sec:regression_residual})

\emph{Residual Diagnostics} is a means of \emph{Model Validation}
(\S\ref{sec:model_validation}) based on the Sample Data (\S\ref{sec:sample})
that was used to construct a Statistical Model (\S\ref{sec:statistical_model}),
consisting of analyzing whether Residuals of a constructed Statistical Model
(\S\ref{sec:statistical_model}) are \emph{Random}
(\S\ref{sec:statistical_randomness}), another method being analyzing how well
the Model Predictions (\S\ref{sec:prediction}) \emph{Fit}
(\S\ref{sec:model_fit}) the original Data

$y - \hat{y}$

(wiki):

example for Sample (\S\ref{sec:sample}) of IID Normally Distributed Random
Variables, $X_1, \ldots, X_n \sim N(\mu, \sigma^2)$, the Sample Mean
(\S\ref{sec:sample_mean}):
\[
  \overline{X} = \frac{X_1 + \cdots + X_n}{n}
\]
is a Random Variable with Normal Distribution:
\[
  \overline{X} = N(\mu, \frac{\sigma^2}{n})
\]
and the \emph{Statistical Errors} (\S\ref{sec:error}) are:
\[
  e_i = X_i - \mu
\]
and the \emph{Residuals} are:
\[
  r_i = X_i - \overline{X}
\]



\subsubsection{Bias}\label{sec:bias}

\emph{Statistical Bias}

cf. \emph{Systematic Error} (Statistical Bias \S\ref{sec:systematic_error})

Sample Bias (Point Estimators \S\ref{sec:sample_bias})

\emph{Underfitting} (Multiple Regression \S\ref{sec:multiple_regression}) -- too
few Covariates, high Bias

Boosting (\S\ref{sec:boosting}) -- Bias reduction



\paragraph{Unbiased Estimate}\label{sec:unbiased_estimate}\hfill

\paragraph{Efficient Estimate}\label{sec:efficient_estimate}\hfill

Unbiased Estimator with Smallest Variance



\subsubsection{Standard Error}\label{sec:standard_error}

the \emph{Standard Error} $S_E$ of a Statistic (Estimate of a Parameter) is the
Standard Deviation (\S\ref{sec:standard_deviation}) of its Sampling Distribution
(\S\ref{sec:sampling_distribution})

cf. Standard Score (\S\ref{sec:standard_score})

the Standard Error equals the Standard Deviation divided by the square root of
the Sample Size, i.e. the Standard Error of the Mean is a measure of
``Dispersion'' of Sample Means around the Population Mean

\fist Resampling (\S\ref{sec:resampling})

\fist cf. \emph{Observational Error} (Measurement Error
\S\ref{sec:observational_error}), \emph{Statistical Error} (\S\ref{sec:error})



\paragraph{Margin of Error}\label{sec:margin_of_error}\hfill

\fist Confidence Interval (\S\ref{sec:confidence_interval})



\subsubsection{Efficiency}\label{sec:efficiency}

\paragraph{Asymptotic Relative Efficiency (ARE)}\label{sec:are}\hfill



\subsubsection{Benchmarking}\label{sec:benchmarking}

or \emph{Post-stratification} (cf. Stratified Sampling
\S\ref{sec:stratified_sample})

(wiki): use of ``auxiliary information'' to adjust Sampling Weights
(\S\ref{sec:weighted_mean}) in an Estimation process



\subsubsection{Empirical Distribution Function}
\label{sec:empirical_distribution}

or \emph{Sample Distribution}

an Unbiased Estimator for the CDF (\S\ref{sec:cdf}) associated with the
Empirical Measure (\S\ref{sec:empirical_measure}) of a Sample
(\S\ref{sec:sample})

note that Estimating Non-parametric Density or Regression Functions requires
making Smoothness assumptions, see Nonparametric Regression
(\S\ref{sec:nonparametric_regression})

\fist cf. Empirical Processes (\S\ref{sec:empirical_process})

(Wasserman04 \S7.1)

for $X_1, \ldots, X_n \sim F$ an IID Sample (Random Sample \S\ref{sec:iid})
where $F$ is a CDF on the Real Line, the \emph{Empirical Distribution Function},
$\hat{F}_n$, is the Discrete CDF with Mass assigning $1/n$ at each Data Point
$X_i$:
\[
  \hat{F}_n(x) = \frac{\sum_{i=1}^n I(X_i \leq x)}{n}
\]
where:
\[
  I(X_i \leq x) = \begin{cases}
    1 & \text{if}\ X_i \leq x \\
    0 & \text{if}\ X_i > x \\
  \end{cases}
\]

\textbf{Thm.} \emph{
  At any fixed value of $x$:
  \begin{align*}
    E(\hat{F}_n(x)) & = F(x)                     \\
    V(\hat{F}_n(x)) & = \frac{F(x)(1 - F(x))}{n} \\
    MSE & = \frac{F(x)(1-F(x))}{n} \to 0 \\
    \hat{F}_n(x) & \xrightarrow{P} F(x)          \\
  \end{align*}
}

\emph{Glivenko-Cantelli Theorem}

\emph{Dvoretsky-Kiefer-Wolfowitz (DKW) Inequality} -- can be used to construct a
Non-parametric $1-\alpha$ Confidence Band (\S\ref{sec:confidence_band}) for $F$
(TODO)



\paragraph{Plug-in Principle}\label{sec:plugin_principle}\hfill

(wiki):

method of Estimation of Statistical Functionals (Functions of the CDF $F$) of a
Population Distribution by evaluating the same Functionals at the Empirical
Distribution based on a Sample

(Wasserman04 \S7.2)

the \emph{Plug-in Estimator} for a Statistical Functional
(\S\ref{sec:statistical_functional}) $\theta = T(F)$ is:
\[
  \hat{\theta} = T(\hat{F}_n)
\]

the Plug-in Estimator for a Linear Functional (\S\ref{sec:linear_functional}):
\[
  T(\hat{F}_n) = \frac{1}{n}\sum_{i=1}^n r(X_i)
\]

Sample Correlation

Sample Quantile



\subsubsection{Density Estimation}\label{sec:density_estimation}

a form of Unsupervised Learning (cf. Cluster Analysis
\S\ref{sec:cluster_analysis})

\fist cf. Generative Models (\S\ref{sec:generative_model})

(Wasserman04, Ch.20)

compared to Non-parametric Estimation of CDFs (via Empirical Distribution
Functions \S\ref{sec:empirical_distribution}), Estimating Non-parametric Density
or Regression Functions requires making Smoothness assumptions

cf. Non-parametric Regression (\S\ref{sec:nonparametric_regression})

Smoothing (Curve Estimation \S\ref{sec:smoothing})

more Smoothing leads to larger Bias, less Smoothing leads to higher Variance;
Optimal Smoothing leads to minimized Risk (Expected Loss \S\ref{sec:risk})

$Risk = Bias^2 + Variance$

Cross-validation Estimator (\S\ref{sec:cross_validation}) of Risk

Confidence Band (\S\ref{sec:confidence_band})

\emph{Curse of Dimensionality} -- Risk increases quickly with Dimension

(Wasserman04, Ch.21)

Orthogonal Function (\S\ref{sec:orthogonal_function}) Density Estimation

Haar Basis, Haar Wavelet (\S\ref{sec:haar_wavelet}) Density
Estimation



\paragraph{Mean Integrated Squared Error (MISE)}\label{sec:mise}\hfill

Loss Function: \emph{Integrated Squared Error (ISE)}

$L^2$ Risk Function (\S\ref{sec:risk_function})



\paragraph{Histogram}\label{sec:histogram}\hfill

\emph{Histogram Estimator}

Non-parametric (\S\ref{sec:nonparametric_model})

simplistic Kernel Density Estimation (\S\ref{sec:kde})

converges at rate $n^{-2/3}$;

Frequency Histogram

\fist Periodogram (Spectral Density Estimation \S\ref{sec:periodogram})

Relative Frequency Histogram (Percentages)

Equilibria of Markov Processes (\S\ref{sec:markov_process}) -- a Markov Process
is said to enter an ``Equilibrium'' if the Histogram of states Converges over
time



\paragraph{Kernel Density Estimation (KDE)}\label{sec:kde}\hfill

\emph{Parzen-Rozenblatt Window Method} (Signal Processing)

Non-parametric Estimation of the PDF of a Random Variable

Estimation of Distribution from Sample Points by Convolution
(\S\ref{sec:convolution}) with a \emph{Kernel Function}
(\S\ref{sec:distribution_kernel})

cf. Histogram (\S\ref{sec:histogram})

cf. Kernel Regression (\S\ref{sec:kernel_regression})

Non-parametric Model (\S\ref{sec:nonparametric_model})

\emph{Bandwidth}

converges at a rate $n^{-4/5}$;
under weak assumptions there does not exist a Non-parametric Estimator that
converges faster than $n^{-4/5}$

\emph{Stone's Theorem}



\subsubsection{Resampling}\label{sec:resampling}

methods of Estimating the precision of Sample Statistics (\S\ref{sec:statistic})

\fist Standard Error (\S\ref{sec:standard_error})

Non-parametric Inference (\S\ref{sec:nonparametric_model}), Permutation Tests
(\S\ref{sec:permutation_test})



\paragraph{Bootstrap Method}\label{sec:bootstrap_method}\hfill

Wasserman04 Ch. 8

for a Statistic (\S\ref{sec:statistic}) $T_n(F_n)$ where
$X = X_1, \ldots, X_n \sim F_n$, two steps:
\begin{enumerate}
  \item Estimate $T_n(F_n)$ with $T_n(\hat{F}_n)$ (Plug-in Principle
    \S\ref{sec:plugin_principle})
  \item Approximate $T_n(\hat{F}_n)$ using ``\emph{Simulation}'': drawing an
    Observation from $\hat{F}_n$ is equivalent to drawing one Point at Random
    from the original Data Set $X$
\end{enumerate}

Bootstrap Normal Interval, Bootstrap Pivotal Interval, Bootstrap Percentile
Interval

Parametric Bootstrap (Wasserman04 \S9.11)



\paragraph{Jackknife Method}\label{sec:jackknife_method}\hfill



\subsubsection{Least Squares}\label{sec:least_squares}

a \emph{Least Square Estimate} is an approximate solution of an Overdetermined
System that minimizes the Sum of Squared Residuals (SSR \S\ref{sec:ssr})

$2$-norm Best Fit \fist cf. $1$-norm Best Fit (\S\ref{sec:1norm_best_fit}),
Chebyshev Approximation ($\infty$-norm Best Fit
\S\ref{sec:chebyshev_approximation})

earliest form of Regression Analysis (\S\ref{sec:regression_analysis})
-- the Sum of Squared Residuals (SSR) gives a measure of how well
an Estimated Regression Function $\hat{r}(x)$ ``Fits'' the Data, and the
Regression Parameters that minimize SSR are called \emph{Least Squares
  Estimates}

(Wasserman04, \S13.2):
 under assumption of Normality ($Y_i | X_i \sim N(\mu_i, \sigma^2)$), the Least
 Squares Estimator is also the Maximum Likelihood Estimator (MLE
 \S\ref{sec:mle})

cf. Squared Deviation from the Mean (SDM \S\ref{sec:sdm})

(wiki): can be derived as a Method of Moments Estimator
(\S\ref{sec:moments_method});
when Observations come from an Exponential Family
(\S\ref{sec:exponential_family}), under mild conditions the Least-squares
Estimates and Maximum-Likelihood Estimates are identical



\paragraph{Linear Estimator}\label{sec:linear_estimator}\hfill

%FIXME



\subsubsection{Least Absolute Deviations (LAD)}\label{sec:lad}

cf. Iteratively Re-weighted Least Squares (IRLS \S\ref{sec:irls})



\subparagraph{Best Linear Unbiased Estimator (BLUE)}\label{sec:blue}\hfill

Estimating Fixed Effects (\S\ref{sec:fixed_effect})

cf. Best Linear Unbiased Predictor (BLUP \S\ref{sec:blup})
-- Predicting Random Effects (\S\ref{sec:random_effect})

\textbf{Gauss-Markov Theorem} \emph{
  In a Linear Model (\S\ref{sec:linear_regression}) where Errors are
  Uncorrelated, have Mean Zero, and equal Variances, the Best Linear Unbiased
  Estimator of the Coefficients is given by the Ordinary Least-Squares (OLS
  \S\ref{sec:ols}) Estimator.
}



\paragraph{Linear Least Squares (LLS)}\label{sec:lls}\hfill

Linear Regression (\S\ref{sec:linear_regression})

Overdetermined Systems (\S\ref{sec:overdetermined_system}); cf. ``Least Norm''
solution for Underdetermined Systems (TODO: xref)

QR Decomposition (\S\ref{sec:qr_decomposition})

has a Closed-form solution

UC Math 352, Lecture 7. - \url{https://www.youtube.com/watch?v=ZWGIchXVbho}



\subparagraph{Ordinary Least Squares (OLS)}\label{sec:ols}\hfill

(MIT 18.086 2006, Lec.21)

as an Optimization Problem:
\begin{flalign*}
  \vec{u}^* + \mathbf{X}\vec{\beta}^* & = \vec{y} \\
  \mathbf{X}^T \vec{u}^*              & = 0 \\
\end{flalign*}
``Saddle-point System'', ``Kuhn-Tucker Equations'':
\[
  \begin{bmatrix}
    \mathbf{I}   & \mathbf{X} \\
    \mathbf{X}^T & \mathbf{0} \\
  \end{bmatrix} \begin{bmatrix}
    \vec{u}^*     \\
    \vec{\beta}^* \\
  \end{bmatrix} = \begin{bmatrix}
    \vec{y} \\
    \vec{0} \\
  \end{bmatrix}
\]

because of the Constraint $\mathbf{X}^T \vec{u}^* = 0$, multiplying the first
equation by $\mathbf{X}^T$ yields the Normal Equation
(\S\ref{sec:normal_equation}):
\[
  \mathbf{X}\vec{\beta}^* = \vec{y}
\]

alternatively, by elimination on the System Equation:
\[
  \begin{bmatrix}
    \mathbf{I} & \mathbf{X} \\
    \mathbf{0} & -\mathbf{X}^T\mathbf{X} \\
  \end{bmatrix} \begin{bmatrix}
    \vec{u}^*     \\
    \vec{\beta}^* \\
  \end{bmatrix} = \begin{bmatrix}
    \vec{y} \\
    -\mathbf{X}^T \vec{y} \\
  \end{bmatrix}
\]

\textbf{Gauss-Markov Theorem} \emph{
  In a Linear Model (\S\ref{sec:linear_regression}) where Errors are
  Uncorrelated, have Mean Zero, and equal Variances, the Best Linear Unbiased
  Estimator (BLUE \S\ref{sec:blue}) of the Coefficients is given by the Ordinary
  Least-Squares Estimator.
}



\subparagraph{Normal Equation}\label{sec:normal_equation}\hfill

UC Math 352 Lec. 7 \url{https://www.youtube.com/watch?v=ZWGIchXVbho}

$A\vec{x} = \vec{b}$

$\mathrm{min}_{\vec{x}} \|A_{\vec{x}} - \vec{b}\|$

\emph{Normal Equation}: $(A^TA)\vec{x} = A^T\vec{b}$ -- Condition Number
(\S\ref{sec:condition_number}) is $\kappa(A)^2$; see QR Factorization
(\S\ref{sec:qr_factorization}) for a better Conditioned solution

Project $\vec{b}$ onto the Column Space of $A$

\[
  \vec{x} = (A^TA)^{-1}A^T\vec{b}
\]

solve by \emph{Cholesky Factorization} (\S\ref{sec:cholesky_decomposition}) ...
TODO \url{https://www.youtube.com/watch?v=VJ-04jOfu-E}



\subparagraph{QR Factorization}\label{sec:qr_factorization}\hfill

QR Decomposition (\S\ref{sec:qr_decomposition})

UC Math 352 Lec. 7 \url{https://www.youtube.com/watch?v=ZWGIchXVbho}

better Condition Number than Normal Equations (\S\ref{sec:normal_equation})

$A\vec{x} = \vec{b}$

$A = QR$ ($Q$ is Square, Orthogonal)

Residual $\vec{r} = A\vec{x} - \vec{b}$

\begin{align*}
     \vec{r} & = QR\vec{x} - \vec{b} \\
  Q^T\vec{r} & = R\vec{x} - Q^T\vec{b} \\
\end{align*}

because Orthogonal Matrices preserve Distances and $Q$ is Orthogonal:
\[
  \|Q^T\vec{r}\|_2 = \|\vec{r}\|_2
\]
minimizing $Q^T\vec{r} = \vec{\rho}$ is equivalent to minimizing $\vec{r}$

splitting $\vec{\rho}$ into:
\begin{enumerate}
  \item $\hat{\rho}   = \hat{R}\vec{x} - \hat{Q}^T\vec{b}$
  \item $\vec{\rho}_N = -Q_N^T\vec{b}$
\end{enumerate}
$\hat{rho}$ can be made Zero by solving $\hat{R}\vec{x} - \hat{Q}^T\vec{b}$ for
$\vec{x}$, which is an Upper Triangular Matrix that can be solved efficiently:
\[
  \hat{\vec{x}} = \hat{R}^{-1}\hat{Q}^T\vec{b}
\]
and $\vec{rho}_N$ is independent of $\vec{x}$ so it is \emph{fixed}, so:
\[
  \|\vec{r}\|^2_2 = \|\hat{Q}_N^T\vec{b}\|_2^2
\]



\paragraph{Generalized Least Squares (GLS)}\label{sec:gls}\hfill

Linear Regression (\S\ref{sec:linear_regression}) technique when there is a
degree of Correlation between Residuals

\begin{itemize}
  \item Heteroscedastic (\S\ref{sec:heteroscedasticity}) Errors -- unequal
    Variances (diagonal entries of the Covariance Matrix)
    \begin{itemize}
      \item Weighted Least Squares (WLS \S\ref{sec:wls})
    \end{itemize}
  \item Correlation between Errors -- off-diagonal entries of the Covariance
    Matrix
\end{itemize}

(wiki):

$\vec{y} = \mathbf{X}\vec{\beta} + \vec{\epsilon}$

$E[\epsilon | \mathbf{X}] = 0$

$cov[\epsilon | \mathbf{X}] = \mathbf{K}$

Estimate $\vec{\beta}$ by minimizing the Squared Mahalanobis Length
(\S\ref{sec:mahalanobis_distance}) of the Residual
$\vec{y} - \mathbf{X}\hat{\beta}$:
\begin{flalign*}
  \hat{\beta}
    & = argmin_{\vec{\beta}} (\vec{y} - \mathbf{X}\vec{\beta})^T
      \mathbf{K}^{-1} (\vec{y} - \mathbf{X}\vec{\beta}) \\
    & = (\mathbf{X}^T \mathbf{K}^{-1} \mathbf{X})^{-1}
      \mathbf{X}^T \mathbf{K}^{-1} \vec{y} \\
\end{flalign*}

the GLS Estimator is Unbiased, Consistent, Efficient, and Asymptotically Normal
with $E[\hat{\beta} | \mathbf{X}] = \vec{\beta}$ and
$cov[\hat{\beta} | \mathbf{X}] = (\mathbf{X}^T \mathbf{K}^{-1} \mathbf{X})^{-1}$

GLS is equivalent to applying OLS to Linearly Transformed version of the Data

WLS is a special case where $\mathbf{K}$ is Diagonal



\subparagraph{Weighted Least Squares (WLS)}\label{sec:wls}\hfill

Variance of Errors are unequal accross Observations (\emph{Heteroscedasticity}
\S\ref{sec:heteroscedasticity})-- Error Covariance Matrix
(\S\ref{sec:covariance_matrix}) may be a Diagonal Matrix other than Identity
Matrix

(wiki):

the ``weight'' for ``unit'' $i$ is proportional to the reciprocal of the
Variance of the Response for unit $i$ (TODO: clarify)

Normal Equations:
\[
  (diag(\vec{w})\mathbf{X})^T diag(\vec{w})\mathbf{X} \hat{\beta}
    = (diag(\vec{w})\mathbf{X})^T (diag(\vec{w})\vec{y}
\]

TODO

\[
  \hat{\beta} = (\mathbf{X}^T \mathbf{W X})^{-1} \mathbf{X}^T \mathbf{W} \vec{y}
\]

\fist Iteratively Re-weighted Least Squares (IRLS \S\ref{sec:irls}) -- for
$L^p$-norm Linear Regression, IRLS at step $k+1$ involves solving WLS



\subparagraph{Feasible Generalized Least Squares (FGLS)}\label{sec:fgls}\hfill

unknown Error Covariance Matrix $\mathbf{K}$

\begin{enumerate}
  \item Estimate Model by OLS and use the Residuals to build a (Consistent)
    Estimator of the Errors Covariance Matrix $\hat{\mathbf{K}}$
  \item use $\hat{\mathbf{K}}$ to perform GLS
\end{enumerate}



\paragraph{Iteratively Re-weighted Least Squares (IRLS)}\label{sec:irls}\hfill

Iterative Method (\S\ref{sec:iterative_method})

equivalent to \emph{minimizing} the \emph{Log-likelihood}
(\S\ref{sec:log_likelihood}) of a Bernoulli Process using Newton's Method
(\S\ref{sec:newtons_method})

for $L^p$-norm Linear Regression, IRLS at step $k+1$ involves solving Weighted
Least Squares (WLS \S\ref{sec:wls})

Least Absolute Deviations (LAD \S\ref{sec:lad}) -- $L^1$-norm Linear Regression

(wiki) --
Maximum Likelihood Estimation (MLE \S\ref{sec:mle}) in Logistic Regression
(\S\ref{sec:logistic_regression}):

Parameters $\vec{\beta}^T = [\beta_0, \beta_1, \ldots]$

Independent Variables $\vec{x}_i^T = [1, x_{i1}, x_{i2}, \ldots]$

Expected Value of the Bernoulli Distribution
$\mu_{y_i | \vec{x}_i} = 1 / (1 + e^{-\vec{\beta}^T \vec{x_i}})$

Iteratively solving for the $(k+1)$th Estimate given the $k$th Estimate of
$\vec{\beta}$:
\[
  \vec{\beta}_{k+1} = (\mathbf{X}^T \mathbf{S}_k \mathbf{X})^{-1} \mathbf{X}^T
    (\mathbf{S}_k \mathbf{X} \vec{\beta}_k + \vec{y} - \vec{\mu}_k)
\]
where:
\begin{itemize}
  \item $\mathbf{S} = diag(\mu_i - \mu_i^2)$ is a
    \emph{Diagonal Weighted Matrix}
  \item $\vec{\mu} = [\mu_1, \ldots, \mu_n]$ is the Vector of Expected Values
  \item $\mathbf{X} = [\vec{1}, \vec{x}_1, \vec{x}_2, \ldots]$ is the Regressor
    (Design) Matrix
  \item $\vec{y}_i^T = [y_1, y_2, \ldots]$ is the Vector of Response Variables
\end{itemize}



\paragraph{Polynomial Least Squares}\label{sec:polynomial_least_squares}\hfill

\paragraph{Non-Linear Least Squares (NLLS)}\label{sec:nlls}\hfill

Non-linear Regression (\S\ref{sec:nonlinear_regression})

examples:
\begin{itemize}
  \item Logistic Regression (\S\ref{sec:logistic_regression})
  \item Probit Regression (\S\ref{sec:probit_regression})
  \item Threshold Regression (TODO)
  \item Smooth Regression (TODO)
  \item Box-Cox Transformed Regression (TODO)
\end{itemize}

Normal Equations:
\[
  (\mathbf{J} \mathbf{W J}) \Delta \vec{\beta} =
    \mathbf{J} \mathbf{W} \Delta \vec{y}
\]



\subparagraph{Gauss-Newton Algorithm}\label{sec:gauss_newton}\hfill

cf. Backpropagation (\S\ref{sec:backpropagation})

QR methods

Gradient methods



\subsubsection{Pooled Estimate}\label{sec:pooled_estimate}

%FIXME



\subsubsection{Set Estimation}\label{sec:set_estimation}

Set-membership approach to Estimation Theory (cf. Probabilistic approach)



\subsubsection{Importance Sampling}\label{sec:importance_sampling}

Umbrella Sampling (Physics)

\fist Independence Metropolis-Hastings (Markov Chain Monte Carlo Method
\S\ref{sec:mcmc})

(Wasserman04 \S24.3)

can be used to reduce Variance in Monte Carlo Methods (\S\ref{sec:monte_carlo})

Sampling from a known Distribution $g$:
\[
  E_g(Y) = \int \frac{h(x)f(x)}{g(x)} g(x) dx
\]
where $Y = h(X)f(X)/g(X)$

Simulating $X_1, \ldots, X_n \sim g$ Estimates $E_g(Y)$ by:
\[
  \hat{E_g(Y)} = \frac{1}{N}\sum_i Y_i
\]
Converges with appropriate choice of $g$ such that the Variance is not Infinite
(FIXME: clarify)

(Thm.) The choice of $g$ that minimizes the Variance of $\hat{E_g(Y)}$ is:
\[
  g^*(x) = \frac{|h(x)| f(x)}{\int|h(s)| f(s) ds}
\]

this may not be useful if it is not known how to sample from $f$

in practice, $g$ should be a tick-tailed Distribution similar to $f|h|$



% ------------------------------------------------------------------------------
\subsection{Hypothesis Testing}\label{sec:hypothesis_testing}
% ------------------------------------------------------------------------------

or \emph{Confirmatory Data Analysis}

\url{https://github.com/puolival/multipy} -- Python library

A \emph{Statistical Test} is a ``procedure'' with Samples as input and results
in a \emph{Hypothesis} (\S\ref{sec:hypothesis}), i.e. a Conjecture
(\S\ref{sec:conjecture}) concerning one or more Statistical Populations
(\S\ref{sec:population}).

\fist In Bayesian Inference (\S\ref{sec:bayesian_inference}), a Hypothesis is
assigned a Probability, while in Frequentist Inference, a Hypothesis is Tested
without assigning a Probability.

Partitioning the Parameter Space (\S\ref{sec:parametric_model}) $\Theta$ into
Disjoint Sets $\Theta_0$ and $\Theta_1$, the \emph{Null Hypothesis}
(\S\ref{sec:null_hypothesis}), $H_0 = \vdash \theta \in \Theta_0$, represents
any Hypothesis, and the \emph{Alternative Hypothesis}
(\S\ref{sec:alternative_hypothesis}), $H_1 = \vdash \theta \in \Theta_1$,
represents an Hypothesis that is accepted in the case that the Null Hypothesis
is Rejected

\begin{enumerate}
  \item Sufficient Evidence: Reject $H_0$ in favor of $H_1$
  \item Insufficient Evidence: fail to Reject $H_0$
\end{enumerate}

\emph{Test Statistic} (\S\ref{sec:test_statistic}) $T(x)$

\emph{One-tail (One-sided) Test}:
\[
  H_0 = \vdash \theta \leq \theta_0 \quad\quad H_1 = \vdash \theta > \theta_0
\]
or:
\[
  H_0 = \vdash \theta \geq \theta_0 \quad\quad H_1 = \vdash \theta < \theta_0
\]

\emph{Two-tail (Two-sided) Test}:
\[
  H_0 = \vdash \theta = \theta_0 \quad\quad H_1 = \vdash \theta \neq \theta_0
\]

Test on a single Mean

Test on a single Sample

\emph{Critical Region} (\S\ref{sec:critical_region}) $R = \{ x : T(x) > c \}$

Type I Error: Rejection of $H_0$ when it is True

Type II Error: Non-Rejection of $H_0$ when it is False

$\beta$: Probability of committing a Type II Error

\begin{align*}
  P(\hat{\theta} | H_0) < \alpha & \Rightarrow \text{reject } H_0 \\
  P(\hat{\theta} | H_0) \geq \alpha & \Rightarrow \text{fail to reject } H_0 \\
\end{align*}

(Wasserman04, Ch.10)

the \emph{Size} or \emph{Significance Level}
(\S\ref{sec:statistical_significance}) of a Test:
\[
  \alpha = \sup_{\theta \in \Theta_0} \beta(\theta)
\]
is the Probability of making a Type I Error

a Test has \emph{Level} $\alpha$ if its Size is less than or equal to $\alpha$

$p$-value: lowest Level of Significance at which the observed Value of
the Statistic is Significant

\emph{Power} (\S\ref{sec:statistical_power}) $1 - \beta$: Probability of
Rejecting $H_0$ given that a specific alternative is True (Probability of
\emph{not} making a Type II Error)

the \emph{Power Function} of a Test with Rejection Region $R$:
\[
  \beta(\theta) = P_\theta(X \in R)
\]

\begin{itemize}
  \item Test for Statistical Randomness (\S\ref{sec:statistical_randomness})
\end{itemize}

\emph{Neyman-Pearson Lemma} -- most Powerful Test for Simple Null Hypothesis
$H_0 = \vdash \theta = \theta_0$ and Simple Alternative Hypothesis
$H_1 = \vdash \theta = \theta_1$

\asterism

\textbf{Bayesian Testing} (\S\ref{sec:bayesian_inference})

(Wasserman04 \S11.8)

places a Prior Probability Distribution (\S\ref{sec:prior_distribution}) on
$H_0$ and on $\theta$ and then computing $P(H_0 | X^n)$; Priors cannot be
Improper; a Prior-free bound on $P(H_0|X^n = x^n)$:
\[
  \frac{\mathcal{L}(\theta_0)}{\mathcal{L}(\theta_0) + \mathcal{L}(\hat\theta)}
    \leq P(H_0|X^n = x^n) \leq 1
\]

\emph{Lindley's Paradox} (\emph{Jeffreys-Lindley Paradox})



\subsubsection{Hypothesis}\label{sec:hypothesis}

A \emph{Statistical Hypothesis} is a Conjecture (\S\ref{sec:conjecture}) or
Assertion (\S\ref{sec:assertion}) concerning one or more Populations
(\S\ref{sec:population}).

cf. Hypothesis (Antecedent \S\ref{sec:antecedent} of a Hypothetical Proposition
\S\ref{sec:proposition})



\paragraph{Null Hypothesis}\label{sec:null_hypothesis}\hfill

$H_0$



\paragraph{Alternative Hypothesis}\label{sec:alternative_hypothesis}\hfill

$H_1$



\paragraph{Simple Hypothesis}\label{sec:simple_hypothesis}\hfill

Hypothesis specifies the Population Distribution completely

$\theta = \theta_0$



\paragraph{Composite Hypothesis}\label{sec:composite_hypothesis}\hfill

$\theta < \theta_0$ or $\theta > \theta_0$



\subsubsection{Test Statistic}\label{sec:test_statistic}

Statistic (\S\ref{sec:statistic}), $T$

(Wasserman04, Ch.10)

\begin{itemize}
  \item $z$-statistic
  \item $t$-statistic
  \item $F$-test
  \item ...
\end{itemize}



\paragraph{Critical Region}\label{sec:critical_region}\hfill

or \emph{Rejection Region}

set of Values of the Test Statistic for which the Null Hypothesis is rejected

\emph{Critical Values} -- boundaries of the Critical Region

$R = \{ x : T(x) > c \}$



\subsubsection{Significance Testing}\label{sec:significance_testing}

Fisher



\paragraph{Statistical Significance}\label{sec:statistical_significance}\hfill

the \emph{Size} or \emph{Significance Level} of a Test:
\[
  \alpha = \sup_{\theta \in \Theta_0} \beta(\theta)
\]
is the Probability of making a Type I Error

a Test has \emph{Level} $\alpha$ if its Size is less than or equal to $\alpha$

increasing $\alpha$ increases Power (\S\ref{sec:statistical_power}), but
increases the Probability of a Type I Error

\fist ANalaysis Of VAriance (ANOVA \S\ref{sec:variance_analysis}) -- compare

three or more ``group means'' for Significance

Exact Tests (\S\ref{sec:exact_test})



\paragraph{$p$-value}\label{sec:p_value}\hfill

lowest Level of Significance at which the Observed value of the Statistic is
Significant:
\[
  P(\hat{\theta} | H_0)
\]

(Wasserman04 \S10.2):

the $p$-value is the Probability under the Null Hypothesis $H_0$ of Observing a
value of the Test Statistic the same as or more extreme than what was actually
Observed

\textbf{Thm.} \emph{
  If the Test Statistic has a Continuous Distribution, then under
  $H_0 = \vdash \theta = \theta_0$ the $p$-value has a $Uniform(0,1)$
  Distribution and therefore one Rejects $H_0$ when $p$-value is less than the
  Significance Level $\alpha$, and the Probability of a Type I Error is
  $\alpha$.
}



\paragraph{Statistical Power}\label{sec:statistical_power}\hfill

Probability that the Test rejects the Null Hypothesis when the Alternative
Hypothesis is True, or equivalently, the Probability of \emph{not} making a Type
II Error

increasing $\alpha$ increases Power, but increases the Probability of a Type I
Error

increasing Sample Size will also increase Power

if the underlying Data has a lower Variability or if the true Parameter is far
from $H_0$, this also increases Power



\subsubsection{Multiple Testing Problem}\label{sec:multiple_testing}

or \emph{Multiple Comparisons Problem}




\paragraph{False Discovery Rate (FDR)}\label{sec:fdr}\hfill

\subparagraph{Bonferroni Correction}\label{sec:bonferroni_correction}\hfill



\paragraph{Family-Wise Error Rate (FWER)}\label{sec:fwer}\hfill

\subparagraph{Bonferroni Method}\label{sec:bonferroni_method}\hfill

or \emph{Holm-Bonferroni Method}



\subsubsection{Wald Test}\label{sec:wald_test}

\subsubsection{$t$-test}\label{sec:t_test}

\emph{Student's $t$-test}

\fist $t$-statistic (\S\ref{sec:t_statistic}),
$t$-distribution (\S\ref{sec:t_distribution})

essentially equal to Wald Test for moderately large $n$

\fist cf. ANalysis Of VAriance (ANOVA \S\ref{sec:variance_analysis}) --
generalization of $t$-test to more than two groups



\subsubsection{$F$-test}\label{sec:f_test}

\fist $F$-statistic (\S\ref{sec:f_statistic}),
$F$-distribution (\S\ref{sec:f_distribution})

Linear Regression



\subsubsection{Chi-squared Test}\label{sec:chi_squared_test}

$\chi^2$ Distribution (\S\ref{sec:chi_squared})

Chi-squared Statistic -- Randomness Condition, Large Counts Condition ($>5$
expected), Independence Condition

Goodness-of-fit (\S\ref{sec:model_fit})

Test for Homogeneity, Association (or Independence)

Logistic Regression



\paragraph{Pearson's Chi-squared Test}\label{sec:pearsons_chi_squared}\hfill



\subsubsection{Exact Test}\label{sec:exact_test}

\emph{Exact Statistics} (\S\ref{sec:exact_statistics}) -- not based on Large
Sample Theory (Asymptotic Theory \S\ref{sec:asymptotic_theory})



\paragraph{Permutation Test}\label{sec:permutation_test}\hfill

or \emph{Re-randomization Test}

Significance Testing (\S\ref{sec:significance_testing})

Non-parametric method for testing whether two Distributions are ``the same''

\fist cf. Resampling (\S\ref{sec:resampling})



\subsubsection{Likelihood-Ratio (LR) Test}\label{sec:lr_test}

used for comparing Fit (\S\ref{sec:model_fit}) of two Statistical Models



% ------------------------------------------------------------------------------
\subsection{Asymptotic Theory}\label{sec:asymptotic_theory}
% ------------------------------------------------------------------------------

or \emph{Large Sample Theory}

\fist cf. \emph{Exact Statistics} (\S\ref{sec:exact_statistics}) -- not based on
Large Sample Theory

\fist Asymptotic Distributions (\S\ref{sec:asymptotic_distribution})

\fist cf. Asymptotic Analysis (\S\ref{sec:asymptotic_analysis})

\fist cf. Asymptotically Consistent Estimator (\S\ref{sec:consistent_estimator})

(wiki):

framework for assessing properties of Estimators (\S\ref{sec:estimator}) and
Statistical Tests (Hypothesis Testing \S\ref{sec:hypothesis_testing}) as Sample
Size (\S\ref{sec:sample_size}) $n \to \infty$

\fist Stochastic Convergence (\S\ref{sec:stochastic_convergence}) -- Convergence
of Sequences (\S\ref{sec:convergent_sequence}) of Random Variables to Limit
Random Variables

Asymptotic Thoerems:
\begin{itemize}
  \item \emph{Law of Large Numbers} (\S\ref{sec:large_numbers}) --
    for Random Variables $X_1, \ldots, X_n$, the Sample Mean
    (\S\ref{sec:sample_mean}) $\overline{X}_n = \frac{1}{n}\sum_i X_i$ Converges
    in Probability to $\mu = E(X_i)$ as $n \to \infty$, i.e.
    $\overline{X}_n$ is close to $\mu$ with high Probability
  \item \emph{Central Limit Theorem} (\S\ref{sec:central_limit})
    for a Sequence of Random Variables $X_i, \ldots, X_n$ with Sample Mean
    $\overline{X}_n$, $\sqrt{n}(\overline{X}_n - \mu)$
    Converges in Distribution to a Normal Distribution
    (\S\ref{sec:normal_distribution}) as $n \to \infty$, i.e. the Sample
    Mean has approximately a Normal Distribution for large $n$
  \item ...
\end{itemize}



\subsubsection{Large Deviations Theory}\label{sec:large_deviations_theory}

\paragraph{Rate Function}\label{sec:rate_function}\hfill



% ------------------------------------------------------------------------------
\subsection{Exact Statistics}\label{sec:exact_statistics}
% ------------------------------------------------------------------------------

not based on Large Sample Theory (Asymptotic Theory
\S\ref{sec:asymptotic_theory})

\fist Exact Test (\S\ref{sec:exact_test})

Non-parametric



% ------------------------------------------------------------------------------
\subsection{Non-parameteric Inference}\label{sec:nonparametric_inference}
% ------------------------------------------------------------------------------

\fist Non-parametric Statistics (\S\ref{sec:nonparametric_statistics})

Statistical Functionals (\S\ref{sec:statistical_functional})

Resampling Methods (\S\ref{sec:resampling})

Non-parametric Regression (\S\ref{sec:nonparametric_regression})

Distribution-free Inference (\S\ref{sec:distribution_free})



% ------------------------------------------------------------------------------
\subsection{Frequentist Inference}\label{sec:frequentist_inference}
% ------------------------------------------------------------------------------

Frequency Interpretation
(\url{https://plato.stanford.edu/entries/probability-interpret/#FreInt}) --
differs from the Classical Interpretation in counting only the \emph{actual}
Outcomes instead of the \emph{possible} Outcomes; Finite Frequentism (Venn)

$f(x; \theta)$

(Wasserman04 \S11.1)

Frequentist postulates:
\begin{enumerate}
  \item Probability refers to limiting Relative Frequencies and Probabilities
    are \emph{objective} properties of the ``real world''
  \item Parameters are fixed, unknown Constants, and no useful Probability
    statements can be made about Parameters
  \item Statistical procedures should be designed to have well-defined long-run
    Frequency properties
\end{enumerate}

cf. \emph{Bayesian Inference} (\S\ref{sec:bayesian_inference}) -- focus is on
subjective ``degree of belief''; assigns Probabilities to Parameters (they are
Random Variables)



\subsubsection{Relative Frequency}\label{sec:relative_frequency}

\emph{Empirical Probability} or \emph{Experimental Probability} or
\emph{Long-run Probability}

after conducting many Trials (\S\ref{sec:trial}) of the same Experiment
(\S\ref{sec:experiment}), the Relative Frequencies of the various Outcomes
(\S\ref{sec:outcome}) and Events (\S\ref{sec:probability_event}) can be assessed

\url{https://plato.stanford.edu/entries/probability-interpret/#FreInt}:

\emph{Hypothetical Frequentism}: extension of Relative Frequencies of an actual
Sequence of ``Trials'' to counterfactual, limiting Relative Frequencies in case
of an Infinite number of Trials

\emph{Reference Class Problem}: Relative Frequencies must be ``Relativised'' to
a ``Reference Class'' (other interpretations of Probability may have this
problem as well)--

solutions restrict to certain Sequences of Outcomes, e.g. (Infinite)
``\emph{Collectives}'' (Von Mises57)--cf. Infinite Bernoulli Sequences
(\S\ref{sec:bernoulli_sequence})--where a \emph{Place-selection} is an effective
method of selecting indices of Members of a Sequence such that the selection or
not of Index $i$ depends \emph{at most} on the first $i-1$ Outcomes
(``attributes''), with the Axioms of \emph{Convergence} (the limiting Relative
Frequency of any Outcome exists) and \emph{Randomness} (the limiting Relative
Frequency of each Outcome in a Collective $\omega$ is the same in any Infinite
Subsequence of $\omega$ determined by Place-selection; note that trivial
Sequences such as $H,H,H,\ldots$ satisfy this ``Randomness'' Axiom; cf. the
Principle of Maximum Entropy in Classical Probability), Algorithmic Randomness
(\S\ref{sec:algorithmic_randomness});
issues with limiting Relative Frequencies are that they violate Countable
Additivity and the Domain of Definition is not a Set-field or a $\sigma$-algebra
(de Finetti72)



\subsubsection{Propensity}\label{sec:propensity}

(wiki):

\emph{Chance} or \emph{Single-case Probability}

a purported ``\emph{cause}'' or explanation of an observed stable Relative
Frequency

invokes the Law of Large Numbers (\S\ref{sec:large_numbers}) to explain stable
\emph{long-run} Frequencies as a manifestation of invariant \emph{single-case}



\subsubsection{Frequency Distribution}\label{sec:frequency_distribution}

\paragraph{Contingency Table}\label{sec:contingency_table}\hfill

or \emph{Cross Tabulation} or \emph{Crosstab}

displays the Multivariate (\S\ref{sec:multivariate_statistics}) Frequency
Distribution of Variables

``\emph{Levels}''

Two-way Tables

Chi-squared Test (\S\ref{sec:chi_squared_test}) -- Degrees of Freedom =
(rows - 1)(columns - 1)

Log-linear Model (\S\ref{sec:log_linear})

(McCullagh02 \S 6.4)



\subsubsection{Confidence Interval}\label{sec:confidence_interval}

or \emph{Confidence Set} for Parameter Spaces of Dimension $2$ or greater

(wiki):

for a Random Sample (\S\ref{sec:sample}) Vector (IID \S\ref{sec:iid}) $X$ from a
Distribution with Parameters $\theta \in \Theta$, a \emph{Confidence Interval}
for $\theta$ with \emph{Confidence Level} (or \emph{Confidence Coefficient}) $1
- \alpha$ is an Interval with Random Endpoints $(a(X), b(X))$, determined by the
Random Variables $a(X)$ and $b(Y)$ such that:
\[
  \forall \theta \in \Theta, P_\theta(a(X) < \theta < b(X)) = 1 - \alpha
\]
note that $\theta$ is a fixed ``true'' value (not a Random Variable)

\fist Standard Score (\S\ref{sec:standard_score}), Margin of Error
(\S\ref{sec:margin_of_error}), $t$-statistic (\S\ref{sec:t_statistic})

assumptions:
\begin{itemize}
  \item Sample is Random
  \item Normal Condition -- more than 10 ``Successes'' and Failures in a Sample
  \item Independence Condition -- when Sampling without replacement, the Sample
    Size $n$ should be less than 10\% of the Population size
\end{itemize}

Estimating a Population Proportion (\S\ref{sec:proportion})

Confidence Limit

Prediction Interval (\S\ref{sec:prediction_interval})

Interval Measurement (\S\ref{sec:measurement_level})

Interval Estimate (\S\ref{sec:interval_estimator})

cf. Credible Intervals (Bayesian Inference \S\ref{sec:credible_interval})

Hypothesis Testing (\S\ref{sec:hypothesis_testing})

One-tail, Two-tail



\paragraph{Confidence Band}\label{sec:confidence_band}\hfill

represents Uncertainty in a Curve Estimate (cf. Smoothing \S\ref{sec:smoothing},
Density Estimation \S\ref{sec:density_estimation}, Kernel Regression
\S\ref{sec:kernel_regression})



\paragraph{Hoeffding's Inequality}\label{sec:hoeffdings_inequality}\hfill

used the analyze the number of required Samples needed to obtain a Confidence
Interval

\fist Probability Inequalities (Classification Error
\S\ref{sec:classification_error})

\textbf{Thm.} (Hoeffding's Inequality)

\emph{
  For $Y_1, \ldots, Y_n$ Independent Observations (\S\ref{sec:observation}) such
  that $E(Y_i) = 0$ and $a_i \leq Y_i \leq b_i$, given $\epsilon > 0$, for any
  $t > 0$:
  \[
    P\Big(\sum_i Y_i \geq \epsilon\Big) \leq
      e^{-t\epsilon} \prod_i e^{t^2(b_i - a_i)^2/8}
  \]
}



% ------------------------------------------------------------------------------
\subsection{Bayesian Inference}\label{sec:bayesian_inference}
% ------------------------------------------------------------------------------

\emph{Bayesian Statistics}

\emph{Evidential Probability} or \emph{Bayesian Probability} -- interpretation
of Probability as a ``reasonable'' \emph{Expectation}
(\S\ref{sec:expected_value}) or ``degree of belief''

Subjective Interpretation

Logical Interpretation (Objective Bayesianism) -- Cox's Theorem

$f(x | \theta)$

Conditional Probabilities (\S\ref{sec:conditional_probability}), Bayes' Rule
(\S\ref{sec:bayes_theorem})

\fist Bayesian Network (Probabilistic Directed Acyclic Graphical Model
\S\ref{sec:bayes_network})

\fist Dirichlet Processes (\S\ref{sec:dirichlet_process})

Subjective Probability %FIXME: section
(\url{https://plato.stanford.edu/entries/probability-interpret/#SubPro}),
Conditioning (\S\ref{sec:conditioning})

\fist Subjective Logic (\S\ref{sec:subjective_logic})

(wiki): every unique Bayesian ``Procedure'' (Decision Rule
\S\ref{sec:decision_rule}) is Admissable (\S\ref{sec:admissable}) and every
Admissable Statistical Procedure is either a Bayesian Procedure or a Limit of
Bayesian Procedures (Wald)

many instances of Regularized Inverse Problems (\S\ref{sec:inverse_problem}) can
be interpreted as special cases of Bayesian Inference

\fist Aumann1987 - \emph{Correlated Equilibrium as an Expression of Bayesian
  Rationality} -- \emph{Correlated Equilibrium}
(\S\ref{sec:correlated_equilibrium}) ``does away with'' the ``dichotomy usually
perceived'' between the \emph{Bayesian} and \emph{Game-theoretic} world-views

(Wasserman04, Ch.11)

Bayesian postulates:
\begin{enumerate}
  \item Probability describes \emph{degree of belief} (not limiting Frequency),
    so Probability statements can be made about things other than Random
    Variables
  \item Probability statements can be made about Statistical Parameters
  \item Inferences about a Parameter $\theta$ are made by producing a
    Probability Distribution for $\theta$, and Inferences such as Point
    Estimates and Interval Estimates can be extracted from this Distribution
\end{enumerate}

cf. \emph{Frequentist Inference} (\S\ref{sec:frequentist_inference}) -- focus is
on ``objective'' long-run Relative Frequencies, and Statistical Parameters are
assumed to be fixed constants, not Random Variables

\fist Bayesian Methods are tied to the \emph{Likelihood Function}
(\S\ref{sec:likelihood}) which does not yield accurate Inferances in
High-dimensional and Non-parametric problems

\emph{Bayesian Method}:
\begin{enumerate}
  \item choose a \emph{Prior Distribution} (\S\ref{sec:prior_distribution}) for
    Model Parameters $\theta$ defined by PDF (\S\ref{sec:pdf}) $f(\theta)$
  \item choose a \emph{Statistical Model} (\S\ref{sec:statistical_model})
    $f(x|\theta)$ reflecting the degree of ``belief'' about $x$ given $\theta$
  \item Observe (\S\ref{sec:observation}) Data (\S\ref{sec:sample})
    $X_1, \ldots, X_n$ and \emph{update} beliefs and calculate the
    \emph{Posterior Distribution} (\S\ref{sec:posterior_distribution})
    $f(\theta | X_1, \ldots, X_n)$
\end{enumerate}

for Discrete $\theta$ and single Discrete $X$:
\[
  P(\Theta = \theta | X = x) = \frac{
    P(X = x|\Theta = \theta)P(\Theta = \theta)
  }{
    \sum_\theta P(X = x | \Theta = \theta) P(\Theta = \theta)
  }
\]
(Bayes' Theorem \S\ref{sec:bayes_theorem})

for Continuous Variables:
\[
  f(\theta | x) = \frac{
    f(x|\theta)f(\theta)
  }{
    \int f(x|\theta)f(\theta) d\theta
  }
\]

for $n$ IID Observations $X_1, \ldots, X_n$:
\[
  f(x_1, \ldots, x_n | \theta) =
    \prod_{i=1}^n f(x_i | \theta) = \mathcal{L}_n(\theta)
\]
where $\mathcal{L}_n$ is the \emph{Likelihood Function} (\S\ref{sec:likelihood})

for $x^n = (x_1, \ldots, x_n)$:
\[
  f(\theta|x^n) = \frac{\mathcal{L}_n(\theta)f(\theta)}{c_n}
    \propto \mathcal{L}_n(\theta)f(\theta)
\]
where $cn = \int \mathcal{L}_n(\theta)f(\theta) d\theta$ is the
\emph{Normalizing Constant}
%FIXME: same concept as Normalizing Constant for continuous random variables ?

i.e. \emph{Posterior is Proportional-to Likelihood times Prior}:
\[
  f(\theta | x^n) \propto \mathcal{L}(\theta)f(\theta)
\]

when the Prior and Posterior Distributions are in the same family, the Prior is
said to be ``\emph{Conjugate}'' with respect to the Model

for multiple Parameters $\theta = (\theta_1, \ldots, \theta_p)$, the Posterior
Density Function $f(\theta|x^n)$ is the same as above, and the \emph{Marginal
  Posterior} for an individual Parameter $\theta_1$ is:
\[
  f(\theta_1 | x^n) =
    \int\cdots\int f(\theta_1,\ldots,\theta_p | x^n) d\theta_2 \cdots d\theta_p
\]
Integral can be approximated by ``\emph{Simulation}''
(\S\ref{sec:stochastic_simulation}), i.e. ``drawing Randomly'' from the
Posterior (Wasserman04 11.7)



\subsubsection{Prior Distribution}\label{sec:prior_distribution}

$f(\theta)$

or \emph{Prior Probability}

when the Prior and Posterior Distributions (\S\ref{sec:posterior_distribution})
are in the same family, the Prior is said to be ``\emph{Conjugate}'' with
respect to the Model

commonly used Prior Distribution: Multivariate Beta Distribution (Dirichlet
Distribution \S\ref{sec:dirichlet_distribution})

\emph{Subjectivism}: Prior should reflect ``subjective opinion'' about $\theta$
before the Data are collected

\emph{Non-informative Prior} -- alternative to Subjective Prior, e.g. Flat
Prior, Jeffrey's prior

\emph{Proper Prior}

\emph{Improper Prior} -- $f(\theta) d\theta = \infty$

\emph{Flat Prior} -- $f(\theta) \propto c$ for some Constant $c$ (also an
Improper Prior since $\int f(\theta) d\theta = \infty$); Flat Priors are not
\emph{Transformation Invariant}: the notion of a Flat Prior is not well-defined
because a Flat Prior on a Parameter does not imply a Flat Prior on a Transformed
Parameter

\emph{Jeffrey's Prior} -- uses Fisher Information (\S\ref{sec:fisher_metric});
Transformation Invariant

(wiki):

\emph{Cromwell's Rule} -- Prior Probabilities of $0$ and $1$ should only be used
for Statements that are Logically True or False, e.g. $2+2 = 4$

\emph{Bernstein-von Mises Theorem} -- Posterior Distribution for unknown
quantities in any problem is effectively Asymptotically Independent of the Prior
Distribution, assuming it obeys \emph{Cromwell's Rule}, as the Sample Data
(\S\ref{sec:sample}) grows large

the effect of the Prior diminishes as $n$ (i.e. $(X_1, \ldots, X_n)$) increases

\emph{Maximum Entropy Principle}: the \emph{Maximum Entropy Distribution}
(\S\ref{sec:maximum_entropy}) for a certain Class of Probability Distributions
minimizes the amount of Prior Information built into the Distribution



\paragraph{Cojugate Prior}\label{sec:conjugate_prior}\hfill

(wiki):

when Prior and Posterior are in the same Family of Probability Distributions,
then they are called \emph{Conjugate Distributions} and the Prior is called the
\emph{Cojugate Prior}



\subparagraph{Stable Count Distribution}\label{sec:stable_count}\hfill

the Conjugate Prior of a One-sided Stable Distribution
(\S\ref{sec:onesided_stable})

related to ``VIX Distribution''



\subsubsection{Posterior Distribution}\label{sec:posterior_distribution}

$f(\theta | x^n)$

\emph{Posterior is Proportional-to Likelihood times Prior}
(\S\ref{sec:prior_distribution}):
\[
  f(\theta | x^n) \propto \mathcal{L}(\theta)f(\theta)
\]

(Wasserman04 \S24.1):
\[
  f(\theta | X^n) = \frac{
    \mathcal{L}(\theta) f(\theta)
  }{
    \int \mathcal{L}(\theta) f(\theta) d\theta
  }
\]
where the Denominator is the \emph{Normalizing Constant}

Marginal Posterior Density -- may require computing high-dimensional Integrals

Posterior Estimates:

\emph{Posterior Mean} (Point Estimate)

\[
  \overline{\theta} = \int \theta f(\theta | X^n) d\theta
\]

for Distributions satisfying ``Regularity Conditions'', e.g. Bernoulli and
Normal Distributions, Posterior Mean is generally close to the MLE (Mean
Likelihood Estimate \S\ref{sec:mle})

Posterior Mean is Admissable (\S\ref{sec:admissable}) for any Strictly Positive
Prior

\emph{Posterior Interval} (Credible Interval \S\ref{sec:credible_interval})

(Wasserman04 \S11.4) Posteriors can be Approximated using ``\emph{Simulation}''
(\S\ref{sec:stochastic_simulation})

\emph{Bernstein-von Mises Theorem} -- Posterior Distribution for unknown
quantities in any problem is effectively Asymptotically Independent of the Prior
Distribution, assuming it obeys \emph{Cromwell's Rule}, as the Sample Data
(\S\ref{sec:sample}) grows large



\subsubsection{Conditioning}\label{sec:conditioning}

Subjective Probability
(\url{https://plato.stanford.edu/entries/probability-interpret/#SubPro}),
Orthodox Bayesianism (\S\ref{sec:bayesian_inference})

\fist cf. Passive, Active Conditioning (Causal Inference
\S\ref{sec:active_conditioning})

\fist not to be confused with Condition Numbers (Numerical Analysis
\S\ref{sec:condition_number})

\begin{itemize}
  \item Conditional Probability (\S\ref{sec:conditional_probability})
  \item Conditional Expectation (\S\ref{sec:conditional_expectation})
  \item Conditional Distribution (\S\ref{sec:conditional_distribution})
\end{itemize}

\fist Conditional Independence (\S\ref{sec:conditional_independence})

\fist Scaling under Conditioning (Scaling Distribution
\S\ref{sec:scaling_distribution})



\subsubsection{Likelihood}\label{sec:likelihood}

(Fisher)

whereas Probability is some Area under a given PDF, the \emph{Likelihood} is the
Density of some PDF at a given Observation value, that is, the Joint Probability
Distribution of Observed Data expressed as a Function of Statistical Parameters
(FIXME: Clarify)

\fist Bayesian Methods are tied to the Likelihood Function which does not yield
accurate Inferances in High-dimensional and Non-parametric problems

\emph{Likelihood Function} $\mathcal{L} : \Theta \to [0, \infty)$ -- the
  Joint Density (\S\ref{sec:joint_probability}) of Sample Data
  (\S\ref{sec:sample}):
\[
  \mathcal{L}(\theta | x) = f_\theta(x)
\]
for the given Observation $x$ of Random Variable $X$ with an Absolutely
Continuous Probability Distribution with PDF (\S\ref{sec:pdf}) $f$ depending on
Parameters (\S\ref{sec:population_parameter}) $\theta$; for a Discrete
Distribution:
\[
  \mathcal{L}(\theta | x) = P_\theta(X = x)
\]

\emph{Likelihood Principle}

\emph{Likelihoodist Statistics} (cf. Frequentism, Bayesianism)

cf. \emph{Probability} (\S\ref{sec:probability}) -- a Probability refers to
variable Data for a fixed Hypothesis (\S\ref{sec:hypothesis_testing}), while a
Likelihood refers to variable Hypotheses for fixed Data

\emph{Maximum Likelihood Estimation} (MLE \S\ref{sec:mle}) -- $\hat{\theta}$:
the value of $\theta$ that Maximizes $\mathcal{L}(\theta)$

Likelihood Interval

Likelihood-ratio Test

\fist a Statistic $T(X^n)$ is \emph{Sufficient}
(\S\ref{sec:sufficient_statistic}) if the Likelihood Function can be computed
knowing only $T(X^n)$ (Wasserman04 \S9.13.2)



\paragraph{Log-likelihood}\label{sec:log_likelihood}\hfill

$\ell$

(wiki): viewing Data as ``evidence'', Log-likelihood is the ``weight'' of
evidence or providing ``\emph{support}'' for a particular Model; the support of
a Model given an Event is the Negative of the Surprisal (Information Content
\S\ref{sec:information_content}), i.e. the Log-probability
(\S\ref{sec:log_probability}), of the Event given the Model: a Model is
supported by an Event to the extent that the Event is ``\emph{unsurprising}''
given the Model

Iteratively Re-weighted Least Squares (\S\ref{sec:irls}) -- equivalent to
\emph{minimizing} the Log-likelihood of a Bernoulli Process
(\S\ref{sec:bernoulli_process}) using Newton's Method
(\S\ref{sec:newtons_method}); used for MLE in Logistic Regression
(\S\ref{sec:logistic_regression})

\fist Cross-entropy Error Function -- minimizing \emph{Negative Log-likelihood}
is the same as minimizing Cross Entropy (\S\ref{sec:cross_entropy})



\subparagraph{Score}\label{sec:score}\hfill

\emph{Score Function} is the Derivative of the Log-likelihood Function

\fist Fisher Information (\S\ref{sec:fisher_metric})



\subsubsection{Credible Interval}\label{sec:credible_interval}

\emph{Posterior Interval} (\S\ref{sec:posterior_distribution})

Interval Estimator (\S\ref{sec:interval_estimator})

Prediction Interval (\S\ref{sec:prediction_interval})

cf. Confidence Interval (Frequentist Inference \S\ref{sec:confidence_interval})



\subsubsection{Bayes Estimator}\label{sec:bayes_estimator}\hfill

or \emph{Bayes Action}

Estimator (or Decision Rule (\S\ref{sec:decision_rule}) that minimizes
(maximizes) Posterior Expected Value of a Loss (Utility) Function
(\emph{Posterior Expected Loss/Utility})

cf. Maximum A Priori (MAP) Estimator (\S\ref{sec:map_estimator})

the Mean Likelihood Estimate (\S\ref{sec:mle}) approximates the Bayes Estimator

Bayes Estimators with constant Risk Function (\S\ref{sec:risk_function}) are
Minimax (\S\ref{sec:minimax})



\subsubsection{Linear Quadratic Estimation (LQE)}\label{sec:lqe}

dual of Linear Quadratic Regulation (LQR \S\ref{sec:lqr})

\fist Kalman Filters (\S\ref{sec:kalman_filter})



% ------------------------------------------------------------------------------
\subsection{Predictive Inference}\label{sec:predictive_inference}
% ------------------------------------------------------------------------------

cf. Predictive Analytics (\S\ref{sec:predictive_analytics})

\fist cf. Regression Analysis (\S\ref{sec:regression_analysis})

$\hat{y}$



\subsubsection{Predictive Model}\label{sec:predictive_model}

\emph{Predictive Modeling}

cf. Detection Theory (\emph{Signal Recovery}) %TODO

Classification (\S\ref{sec:classification})

Cross-validation (\S\ref{sec:cross_validation})

Algorithmic Trading, Backtesting

cf. Scenario Analysis (\S\ref{sec:scenario_analysis}): based on
\emph{hypothetical} Data, not historical Data



\subsubsection{Prediction}\label{sec:prediction}

\subsubsection{Retrodiction}\label{sec:retrodiction}

\begin{itemize}
  \item Backtesting (\S\ref{sec:backtesting})
\end{itemize}



\subsubsection{Prediction Interval}\label{sec:prediction_interval}\hfill

Interval Estimate (\S\ref{sec:interval_estimator}) of where future Observations
(\S\ref{sec:observation}) will fall with a certain Probability, given what has
already been Observed

Frequentist: Confidence Interval (\S\ref{sec:confidence_interval})

Bayesian: Credible Interval (\S\ref{sec:credible_interval})

\emph{Predictive Performance} -- a means of Model Validation
(\S\ref{sec:model_validation}) which is an analysis of whether a constructed
Statistical Model (\S\ref{sec:statistical_model}) holds up when applied to new
Data (\S\ref{sec:sample})



\paragraph{Prediction Band}\label{sec:prediction_band}\hfill



\subsubsection{Predictability}\label{sec:predictability}

\fist Predictable Process (\S\ref{sec:predictable_process})



\subsubsection{Linear Predictor}\label{sec:linear_predictor}

\emph{Linear Predictor Function}

\fist Linear Regression (\S\ref{sec:linear_regression}) -- models Relationships
in Multivariate Data using Linear Predictor Functions with parameters Estimated
from the Data

\fist Generalized Linear Model (\S\ref{sec:glm}) -- Linear Predictor is one
component of a GLM along with a family of Exponential Distributions and a Link
Function

\fist Linear Classifier (\S\ref{sec:linear_classifier})



\paragraph{Best Linear Unbiased Prediction (BLUP)}\label{sec:blup}\hfill

Predicting Random Effects (\S\ref{sec:random_effect});
cf. Mixed Models (\S\ref{sec:mixed_model})

cf. Best Linear Unbiased Estimator (BLUE \S\ref{sec:blue}) -- Estimating
Fixed Effects

under ``suitable assumptions'' on the Priors, Gaussian Process Regression
(Kriging \S\ref{sec:gaussian_process_regression}) gives the best BLUP of the
intermediate values



% ------------------------------------------------------------------------------
\subsection{Causal Inference}\label{sec:causal_inference}
% ------------------------------------------------------------------------------

cf. Experimental Studies

(wiki):

identification of the Cause of an ``Effect'' by establishing \emph{Covariation}
(\S\ref{sec:covariance}) of Cause and Effect, a \emph{Time-order Relation} with
the Cause preceding the Effect, and the elimination of plausible alternative
Causes

the main difference between \emph{Causal Inference} and an Inference of
\emph{Association} (Dependence \S\ref{sec:dependence}) is that the former
analyzes the ``response'' of the ``effect variable'' when the Cause is changed.

an example of ``Causal Reasoning'' (TODO: xref)

\url{http://www.inference.vc/untitled/} - \emph{ML beyond Curve Fitting: An
  Intro to Causal Inference and do-Calculus}

\emph{Categorical Semantics for Causal Structure} -
\url{https://golem.ph.utexas.edu/category/2018/01/a_categorical_semantics_for_ca.html}
- $*$-autonomous (\S\ref{sec:star_autonomous}) extension of a given Compact
Closed Category

(McCullagh02):

Causal mechanisms are necessarily \emph{context dependent} in ways that
Categories and Morphisms are not;
a given Model arising in different fields may be capable of numerous
``mechanistic'' interpretations, and Models exist for which \emph{no}
mechanistic interpretation is ``readily'' available or else are in conflict
with accepted ``scientific'' laws, but such alternative Models are
\emph{necessary} in order to test scientific laws

(Wasserman04, Ch.16)



\subsubsection{Causation}\label{sec:causation}

%FIXME: move section?

cf. Covariance (\S\ref{sec:covariance})

Markov Process (\S\ref{sec:markov_process}) -- Probabilistic expression of
``Direct Causality'' (Mandelbrot97E)

\fist (wiki): for Ergodic Signals with a Linear System Function, Signal
Coherence (\S\ref{sec:signal_coherence}) can be used to Estimate the Causality
between System input and output (FIXME: clarify)



\subsubsection{Causal Model}\label{sec:causal_model}

%FIXME: move section?



\paragraph{Counterfactual Model}\label{sec:counterfactual}\hfill

(Wasserman04, \S16.1)

\textbf{Binary Random Variable $X$}

Outcome Variable $Y$

introduce two new Random Variables $(C_0, C_1)$ called \emph{Potential Outcomes}
where $C_0$ is the Outcome if $X = 0$ and $C_1$ is the Outcome if $X = 1$

\emph{Consistency Relationship}:
\[
  Y = \begin{cases}
    C_0 & \text{if} X = 0 \\
    C_1 & \text{if} X = 1 \\
  \end{cases}
\]

when $X = 0$, $C_1$ is a \emph{Counterfactual}, and vice versa when $X = 1$,
$C_0$ is Counterfactual

measuring ``\emph{Causal Effect}''

\begin{itemize}
  \item \emph{Average Causal Effect}:
    \[
      \theta = E[C_1] - E[C_0]
    \]
    i.e. $\theta$ is the Mean if every Observed $X = 1$, minus the Mean if every
    Observed $X = 0$

  \item for Binary $C_0$, $C_1$, the \emph{Causal Odds Ratio}:
    \[
      \frac{
        \frac{P(C_1 = 1)}{P(C_1 = 0)}
      }{
        \frac{P(C_0 = 1)}{P(C_0 = 0)}
      }
    \]
    and \emph{Causal Relative Risk}:
    \[
      \frac{P(C_1 = 1)}{P(C_0 = 1)}
    \]
\end{itemize}

the \emph{Association}:
\[
  \alpha = E[Y | X = 1] - E[Y | X = 0]
\]

\textbf{Thm.} \emph{Association is not Causation, i.e. in general
$\theta \neq \alpha$}

this is because $(C_0, C_1)$ is not Independent of $X$

instead by using \emph{Random Assignment} (cf. Random Sampling
\S\ref{sec:random_sample}) of $X$ (FIXME: explain), $\theta = \alpha$, and any
Consistent Estimator (\S\ref{sec:consistent_estimator}) of $\alpha$ is a
Consistent Estimator of $\theta$

\emph{Conditional Causal Effect}

\textbf{Continuous $X$}

$(C_0, C_1)$ is replaced by the \emph{Counterfactual Function} $C(x)$ is the
Outcome for an Observed $x$

Consistency Relation $Y \equiv C(X)$

\emph{Causal Regression Function}:
\[
  \theta(x) = E(C(x))
\]

\emph{Association Regression Function}:
\[
  r(x) = E[Y | X = x]
\]

\textbf{Thm.} \emph{In general, $\theta(x) \neq r(x)$, but when $X$ is Randomly
  Assigned, $\theta(x) = r(x)$}


\textbf{Observational Study} -- a study in which $X$ is \emph{not} Randomly
Assigned; \emph{Confounding Variables}, \emph{Adjusted Treatment Effect}



\paragraph{Causal Graph}\label{sec:causal_graph}\hfill

or \emph{Causal Network}

\fist Bayesian Network (\S\ref{sec:bayes_network}) -- ``Dependency structure'';
Probabilistic DAG (\S\ref{sec:dag})

alternative to Counterfactuals for representing Causal Relations

finding the correct Causal Graph from Data of two Variables is impossible; for
more Variables there are Large Sample methods under certain assumptions, but
there is no way to know whether the Sample Size is large enough to be reliable

(Wasserman04, Ch.17)

Conditional Independence (\S\ref{sec:conditional_independence}) -- for Random
Variables $X$, $Y$, $Z$, given $Z$, $X$ and $Y$ are \emph{Conditionally
  Independent}, $X \coprod Y | Z$ if for all $x,y,z$:
\[
  f_{X,Y|Z}(x,y|z) = f_{X|Z}(x|z) f_{Y|Z}(y|z)
\]
i.e. when $Z$ is known, $Y$ provides no extra information about $X$;
equivalently:
\[
  f(x|y, z) = f(x|z)
\]

$X \coprod Y | Z \Rightarrow Y \coprod X | Z$

in a Probabilistic DAG, each Vertex represents a Random Variable

a DAG $\mathcal{G}$ with Vertices $V = (X_1, \ldots, X_n)$ \emph{Represents} a
Distribution $P$ for $V$ with PDF $f$ if:
\[
  f(v) = \prod_{i=1}^k f(x_i | \pi_i)
\]
where $\pi_i$ are the Parents of $X_i$; the Set of Distributions Represented by
$\mathcal{G}$ is denoted $M(\mathcal{G})$

Markov Condition (\S\ref{sec:markov_condition}) -- every Node is Conditionally
Independent of its Non-descendents, given its Parents

Directional Separation (\S\ref{sec:directional_separation})

$\mathcal{I}(\mathcal{G})$ -- Independence Statements implied by $\mathcal{G}$

two DAGs $\mathcal{G}_1$, $\mathcal{G}_2$ are Markov Equivalent if
$\mathcal{I}(\mathcal{G}_1) = \mathcal{I}(\mathcal{G}_2)$



\subparagraph{Active Conditioning}\label{sec:active_conditioning}\hfill

(Wasserman04, \S17.08)

\emph{Passive Conditioning} -- Conditioning by Observation

\emph{Active Conditioning} -- Conditioning by Intervention



\subparagraph{Structural Equation Modeling (SEM)}\label{sec:sem}\hfill

%FIXME: move section ?

Confirmatory Factor Analysis, Confirmatory Composite Analysis, Path Analysis,
Partial Least Squares Path Modeling, Latent Growth Modeling



\subparagraph{Pairwise Markov Graph}\label{sec:pairwise_markov}\hfill

(Wasserman04, \S18.2)

Undirected Graph (\S\ref{sec:undirected_graph})

encodes a Set of Pairwise Conditional Independence Relations
(\S\ref{sec:independence})

Global Markov Property



% ------------------------------------------------------------------------------
\subsection{Distribution-free Inference}\label{sec:distribution_free}
% ------------------------------------------------------------------------------

Distribution-free Methods

Ordinal Data



% ------------------------------------------------------------------------------
\subsection{Fiducial Inference}\label{sec:fiducial_inference}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Topological Inference}\label{sec:topological_inference}
% ------------------------------------------------------------------------------

Wasserman14 - \emph{Robust Topological Inference}

TDA (R package)



% ==============================================================================
\section{Multivariate Statistics}\label{sec:multivariate_statistics}
% ==============================================================================

\emph{simultaneous} Observation (\S\ref{sec:observation}) and Analysis of more
than one Outcome Variable (\emph{Multivariate Random Variables} or \emph{Random
  Vectors} \S\ref{sec:random_vector})

\begin{itemize}
  \item Multivariate Analysis (\S\ref{sec:multivariate_analysis})
  \item Statistical Classification (\S\ref{sec:classification})
    -- Discrete Response Variable
  \item Regression Analysis (\S\ref{sec:regression_analysis}) -- Estimating
    (\S\ref{sec:estimation_theory}) the Relation between Variables in
    Multivariate Data; note that this is different from Multivariate Analysis in
    that only the Univariate Conditional Distribution of a single Outcome
    Variable is considered; cf. Multivariate Regression
    (\S\ref{sec:multivariate_regression})
  \item Cluster Analysis (\S\ref{sec:cluster_analysis}) --
    ``Unsupervised Learning''
  \item Artificial Neural Networks (\S\ref{sec:ann}) -- extends Regression and
    Clustering to Non-linear Multivariate Models
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Multivariate Analysis}\label{sec:multivariate_analysis}
% ------------------------------------------------------------------------------

\subsubsection{Interaction}\label{sec:interaction}

\emph{Interaction Variable}

product of two or more Explanatory Variables

cf. Basis Functions (\S\ref{sec:basis_function})



\subsubsection{Ordination}\label{sec:ordination}

or \emph{Gradient Analysis}

cf. Gradient (Vector Calculus \S\ref{sec:gradient})

cf. Clustering (\S\ref{sec:cluster_analysis})



\paragraph{Principal Components Analysis (PCA)}\label{sec:pca}\hfill

Dimensionality Reduction (\S\ref{sec:dimensionality_reduction})

cf. Factor Analysis (\S\ref{sec:factor_analysis})

cf. Dynamic Mode Decomposition (\S\ref{sec:dmd})



\paragraph{Multidimensional Scaling}\label{sec:multidimensional_scaling}\hfill

\fist Scaling (Similarity Transformation \S\ref{sec:scaling})

Classical Multidimensional Scaling (Principal Coordinate Analysis)

Metric Multidimensional Scaling (mMDS)

Non-metric Multidimensional Scaling (nMDS)

Generalized Multidimensional Scaling (GMDS)

cf. Scale Analysis (\S\ref{sec:statistical_scale})



\paragraph{Correspondence Analysis}\label{sec:correspondence_analysis}\hfill

\subparagraph{Detrended Correspondence Analysis}
\label{sec:detrended_correspondence}\hfill

\fist cf. Detrended Fluctuation Analysis (\S\ref{sec:detrended_fluctuation})



\subparagraph{Canonical Correspondence Analysis}
\label{sec:canonical_correspondence}\hfill



\paragraph{Bray-Curtis Ordination}\label{sec:bray_curtis_ordination}\hfill

\paragraph{Redundancy Analysis}\label{sec:redundancy_analysis}\hfill



\subsubsection{Factor Analysis}\label{sec:factor_analysis}

cf. PCA (\S\ref{sec:pca})



\subsubsection{Multivariate Analysis of Variance (MANOVA)}\label{sec:manova}

Variance Analysis (ANOVA \S\ref{sec:variance_analysis})



\subsubsection{Discriminant Analysis}\label{sec:discriminant_analysis}



% ==============================================================================
\section{Nonparametric Statistics}\label{sec:nonparametric_statistics}
% ==============================================================================

not based only on Parameterized Families of Probability Distributions

includes both Descriptive and Inferential Statistics

Nonparametric Regression (\S\ref{sec:nonparametric_regression})

Nonparametric Models (\S\ref{sec:nonparametric_model})

Nonparametric Inference (\S\ref{sec:nonparametric_inference})

Order Statistics (\S\ref{sec:order_statistic})

Rank Statistics (\S\ref{sec:rank_statistic})

Kernel Density Estimation (\S\ref{sec:kde})



% ==============================================================================
\section{Statistical Learning Theory}\label{sec:statistical_learning_theory}
% ==============================================================================

% ------------------------------------------------------------------------------
\subsection{Learning Algorithm}\label{sec:learning_algorithm}
% ------------------------------------------------------------------------------

(wiki)

Model Fitting (\S\ref{sec:model_fit}):
\begin{itemize}
  \item Parameter Estimation (\S\ref{sec:estimation_theory})
  \item Feature Selection (\S\ref{sec:feature_selection})
\end{itemize}

a Model (\S\ref{sec:statistical_model}), e.g. Naive Bayes Classifier
(\S\ref{sec:naive_bayes}), ANN (\S\ref{sec:ann}), is ``Trained'' on a Training
Dataset (\S\ref{sec:training_dataset}) using a \emph{Supervised Learning Method}
(cf. Statistical Classification \S\ref{sec:classification}):
\begin{itemize}
  \item Gradient Descent (\S\ref{sec:gradient_descent})
  \item Stochastic Gradient Descent (SGD \S\ref{sec:sgd})
  \item ...
\end{itemize}

\fist cf. Learning Process (ANNs \S\ref{sec:learning_process})



\subsubsection{Hyperparameter}\label{sec:hyperparameter}

Parameters set before Learning Algorithm begins



\subsubsection{Training Dataset}\label{sec:training_dataset}

examples used to initially \emph{Fit} the Parameters of a Statistical Model

\emph{Ground Truth} (FIXME)

cf. Statistical Sample (\S\ref{sec:sample}), Dataset (\S\ref{sec:dataset})



\subsubsection{Validation Dataset}\label{sec:validation_dataset}

Fitted Model is used to \emph{Predict} Responses for Observations in the
Validation Dataset

tuning Hyperparameters (\S\ref{sec:hyperparameter})



\subsubsection{Test Dataset}\label{sec:test_dataset}

used to provide an Unbiased evaluation of the final Model Fit on the Training
Dataset



% ------------------------------------------------------------------------------
\subsection{Statistical Classification}\label{sec:classification}
% ------------------------------------------------------------------------------

\emph{Supervised Learning} where the Response Variable is \emph{Discrete}; cf.
\emph{Regression} where the Response Variable is Continuous

cf. Parameter Estimation (\S\ref{sec:estimation_theory}), Feature Selection
(\S\ref{sec:feature_selection})

\fist Predictive Modeling (\S\ref{sec:predictive_modeling})

Classification is an example of \emph{Pattern Recognition} (assignment of some
Output Value to a given Input Value), other examples are Regression Analysis
(\S\ref{sec:regression_analysis}) and Cluster Analysis (Unsupervised Learning
\S\ref{sec:cluster_analysis})

Loss (\S\ref{sec:objective_function})

(wiki):

\emph{Features} (Properties of Observations \S\ref{sec:observation} or
\emph{Instances} \S\ref{sec:feature_vector}) are \emph{Explanatory Variables}
(Regressors \S\ref{sec:independent_variable}) and possible values of the
Dependent Variable (\S\ref{sec:dependent_variable}) are prediction
\emph{Categories} (or \emph{Classes}, i.e. Categorical Variables
\S\ref{sec:statistical_data_type}), sometimes called \emph{Outcomes} (cf. Trial
Outcomes \S\ref{sec:outcome})

an Algorithm (\S\ref{sec:algorithm}) that implements Classification is called a
\emph{Classifier} (or \emph{Classification Rule})

finding a Classifier is based on a \emph{Training Dataset}
(\S\ref{sec:training_dataset}) --FIXME: clarify

often done with Logistic Regression (\S\ref{sec:logistic_regression})

\emph{Categorical Cross-entropy} (\S\ref{sec:cross_entropy}) -- Loss Function
for Classification (cf. Squared Error Loss Function for Regression)

\fist VC Dimension (\S\ref{sec:vc_dimension}) -- measure of the capacity
(expressive power) of a Space of Functions that can be Learned by a
Classification Algorithm

\fist Decision Trees (Decision Theory \S\ref{sec:decision_tree}) --
``Hierarchical Axis-parallel Classifiers''; Partitioning of Covariate Space;
paths from Root to Leaf represent Classification Rules

Classification Models (increasingly indirect):
\begin{itemize}
  \item Distribution-free Model (cf. Non-parametric Model
    \S\ref{sec:nonparametric_model}, Descriptive Statistics
    \S\ref{sec:descriptive_statistics}) -- compute a Label directly from an
    Observation, without using a Probability Distribution
  \item Discriminative Models (\S\ref{sec:discriminative_model}) -- tries to
    Model the Conditional Distribution $P(Y|X = x)$ by depending on
    \emph{Observed Data}-- Estimation of the Probability of a Label given an
    Observation; makes fewer assumptions about Distributions and relies
    more on \emph{Data quality}
  \item Generative Models (\S\ref{sec:generative_model}) -- Model of the
    Joint Probability Distribution on $X \times Y$; Estimation of the Joint
    Distribution, which can then be used to compute the Conditional Probability
    for Classification purposes
\end{itemize}

(symmetric):
\begin{itemize}
  \item Generative Model -- Model of the Observable given the Label $P(X|Y = y)$
  \item Discriminative Model -- Model of the Label given the Observation
    $P(Y|X = x)$
\end{itemize}

(Wasserman04, Ch.22)



\subsubsection{Feature Vector}\label{sec:feature_vector}

Explanatory Variable (Regressor), ``Instance''

\emph{Feature Space}



\subsubsection{Feature Scaling}\label{sec:feature_scaling}

\subsubsection{Min-max Normalization}\label{sec:minmax_normalization}

\emph{Min-max Scaling} or \emph{Rescaling}

\fist cf. Normalizing Ratio (\S\ref{sec:normalizing_ratio})



\subsubsection{Regularizer}\label{sec:regularizer}

(wiki): Empirical Learning of Classifiers is always an \emph{Underdetermined
  Problem} because it attempts to Infer a Function of \emph{any} given $x$ from
only a limited number of examples $x_1, x_2, \ldots, x_n$; \emph{Regularization}
(\S\ref{sec:regularization}) can be used to Learn simpler Models and avoid
Overfitting



\subsubsection{Generalization}\label{sec:generalization}

%FIXME

\subsubsection{Classification Model}\label{sec:classification_model}

\paragraph{Generative Model}\label{sec:generative_model}\hfill

Statistical Model of the \emph{Joint Probability Distribution}
(\S\ref{sec:joint_probability}) $P(X,Y)$

an alternative definition is that a Generative Model is a Model of the
Conditional Probability of the Observable given a Label: $P(X|Y = y)$
(cf. Discriminative Model \S\ref{sec:discriminative_model} $P(Y|X = x)$)

Generative methods of determining Parameters for a Linear Classifier
(\S\ref{sec:linear_classifier}):
\begin{itemize}
  \item Linear Discriminant Analysis (LDA or Fisher's Linear Discriminant
    \S\ref{sec:lda})
  \item Naive Bayes Classifier (\S\ref{sec:naive_bayes})
\end{itemize}

GPT-2: Unsupervised (Generative) Transformer (\S\ref{sec:transformer}) Language
Model (\S\ref{sec:statistical_language_model})

\fist Generative Adversarial Network (GAN \S\ref{sec:gan}): combines a
Generative Network with a Discriminative Network

2017 - Pascual - \emph{PixelCNN, WaveNet \& Variational Autoencoders} -
\url{https://www.youtube.com/watch?v=FeJT8ejgsL0}

Model the Probability Density Fucntion:
\begin{itemize}
  \item Explicitly
    \begin{itemize}
      \item ``Tractable'' Density -- PixelRNN, PixelCNN, WaveNet
      \item Approximate Density -- Variational Auto-encoders (VAEs
        \S\ref{sec:vae})
    \end{itemize}
  \item Implicitly
    \begin{itemize}
      \item Generative Adversarial Networks
    \end{itemize}
\end{itemize}

2017 - Yeung - Stanford CS231n - \emph{Lecture 13: Generative Models} -
\url{https://www.youtube.com/watch?v=5WoItGTWV54}

cf. Unsupervised Learning (Cluster Analysis \S\ref{sec:cluster_analysis})

Density Estimation (\S\ref{sec:density_estimation}) -- learn $p_{model}(x)$
similar to $p_{data}(x)$

\emph{Explicit Density Estimation} -- explicitly ``\emph{define and solve for}''
$p_{model}(x)$

\emph{Implicit Density Estimation} -- \emph{learn} a model that can sample from
$p_{model}(x)$ without explicitly defining it (FIXME: clarify)

\begin{itemize}
  \item Explicit Density
  \begin{itemize}
    \item Tractable Density
      \begin{itemize}
        \item Fully-visible Belief Nets -- PixelRNN/CNN, NADE, MADE
        \item Change-of-variables Models (Non-linear ICA --FIXME: ???)
      \end{itemize}
    \item Approximate Density
    \begin{itemize}
      \item Markov Chain -- Boltzmann Machine (Energy-based Model
        \S\ref{sec:ebm})
      \item Variational -- Variational AutoEncoder (\S\ref{sec:vae})
    \end{itemize}
  \end{itemize}
  \item Implicit Density
  \begin{itemize}
    \item Markov Chain -- Generative Stochastic Network (GSN \S\ref{sec:gsn})
    \item Direct -- Generative Adversarial Network (GAN \S\ref{sec:gan})
  \end{itemize}
\end{itemize}



\subparagraph{Energy-Based Model (EBM)}\label{sec:ebm}\hfill

Boltzmann Machine (\S\ref{sec:boltzmann_machine})



\subparagraph{Deep Belief Network (DBN)}\label{sec:dbn}\hfill

composed from Unsupervised Networks (RBMs, Autoencoders)



\subparagraph{Stochastic Block Model}\label{sec:stochastic_block_model}\hfill



\paragraph{Discriminative Model}\label{sec:discriminative_model}\hfill

or \emph{Conditional Model}

Statistical Model of the \emph{Conditional Probability}
(\S\ref{sec:conditional_probability}) $P(Y | X = x)$

Discriminative methods of determining Parameters for a Linear Classifier
(\S\ref{sec:linear_classifier}):
\begin{itemize}
  \item Logistic Regression (\S\ref{sec:logistic_regression})
  \item Perceptron (\S\ref{sec:perceptron})
  \item Support Vector Machines (\S\ref{sec:svm})
\end{itemize}



\subsubsection{Classification Error}\label{sec:classification_error}

(Wasserman04, \S22.8)

Loss Functions for Classifiers:
\begin{itemize}
  \item True Error Rate
  \item Empirical Error Rate (Training Error Rate)
\end{itemize}

note that the Training Error Rate is a bad Estimate because it is Biased
downward

Bias-Variance tradeoff

Estimating the Error Rate:

Cross-validation Estimate

Probability Inequalities -- Confidence Interval \fist Hoeffding's Inequality
(\S\ref{sec:hoeffdings_inequality}); Empirical Risk Minimization (ERM
\S\ref{sec:erm})



\subsubsection{Naive Bayes Classifier}\label{sec:naive_bayes}

Generative Model (\S\ref{sec:generative_model}) for Linear Classification
(\S\ref{sec:linear_classifier})

assumes Components of $X$ are Independent

useful when $x$ is High-dimensional and Discrete



\subsubsection{Binary Classifier}\label{sec:binary_classifier}

Linear (\S\ref{sec:linear_classifier}) Binary Classifiers:
\begin{itemize}
  \item Perceptron (\S\ref{sec:perceptron})
  \item Support Vector Machine (SVM \S\ref{sec:svm}) -- Non-probabilistic
\end{itemize}



\subsubsection{Linear Classifier}\label{sec:linear_classifier}

a \emph{Linear Predictor Function} (\S\ref{sec:linear_predictor}) assigns a
``score'' to each possible category $k$ by taking the Dot Product of the Feature
Vector with a Vector of \emph{Weights}

methods for determining Parameters of a Linear Classifier

Generative (\S\ref{sec:generative_model}) methods:
\begin{itemize}
  \item Linear Discriminant Analysis (LDA or Fisher's Linear Discriminant
    \S\ref{sec:lda})
  \item Naive Bayes Classifier (\S\ref{sec:naive_bayes})
\end{itemize}

Discriminative (\S\ref{sec:discriminative_model}) methods:
\begin{itemize}
  \item Logistic Regression (\S\ref{sec:logistic_regression})
  \item Perceptron (\S\ref{sec:perceptron}) -- also a Binary Classifier
    (\S\ref{sec:binary_classifier})
  \item Support Vector Machines (\S\ref{sec:svm})
\end{itemize}

Probit Regression (\S\ref{sec:probit_regression}) -- FIXME: Discrminative ???

``Kernalization'' (Wasserman04, \S22.10) -- a Linear Classifier in a
Higher-dimensional Space corresponds to a Non-linear Classifier in the original
space; \emph{Mercer's Theorem}



\paragraph{Linear Discriminant Analysis (LDA)}\label{sec:lda}\hfill

\emph{Fisher's Linear Discriminant}

cf. Logistic Regression (\S\ref{sec:logistic_regression}) -- in LDA, the Joint
Distribution $f(x,y = f(x|y)f(y)$ is Estimated by maximizing the Likelihood; in
Logistic Regression, only $f(y|x)$ is Estimated and the Conditional Likelihood
is maximized, neglecting the Marginal Distribution $f(x)$



\subparagraph{Discriminant Function}\label{sec:discriminant_function}\hfill



\paragraph{Kernel Method}\label{sec:kernel_method}\hfill

\emph{the Kernel Trick}: using \emph{Kernel Functions} (Positive-definite
Kernels \S\ref{sec:pd_kernel}) enables Kernel Methods to operate in a
high-dimensional \emph{Implicit Feature Space} without having to compute the
\emph{Coordinate} of the Data in that Space, instead by computing the Inner
Products between the \emph{Images} of all \emph{pairs} of Data in the Feature
Space (\S\ref{sec:feature_vector})

(Jacot, Gabriel, Hongler 2018): at initialization, ANNs (\S\ref{sec:ann}) are
equivalent to Gaussian Processes (\S\ref{sec:gaussian_process}) in the
``Infinite-width Limit'', connecting them to Kernel Methods, and the
\emph{evolution} of an ANN during Training can also be described by a Kernel



\subparagraph{Support Vector Machine (SVM)}\label{sec:svm}\hfill

or \emph{Perceptron of Optimal Stability}

an extension of the Perceptron (\S\ref{sec:perceptron}) Model where the
Separating Hyperplanes are chosen to have the largest distance to the nearest
Training-data Point of any Class (\emph{Functional Margin})

Non-probabilistic Binary Linear Classifier

Discriminative Model (\S\ref{sec:discriminative_model})

Support Vectors

Maximum Margin Hyperplane

Slack Variables

Quadratic Programming (\S\ref{sec:quadratic_programming})



\paragraph{Perceptron}\label{sec:perceptron}\hfill

Discriminative Method (\S\ref{sec:discriminative_model})

Binary (\S\ref{sec:binary_classifier}) Linear Classifier
(\S\ref{sec:linear_classifier})

\fist Support Vector Machine (SVM \S\ref{sec:svm}) -- an extension of the
Perceptron (\S\ref{sec:perceptron}) Model where the Separating Hyperplanes are
chosen to have the largest distance to the nearest Training-data Point of any
Class (\emph{Functional Margin})

\fist Neural Networks (\S\ref{sec:ann}) -- a Perceptron (or \emph{Linear
  Threshold Unit}) is an \emph{Artificial Neuron}
(\S\ref{sec:artificial_neuron}) using the Unit Step Function
(\S\ref{sec:unit_step_function}) as the Activation Function

\fist Single-layer Perceptron (\S\ref{sec:single_layer_perceptron})
-- simplest Feed-forward Neural Network (\S\ref{sec:ffnn})

\emph{Delta Rule} -- special case of Backpropagation
(\S\ref{sec:backpropagation}) for training a Single-layer Neural network

\fist Threshold Logic Unit (TLU \S\ref{sec:tlu})



\subparagraph{Multiclass Perceptron}\label{sec:multiclass_perceptron}\hfill

\fist Multiclass Classification (\S\ref{sec:multiclass})



\subsubsection{Quadratic Classifier}\label{sec:quadratic_classifier}

Quadratic Disciminant Analysis (QDA)



\subsubsection{k-nearest Neighbors (KNN) Classfier}\label{sec:knn_classifier}

Non-parametric method

Instance-based Learning or Lazy Learning

cf. kNN Regression (\S\ref{sec:knn_regression})



\subsubsection{Multiclass Classification}\label{sec:multiclass}

or \emph{Multinomial Classification}

Multiclass Perceptron (\S\ref{sec:multiclass_perceptron})



\subsubsection{Multi-label Classification}\label{sec:multilabel}

generalization of Multiclass Classification (\S\ref{sec:multiclass}) where
Multiple ``Labels'' may be assigned to each ``Instance'' (FIXME: clarify)



\subsubsection{Ensemble Learning}\label{sec:ensemble_learning}

use of multiple Learning Algorithms to obtain better Predictive performance



\paragraph{Bayes Classifier}\label{sec:bayes_classifier}\hfill

\emph{Bayes Optimal Classifier}

\emph{Bayes Rule} (\S\ref{sec:bayes_theorem})

(Wasserman04, \S22.2)

$h^*(x)$

note the Bayes Classifier is not ``Bayesian'', i.e. it can be Estimated using
either Frequentist or Bayesian methods

\textbf{Thm.} \emph{Bayes Rule is Optimal, i.e. if $h$ is any other Classifier
  then $L(h^*) \leq L(h)$ where $L$ is the True Error Rate Loss Function}

approaches:
\begin{itemize}
  \item Empirical Risk Minimization (ERM \S\ref{sec:erm})
  \item Regression
  \item Density Estimation
\end{itemize}

Regression Function $r(x)$

Bayes Classifier for $Y \in \mathcal{Y} = \{0, 1\}$:
\[
  h^*(x) = \begin{cases}
    1 & \text{if} r(x) > 0.5 \\
    0 & \text{otherwise} \\
  \end{cases}
\]



\paragraph{Bootstrap Aggregation}\label{sec:bootstrap_aggregation}\hfill

or \emph{Bagging}

Variance reduction

useful for highly Non-linear Classifiers (cf. Decision Trees
\S\ref{sec:decision_tree})



\subparagraph{Random Subspace Method}\label{sec:random_subspace_method}\hfill

\emph{Feature Bagging} or \emph{Attribute Bagging}



\paragraph{Boosting}\label{sec:boosting}\hfill

Bias (\S\ref{sec:bias}) reduction

emphasizes Mis-classifications in previous Models

AdaBoost

Gradient Boosting



\paragraph{Stacked Generalization}\label{sec:stacked_generalization}\hfill

or \emph{Stacking}



\subsubsection{Probabilistic Classification}
\label{sec:probabilistic_classification}

use of Statistical Inference (\S\ref{sec:inferential_statistics})



% ------------------------------------------------------------------------------
\subsection{Regression Analysis}\label{sec:regression_analysis}
% ------------------------------------------------------------------------------

\emph{Regression} (or \emph{Curve Estimation}) is the Estimation
(\S\ref{sec:estimation_theory}) of \emph{Relations} (Dependencies
\S\ref{sec:dependence}) in Multivariate Data (\S\ref{sec:random_vector}).

Note that Regression Analysis is different from Multivariate Analysis
(\S\ref{sec:multivariate_analysis}) in that only the Univariate Conditional
Distribution of a single Outcome Variable is considered (cf. Multivariate
Regression \S\ref{sec:multivariate_regression}).

\emph{Supervised Learning} where the Response Variable is \emph{Continuous}; cf.
\emph{Classification} (\S\ref{sec:classification}) where the Response Variable
is Discrete

specifically, an Estimation of the \emph{Regression Function}

$r(x) = E(Y | X = x)$.

commonly this is an Estimate of the Conditional Expectation
(\S\ref{sec:conditional_expectation}) of a Dependent Variable for a given
Independent Variable; also the Quantile (\S\ref{sec:quantile}) or other Location
Parameter

Interaction Variables (\S\ref{sec:interaction}), Basis Functions
(\S\ref{sec:basis_function})

\fist cf. Curve Fitting (\S\ref{sec:curve_fitting}), Curve Estimation (Smoothing
\S\ref{sec:smoothing})

\emph{Regression Variable}, ``Regressor'', ``Predictor'', ``Feature'', or
``Explanatory Variable'' -- \emph{Independent Variable}
(\S\ref{sec:independent_variable}); Covariate

\emph{Response Variable}, ``Regressand'', ``Outcome'', or ``Explained Variable''
-- \emph{Dependent Variable} (\S\ref{sec:dependent_variable}); Criterion

\emph{Regression Function} -- the Function of the Independent Variables to be
Estimated (\S\ref{sec:estimation_theory}):
\[
  r(x) = E(Y | X = x) = \int y f(y|x) dy
\]
that is, the Expected Value of the Response Variable given that the Regression
Variable takes a specific value, where $r \in \mathcal{F}$ is specified by
choice of (Regression) Model Parameters (\S\ref{sec:statistical_model}) $\theta$

\fist cf. Predictive Inference (\S\ref{sec:predictive_inference}),
Prediction Interval (\S\ref{sec:prediction_interval})

Regression Analysis is also concerned with characterizing the \emph{variation}
of the Dependent Variable $X$ around the \emph{Prediction}
(\S\ref{sec:prediction}) $Y$ of the Regression Function using a Probability
Distribution

cf. ``Predictive Analytics''

example of \emph{Pattern Recognition} (assignment of some Output Value to a
given Input Value), other examples are Statistical Classification
(\S\ref{sec:classification})--when the Response Variable is
Discrete--and Cluster Analysis (\S\ref{sec:cluster_analysis})

\emph{Squared Error} (\S\ref{sec:squared_deviation}) -- Loss Function for
Regression (cf. Categorical Cross-entropy Loss Function for Classification)

cf. Numerical Analysis (\S\ref{sec:numerical_analysis}): Interpolation
(\S\ref{sec:interpolation}), Extrapolation (TODO)

\fist Artificial Neural Networks (ANNs \S\ref{sec:ann}) generalize Regression
and Clustering (\S\ref{sec:cluster_analysis}) to Non-linear Multivariate Models

\emph{Statistical Assumptions} (\S\ref{sec:statistical_assumption}):
\begin{itemize}
  \item the Sample is ``representative'' of the Population for the Inference
    Prediction
  \item the Error is a Random Variable with Mean $0$ Conditional on the
    Regressor(s)
  \item the Regressors are Measured (Observed) with no Error (cf. Measurement
    Error Models \S\ref{sec:measurement_error_model})
  \item the Regressors are Linearly Independent
  \item the Errors are Uncorrelated (\S\ref{sec:statistical_correlation})
  \item (\emph{Homoscedasticity} \S\ref{sec:homoscedasticity}) the Variance of
    the Error is Constant accross Observations (cf. Weighted Least Squares
    \S\ref{sec:wls})
\end{itemize}
at are sufficient for the Least-squares Estimator (\S\ref{sec:least_squares}) to
be Unbiased (\S\ref{sec:unbiased_estimate}), Consistent
(\S\ref{sec:consistent_estimator}), and Efficient
(\S\ref{sec:efficient_estimate}) in the Class of \emph{Linear Unbiased
  Estimators} (TODO: xref)

\asterism

(Wasserman04, Ch.13)

Estimate the Regression Function $r(x)$ from Sample Data (\S\ref{sec:sample}) of
the form:
\[
  (Y_1,X_1), \ldots, (Y_n,X_n) \sim F_{X,Y}
\]

Estimate $\hat{r}(x)$

\emph{Predicted (Fitted) Values}:
\[
  \hat{Y}_i = \hat{r}(X_i)
\]

\emph{Residuals} (\S\ref{sec:regression_residual}):
\[
  \hat{\epsilon}_i = Y_i - \hat{Y}_i
\]

the \emph{Residual Sum of Squares} (SSR \S\ref{sec:ssr}) is a measure of how
well the Estimated Regression Function ``Fit'' the Data:
\[
  \sum_{i=1}^n \hat{\epsilon}_i^2
\]
the Regression Parameters that miminize SSR are caled \emph{Least Squares
  Estimates} (\S\ref{sec:least_squares})



\subsubsection{Regression Model}\label{sec:regression_model}

a \emph{Statistical Model} (\S\ref{sec:statistical_model}) which makes some
assumption about the Relations (Dependences \S\ref{sec:dependence}) among
Multivariate Data (\S\ref{sec:random_vector})

\emph{Regression Model}:
\begin{itemize}
  \item \emph{Unknown Parameters} ($\beta$)
  \item \emph{Independent Variables} ($X$) -- ``Regression Variable'',
    ``Regressor'', ``Covariate'', ``Explanatory Variable''
  \item \emph{Dependent Variable} ($Y$) -- ``Response Variable'',
    ``Regressand'', ``Criterion'', ``Explained Variable''; variable whose values
    are to be ``explained'' in terms of the Independent Variable
\end{itemize}

the Regression Parameters that miminize Residual Sums of Squares (SSR
\S\ref{sec:ssr}) are called \emph{Least Squares Estimates}
(\S\ref{sec:least_squares})

cf. Autoregressive Models (\S\ref{sec:autoregressive_model})

(Wasserman04 \S13.2):
 under assumption of Normality ($Y_i | X_i \sim N(\mu_i, \sigma^2)$), the Least
 Squares Estimator is also the Maximum Likelihood Estimator (MLE
 \S\ref{sec:mle})

(Wasserman04 \S13.6)

Model Selection

\emph{Prediction Risk}, \emph{Training Error}

\emph{Mallows's $C_p$}, AIC (\S\ref{sec:aic})

Leave-one-out Cross-validation (\S\ref{sec:cross_validation}),
$k$-fold Cross-validation

Bayesian Information Criterion (BIC) %TODO: xref

Zheng-Loh Model Selection Method

Linear Regression Models (\S\ref{sec:linear_regression})

...



\paragraph{Measurement Error Model}\label{sec:measurement_error_model}\hfill

accounts for Observational (Measurement) Error (\S\ref{sec:observational_error})



\subsubsection{Regression Error}\label{sec:regression_error}

\fist cf. Statistical Error (\S\ref{sec:error})

Mean Squared Error (MSE) or Mean Squared Deviation (MSD)

Deviation from value Predicted by the ``\emph{true}'' Regression Function

$\epsilon$



\subsubsection{Regression Residual}\label{sec:regression_residual}

Deviation from value Predicted by the Estimated Regression Function

\fist cf. Residual (\S\ref{sec:residual})

$y - \hat{y}$

the Vector of Regression Residuals $\hat{e}$ can be expressed in terms of the
Influence Matrix (\S\ref{sec:influence_matrix}), $\hat{y} = \mathbf{H}\vec{y}$:
\[
  \hat{e} = \vec{y} - \hat{y} = \vec{y} - \mathbf{H}\vec{y} =
    (\mathbf{I} - \mathbf{H})\vec{y}
\]
where $(\mathbf{I} - \mathbf{H})$ is the \emph{Residual Maker Matrix}

$S$ -- Standard Deviation (\S\ref{sec:standard_deviation}) of Residuals

Residual Plot

SSE -- Sum of Squared Residuals (SSR or RSS \S\ref{sec:ssr}); for a Simple
Linear Model (\S\ref{sec:simple_linear_regression}):
\[
  \sum_n (y_i - \hat{\beta_1} x_i + \hat{\beta_0})
\]
can be re-written as:
\[
  n (\overline{y^2} - 2 \hat{\beta_1} \overline{x y}
    - 2 \hat{\beta_0} \overline{y} + \hat{\beta_1}^2 \overline{x^2}
    + 2 \hat{\beta_1} \hat{\beta_0} \overline{x} + \hat{\beta_0}^2)
\]
finding where the Partial Derivative with respect to $\hat{\beta_0}$ and
$\hat{\beta_1}$ are both Zero gives the Least-squares Estimate
(\S\ref{sec:least_squares}) of the Regression Function

solving for $\hat{\beta_1}$:
\[
  \hat{\beta_1} = \frac{
    (\overline{x})\overline{y} - \overline{xy}
  }{
    (\overline{x})^2 \overline{x^2}
  }
\]
or equivalently:
\[
  \hat{\beta_1} = \frac{
    Cov(x,y)
  }{
    Var(x)
  }
\]
and substituting to solve for $\hat{\beta_0}$:
\[
  \hat{\beta_0} = \overline{y} - \frac{
    \overline{x} Cov(x,y)
  }{
    Var(x)
  }
\]



\subsubsection{Fraction of Variance Unexplained (FVU)}\label{sec:fvu}

Fraction of Variance of the Regressand (Dependent Variable) $Y$ which cannot be
explained (i.e. not correctly Predicted) by the Explanatory Variables $X$

``Statistical Noise'' (cf. Noise Signal \S\ref{sec:noise})



\subsubsection{Determination Coefficient}\label{sec:determination_coefficient}

``\emph{R-squared}''

how much the variation in $y$ is ``explained'' by $x$

$R^2 = SSR/SST$

\[
  r^2 = 1 - \frac{
    ESS_{\hat{y}}
  }{
    TSS_{\overline{y}}
  }
\]

ESS -- Explained Sum of Squares (\S\ref{sec:ess})

TSS -- Total Sum of Squares (\S\ref{sec:tss})

cf. $r$ -- Correlation Coefficient (\S\ref{sec:correlation_coefficient})

measure of Goodness-of-fit (\S\ref{sec:model_fit}) in Logistic Regression
(\S\ref{sec:logistic_regression})



\subsubsection{Influence Matrix}\label{sec:influence_matrix}

or \emph{Hat Matrix} or \emph{Projection Matrix} (cf.
Linear Projection \S\ref{sec:linear_projection})

(wiki):

relates the Vector of Observed Response Values $\vec{y}$ to the Vector of Fitted
Values $\hat{y}$:
\[
  \hat{y} = \mathbf{H}\vec{y}
\]

the Vector of Regression Residuals (\S\ref{sec:regression_residual}) $\hat{e}$
can be expressed in terms of the Influence Matrix:
\[
  \hat{e} = \vec{y} - \hat{y} = \vec{y} - \mathbf{H}\vec{y} =
    (\mathbf{I} - \mathbf{H})\vec{y}
\]
where $(\mathbf{I} - \mathbf{H})$ is the \emph{Residual Maker Matrix}

\begin{itemize}
  \item $\mathbf{H} \equiv \mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T$
    -- OLS (\S\ref{sec:ols})
  \item $\mathbf{H} \equiv \mathbf{X}
    (\mathbf{X}^T\mathbf{\Psi}^{-1}\mathbf{X})^{-1}
    \mathbf{X}^T\mathbf{\Psi}^{-1}$
    -- GLS (\S\ref{sec:gls})
\end{itemize}



\subsubsection{Non-parametric Regression}\label{sec:nonparametric_regression}

Regression Function is chosen from an Infinite-dimensional Family of Functions

Non-parametric Statistics (\S\ref{sec:nonparametric_statistics})

\fist cf. Density Estimation (\S\ref{sec:density_estimation})

(Wasserman04, \S20.4)

(Wasserman04, Ch.21)

Orthogonal Function (\S\ref{sec:orthogonal_function}) Regression Estimator

Haar Basis, Haar Wavelet (\S\ref{sec:haar_wavelet}) Regression



\paragraph{Kernel Regression}\label{sec:kernel_regression}\hfill

cf. Kernel Density Estimation (KDE \S\ref{sec:kde})

Kernel Function

Nadaraya-Watson Kernel Estimator

Kernel Smoother

Confidence Bands (\S\ref{sec:confidence_band})



\paragraph{Additive Regression}\label{sec:additive_regression}\hfill

Additive Model (AM)

not fully Non-parametric

\emph{Backfitting} Algorithm



\subparagraph{Generalized Additive Model (GAM)}\label{sec:gam}\hfill

Generalized Linear Model (\S\ref{sec:glm}) where the Linear Predictor depends
Linearly on unknown Smooth Functions of Predictor Variables



\paragraph{k-nearest Neighbors (KNN) Regression}\label{sec:knn_regression}

Instance-based Learning or Lazy Learning

cf. kNN Classification (\S\ref{sec:knn_classifier})



\subsubsection{Linear Regression}\label{sec:linear_regression}

\emph{Linear Regression Model}

Relationships are modeled using \emph{Linear Predictor Functions}
(\S\ref{sec:linear_predictor}) which are Linear Functions of a Set of
Coefficients and Explanatory (Independent) Variables:
\[
  Y_i = \beta_0 + \beta_1\phi_1(X_{i1}) + \cdots +
    \beta_p\phi_p(X_{ip}) + \varepsilon_i
\]
for $i \in \{1, \ldots, n\}$ where $\phi$ are Basis Functions
(\S\ref{sec:basis_function})

Assuming $\varepsilon_i | X_i \sim N(0, \sigma^2)$ is the same as Assuming
$Y_i | X_i \sim N(\mu_i, \sigma^2)$

cf. \emph{Correlation} (\S\ref{sec:statistical_correlation}) -- measure of how
close two Random Variables are to having a \emph{Linear Relationship}

\begin{itemize}
  \item Simple Linear Regression (\S\ref{sec:simple_linear_regression})
  \item Multivariate (``General'') Linear Regression
    (\S\ref{sec:multivariate_linear_regression})
  \item Generalized Linear Models (GLMs \S\ref{sec:glm})
\end{itemize}

Fit using Estimators:
\begin{itemize}
  \item Linear Least Squares (\S\ref{sec:lls}): if Errors are
    \emph{Normally Distributed}, Least Squares ($2$-norm Best Fit) should be
    used
    \begin{itemize}
      \item Ordinary Least Squares (\S\ref{sec:ols}): if Errors are
        \emph{Normally Distributed}, Least Squares ($2$-norm Best Fit) should be
        used
    \end{itemize}
  \item Generalized Least Squares (\S\ref{sec:gls}): if
    there is a degree of Correlation between Residuals (Fitting Deviations
    \S\ref{sec:residual})
  \item ...
\end{itemize}

\textbf{Gauss-Markov Theorem} \emph{
  In a Linear Model where Errors are Uncorrelated, have Mean Zero, and equal
  Variances, the Best Linear Unbiased Estimator (BLUE \S\ref{sec:blue}) of the
  Coefficients is given by the OLS Estimator.
}

OLS can be solved by:
\begin{itemize}
  \item in the case of a Simple Linear Regression Model
    (\S\ref{sec:simple_linear_regression}):
    \begin{flalign*}
      \hat{\beta_1} & = \frac{
        \overline{X} \overline{Y} - \overline{XY}
      }{
        (\overline{X})^2 - \overline{X^2}
      } \\
      \hat{\beta_0} & = \overline{Y} - \hat{\beta_1} \overline{X} \\
    \end{flalign*}
    or equivalently:
    \begin{flalign*}
      \hat{\beta_1} & = \frac{Cov(X,Y)}{Var(X)} \\
      \hat{\beta_0} & = \overline{Y} - \frac{\overline{X} Cov(X, Y)}{Var(X)} \\
    \end{flalign*}
    (\url{https://www.youtube.com/watch?v=8RSTQl0bQuw})
  \item in the general case $\vec{y} = \mathbf{X}\vec{\beta}$, solving the
    Normal Equation (\S\ref{sec:normal_equation})
    $(\mathbf{X}^T\mathbf{X})\vec{\beta} = \mathbf{X}^T\vec{\beta}$:
    \[
      \hat{\vec{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\vec{y}
    \]
    note that solution using Cholesky Factorization
    (\S\ref{sec:cholesky_decomposition}) is \emph{Ill-conditioned}
  \item the standard method uses QR-factorization (\S\ref{sec:qr_factorization})
    $\mathbf{X} = QR$ ($Q$ is Square, Orthogonal) to avoid the Ill-conditioning
    in the Normal Equation:
    \[
      \hat{\vec{\beta}} = \hat{R}^{-1}\hat{Q}^T\vec{y}
    \]
  \item Gradient Descent (\S\ref{sec:gradient_descent}) ... TODO
\end{itemize}

\fist cf. Convex Optimization (\S\ref{sec:convex_optimization}) -- for Linear
Regression, a Mean-Square Error Loss Function is always \emph{Convex} (example
\url{https://towardsdatascience.com/introduction-to-machine-learning-algorithms-linear-regression-14c4e325882a}

\fist cf. Linear Programming (\S\ref{sec:linear_programming})
-- article: \emph{Linear Programming for Linear Regression};
\url{https://lazyprogrammer.me/linear-programming-for-linear-regression/}

\fist Hierarchical Linear Models (Multilevel Models
\S\ref{sec:multilevel_model})

(McCullagh02 \S 4): Categorical definition



\paragraph{Simple Linear Regression}\label{sec:simple_linear_regression}\hfill

single (One-dimensional) Regressor (Independent Variable)

Regression Coefficients

Error Term $\varepsilon$

$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$

for the $i$th Observation (\S\ref{sec:observation})

assuming that $Y$ can be Approximated by a Linear Function of $X$ and the IID
Distribution of the $\varepsilon_i$s is Normal with Mean Zero, the
\emph{Regression Model} (\S\ref{sec:statistical_model}) has three Parameters--
$\beta_0$, $\beta_1$, and the Variance $\sigma^2$ of $\varepsilon$:
\[
  \theta = (\beta_0, \beta_1, \sigma^2)
\]
and each possible value of $\theta$ determines a Distribution $P_\theta$ on the
Sample Space (\S\ref{sec:sample_space}) $S$ of all possible $(Y, X)$ pairs

\url{https://www.youtube.com/watch?v=FGesqq22TCM}: Equation for a Regression
Line passing through the Sample Mean $(\overline{X}\overline{Y})$ with Slope
$r(s_y/s_x)$ where $r$ is the Sample Correlation Coefficient, and $s_y$ and
$s_x$ are Sample Standard Deviations

\url{https://www.youtube.com/watch?v=8RSTQl0bQuw}:
\begin{flalign*}
  \hat{\beta_1} & = \frac{
    \overline{X} \overline{Y} - \overline{XY}
  }{
    (\overline{X})^2 - \overline{X^2}
  } \\
  \hat{\beta_0} & = \overline{Y} - \hat{\beta_1} \overline{X} \\
\end{flalign*}
or equivalently:
\begin{flalign*}
  \hat{\beta_1} & = \frac{Cov(X,Y)}{Var(X)} \\
  \hat{\beta_0} & = \overline{Y} - \frac{\overline{X} Cov(X, Y)}{Var(X)} \\
\end{flalign*}

\asterism

\url{https://www.youtube.com/watch?v=8w6EPyEqE9M} (Khan)

Standard Error of Estimated Parameters (Coefficients); Estimate of the Standard
Deviation of the Sampling Distribution of the Slope; Confidence Interval
(\S\ref{sec:confidence_interval})-- DoF for a Slope Coefficient in a Linear
Model is the number of Sample Points minus 2

$z$-statistic (\S\ref{sec:z_statistic}):
\[
  z = \frac{b - \beta_0}{\sigma_b}
\]

$t$-statistic (\S\ref{sec:t_statistic}):
\[
  t = \frac{b - \beta_0}{SE_b}
\]

\asterism

(Wasserman04 \S13.1)

Least Squares Estimates (\S\ref{sec:least_squares}): TODO



\paragraph{Multiple Linear Regression}
\label{sec:multiple_linear_regression}\hfill

Multiple Regression (\S\ref{sec:multiple_regression}) --
multiple Correlated \emph{Independent Variables}

cf. Multivariate (General Linear) Regression
(\S\ref{sec:multivariate_linear_regression}) -- multiple Correlated
\emph{Dependent Variables}

(wiki) $p$ Independent Variables:
\[
  y_i = \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} +
    \varepsilon_i
\]
where $x_{ij}$ is the $i$-th Observation (\S\ref{sec:observation}) of the $j$-th
Independent Variable



\paragraph{Multivariate Regression}
\label{sec:multivariate_regression}\hfill

\emph{Multivariate Regression Model} or \emph{General Linear Model}

multiple Correlated \emph{Dependent Variables}

cf. Multiple Linear Regression (\S\ref{sec:multiple_linear_regression})
-- multiple Correlated \emph{Independent Variables}

\fist not to be confused with Generalized Linear Models (GLMs \S\ref{sec:glm}):
here ``General'' just means a Multivariate Regressor as opposed to Univariate
Regressor; GLMs are a generalization of Linear Models (General or otherwise)
that allows the the Range of the Regressand to be Categorical (Discrete)--as
opposed to Continuous--and for the Variance of the Regressand to depend on the
Mean (Expected Value)

cf. Multivariate Statistics (\S\ref{sec:multivariate_statistics})

(wiki):

$\mathbf{Y} = \mathbf{XB} + \mathbf{U}$

$\mathbf{Y}$ -- Matrix of Multivariate Measurements: each column being a Set of
Measurements on one of the Dependent Variables

$\mathbf{X}$ -- Matrix of Observations of Independent Variables: each column
being a Set of Observations of one of the Independent Variables

$\mathbf{B}$ -- Matrix of Parameters to be Estimated

$\mathbf{U}$ -- Matrix of Errors

\begin{itemize}
  \item Variance Analysis (ANOVA \S\ref{sec:variance_analysis})
\end{itemize}

\fist Artificial Neural Networks (ANNs \S\ref{sec:ann}) generalize Regression
and Clustering (\S\ref{sec:cluster_analysis}) to Non-linear Multivariate Models

\asterism

\emph{Regression and Automated Differentiation} -
\url{https://idontgetoutmuch.wordpress.com/2013/04/26/regression-and-automated-differentiation-4/}
-- Automatic Differentiation (\S\ref{sec:automatic_differentiation})

Model:
\[
  y_i = \vec{\theta}^T \vec{x}_i + e_i
\]
where $i \in \{1, \ldots, n\}$ for $n$ Observations, and $\vec{\theta}$ and
$\vec{x}$ are both Column Vectors of length $m$ (FIXME: is this really
multivariate or should it be multiple regression instead ???)

Maximize the Likelihood (\S\ref{sec:likelihood}) with respect to $\vec{\theta}$:
\[
  \mathcal{L}(\vec{\theta}; \mathbf{X}, \vec{y}) =
    \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma}}
      e^\frac{-(y_i - \vec{\theta}^T \vec{x}_i)^2}{2\sigma^2}
\]
use Log-likelihood (\S\ref{sec:log_likelihood}) $\log \mathcal{L}(\vec{\theta})
= \lambda(\vec{\theta})$ instead since $\log$ is Monotonic; Maximizing the
Likelihood is the same a Minimizing the (Biased) Variance Estimate:
\[
  \frac{1}{n} \sum_{i=1}^n (y_i - \vec{\theta}^T\vec{x}_i)^2
\]
define a Cost Function (\S\ref{sec:objective_function}):
\[
  \mathcal{J}(\vec{\theta}) =
    \frac{1}{2n} \sum_{i=1}^n (y_i - \vec{\theta}^T \vec{x}_i)^2
\]
(FIXME: this is sum of squared deviations ???)
Minimize Cost Function using \emph{Gradient Descent}
(\S\ref{sec:gradient_descent}):
\[
  \vec{\theta}_{k+1} = \vec{\theta}_k - \gamma \nabla \mathcal{J}(\vec{\theta})
\]
where $\vec{\theta}_k$ is the $k$th Estimate of $\vec{\theta}$, and $\gamma$ is
a \emph{Learning Rate}

for large numbers of Observations, see Stochastic Gradient Descent (SGD
\S\ref{sec:sgd})



\paragraph{Orthogonal Regression}\label{sec:orthogonal_regression}\hfill

\subparagraph{Deming Regression}\label{sec:deming_regression}\hfill

accounts for Error in $X$ and $Y$ Observations (cf. Simple Linear Regression
which only accounts for Vertical Errors)



\subsubsection{Polynomial Regression}\label{sec:polynomial_regression}

Regression Analysis using Basis Functions (\S\ref{sec:basis_function})



\subsubsection{Segmented Regression}\label{sec:segmented_regression}

\subsubsection{Generalized Linear Model (GLM)}\label{sec:glm}

1983 - McCullagh, Nelder - \emph{Generalized Linear Models}

generalization of Simple and Multivariate Linear Regression to Models where:
\begin{enumerate}
  \item Regressands can be Categorical (Discrete) Variables
  \item the Variance of Regressands can depend on the Mean (Expected Value)
  \item Error Distributions other than the Normal Distribution
\end{enumerate}

not to be confused with ``General'' (Multivariate) Linear Models''
(\S\ref{sec:multivariate_regression}): special case of GLM where the
Distribution of Residuals follow a Conditionally Normal Distribution
(FIXME: and response variables are continuous, and variance is constant ???)

\fist Generalized Additive Model (GAM \S\ref{sec:gam}) -- GLM where the Linear
Predictor depends Linearly on unknown Smooth Functions of Predictor Variables

(wiki):

three components of a GLM:
\begin{enumerate}
  \item a Linear Predictor (\S\ref{sec:linear_predictor})
    $\eta = \mathbf{X\beta}$
  \item a \emph{Link Function} (\S\ref{sec:link_function}) $g$ such that:
    \[
      E(\mathbf{Y}|\mathbf{X}) = \mu = g^{-1}(\eta)
    \]
  \item Variance Function $V$ (usually ``follows from an Exponential Family of
    Distributions''):
    \[
      Var(Y) = V(\mu)
    \]
\end{enumerate}
(TODO: clarify variance function )

Natural Exponential Families (\S\ref{sec:natural_exponential_family})

Exponential Dispersion Model (\S\ref{sec:exponential_dispersion})

Least-squares Estimate (\S\ref{sec:least_squares}) may be used to fit a
Generalized Linear Model by iteratively applying the Local Quadratic
Approximation (FIXME: explain)

\begin{itemize}
  \item Binomial Regression (\S\ref{sec:binomial_regression})
  \item Log-linear (Poisson) Regression (\S\ref{sec:log_linear})
  \item Linear Regression (\S\ref{sec:linear_regression})
  \item ...
\end{itemize}



\paragraph{Link Function}\label{sec:link_function}\hfill

\paragraph{Binomial Regression}\label{sec:binomial_regression}\hfill

essentially the same as Binary Choice Models (\S\ref{sec:binary_choice})



\subparagraph{Binary Regression}\label{sec:binary_regression}

Models:
\begin{itemize}
  \item Logistic (Logit) Regression (\S\ref{sec:logistic_regression})
  \item Probit Regression (\S\ref{sec:probit_regression})
\end{itemize}



\paragraph{Logistic Regression}\label{sec:logistic_regression}\hfill

or \emph{Logit Regression}

\fist Logistic Distribution (\S\ref{sec:logistic_distribution})

Binary Regression (\S\ref{sec:binary_regression})

Non-linear Model

Non-Linear Least Squares (NLLS \S\ref{sec:nlls})

can be formulated as a special case of Generalized Linear Models
(\S\ref{sec:glm})

cf. Statistical Classification (\S\ref{sec:classification}) -- Logistic
Regression as a Discriminative (\S\ref{sec:discriminative_model}) method of
determining Parameters for a Linear Classifier (\S\ref{sec:linear_classifier})

\fist Linear Discriminant Analysis (LDA \S\ref{sec:lda}) -- in LDA, the Joint
Distribution $f(x,y = f(x|y)f(y)$ is Estimated by maximizing the Likelihood; in
Logistic Regression, only $f(y|x)$ is Estimated and the Conditional Likelihood
is maximized, neglecting the Marginal Distribution $f(x)$

\emph{Logistic Model}: uses a Logistic Function (\S\ref{sec:logistic_function})
to Model a \emph{Binary Dependent Variable} $Y_i \in \{ 0, 1 \}$

Logistic Function $e^x / (1 + e^x)$

for a $k$-dimensional Covariate $X$:
\[
  p_i \equiv P(Y_i = 1 | X = x) = \frac{
    e^{\sum_{j=1}^k \beta_j x_{ij}}
  }{
    1 + e^{\sum_{j=1}^k \beta_j x_{ij}}
  }
\]

\[
  logit(p_i) = \sum_{j=1}^k \beta_j x_{ij}
\]
where:
\[
  logit(p) = log\Big(\frac{p}{1-p}\Big)
\]
(FIXME: explain)

\[
  Y_i | X_i = x_i \sim Bernoulli(p_i)
\]

Conditional Likelihood:
\[
  \mathcal{L}(\beta) = \prod_{i=1}^n p_i(\beta)^{Y_i} (1 - p_i(\beta))^{1-Y_i}
\]

the Maximum Likelihood Estimate (MLE \S\ref{sec:mle}) can be obtained by
maximizing $\mathcal{L}(\beta)$ numerically using Iteratively Re-weighted Least
Squares (\S\ref{sec:irls}):

choose starting $\hat{\beta}^0 = (\hat{\beta}_1^0, \ldots, \hat{\beta}_k^0)$
and compute $p_i^0$ for $i = 1, \ldots, n$, and iterate from $s = 0$:
\begin{enumerate}
  \item set
    \[
      Z_i = logit(p_i^s) + \frac{Y_i - p_i^s}{p_i^s(1 - p_i^s)}
    \]
  \item let $W$ be a Diagonal Matrix with $(i,i)$ equal to $p_i^s(1 - p_i^s)$
  \item set
    \[
      \hat{\beta}^s = (X^T W X)^{-1} X^T W Z
    \]
  corresponding to doing a Weighted Linear Regression of $Z$ on $X$
\end{enumerate}

(wiki): Logistic Regression Predicts the \emph{Probability} of particular
Outcomes rather than the Outcomes themselves

Logistic Regression Models violate the Assumptions in Linear Regression Models
in that the Residuals cannot be Normally Distributed; in a Logistic Model, the
Conditional Distribution $y | x$ is a Bernoulli Distribution
(\S\ref{sec:bernoulli_distribution}), whereas in Linear Regression the
Conditional Distribution is Normally Distributed

\emph{Binary Logistic Regression} -- Models \emph{Probability} of output in
terms of input, and does \emph{not} perform Statistical Classification, although
it can be \emph{used} to make a Binary Classifier by choosing a ``cutoff'' value
and Classifying inputs with Probability greater than the cutoff as one class and
below as the other class

the Model ``Coefficients'' (FIXME: clarify) are generally not Estimated by a
Closed-form Expression (unlike Linear Least Squares in Linear Regression),
instead they are Estimated using \emph{Maximum Likelihood Estimation} (MLE
\S\ref{sec:mle}) by an \emph{Iterative Process} (\S\ref{sec:iterative_method})

see also:
\begin{itemize}
  \item Multinomial Logistic Regression (\S\ref{sec:multinomial_regression})
  \item Ordered Logistic Regression (Ordered Logit \S\ref{sec:ordered_logit})
\end{itemize}

\asterism

\url{https://www.youtube.com/watch?v=ckkiG-SDuV8}:

in Logistic Regression, the Odds Ratio (\S\ref{sec:odds_ratio}) for an
Independent Variable represents how the Odds change with a 1 unit increase in
the Independent Variable, holding all other variables constant

\url{https://www.youtube.com/watch?v=NmjT1_nClzg}:

the Dependent Variable in Logistic Regression follows a \emph{Bernoulli
  Distribution} (\S\ref{sec:bernoulli_distribution}):
\[
  Y | X = x \sim Bernoulli(p)
\]
in Logistic Regression, the unknown Parameter $p$ is Estimated for a given
Linear Combination of Independent Variables

the \emph{Logit} (Inverse Logistic Function \S\ref{sec:logit}) or \emph{Log
  Odds}--the Natural Log of the Odds (\S\ref{sec:odds})--links the Linear
Combination of Independent Variables, with Domain $(-\infty, \infty)$, to the
Bernoulli Parameter $p$, with Domain $[0, 1]$:
\[
  logit(p) = \ln odds = \ln \Big(\frac{p}{1 - p}\Big) = \ln p - \ln (1 - p)
\]

the Standard Logistic Function (\S\ref{sec:logistic_function}), $\sigma(t)$,
that is the Inverse Logit, or \emph{Mean Function}:
\[
  \mu_{y | x} = p(x) = \sigma(t) = logit^{-1}(t) = \frac{1}{1 + e^{-t}}
\]
gives the \emph{Probability} of the Dependent (Bernoulli) Random Variable being
$1$ \emph{given} some Linear Combination $t = \beta_0 + \beta_1 x$ of
Independent Variable $x$

now the Logit of $p(x)$ is expressible as a Linear Function of the Dependent
Variable $x$:
\[
  logit(p(x)) = \ln \Big(\frac{p(x)}{1 - p(x)}\Big) = \beta_0 + \beta_1 x
\]

note that Response Variables $Y_i$ are \emph{not Identically Distributed} as
$P(Y_i = 1 | X)$ differs for each $X_i$, although they \emph{are Independent}
for a given Design Matrix $\mathbf{X}$ and shared Parameters $\vec{\beta}$
(wiki)

this is derived by expressing the Log Odds as a Linear Function of the
Independent Variables and solving for $\hat{p}$:
\begin{flalign*}
  \ln \Big(\frac{\hat{p}}{1 - \hat{p}}\Big) & = \beta_0 + \beta_1 x \\
  \frac{\hat{p}}{1 - \hat{p}}               & = e^{\beta_0 + \beta_1 x} \\
  \hat{p} & = \frac{e^{\beta_0 + \beta_1 x}}{1 + e^{\beta_0 + \beta_1 x}} \\
          & = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x)}} \\
\end{flalign*}

Regression Coefficients for Logistic Regression are calculated using Maximum
Likelihood Estimation (MLE \S\ref{sec:mle})

Iteratively Re-weighted Least Squares (IRLS \S\ref{sec:irls})

Parameters $\vec{\beta}^T = [\beta_0, \beta_1, \ldots]$

Independent Variables $\vec{x}_i^T = [1, x_{i1}, x_{i2}, \ldots]$

Expected Value of the Bernoulli Distribution
$\mu_{y_i | \vec{x}_i} = 1 / (1 + e^{-\vec{\beta}^T \vec{x_i}})$

Iteratively solving for the $(k+1)$th Estimate given the $k$th Estimate of
$\vec{\beta}$:
\[
  \vec{\beta}_{k+1} = (\mathbf{X}^T \mathbf{S}_k \mathbf{X})^{-1} \mathbf{X}^T
    (\mathbf{S}_k \mathbf{X} \vec{\beta}_k + \vec{y} - \vec{\mu}_k)
\]
where:
\begin{itemize}
  \item $\mathbf{S} = diag(\mu_i - \mu_i^2)$ is a
    \emph{Diagonal Weighted Matrix}
  \item $\vec{\mu} = [\mu_1, \ldots, \mu_n]$ is the Vector of Expected Values
  \item $\mathbf{X} = [\vec{1}, \vec{x}_1, \vec{x}_2, \ldots]$ is the Regressor
    (Design) Matrix
  \item $\vec{y}_i^T = [y_1, y_2, \ldots]$ is the Vector of Response Variables
\end{itemize}

Goodness-of-fit (\S\ref{sec:model_fit}) measured using Coefficient of
Determination $R^2$ (\S\ref{sec:determination_coefficient})

Deviance Table, $\chi$-square (cf. ANOVA Table, $f$-test in Linear Regression)

\url{https://www.youtube.com/watch?v=hWLdFMccpTY}:

Gradient of Negative Log-likelihood (\S\ref{sec:log_likelihood}):
$\nabla_{\vec{\beta}} -\ell = \mathbf{X}^T (\vec{\mu} - \vec{y})$

Hessian:
$\nabla_{\vec{\beta}}^2 -\ell = \mathbf{X}^T \mathbf{S} \mathbf{X}$

since the above Hessian is Positive Semi-definite, $-\ell$ is Convex

IRLS: update equation for Newton's Method takes the form of a solution for a WLS
(\S\ref{sec:wls}) problem

\asterism

2019 - Khan - PUCIT CS667 - Advanced Machine Learning --
Newton-Raphson (Newton's Method \S\ref{sec:newtons_method}) update for
minimizing a Function $f(\vec{w})$:
\[
  \vec{w}^{k+1} = \vec{w}^k - \mathsf{H}^{-1}\nabla_{\vec{w}} f(\vec{w})
\]
where $\mathsf{H}$ is the Hessian Matrix of Second Derivatives:
\[
  \frac{\partial^2 f}{\partial{w_i} \partial{w_j}}
\]

Cost Function (TODO)

\emph{Logistic Loss}: Negative Log-likelihood Function, Cross-entropy Error
Function (TODO)

Iteratively Re-weighted Least Squares (IRLS \S\ref{sec:irls})

\asterism

with the Logistic (Sigmoid) Activation Function
(\S\ref{sec:activation_function}), a Single-layer Neural Network
(\S\ref{sec:ffnn}) is identical to a Logistic Regression Model

\emph{Neural Networks} (\S\ref{sec:ann}) can be viewed as a generalization of
Logistic Regression
(\url{https://idontgetoutmuch.wordpress.com/2013/05/31/neural-networks-and-automated-differentiation-3/})

\emph{Logistic Regression and Automated Differentiation} -
\url{https://idontgetoutmuch.wordpress.com/2013/04/30/logistic-regression-and-automated-differentiation-3/}
-- Automatic Differentiation (\S\ref{sec:automatic_differentiation})

\begin{flalign*}
  P(y = 1 | \vec{x}; \vec{\theta}) & = h_{\vec{\theta}}(\vec{x}) \\
  P(y = 0 | \vec{x}; \vec{\theta}) & = 1 - h_{\vec{\theta}}(\vec{x}) \\
\end{flalign*}
where $\vec{x}$ and $\vec{\theta}$ are Vectors of length $m$, and:
\[
  h_{\vec{\theta}}(\vec{x}) = g(\vec{\theta}^T \vec{x})
\]
where $g$ is a Function such as the Logistic Function
(\S\ref{sec:logistic_function}) $g(x) = 1/(1 + e^{-x})$ or Hyperbolic Tangent
(\S\ref{sec:hyperbolic_function}) $g(x) = tanh x$

rewriting as a Conditional Distribution:
\[
  p(y | \vec{x}; \vec{\theta}) =
    (h_{\vec{\theta}}(\vec{x}))^y (1 - h_{\vec{\theta}}(\vec{x}))^{1-y}
\]

in order to find the value of $\vec{\theta}$ that ``gives the maximum
Probability'' to the Observations, Maximize the Likelihood
(\S\ref{sec:likelihood}):
\begin{flalign*}
  \mathcal{L}(\vec{\theta})
    & = \prod_{i=1}^n p(y_i | \vec{x}_i; \vec{\theta}) \\
    & = \prod_{i=1}^n (h_{\vec{\theta}}\vec{x}_i)^{y_i}
          (1 - h_{\vec{\theta}}\vec{x}_i)^{1-y_i} \\
\end{flalign*}
assuming $n$ Observations

Maximize the Log-likelihood (\S\ref{sec:log_likelihood}) since $\log$ is
Monotonic:
\begin{flalign*}
  \lambda (\vec{\theta})
    & = \log \mathcal{L}(\vec{\theta}) \\
    & = \sum_{i=1}^n y_i \log h_{\vec{\theta}} \vec{x}_i +
          (1-y_i) \log (1 - h_{\vec{\theta}} \vec{x}_i) \\
\end{flalign*}
using Gradient Descent (\S\ref{sec:gradient_descent}):
\[
  \vec{\theta}_{k+1} = \vec{\theta}_k - \gamma \nabla \mathcal{J} (\vec{\theta})
\]
where $\theta_k$ is the $k$th Estimate of the Parameters $\theta$ and $\gamma$
is a \emph{Learning Rate}

when number of Observations is high, cheaper alternative is Stochastic Gradient
Descent (SGD \S\ref{sec:sgd})

when the Observations/Training Data (Dataset) are Linearly Separable, then the
magnitude of the Parameters can grow without bound as the Parameterized Logistic
Function tends to the Unit Step Function (\S\ref{sec:unit_step_function}), and
there may be more than one separating Hyperplane-- to avoid this, instead
Maximize a \emph{Penalized Log-likelihood Function}:
\[
  \lambda (\vec{\theta}) = \sum_{i=1}^n
    y_i \log h_{\vec{\theta}} \vec{x}_i
    + (1-y_i) \log (1 - h_{\vec{\theta}} \vec{x}_i)
    - \frac{\delta}{2} \|\vec{\theta}\|^2
\]
(TODO: explain)



\subparagraph{Multinomial Logistic Regression}
\label{sec:multinomial_regression}\hfill



\paragraph{Probit Regression}\label{sec:probit_regression}

Binary Regression (\S\ref{sec:binary_regression})

Linear Classifier (\S\ref{sec:linear_classifier})

Non-linear Model

Non-Linear Least Squares (NLLS \S\ref{sec:nlls})



\paragraph{Ordinal Regression}\label{sec:ordinal_regression}\hfill

\emph{Ranking Learning}



\subparagraph{Ordered Logit}\label{sec:ordered_logit}\hfill

\emph{Ordered Logistic Regression} or \emph{Proportional Odds Model}



\paragraph{Log-linear Model}\label{sec:log_linear}\hfill

or \emph{Poisson Regression}

count data

\emph{Contingency Tables} (\S\ref{sec:contingency_table})

Natural Language Processing

(Wasserman04, Ch.19)

Multivariate Discrete Data --
fitting Discrete Data to a Graphical Model (\S\ref{sec:graphical_model})

Undirected Graphs \fist Pairwise Markov Graph (\S\ref{sec:pairwise_markov})

Dicrete Random Vector $X = (X_1, \ldots, X_m)$ where each
$X_j \in \{ 1, 2, \ldots, r_j \}$ for some $r_j$

Probability Mass Function $f(x) = P(X = x) = P(X_1 = x_1, \ldots, X_m = x_m)$

a Sample of $n$ Vectors is a Sample from a Multinomial Distribution
(\S\ref{sec:multinomial_distribution}) with $N = r_1 r_2 \cdots r_m$ Categories
where Data can be represented as ``counts'' in a
$r_1 \times r_2 \times \cdots \times r_m$ table (FIXME: clarify)

$p = (p_1, \ldots, p_N)$ -- Multinomial Parameter

given a Vector $x = (x_1, \ldots, x_n)$ and Subset
$A \subset \{ 1, \ldots, m \}$, let $x_A = (x_j : j \in A)$

\textbf{Thm.} \emph{
  The Joint Probability Function $f(x)$ of a Random Vector
  $X = (X_1, \ldots, X_n)$ can be written as the \textbf{Log-linear Expansion}
  of $f$:
  \[
    \log f(x) = \sum_A \psi_A(x)
  \]
  over all $A \in 2^{\{ 1, \ldots, m\}}$ where $\psi$ satisfies:
  \begin{enumerate}
    \item $\psi_{\varnothing}(x)$ is Constant
    \item $\psi_A(x)$ is only a Function of $x_A$ and not any other $x_j$
    \item if $i \in A$ and $x_i = 0$ then $\psi_A(x) = 0$
  \end{enumerate}
}

Parameter Spaces (TODO)

\textbf{Graphical Log-linear Model}

if ``missing terms'' correspond only to Conditional Independence Constraints,
not any other kinds of ``Constraints''
(FIXME: explain)

\textbf{Hierarchical Log-linear Model}

\emph{Hierarchical} if $\psi_A = 0$ and $A \subset B$ implies $\psi_B = 0$

Superset of Graphical Models

Hierarchical Models can be written using \emph{Generators}

\emph{Saturated Model}

Submodel \emph{Deviance}

\textbf{Negative Binomial Regression}



\subsubsection{Multiple Regression}\label{sec:multiple_regression}

Definite Quadratic Forms (\S\ref{sec:definite_quadratic})

Multiple Linear Regression (\S\ref{sec:multiple_linear_regression})

note that adding more Covariates, the Bias of the Predictions descreases and the
Variance increases

\emph{Underfitting} -- too few Covariates, high Bias

\emph{Overfitting} -- too many Covariates, high Variance

(wiki): uses Additive Logic (FIXME: xref ???); cf. Necessary Condition Analysis
(NCA \S\ref{sec:nca}) -- uses Necessary Logic (\S\ref{sec:alethic_logic})



\paragraph{Multi-collinearity}\label{sec:multicollinearity}\hfill

Ridge Regression (\S\ref{sec:ridge_regression})



\subsubsection{Tikhonov Regularization}\label{sec:tikhonov_regularization}\hfill

Regularization (\S\ref{sec:regularization})



\paragraph{Ridge Regression}\label{sec:ridge_regression}\hfill

or \emph{Weight Decay}

particular type of Tikhonov Regularization useful to mitigate Multicollinearity
(\S\ref{sec:multicollinearity})



\subsubsection{Gaussian Process Regression}
\label{sec:gaussian_process_regression}

\emph{Kriging} or \emph{Wiener-Komogorov Prediction}

under ``suitable assumptions'' on the Priors, Kriging gives the \emph{Best
  Linear Unbiased Prediction} (BLUP \S\ref{sec:blup}) of the intermediate values

\fist Spatial Analysis (\S\ref{sec:spatial_analysis})



\subsubsection{Nonlinear Regression}\label{sec:nonlinear_regression}

Observational Data Modeled by a by a Non-linear Function of Model Parameters and
one or more Independent Variables

$Y = f(\vec{X}, \vec{b})$

Non-Linear Least Squares (NLLS \S\ref{sec:nlls})



\subsubsection{Necessary Condition Analysis (NCA)}\label{sec:nca}

(wiki): uses Necessity Logic (\S\ref{sec:alethic_logic});
cf. Multiple Regression (\S\ref{sec:multiple_regression}) -- uses Additive Logic
(FIXME: xref ???)



% ------------------------------------------------------------------------------
\subsection{Cluster Analysis}\label{sec:cluster_analysis}
% ------------------------------------------------------------------------------

\emph{Unsupervised Learning}

cf. Classification (Supervised Learning \S\ref{sec:classification})

see also Density Estimation (\S\ref{sec:density_estimation})

example of Pattern Recognition (assignment of some Output Value to a given Input
Value), other examples are Statistical Classification and Regression Analysis
(\S\ref{sec:regression_analysis})

Artificial Neural Networks (ANNs \S\ref{sec:ann}) generalize Regression
(\S\ref{sec:regression_analysis}) and Clustering to Non-linear Multivariate
Models



\subsubsection{Hierarchical Clustering}\label{sec:hierarchical_clustering}

\subsubsection{Competitive Learning}\label{sec:competitive_learning}

\emph{Hebbian Learning}, \emph{Errorless Learning}

Self-Organizing Feature Maps (\S\ref{sec:sofm})



\subsubsection{Dimensionality Reduction}\label{sec:dimensionality_reduction}

Feature Selection

Feature Extraction

Principal Component Analysis (PCA \S\ref{sec:pca})



\paragraph{Dynamic Mode Decomposition (DMD)}\label{sec:dmd}\hfill

Composition Operator (Koopman Operator \S\ref{sec:composition_operator})

cf. PCA (\S\ref{sec:pca})

\fist Reservoir Computing (\S\ref{sec:reservoir_computing})



\paragraph{Self-Organizing Feature Map (SOFM)}\label{sec:sofm}\hfill

ANNs (\S\ref{sec:ann}) using \emph{Competitive Learning}
(\S\ref{sec:competitive_learning}) instead of Error-correction Learning
(Backpropagation)



\subsubsection{Autoencoder}\label{sec:autoencoder}

\emph{Feature Learning}

(wiki): a type of ANN (\S\ref{sec:ann}) used to learn efficient Encoding
(\S\ref{sec:encoding}) in an Unsupervised manner

2018 - Le -
\emph{A Purely Functional Typed Approach to Trainable Models (Part 3)} -
\url{https://blog.jle.im/entry/purely-functional-typed-models-3.html}
--
an Autoencoder is a type of Model that Composes a Function that ``compresses''
information with a Function that ``decompresses'' it, where \emph{Training} an
Autoencoder involves Training the \emph{Composition} of the two Functions to
produce the \emph{Identity Function}



\paragraph{Regularized Autoencoder}\label{sec:regularized_autoencoder}\hfill

\fist Regularization (\S\ref{sec:regularization})



\subparagraph{Sparse Autoencoder}\label{sec:sparse_autoencoder}\hfill

\subparagraph{Denoising Autoencoder}\label{sec:denoising_autoencoder}\hfill

\subparagraph{Contractive Autoencoder}\label{sec:contractive_autoencoder}\hfill



\paragraph{Variational AutoEncoder (VAE)}\label{sec:vae}\hfill

(wiki): VAEs are Directed Probabilistic Graphical Models (DPGM
\S\ref{sec:graphical_model}) with Posterior Distribution Approximated by a
Neural Network, forming an ``Autoencoder-like'' architecture

VAEs make strong assumptions about the Distribution of Latent Variables, using a
Variational Bayesian (\S\ref{sec:variational_bayesian}) approach for Latent
Representation Learning; uses a Stochastic Gradient Variational Bayes (SGVB)
Estimator for the training algorithm

assumes Data is Generated by a Graphical Model $p_\theta(\vec{x} | \vec{h})$ and
Encoder is learning an Approximation $q_\phi(\vec{h} | \vec{x})$ to the
Posterior Distribution $p_\theta(\vec{h} | \vec{x})$, where $\phi$ are the
Parameters of the Encoder (Discriminative Model) and $\theta$ are the Parameters
of the Decoder (Generative Model)

2017 - Pascual - \emph{PixelCNN, WaveNet \& Variational Autoencoders} -
\url{https://www.youtube.com/watch?v=FeJT8ejgsL0}

allows Autoencoder to be used in Generative Models (\S\ref{sec:generative_model}



% ------------------------------------------------------------------------------
\subsection{Artificial Neural Network (ANN)}\label{sec:ann}
% ------------------------------------------------------------------------------

%FIXME: move section ?

or \emph{Connectionist System}

extends Regression (\S\ref{sec:regression_analysis}) and Clustering
(\S\ref{sec:cluster_analysis}) to Non-linear Multivariate Models

(Wasserman04, \S22.11) --
simplest Neural Network Regression Model:
\[
  Y = \beta_0 + \sum_{j=1}^p \beta_j \sigma (\alpha_0 + \alpha^T X)
\]
where $\sigma$ is a Smooth Function, often:
\[
  \sigma(v) = \frac{1}{1 + e^{-v}}
\]

Stochastic Gradient Descent (SGD \S\ref{sec:sgd}) -- \emph{de facto} standard
Algorithm for training ANNs

\fist cf. Self-Organizing Feature Maps (\S\ref{sec:sofm}) -- ANNs trained using
(Unsupervised) Competitive Learning (\S\ref{sec:competitive_learning})

(Jacot, Gabriel, Hongler 2018): at initialization, ANNs (\S\ref{sec:ann}) are
equivalent to Gaussian Processes (\S\ref{sec:gaussian_process}) in the
``Infinite-width'' limit, connecting them to \emph{Kernel Methods}
(\S\ref{sec:kernel_method}), and the \emph{evolution} of an ANN during Training
can also be described by a Kernel

(wiki) applications:
\begin{itemize}
  \item Function Approximation, Regression Analysis
  \item Classification, Pattern Recognition
  \item Cluster Analysis, Filtering, Compression
  \item Non-linear System (\S\ref{sec:nonlinear_equation_system})
    Identification and Control
\end{itemize}

\url{https://statmodeling.stat.columbia.edu/2019/05/21/neural-nets-vs-statistical-models/}
-- some comments on Hierarchical Models as related to Neural Networks:
\begin{quote}
  Neural nets are a special case of Statistical Models, typically Bayesian
  Hierarchical Logistic Regression with latent Parameters. But Neural Nets are
  typically Estimated in a different way: the resulting Posterior Distributions
  will generally be Multimodal, so rather than try the hopeless task of
  traversing the whole Posterior Distribution, we’ll use various approximate
  methods, which then are evaluated using predictive accuracy.
\end{quote}

\emph{Neural Networks and Automated Differentiation} -
\url{https://idontgetoutmuch.wordpress.com/2013/05/31/neural-networks-and-automated-differentiation-3/}

Neural Networks can be viewed as a generalization of Logistic Regression
(\S\ref{sec:logistic_regression})

2018 - Penkovsky - \emph{10 Days of Grad: Deep Learning From First Principals} -
\url{https://penkovsky.com/neural-networks/}

\asterism

\url{http://www.cs.stir.ac.uk/courses/ITNP4B/lectures/} -- slides

ANNs can be represented as \emph{Weighted Directed Graphs}
(\emph{Directed Networks} \S\ref{sec:directed_network})

\asterism

2019 - Gavranovi\'c - \emph{Learning Functors using Gradient Descent} -
\url{https://www.youtube.com/watch?v=PRt7Fu_-xr0}:

Unsupervised Learning

CycleGAN

a ``\emph{Schema}'' is a Quotient Category $\cat{Free}(G)/\sim$

Neural Networks as \emph{Parameterized Morphisms}, i.e. Morphisms in the
Category $\cat{Para}(\cat{Euc})$ where $\cat{Euc}$ is the Category of Euclidean
Spaces
\[
  \cat{Para} : (\mathcal{V}, I, \otimes)
    \to (\cat{Para}(\mathcal{V}), I, \otimes)
\]
mapping between Small Symmetric Monoidal Categories

$(\cat{Euc}, 1, \times)$

(TODO: xref parameterized category)

a \emph{Neural Network Architecture} is a Functor
$Arch : \cat{Free}(G) \to \cat{Para}(\cat{Euc})$

a \emph{Model} is a Functor $Model : \cat{Free}(G) \to \cat{Euc}$

given an Architecture $Arch$ and a Parameter $p \in \mathcal{P}(Arch)$, a Model
$Model_p : \cat{Free}(G) \to \cat{Euc}$ \emph{generalizes} the notion of
a Model in Machine Learning, allowing it to be used for inference and evaluated

Adversarial Loss, Path-equivalence Loss

a \emph{Task} is a Schema + a Dataset

\asterism

2020 - Mordvintsev, Randazzo, Niklasson, Levin - \emph{Growing Neural Cellular
  Automata}

Cellular Automata (\S\ref{sec:cellular_automaton}) with Differentiable update
rules

\emph{Decentralized Learning Modelling}



\subsubsection{Artificial Neuron}\label{sec:artificial_neuron}

the \emph{Nodes} of an ANN

receives one or more \emph{Inputs} (cf. Synapse), individually \emph{Weights}
each Input, and passes the \emph{Sum} of Weighted Inputs through a (usually
Non-linear) \emph{Activation Function} (\S\ref{sec:activation_function}) to
produce an \emph{Output} (cf. Axon)

\begin{itemize}
  \item $\{ x_0, x_1, \ldots, x_n \}$ -- Inputs
  \item $\{ w_0, w_1, \ldots, w_n \}$ -- Weights
\end{itemize}

usually Input $x_0$ is assigned the value $1$, so that $w_0 = b$ is a
\emph{Bias}

the \emph{Output}, $y$:
\[
  y = \varphi \Big( \sum_{i=0}^n w_i x_i \Big)
\]
where $\varphi$ is the \emph{Activation Function}
(\S\ref{sec:activation_function})

the Output may either be propagated to the Input of the next Layer, or exit the
Network as part of an Output Vector

a Neuron has no ``learning process'' (FIXME: clarify)

\begin{itemize}
  \item Threshold Logic Unit (TLU \S\ref{sec:tlu})
  \item Perceptron (\S\ref{sec:perceptron}) or ``\emph{Linear Threshold Unit}''
    -- Neuron using the Unit Step Function (\S\ref{sec:unit_step_function}) as
    the Activation Function
  \item ...
\end{itemize}



\paragraph{Activation Function}\label{sec:activation_function}\hfill

sometimes ``Transfer Function'', not to be confused with the Transfer Function
(\S\ref{sec:transfer_function}) of a Control System (\S\ref{sec:control_system})
or the Transfer Function (Evolution Function \S\ref{sec:evolution_function}) of
a Dynamical System

defines the \emph{Output} of a Node for a given Input or Set of Inputs

the Activation Function is applied to the Dot Product (Weighted Sum)
$\vec{w}^T \vec{x}$, called the \emph{Activation}

(wiki):

Training by Backpropagation (\S\ref{sec:backpropagation}) requires Derivatives
of Activation Functions, which can be computed using Automatic Differentiation
(\S\ref{sec:automatic_differentiation})

any Multi-Layer Peceptron (MLP \S\ref{sec:mlp}) Network using a Linear
Activation Function has an equivalent \emph{Single-layer} Network; i.e. to gain
advantages from multiple Layers requires a \emph{Non-linear} Activation Function

\emph{Universal Approximation Theorem} (\S\ref{sec:universal_approximation}):
when the Activation Function is Non-linear, a Two-layer Neural Network can be
proven to be a Universal Function Approximator

\begin{itemize}
  \item Identity
  \item Binary Step
  \item Logistic (Sigmoid)
  \item Tanh
  \item Arctan
  \item Arsinh
  \item Softsign (ElliotSig)
  \item Inverse Square Root Unit (ISRU)
  \item SQuare Non-Linearity (SQNL)
  \item Rectified Linear Unit (ReLU) -- most common in DNNs (\S\ref{sec:dnn})
  \item Exponential Linear Unit (ELU)
  \item Adaptive Piecewise Linear (APL)
  \item SoftPlus
  \item Bent Identity
  \item Sigmoid Linear (SiL)
  \item SoftExponential
  \item Soft Clipping
  \item Sinusoid
  \item Sinc
\end{itemize}

with the Logistic (Sigmoid) Activation Function, a Single-layer Neural Network
is identical to a Logistic Regression Model (\S\ref{sec:logistic_regression})



\paragraph{Threshold Logic Unit (TLU)}\label{sec:tlu}\hfill

McCulloch-Pitts Neuron

cf. Perceptron (\S\ref{sec:perceptron})

Nuerons in Hopfield Networks (\S\ref{sec:hopfield_network})



\subsubsection{Layer}\label{sec:ann_layer}

a \emph{Layer} is a Set of Nodes that have the same distance from ``the Inputs''
(FIXME: clarify)

\emph{Input Layer} or \emph{Visible Layer} -- Input Variables: by convention
this ``Layer'' is \emph{not counted}, or referred to as ``Layer $0$'', e.g. a
Single-layer Perceptron has Input Variables and an Output Layer only, an MLP
with a single Hidden Layer is a 2-layer MLP

\emph{Output Layer} -- Layer of Nodes (Neurons) that produce Output Variables

\emph{Hidden Layer}

\begin{itemize}
  \item Single-layer Perceptron (\S\ref{sec:single_layer_perceptron})
  \item Multi-Layer Perceptron (MLP \S\ref{sec:mlp})
\end{itemize}

notation for the number of Layers (from Input to Output): 2/8/1 --
(\url{https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/})

\emph{Fully-connected Layer} -- every Node in one Layer is connected to every
Node in the next layer; cf. Multi-layer Perceptron (\S\ref{sec:mlp}), Restricted
Boltzmann Machine (\S\ref{sec:rbm})



\subsubsection{Learning Process}\label{sec:learning_process}

\emph{Learning Rule} or \emph{Learning Process} -- Algorithm by which the Weight
and Bias levels of a Network are repeatedly updated to improve the Network's
``performance''

\begin{itemize}
  \item Unsupervised Learning -- Dentity Estimation
    (\S\ref{sec:density_estimation}), Cluster Analysis
    (\S\ref{sec:cluster_analysis})
  \item Supervised Learning -- Classification (\S\ref{sec:classification}),
    Regression Analysis (\S\ref{sec:regression_analysis})
  \item Reinforcement Learning (\S\ref{sec:reinforcement_learning})
\end{itemize}

\fist cf. Learning Algorithm (\S\ref{sec:learning_algorithm}),
Training Set (\S\ref{sec:training_dataset})

Online methods:
\begin{itemize}
  \item Stochastic Gradient Descent (\S\ref{sec:sgd})
\end{itemize}

Batch methods:
\begin{itemize}
  \item Conjugate Gradient Descent (\S\ref{sec:conjugate_gradient_method})
\end{itemize}



\paragraph{Backpropagation}\label{sec:backpropagation}\hfill

\emph{Error-correction Learning} -- cf. Competitive Learning
(\S\ref{sec:competitive_learning})

1982 - Werbos -
\emph{Applications of Advances in Nonlinear Sensitivity Analysis}

2017 - Fong, Spivak, Tuy\'eras - \emph{Backprop as Functor: A compositional
  perspective on supervised learning}

Haskell -- $\mathtt{Numeric.Backprop}$ ($\mathtt{backprop}$ library)

2018 - Le - \emph{A Purely Functional Typed Approach to Trainable Models} -
\url{https://blog.jle.im/entry/purely-functional-typed-models-1.html}

process of ``Training'' a Regression Model (\S\ref{sec:regression_analysis});
cf. Maximum Likelihood Estimation (MLE \S\ref{sec:mle})

cf. Gauss-Newton Algorithm (Non-linear Least Squares \S\ref{sec:gauss_newton})

cf. \emph{Least Mean Squares} (LMS \S\ref{sec:lms})

\emph{Neural Networks and Automated Differentiation} -
\url{https://idontgetoutmuch.wordpress.com/2013/05/31/neural-networks-and-automated-differentiation-3/}

\emph{Backpropagation} -- Gradient Descent (\S\ref{sec:gradient_descent}) with
Reverse-mode Automatic Differentiation (\S\ref{sec:automatic_differentiation})

\emph{Delta Rule} -- special case of Backpropagation for updating the Weights of
Input to Neurons in a Single-layer Neural Network

(wiki): requires Derivatives of Activation Functions, which can be computed
using Automatic Differentiation

Backpropagation computes the Gradients, while Stochastic Gradient Descent
(\S\ref{sec:sgd}) \emph{uses} the Gradients for ``Training'' the Model via
Optimization

Loss Functions -- Squared Error (Regression), Cross-entropy (Classification)

Gradient Descent requires computing the Derivative for the \emph{Loss Function}
with respect to the Weights in the Network

Assumptions on the Loss Function, $L$, for use in Backpropagation:
\begin{enumerate}
  \item can be written as an Average $L = \frac{1}{n} \sum_x L_x$ over Loss
    Functions $F_x$ for $n$ individual Training examples, $x$-- this is required
    because Backpropagation calculates the Gradient of the Loss Function for a
    \emph{single} Training example, which needs to be generalized to the
    \emph{overall} Loss Function
  \item can be written as a Function of the \emph{Outputs} from the Neural
    Network
\end{enumerate}

Backpropagation is not guaranteed to find the Global Minimum of the Loss
Function, only a Local Minimum

does not require Normalization of Input Vectors, although Normalization could
improve performance

2013 - Buitl\'eir, Russell, Daly -
\emph{A Functional Approach to Neural Networks}

2019 - Kahn - PUCIT CS667:

application of the Multivariate Chain Rule (\S\ref{sec:chain_rule})

Backpropagation algorithm:
\begin{enumerate}
  \item Forward propagate input to compute Activations and Outputs for every
    Layer
  \item Evaluate the Error for every Neuron in the Output Layer
  \item Evaluate the Error for every Neuron in every Hidden Layer via
    \emph{Backpropagation}
  \item Compute Derivative of each Weight $\partial f / \partial w$ via the
    Error and the Input
  \item Update each Weight via \emph{Gradient Descent}
\end{enumerate}

\asterism

2019 - Fong, Johnson - \emph{Functorial Backpropagation and Symmetric Lenses} -
\url{https://www.youtube.com/watch?v=s0WTRHe-4ZI}

\fist Lenses (\S\ref{sec:lens})

$A$ -- Input

$B$ -- Output

$P$ -- Parameters

``\emph{Learners}'':

$I : A \times P \to B$ -- \emph{Implement}

$U : A \times P \times B \to P$ -- \emph{Update}

$r : A \times P \times B \to A$ -- \emph{Request}

when the Parameters are the Identity, $1$:

$I : A \times 1 \to B$

$U : A \times 1 \times B \to 1$

$r : A \times 1 \times B \to A$

then this is a a \emph{Set-based} ("\emph{Bare}") \emph{Lens}:

$get : A \to B$ (Implement)

$put : A \times B \to A$ (Request)

alternatively, adding parentheses:

$I : (A \times P) \to B$

$U : (A \times P) \times B \to P$

$r : (A \times P) \times B \to A$

gives a Lens:

$get : (A \times P) \to B$ (Implement)

$put : (A \times P) \times B \to (A \times P)$ (Request $\times$ Update)

(note that in this case, $put$ is composed of both Request and Update)

"\emph{Lenses are Learners}"

Composition of Learners

\emph{Symmetric Lenses}

... TODO



\subparagraph{BackPropagation Through Time (BPTT)}\label{sec:bptt}\hfill

RNNs (\S\ref{sec:rnn})

2014 - Gibiansky - \emph{Recurrent Neural Networks} -
\url{http://andrew.gibiansky.com/blog/machine-learning/recurrent-neural-networks/}



\subsubsection{Feed-Forward Neural Network (FFNN)}\label{sec:ffnn}

no Cycles between Nodes (Neurons)

with the Logistic (Sigmoid) Activation Function, a Single-layer Neural Network
is identical to a Logistic Regression Model (\S\ref{sec:logistic_regression})

\url{https://blog.jle.im/entry/purely-functional-typed-models-3.html}: a
Feed-forward Layer can be turned into a Recurrent Layer (\S\ref{sec:rnn}) or an
Autoregressive Model (\S\ref{sec:autoregressive_model})



\paragraph{Universal Approximation Theorem}
\label{sec:universal_approximation}\hfill

every Continuous Function mapping Intervals of Real Numbers to some Output
Interval of Real Numbers can be Approximated arbitrarily closely by a
Multi-layer Perceptron with a single Hidden Layer

when the Activation Function is Non-linear, a Two-layer Neural Network can be
proven to be a Universal Function Approximator



\paragraph{Single-layer Perceptron}\label{sec:single_layer_perceptron}\hfill

simplest Feed-Forward Neural Network

cf. Perceptron (\S\ref{sec:perceptron}) -- Binary Linear Classifier
(\S\ref{sec:linear_classifier}); an Artificial Neuron using the Unit Step
Function (\S\ref{sec:unit_step_function}) as the Activation Function; simplest
FFNN

Perceptron Learning Algorithm does not terminate if the ``Learning Set'' is not
Linearly Separable, e.g. a Boolean Exclusive-OR problem

(wiki):

\emph{Delta Rule} -- special case of Backpropagation for Single-layer Neural
Networks; for a Neuron $j$ with Activation Function $\phi(x)$, the Delta Rule
for $j$'s $i$th Weight $w_{ji}$ is given by:
\[
  \Delta w_{ji} = r(t_j - y_j) \phi'(h_j) x_i
\]
where $r$ is the constant Learning Rate, $\phi'$ is the Derivative of the
Activation Function, $x_i$ is the $i$th Input, $t_j$ is $j$'s target Output,
$y_j$ is $j$'s actual Output, and $h_j$ is the Weighted Sum of $j$'s Inputs (the
``Induced Local Field'')



\paragraph{Multi-Layer Perceptron (MLP)}\label{sec:mlp}\hfill

(wiki): any MLP using a Linear Activation Function has an equivalent
\emph{Single-layer} Network; i.e. to gain advantages from multiple Layers
requires a \emph{Non-linear} Activation Function

cf. Restricted Boltzmann Machine (RBM \S\ref{sec:boltzmann_machine})

\fist Convolutional Nueral Network (CNN \S\ref{sec:cnn}) -- ``Regularized''
versions of MLP \fist Regularization (\S\ref{sec:regularization})



\subsubsection{Deep Neural Network (DNN)}\label{sec:dnn}

\emph{Shift-invariant Neural Networks}

\emph{Deep Learning} or \emph{Hierarchical Learning}

reduces the number of connections by reducing the number of free Parameters

connectivity pattern between Neurons inspried by organization of Visual Cortex

Cross-correlation (\S\ref{sec:cross_correlation})

ReLU activation

\asterism

2014 - Olah - \emph{Neural Networks, Manifolds, and Topology} -
\url{http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/} --

to understand behavior of DNNs, start with low-dimensional DNNs

lower-bounds on the complexity of a Neural Network capable of Classifying
certain Datasets

each Layer transforms the Datainto a new \emph{Representation}, and the
final Representation is a \emph{Line} (Hyperplane) through the Data

e.g. a tanh (Sigmoid) Layer consists of an Affine Transformation (Linear
Transformation by the Weight Matrix and a Translation by the Bias) and
point-wise application of tanh

similarly for other ``standard'' Layers: Affine Transformation + pointwise
application of Monotone Activation Function

each such transformation deforms space but does not ``cut'', ``break'', or
``fold'' it, i.e. it preserves \emph{Topological Invariants} (cf. Homeomorphisms
or ``Bicontinuous Transformations'' \S\ref{sec:homeomorphism}), e.g. a Connected
Set will be Connected after transformation and vice-versa

\emph{Theorem}: a tanh Layer with a $N \times N$ Non-singular (Invertible)
Weights Matrix is a Homeomorphism

note tanh and sigmoid (logit) are Continuous Functions, but ReLU is \emph{not}

Manifold (\S\ref{sec:manifold})

\emph{Manifold Hypothesis}: TODO

all $n$-dimensional Manifolds can be Untangled in $2n + 2$ Dimensions

a Neural Net may attempt to stretch tangled portions as thinly as possible to
pull the Manifolds apart, resulting in a local minimum; \emph{Contractive
  Penalties}, i.e. penalizing the derivatives of layers at data points may be
used to mitigate this (cf. Contractive Autoencoders
\S\ref{sec:contractive_autoencoder})

\asterism

2015 - Olah - \emph{Neural Networks, Types, and Functional Programming}
- \url{http://colah.github.io/posts/2015-09-NN-Types-FP/} --
three perspectives on Deep Learning:
\begin{enumerate}
  \item Neuroscience, Biology
  \item Representations, Transformations (``Manifold Hypothesis'')
  \item Probability, finding Latent Variables
\end{enumerate}
extending (2.) to Deep Learning as a connection between \emph{Optimization} and
\emph{Functional Programming} where \emph{Representations} correspond to
\emph{Types}

re-use of Functions (Abstraction)

re-use of Nuerons: \emph{Weight Sharing} or ``\emph{Weight Tying}''-- CNNs, RNNs

Neural Network ``patterns'' are Higher-order Functions:
\begin{itemize}
  \item Encoding RNNs are \emph{Folds}
  \item Generative RNNs are \emph{Unfolds}
  \item (general) RNNs are \emph{Accumulating Maps}
  \item Bidirectional RNNs are a \emph{Zip} of a Left- and a Right-accumulating
    Map
  \item a Conv Layer is a \emph{Window Map} (Function applied to ``window''
    around every element)
  \item Recursive Neural Networks (TreeNets) are \emph{Catamorphisms}
    (\S\ref{sec:catamorphism})
  \item reverse TreeNets are \emph{Anamorphisms}
  \item a Learned Vector is a \emph{Constant}
  \item an Embedding Layer is \emph{List Indexing}
\end{itemize}



\subsubsection{Convolutional Neural Network (CNN)}\label{sec:cnn}

``Regularized'' versions of Multi-layer Perceptrons (\S\ref{sec:mlp})
\fist Regularization (\S\ref{sec:regularization})

``Convolution Layers'' don't actually do a Convolution
(\S\ref{sec:convolution}):
rather a \emph{Cross-correlation} (or ``Sliding Dot-product''
\S\ref{sec:cross_correlation})

\emph{Weight Sharing} or ``\emph{Weight Tying}''

application of multiple ``cascaded'' ``Convolution'' Kernels

``Neocognition'', Spatial Averaging (Fukushima 1980), ``Cresceptron'', Max
Pooling (Weng et al.)

1989 - LeCun, Boser, Denker, Henderson, Howard, Hubbard, Jackel -
  \emph{Backpropagation Applied to Handwritten Zip Code Recognition}

2014 - Olah - \emph{Conv Nets: A Modular Perspective} -
  \url{http://colah.github.io/posts/2014-07-Conv-Nets-Modular/}

2014 - Olah - \emph{Understanding Convolutions} -
  \url{http://colah.github.io/posts/2014-07-Understanding-Convolutions/}

2015 - Springenberg, Dosovitskiy, Brox, Riedmiller -
\emph{Striving for Simplicity: The All Convolutional Net}
-- Model without Max Pooling (including Deconvolutional Layers)

2016 - Radford, Metz, Chintala - \emph{Unsupervised Representation Learning with
  Deep Convolutional Generative Adversarial Networks} -- DCGANs
(\S\ref{sec:gan})

Dilated (Atrous) Convolution

Pooling -- ``$p$-norm Subsampling'' (\S\ref{sec:downsampling})



\paragraph{Time Delay Neural Network}\label{sec:tdnn}\hfill

first CNN (1987)



\subsubsection{Recursive Neural Network}\label{sec:recursive_nn}

or \emph{TreeNet}



\paragraph{Hopfield Network}\label{sec:hopfield_network}\hfill

(wiki)

\emph{Complete Undirected Graph} (\S\ref{sec:complete_graph}):
\[
  G = \langle{V, f}\rangle
\]
where $V$ is a Set of Threshold Logic Units (a.k.a. McCulloch-Pitts Neurons
\S\ref{sec:tlu}) and $f : V^2 \to \reals$ is a Function linking pairs of
Units to a \emph{Connectivity Weight} with restrictions:

$w_{ii} = 0$ -- no Unit is connected to itself

$w_{ij} = w_{ji}$ -- connections are \emph{Symmetric}; this guarantees the
``Energy Function'' decreases monotonically while following the Activation rules

\asterism

2020 - Ramsauer, et al. - \emph{Hopfield Networks is All You Need}:

\emph{``Transformer Attention'' mechanism} -- Update Rule of a Hopfield Network
with Continuous States

\url{https://github.com/ml-jku/hopfield-layers}



\subparagraph{Boltzmann Machine}\label{sec:boltzmann_machine}\hfill

a \emph{Markov Random Field} (\S\ref{sec:markov_random_field})

uses \emph{Annealed Gibbs Sampling} instead of Gradient Descent

``\emph{Energy-based Models}'' (\S\ref{sec:ebm}) -- Botlzmann Distribution from
Statistical Mechanics is used in Sampling Function (Impulse Train
\S\ref{sec:impulse_train})

Restricted Boltzmann Machine (RBM) -- no \emph{intralayer} connections between
Units; cf. Multi-layer Perceptron (\S\ref{sec:mlp})

Deep Boltzmann Machine (DBM)

Semi-restricted Boltzmann Machine (SRBM)

Generative Models with Explicit, Approximate Density

Deep Belief Network (DBN \S\ref{sec:dbn})



\subparagraph{Restricted Boltzmann Machine (RBM)}\label{sec:rbm}\hfill

Contrastive Divergence training

Encoder/Decoders share weights



\paragraph{Recurrent Neural Network (RNN)}\label{sec:rnn}\hfill

special case of Recursive Neural Network with structure of a \emph{linear chain}
(FIXME: clarify)

\emph{Stateful}; can be used to learn \emph{Sequential} mappings

\emph{Weight Sharing} or ``\emph{Weight Tying}''

BackPropagation Through Time (BPTT \S\ref{sec:bptt})

RNNs having internal State makes them equivalent to general computations rather
than one-way mappings (cf. Feed-forward Neural Networks and similar)
--\url{https://penkovsky.com/neural-networks/day1/#fn:fn-6}

1999 - Tino, Dorffner - \emph{Recurrent Neural Networks with Iterated Function
  System Dynamics} -- IFS (\S\ref{sec:ifs})

\asterism

2015 - Karpathy - \emph{The Unreasonable Effectiveness of Recurrent Neural
  Networks} -
\url{http://karpathy.github.io/2015/05/21/rnn-effectiveness/}

RNNs are Turing Complete (Siegelmann 1995)

training Feed-forward or Convolution Nets is \emph{Optimization over
  Functions}, training Recurrent Nets is \emph{Optimization over Programs}

compared to standard Feed-forward or Convolutional Networks, a Recurrent Network
does \emph{not} require mapping \emph{fixed-size} input Vector to a fixed-size
Output Vector using a fixed amount of computational steps (e.g. the number of
Layers)-- they can operate over \emph{Sequences} of Vectors in both the input
and the Output
\begin{itemize}
  \item One-to-one: Feed-forward/Convolution (e.g. image classification)
  \item One-to-many: Sequence output (e.g. image captioning)
  \item Many-to-one: Sequence input (e.g. sentiment analysis)
  \item Many-to-many: Sequence input and Sequence output (e.g. machine
    translation)
  \item Synced many-to-many: ``synced'' Sequence input and output (e.g. video
    classification with label for each frame)
\end{itemize}
there are no pre-specified constraints on the \emph{lengths} of Sequences
because the \emph{Recurrent Transformation} is fixed and can be applied an
arbitrary number of times

\asterism

2011 - Sutskever, Martens, Hinton -
  \emph{Generating Text with Recurrent Neural Networks}

Hessian-Free (HF) Optimization (Truncated Newton Method
\S\ref{sec:truncated_newton})

Multiplicative RNN (\S\ref{sec:mrnn})

``Vanishing/Exploding Gradients Problem''

an RNN can be viewed as a \emph{very} Deep Neural Network with \emph{Weight
  Sharing} accross Time

\asterism

2018 - Le -
\emph{A Purely Functional Typed Approach to Trainable Models (Part 2)} -
\url{https://blog.jle.im/entry/purely-functional-typed-models-2.html}

\fist Autoregressive Models (Time Series Analysis
\S\ref{sec:autoregressive_model})

2018 - Le -
\emph{A Purely Functional Typed Approach to Trainable Models (Part 3)} -
\url{https://blog.jle.im/entry/purely-functional-typed-models-3.html}
-- a general Autoregressive Model $AR(p)$ of any Order $p$ can be defined as a
\emph{Lagged} Fully Connected Layer



\subparagraph{Simple Recurrent Neural Network (SRNN)}\label{sec:srnn}\hfill

\textbf{Elman Network}

\url{https://www.youtube.com/watch?v=e2sGq_vI41s}:

Temporal XOR:
$0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0$


\textbf{Jordan Network}



\subparagraph{Multiplicative Recurrent Neural Network (MRNN)}\label{sec:mrnn}
\hfill

2014 - Gibiansky - \emph{Recurrent Neural Networks} -
\url{http://andrew.gibiansky.com/blog/machine-learning/recurrent-neural-networks/}



\subparagraph{Long Short-Term Memory (LSTM)}\label{sec:lstm}\hfill



\paragraph{Reservoir Computing}\label{sec:reservoir_computing}\hfill

2017 - Penkovsky - \emph{Theory and Modeling of Complex Nonlinear Delay Dynamics
  Applied to Neuromorphic Computing}

\emph{Time-delay Systems} (Delay Differential Equations
\S\ref{sec:time_delay_system})

2020 - Chen, Nurdin, Yamamoto - \emph{Temporal Information Processing on Noisy
  Quantum Computers}

2020 - Bollt - \emph{On Explaining the Surprising Success of Reservoir Computing
  Forecaster of Chaos?} - \url{https://www.youtube.com/watch?v=GOeAcJvdoOU}:

\begin{itemize}
  \item Universal Machine Learning
  \item Vector Auto-regressive Modelling (\S\ref{sec:var})
  \item Dynamic Mode Decomposition (DMD \S\ref{sec:dmd})
\end{itemize}

Delay Embedding Theorem (\S\ref{sec:delay_embedding}) -- classical approach to
predicting Chaotic behavior



\subparagraph{Echo State Network (ESN)}\label{sec:esn}\hfill

\subparagraph{Liquid-State Machine (LSM)}\label{sec:liquid_state}\hfill

\subparagraph{Fractal Prediction Machine}
\label{sec:fractal_prediction_machine}\hfill



\subsubsection{Residual Neural Network (ResNet)}\label{sec:resnet}

\emph{Skip Connections}

use with deep CNNs to allow more layers

cf. ``pyramidal cells'' in biology



\subsubsection{Graph Neural Network (GNN)}\label{sec:gnn}

\url{http://cse.msu.edu/~mayao4/tutorials/aaai2020/}



\paragraph{Transformer}\label{sec:transformer}\hfill

chain of Encoders and chain of Decoders

GPT-2: Unsupervised (Generative) Transformer Language Model
(\S\ref{sec:statistical_language_model})

\url{https://thegradient.pub/transformers-are-graph-neural-networks/}



\subsubsection{Generative Stochastic Network (GSN)}\label{sec:gsn}

2013 - Bengio, Yao, Alain, Vincent -
\emph{Generalized denoising auto-encoders as generative models}

2014 - Bengio, Thibodeau-Laufer, Yosinski -
\emph{Deep generative stochastic networks trainable by backprop}

2014 - Bengio, Thiboudeau-Laufer, Alain, Yosinski -
\emph{Deep generative stochastic networks}



\subsubsection{Generative Adversarial Network (GAN)}\label{sec:gan}

(wiki):

a pair of Neural Networks contest with each other in a Game (\S\ref{sec:game})

originally proposed as a form of Generative Model
(\S\ref{sec:generative_model}) for Unsupervised Learning (cf. Cluster Analysis,
Density Estimation),
also applied to Semi- and Fully-supervised Learning, and Reinforcement Learning

\emph{Generative Network} (cf. Generative Model) -- generates ``candidates'';
typically a ``Deconvolutional'' Network

\emph{Generative Model} (cf. Discriminative Model
\S\ref{sec:discriminative_model}) -- ``evaluates'' candidates; typically a
Convolutional Network

given a Training Set, the GAN is to \emph{learn} to generate new Data with the
same \emph{Statistics} as the Training Set

the Generative Network's Objective is to increase the Loss of the Discriminator
Network by producing novel candidates that the Discriminator accepts as part of
the ``true'' Data Distribution

the Discriminator is Trained by being presented with Samples from the Training
Dataset

the Generator typically seeded with randomized Input Sampled from a predefined
``Latent Space'' (e.g. a Multivariate Normal Distribution)

candidates synthesized by the Generator are evaluated by the Discriminator, and
the Generator is Trained based on whether it succeeds in ``fooling'' the
Discriminator

2014 - Goodfellow, et al. - \emph{Generative Adversarial Nets}:

Generative Model $G$ captures Data Distribution

Discriminative Model $D$ Estimates Probability that a Sample came from Training
Data rather than $G$

Training $G$ to \emph{Maximize} the Probability that $D$ makes a mistake

framework corresponds to a \emph{Minimax Two-player Game} (\S\ref{sec:minimax})

in the space of arbitrary Functions $G$ and $D$, a \emph{unique solution} exists
with $G$ recovering the Training Data Distribution and $D$ equal to $0.5$
everywhere

when $G$ and $D$ are Multilayer Perceptrons, the system can be trained with
Backpropagation

Noise-contrastive Estimation (Gutmann, Hyvarinen 2010) --
\emph{Discriminative} Training critereon used to Fit a \emph{Generative} Model

GANs: instead of Fitting a \emph{seperate} Discriminative Model, the Generative
Model itself is used to \emph{Discriminate Generated Data} from Samples of a
fixed Noise Distribution

cf. Generative Stochstaic Network (GSN), Denoising Auto-encoders --
(Bengio, et. al)

2016 - Radford, Metz, Chintala - \emph{Unsupervised Representation Learning with
  Deep Convolutional Generative Adversarial Networks} -- DCGANs

\asterism

2017 - Pascual - UPC2017 \emph{Generative Adversarial Networks} -
\url{https://www.youtube.com/watch?v=a1aM0yUJXUI}

2017 - Yeung - CS231n - \emph{Lecture 13: Generative Models} -
\url{https://www.youtube.com/watch?v=5WoItGTWV54}

Minimax Game

Objective Function:
\[
  \min_{\theta_g} \max_{\theta_d} \Big(
    \expect_{x \sim p_{data}} \log D_{\theta_d}(x) +
    \expect_{z \sim p(z)} \log (1 - D_{\theta_d}(G_{\theta_g}(z)))
  \Big)
\]
where $D_{\theta_d}(x)$ is the Discriminator Output Likelihood in $(0, 1)$ for
``real'' Data $x$, and $D_{\theta_d}(G_{\theta_g}(z))$ is the Discriminator
Output Likelihood in $(0, 1)$ for the ``fake'' Data $G(z)$ produced by the
Generator

\emph{Gradient Ascent} on Discriminator:
\[
  \max_{\theta_d} \Big(
    \expect_{x \sim p_{data}} \log D_{\theta_d}(x) +
    \expect_{z \sim p(z)} \log (1 - D_{\theta_d}(G_{\theta_g}(z)))
  \Big)
\]
\emph{Gradient Descent} on Generator:
\[
  \min_{\theta_g} \expect_{z \sim p(z)} \log (1 - D_{\theta_d}(G_{\theta_g}(z)))
\]
note that the Optimization Objective for the Generator of \emph{minimizing} the
Likelihood of the Discriminator being correct has a flat Gradient when the Loss
is high, and a steep Gradient when the Loss is already low, so it is better to
train by Gradient Ascent to \emph{maximize} the Likelihood of the Discriminator
being wrong:
\[
  \max_{\theta_g} \expect_{z \sim p(z)} \log (D_{\theta_d}(G_{\theta_g}(z)))
\]



% ==============================================================================
\section{Computational Learning Theory}\label{sec:computational_learning_theory}
% ==============================================================================

%FIXME start new document ???



% ------------------------------------------------------------------------------
\subsection{Algorithmic Learning Theory}\label{sec:algorithmic_learning}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Vapnik-Chervonenkis Theory}\label{sec:vc_theory}
% ------------------------------------------------------------------------------

\emph{VC Theory}



\subsubsection{Shattered Set}\label{sec:shattered_set}

\emph{Shatter Coefficient}



\subsubsection{VC Class}\label{sec:vc_class}

\emph{Hypothesis Class}



\paragraph{VC Dimension}\label{sec:vc_dimension}\hfill

\emph{Model Complexity} (\S\ref{sec:statistical_model})

measure of the capacity (expressive power) of a Space of Functions that can be
Learned by a Statistical Classification Algorithm (\S\ref{sec:classification})

defined as the Cardinality of the largest Set of Points that the Algorithm can
\emph{Shatter} (\S\ref{sec:shattered_set})



% ==============================================================================
\section{Statistical Randomness}\label{sec:statistical_randomness}
% ==============================================================================

cf. \emph{Algorithmic Randomness} (\S\ref{sec:algorithmic_randomness}) --
Universal Test, Universal Sequential Test (Martin-L\"of66)

cf. Statistical Fluctuation (\S\ref{sec:statistical_fluctuation})
%FIXME: move fluctuation under this heading ???

\emph{Subsequence Selection Criterion} (\S\ref{sec:random_sequence}) --
\emph{Mises-Church Randomness}: any Recursive Function which having read the
first $N$ elements of the Sequence decides if it wants to select element $N+1$

cf. Quasi-random (Low-discrepancy) Sequences (\S\ref{sec:low_discrepancy})

Tests (\S\ref{sec:hypothesis_testing}):
\begin{itemize}
  \item Frequency test
  \item Serial Test
  \item Poker Test
  \item Gap Test
  \item ...
\end{itemize}

(Mandelbrot97E)

\emph{Seven States of Randomness}

problem of Determinism in physics in the face of Randomness is mitigated by lack
of information (e.g. state of individual atoms in a gas)

problem of Causality and Rationality in finance are exaggerated due to more or
less ``perfect'' information of markets

from ``more'' to ``less'' random: a fair coin, a biased coin, a coin with
``memory''

``mild'' randomness: statistics ordinarily deal with observations that fluctuate
around a ``normal'' state; cf. the edge of a razor blade is jagged on close
inspection but has a higly representative ``trend'' when viewed at larger scales

``wild'' randomness: ``non-averaging'' change; cf. a coastline reveals
irregularity at every scale

``at random'': not fully predictable or controllable

*ex-post* vs. *ex-ante*: after the fact reasonable causes may be attributed to
some features, but before the fact the ``situation is much different''

``mild'' (Gaussian), ``slow'' (Log-normal), ``wild'' (Scaling with Infinite
Variance, i.e. $\alpha < 2$)

Slow Randomness is a complex intermediate state between two states of greater
simplicity

Mild and Wild Randomness are defined by criterea that distinguish between
``even'' (roughly equal) portioning of $N$ addends in a Sum $\sum_1^N U_n$ in
the case of Mild Randomness, and ``concentrated'' portioning where one or a
``few'' fo the addends predominate in the case of Wild Randomness

Mild (Gaussian) -- Short-run and Long-run even-ness, Tail-mixing

Slow (Lognormal) -- Short-run Concentration and Long-run even-ness,
Tail-preserving

Wild (Scaling) -- Short-run and Long-run Concentration, Tail-preserving

Short-run ($N=2$ or ``a few'') -- Mild ``tail-mixing'', Wild
``tail-preserving'' (shorthand: $P_N \sim N P$); criterea:
\begin{enumerate}
  \item ``Concentration in Mode'' -- involves the Convexity of $\ln p(u)$ where
    $p(u)$ is the PDF of the addends
  \item ``Concentration in Probability'' -- Tail Preservation Relation
    ($P_N \sim N P$); involves a Limit Theorem
\end{enumerate}

Concentration in the Long Run implies Concentration in the Short Run, but not
the other way around

Middle-run ($N =$ ``many'') -- Slow (Pre-Gaussian but ``tail-preserving'');
Short-run Concentration and Long-run evenness; \emph{Pre-asymptotics}

Mild Randomness is characterized by an absence of ``structure'' and by a ``local
level'' of Statistical Dependence; cf. properties of a gas (``Fickian'') as a
state of matter

Wild Randomness is characterized by presence of ``structure'' and Long-range
Dependence (\S\ref{sec:long_range_dependence}); cf. properties of ``solid''
matter

\begin{itemize}
  \item Wild vs. Pre-Gaussian: classical Limit Theorems define
    \emph{Concentration} in the Long-run
\end{itemize}

Long-run ($N \to \infty$) -- Pre-Guassian (``\emph{even}'' in the Long-run):
$1 / N \to 0$; ``Theory of Errors'', ``absence of Concentration in the
Long-run'' (cf. Central Limit Theorem \S\ref{sec:central_limit})-- the
assumption that Errors are Gaussian because they are the Observable Outcome of a
large number of separate Additive contributions such that the largest is
negligible compared to the Sum both \emph{ex-ante} (in terms of Distributions)
and \emph{ex-post} (in terms of Realized values)

Law of Large Numbers:
\[
  \frac{1}{N} \sum_{n=1}^N U_n
\]
Limit is $\expect(U)$ as $N \to \infty$

Central Limit Theorem:
\[
  \frac{1}{\sqrt{N}} \sum_{n=1}^N U_n - N \expect{U}
\]
(FIXME: the book writes $A_N \sim \frac{1}{\sqrt{N}}$, is this a typo for
$A_N = ...$ ???)
Limit is a Gaussian as $N \to \infty$; the Domain of ``Universality of
Attraction'' to the Gaussian includes \emph{all} $U$ satisfying $\expect(U^2) <
\infty$ and also some cases where $\expect(U^2)$ Diverges ``slowly enough''

failure to be Pre-Gaussian occurs when:
\begin{itemize}
  \item Population Variance or Expected Value is Infinite
  \item Dependence is Long-range or ``global'', not Short-range (Markovian)
  \item total Probability must be taken as Infinite
\end{itemize}

Scaling (\S\ref{sec:scaling_distribution}) Variables with $\alpha < 2$ satisfy
$\expect(U^2) < \infty$ but are \emph{not} Pre-Gaussian
(FIXME: how does this comport with the universality of attraction to the
gaussian above including all $U$ statisfying $\expect(U^2) < \infty$ ???)

Domains of ``Universality of Attraction'' to Non-Gaussian Limits: each value
$\alpha < 2$ defines its own Domain of Universality, and each Domain is
extremely narrow compared to the Domain of the Gaussian and reduces to Variables
for which:
\[
  \prob(U > u) \sim u^{-\alpha} L(u)
\]
where $L(u)$ is Logarithmic or slowly varying (i.e.
$\lim_{h \to \infty} \frac{L(hu)}{L(u)} = 1$)

if $U_n$ is in the Domain of Universality of $\alpha < 2$, the Limit $\sum U_n$
is a Random Variable called \emph{$L$-stable} (\S\ref{sec:lsm}), as
$N \to \infty$:
\[
  N^\frac{1}{\alpha} \sum_{n=1}^N U_n - N \expect{U}
\]
when $1 < \alpha < 2$ and:
\[
  N^\frac{1}{\alpha} \sum_{n=1}^N U_n
\]
when $0 < \alpha < 1$

\begin{itemize}
  \item Mild vs. Long-tailed: Short-run Concentration, Convexity of $\ln p(u)$,
    and Tail Preservation Relation
\end{itemize}

criterea: \emph{Concentration in Mode}, \emph{Concentration in Probability}

\emph{Tail Preservation Relation} -- $\overline{F}_N(u) \sim N \overline{F}(u)$

cf. Extreme Value Analysis (\S\ref{sec:eva})

for $U_n$ ($1 \leq n \leq N$) IID with Tail Probability $\overline{F}(u)$, and
$\tilde{F}_N(u)$ the Tail Probability of $\tilde{U}_N = \max(U_n)$, then:
\[
  1 - \tilde{F}_N(u) = F(u)^N
\]
in the Tail where $\overline{F}(u) \ll 1$ and $\tilde{F}(u) \ll 1$, in
\emph{all} cases: $\tilde{F}(u) \sim N \overline{F}$

for $U', U'' \sim p(u)$, $U = U' + U''$ has PDF $p_2(u)$ given by the
\emph{Doubling Convolution}:
\[
  p_2(x) = \int p(u) p(x - u) \diffy{u}
\]
and when $u$ is known, the Conditional PDF of $u'$ is given by the
\emph{Portioning Ratio}:
\[
  \frac{p(u') p(u - u')}{p_2(u)}
\]
and the Conditional Expectation of $U'$ is always $\frac{u}{2}$, and the
Conditional Expectation of $\min(u', u'')$ is not given by any ``mangeable
expansion''

studying the Location of the most Probable values of $\min(u', u'')$ and
$\max(u', u'')$, called ``\emph{Modes}'', leads to a criterion for defining the
Concentration vs. even-ness in Mode based on the Convexity of $\ln p(u)$

\emph{Concentration in Mode} -- sufficient criterion of even-ness or
Concentration ``in Mode'': the Graph of $\ln p(u)$ is Cap- or Cup-convex for
sufficiently large values of $u$

when the Convexity $\ln p(u)$ is \emph{Uniform} for all $u$, the sign of:
\[
  \Delta(u) = 2 \ln p(\frac{u}{2}) - \ln p(0) - \ln p(u)
\]
is \emph{Independent} of $u$

when the Graph of $\ln p(u)$ is Cap-convex, the Portioning Ratio is
\emph{maximum} for $u' = \frac{u}{2}$ and Portioning is \emph{even} in terms of
Mode

when the Graph of $\ln p(u)$ is Cup-convex, the Portioning Ratio is
\emph{minimum} for $u' = \frac{u}{2}$ and Portioning is \emph{Concentrated} in
terms of Mode

when $\ln p(u)$ is straight, the addends are Exponential and the Portioning
Ratio is constant

Distributions with Uniform Convexity of $\ln p(u)$ show that the distinction
between Mild and Long-tailed Randomness cannot be identified with the
distinction between ``even'' and Concentrated Short-run Portioning

when $\ln p(u)$ is of non-constant Convexity (e.g. as the Lognormal Distribution
has $\ln p(u)$ equal to the Gaussian, which is a bell curve of mixed Convexity),
so Portioning is even for $u$ near the Mode and Concentrated for large $u$;
Cauchy Distribution is also mixed

\fist Gamma Distribution shows the need for a criterion of ``Mildness'' that
goes beyond the Convexity of $\ln p(u)$

\emph{Concentration in Probability} -- criterion $p_2(u) \sim 2p(u)$ of Tail
Preservation under Addition as defining Long-tailedness

$P_N(u) = NP(u)$ expresses that the Tail behavior of $U$ is preseved under
Finite Addition

$N = 3$ -- taking $u'$, $u''$, and $u^0$ to be the distances from an interior
Point to the sides of an Equilateral Triangle of height $u$, then $u = u' + u''
+ u^0$ and:
\begin{itemize}
  \item when the $U$ are Exponential, then the Conditional Distribution of
    Points in the Triangle is Uniform
  \item when $U$ is Mild, then the Conditional Distribution is concentrated near
    the center
  \item when $U$ is Short-run Concentrated, the Conditional Distribution
    concentrates near the corners
\end{itemize}
the same distinction holds for $N = 4, 5, \ldots$

``Extreme'' Randomness -- Tail Probability $P(u) = \frac{1}{\ln u}$
Concentration Converges to $1$ as $N \to \infty$, i.e. whenever $P(u)$ is a
``slowly varying function'' $\lim_{u\to\infty}\frac{P(hu)}{P(u)} \to 1$ for $h >
0$; Log-cauchy (\S\ref{sec:log_cauchy})

Seven States of Randomness

alternative criteria: rate of increase as Function of $q$ of the Moment
$\expect(U^q)$ or ``Scale Factor'' ($\expect(U^q)^\frac{1}{q}$)



% ------------------------------------------------------------------------------
\subsection{Randomization}\label{sec:randomization}
% ------------------------------------------------------------------------------

\begin{itemize}
  \item Random Experiments (\S\ref{sec:experiment}), cf. Observation
    (\S\ref{sec:observation}), Sampling (\S\ref{sec:random_sample})
  \item Survey Sampling
  \item Resampling (\S\ref{sec:resampling})
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Pseudorandom Process}\label{sec:pseudorandom_process}
% ------------------------------------------------------------------------------

Deterministic System (\S\ref{sec:deterministic_system}) exhibiting Statistical
Randomness

cf. \emph{Stochastic Process} (\S\ref{sec:stochastic_process})

cf. Quasi-random (Low Discrepancy) Sequences (\S\ref{sec:low_discrepancy})

\emph{Hash Functions} can create ``Random Numbers'' solely based on an Input
with no dependency on previous queries

\fist Pseudo-random Number Sampling (\S\ref{sec:pseudorandom_sampling})

2015 -
\url{http://blog.runevision.com/2015/01/primer-on-repeatable-random-numbers.html}
- \emph{Primer on Repeatable Random Numbers}



\subsubsection{Middle-square Method}\label{sec:middle_square_method}



% ------------------------------------------------------------------------------
\subsection{Exchangeable Sequence}\label{sec:exchangeable_sequence}
% ------------------------------------------------------------------------------

an \emph{Exchangeable (Interchangeable) Sequence of Random Variables} is a
Finite or Infinite Sequence $X_1, X_2, X_3, \ldots$ such that the Joint
Probability Distribution is equal under any Finite Permutation of terms

equivalent to the concept of ``\emph{Statistical Process Control (SPC)}''
(Quality Control)

Representation Theorem



\subsubsection{Infinitely Exchangeable Sequence}
\label{sec:infinitely_exchangeable}

an Infinitely Exchangeable Sequence is Strictly Stationary
(\S\ref{sec:stationary_process})

Predictive Inference, Bayesian Statistics (Finetti) --TODO: xref

(McCullagh02)



\subsubsection{Partially Exchangeable Array}
\label{sec:partially_exchangeable}

1981 - Aldous -
\emph{Representaions for Partially Exchangeable Arrays of Random Variables}

(McCullagh02)



% ==============================================================================
\section{Stochastic Process}\label{sec:stochastic_process}
% ==============================================================================

A \emph{Stochastic Process} (or \emph{Random Process}) is an Indexed Family of
possibly \emph{Dependent} (\S\ref{sec:dependence}) Random Variables
(\S\ref{sec:random_variable}) $\{ X_t : t \in T \}$ with a common State Space,
$V$. An \emph{Outcome} for a Stochastic Process is a particular \emph{Path} or
``\emph{Sample Function}'' (or ``\emph{Realization}''), assigning a Point in
State Space $X_t(\omega) = x_t \in V$ to each Random Variable in the Family;
that is, a Stochastic Process is a Random Variable taking values in a Space of
\emph{Functions} from the Index Set to Points in the underlying State Space.
Equivalently, a Stochastic Process defines a Probability Distribution over a
``Space of Paths'' (MIT 18.s096).

the induced Measure on the Space of Paths is called the ''\emph{Law}'' of the
Stochastic Process (\S\ref{sec:process_law})

A Process in which each Point is Stochastically Independent
(\S\ref{sec:independence}) is called a \emph{Completely Random Process} (e.g.
Bernoulli Process \S\ref{sec:bernoulli_process}, Poisson Process
\S\ref{sec:poisson_process}).

\fist a \emph{Random Sequence} (\S\ref{sec:random_sequence}) is a special case
of Completely Random Process where the Index Set is some Subset of the Integers
(e.g. a Sequence of IID Observations; cf. Random Sample
\S\ref{sec:random_sample})

\fist a \emph{Pseudorandom Process} (\S\ref{sec:pseudorandom_process}) is a
Determinstic Process exhibiting Statistical Randomness
(\S\ref{sec:statistical_randomness})

\fist cf. Data Generating Process (\S\ref{sec:data_generating_process})

\fist \emph{Noise Signal} (\S\ref{sec:noise}) -- a Signal produced by a
Stochastic Process

\fist Statistical Signal Processing (\S\ref{sec:statistical_signal}) -- treats
Signals as Stochastic Processes;
note that a Signal may have a ``White'' Frequency Spectrum but still be Serially
Dependent (Mandelbrot97E)

\fist Stochastic Calculus (\S\ref{sec:stochastic_calculus}) -- consistent theory
of Integration defined for Integrals of Stochastic Processes with respect to
other Stochastic Processes:
\begin{itemize}
  \item Stochastic Differential Equation (\S\ref{sec:sde}) -- Differential
    Equation in which one or more Terms is a Stochastic Process
  \item Predictable Process (\S\ref{sec:predictable_process}) -- Process whose
    value is knowable at a prior time; smallest Class of Processes that is
    Closed under taking limits of Sequences (FIXME: clarify)
  \item Adapted Proces (Non-anticipative Process \S\ref{sec:adapted_process}) --
    cannot be Predicted into the Future (FIXME: clarify)
\end{itemize}
It\^o Integrals (\S\ref{sec:ito_integral}), Stratonovich Integrals
(\S\ref{sec:stratonovich_integral})

cf. Harmonic Functions (\S\ref{sec:harmonic_function})

\fist cf. Stochastic Optimization (\S\ref{sec:stochastic_optimization})

\fist cf. Non-deterministic Dynamical Systems
(\S\ref{sec:nondeterministic_dynamical_system})

First-hitting-time Model

classifications:

\begin{itemize}
  \item State Space
  \item Index Set -- Cardinality: Discrete, Continuous
  \item Dependence
\end{itemize}

1984 - Kingman - \emph{Present Position and Potential Developments: Some
  Personal Views: Probability and Random Processes}

main types of Random Processes:
\begin{enumerate}
  \item Random Function $X_t$ where $t$ is a Real Variable -- cf. Markov
    Processes (\S\ref{sec:markov_process})
  \item Random Function $X_t$ where $t$ is taken from an Un-ordered Parameter
    Space -- cf. Gaussian Processes (\S\ref{sec:gaussian_process}), Markov
    Random Fields (\S\ref{sec:markov_random_field})
  \item Point Processes on a general Space $Z$ -- cf. Poisson Processes
    (\S\ref{sec:poisson_process})
  \item Random Geometric Objects -- represented as Points in some Geometric
    Manifold and treated as Point Processes
\end{enumerate}

Analytic approach -- calculations of Probabilities and Expectations of Joint
Distributions of Random Processes

Synthetic approach -- Probabilities of Statements or Assertions about Random
Processes

Wasserman04, Ch.23:

\emph{Stochastic Process} -- collection of Random Variables:
\[
  \{ X(t) : t \in T \}
\]
with Index Set $T$, taking values in the \emph{State Space} (cf. Dynamical
Systems \S\ref{sec:dynamical_system}), $\mathcal{X}$

\begin{itemize}
  \item Markov Process (\S\ref{sec:markov_process}) -- Probability Distribution
    of $X_i$ Depends only on $X_{i-1}$
  \item Random Field (\S\ref{sec:random_field}) -- $T$ allowed to be any
    Topological Space
\end{itemize}

the Joint Probability Density Function (\S\ref{sec:joint_probability}) of
$X_1, \ldots, X_n$ Random Variables can be written as:
\begin{flalign*}
  f(x_1, \ldots, x_n)
    & = f(x_1) f(x_2 | x_1) \cdots f(x_n | x_1, \ldots, x_{n-1}) \\
    & = \prod_{i=1}^n f(x_i | x_1, \ldots, x_{i-1}) \\
\end{flalign*}
for a Markov Process, this simplifies to:
\[
  f(x_0, \ldots, x_t) = f(x_1)f(x_2|x_1)f(x_3|x_2) \cdots f(x_t|x_{t-1})
\]



% ------------------------------------------------------------------------------
\subsection{Stochastic Process Law}\label{sec:process_law}
% ------------------------------------------------------------------------------

the ``\emph{Law}'' or \emph{Probability Law} of a Stochastic Process is the
Measure that the Process induces on the Space of Paths

the Probability Law of a Wiener Process is the Wiener Measure on the Space of
Continuous Functions with $g(0) = 0$



% ------------------------------------------------------------------------------
\subsection{Daniell-Kolmogorov Extension}\label{sec:kolmogorov_extension}
% ------------------------------------------------------------------------------

\emph{Daniell-Kolmogorov Extension Theorem} (or \emph{Kolmogorov Consistency
  Theorem}) -- a suitably ``consistent'' collection of Finite-dimensional
Distributions will define a Stochastic Process



% ------------------------------------------------------------------------------
\subsection{Statistical Fluctuation}\label{sec:statistical_fluctuation}
% ------------------------------------------------------------------------------

Statistical Mechanics \& Thermodynamics; e.g. Shot (Poisson
\S\ref{sec:poisson_process}) Noise in electronics and optical devices--
originates from discrete nature of electric charge and particle nature of light,
resp.

cf. Statistical Randomness (\S\ref{sec:statistical_randomness})



\subsubsection{Detrended Fluctuation Analysis}\label{sec:detrended_fluctuation}

Peng et al. 1994

Statistical Self-affinity (\S\ref{sec:self_affinity}) of a Signal
(\S\ref{sec:signal}) or Time Series (\S\ref{sec:time_series})

\fist cf. Detrended Correlation Analysis (\S\ref{sec:detrended_correspondence})

Long-range Dependence Processes (\S\ref{sec:long_range_dependence})

Autocorrelation (\S\ref{sec:autocorrelation})

Pink ($1/f$) Noise (\S\ref{sec:pink_noise})



% ------------------------------------------------------------------------------
\subsection{Covariance Function}\label{sec:covariance_function}\hfill
% ------------------------------------------------------------------------------

(or \emph{``Kernel''}, not to be confused with Window Functions
\S\ref{sec:distribution_kernel} in Kernel Density Estimation)

(wiki): the Covariance Function $C(x, y)$ describes the ``Spatial or Temporal''
Covariance (\S\ref{sec:covariance}) of a Random Variable Process or Field
(\S\ref{sec:random_field}) $Z(x)$ on a Domain $D$ at two ``\emph{locations}''
$x$ and $y$:
\[
  C(x, y) := Cov(Z(x), Z(y)) = E[(Z(x) - E(Z(x))) \cdot (Z(y) - E(Z(y)))]
\]

the Covariance Function is called \emph{Autocovariance}
(\S\ref{sec:autocovariance}) in:
\begin{itemize}
  \item Time Series (\S\ref{sec:time_series}) -- $x$ and $y$ are locations in
    Time
  \item Multivariate Random Fields (\S\ref{sec:multivariate_random_field})
\end{itemize}

Cross-covariance (\S\ref{sec:cross_covariance}) is the Covariance between two
different Random Variables at different locations



\subsubsection{Autocovariance}\label{sec:autocovariance}

cf. Autocorrelation (\S\ref{sec:autocorrelation})
%FIXME: move section?



\subsubsection{Cross-covariance}\label{sec:cross_covariance}

cf. Cross-correlation (\S\ref{sec:cross_correlation})



% ------------------------------------------------------------------------------
\subsection{Autocorrelation Function}\label{sec:autocorrelation_function}
% ------------------------------------------------------------------------------

Autocorrelation (\S\ref{sec:autocorrelation})

Autoregressive Models (\S\ref{sec:autoregressive_model})



% ------------------------------------------------------------------------------
\subsection{Stochastic Drift}\label{sec:stochastic_drift}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Stochastic Convergence}\label{sec:stochastic_convergence}
% ------------------------------------------------------------------------------

Convergence of Sequences (\S\ref{sec:convergent_sequence}) of Random Variables
(\S\ref{sec:random_variable}) to a Limit Random Variable

\fist Asymptotic Theory (Large Sample Theory \S\ref{sec:asymptotic_theory})

\fist cf. Measure Convergence (\S\ref{sec:measure_convergence})

Wasserman04 Ch.5

\textbf{Modes of Convergence}
For a Sequence of Random Variables $X_1, X_2, \ldots$, and Random Variable $X$,
with $F_{X_n}$ the CDF (\S\ref{sec:cdf}) of $X_n$ and $F_X$ the CDF of $X$:
\begin{itemize}
  \item \emph{Convergence in Distribution} (\emph{Weak Convergence}) --
    $X_n \rightsquigarrow X$ if for all $x$ at which $F_X$ is Continuous:
    \[
      \lim_{n\to\infty} F_{X_n}(x) = F_X(x)
    \]
  \item \emph{Convergence in Probability} -- $X_n \xrightarrow{P} X$ if for
    every $\epsilon > 0$:
    \[
      \lim_{n\to\infty}P(|X_n - X| > \epsilon) = 0
    \]
  \item \emph{Almost Sure (Everywhere) Convergence} (\emph{Strong Convergence})
    -- $X_n \xrightarrow{as} X$ if:
    \[
      P(\lim_{n\to\infty}X_n = X) = 1
    \]
  \item \emph{Sure (Everywhere) Convergence} (\emph{Pointwise Convergence})
  \item \emph{Convergence in the $r$th Mean} or \emph{$L^r$-norm}
    (\S\ref{sec:lp_space})
    \begin{itemize}
      \item \emph{Convergence in Quadratic Mean ($L^2$)} --
        $X_n \xrightarrow{qm} X$ if:
        \[
          \lim_{n\to\infty} E(X_n - X)^2 = 0
        \]
      \item \emph{Convergence in $L^1$} -- $X_n \xrightarrow{L^1} X$ if:
        \[
          \lim_{n\to\infty} E(|X_n - X|) = 0
        \]
    \end{itemize}
\end{itemize}

\textbf{Thm.}
\begin{itemize}
  \item $X_n \xrightarrow{qm} X \Rightarrow X_n \xrightarrow{L^1} X$
  \item $X_n \xrightarrow{L^1} X \Rightarrow X_n \xrightarrow{P} X$
  \item $X_n \xrightarrow{as} X \Rightarrow X_n \xrightarrow{P} X$
  \item $X_n \xrightarrow{P} X \Rightarrow X_n \rightsquigarrow X$
  \item $X \rightsquigarrow X \wedge \exists c : P(X = c) = 1 \Rightarrow
    X_n \xrightarrow{P} X$
\end{itemize}

\emph{Slutsky's Theorem}



% ------------------------------------------------------------------------------
\subsection{Filtration}\label{sec:stochastic_filtration}
% ------------------------------------------------------------------------------

cf. Filtration (Abstract Algebra \S\ref{sec:filtration})

Filtered Probability Space



% ------------------------------------------------------------------------------
\subsection{Compound Process}\label{sec:compound_process}
% ------------------------------------------------------------------------------

or \emph{Seperable Process}

Mandelbrot97E

\emph{Directing Function} $\theta(t)$

\emph{Compounding Function} (\emph{Directed Function}) $X(\theta)$

\emph{Compound Process} $X(\theta(t))$

%FIXME: riemann-stieltjes integral ???

\emph{Spectra} (\S\ref{sec:frequency_spectrum}) of Compound Processes are only
sensitive to the Spectrum of the Directed (Compounding) Function (and completely
blind to properties of the Directing Function); e.g. the Directing Function
(Increments) may be strongly Dependent, but \emph{Uncorrelated} (i.e. Spectrally
White)

Discontinous Compounding -- modifies both the Graph and Trail

Subordination -- Discontinuous Compounding with a Directing Function with
Non-negative Statistically Independent Increments;
when the Directing Function is Self-affine, it must be an $L$-stable
(\S\ref{sec:lsm}) Non-decreasing Function or ``Stable Subordinator''

\fist cf. Subordination (Analysis \S\ref{sec:subordination})

a Directing Function that is a Devil Staircase (\S\ref{sec:devil_staircase}) is
called a \emph{Fractal Time} (\S\ref{sec:fractal_time})

Continuous Compounding -- modifies the Graph of $X(t)$ but leaves the Trail
(i.e. Path without the Time Axis) unchanged; \emph{Multifractal Time}
(\S\ref{sec:multifractal_time})



% ------------------------------------------------------------------------------
\subsection{Discrete-time Stochastic Process}\label{sec:discretetime_stochastic}
% ------------------------------------------------------------------------------

\begin{itemize}
  \item Discrete-time Martingale (\S\ref{sec:martingale})
  \item Discrete-time Autoregressive Process (\S\ref{sec:autoregressive_model})
  \item Discrete-time Moving Average Process (\S\ref{sec:moving_average_model})
\end{itemize}

\fist Time Series (\S\ref{sec:time_series})




\subsubsection{Bernoulli Process}\label{sec:bernoulli_process}

Mathematical Formalization of \emph{Binomial (Bernoulli) Trials}
(\S\ref{sec:binomial_trial})

Binary Entropy (\S\ref{sec:binary_entropy}) -- Entropy of a Bernoulli Process
with Probabilty $p$

Stochastic Computing

cf. \emph{Binomial Process} (Point Process \S\ref{sec:binomial_process})

Iteratively Re-weighted Least Squares (IRLS \S\ref{sec:irls}) -- equivalent to
minimizing the Log-likelihood (\S\ref{sec:log_likelihood}) of a Bernoulli
Distributed Process using Newton's Method (\S\ref{sec:newtons_method}); used for
MLE in Logistic Regression (\S\ref{sec:logistic_regression})



\paragraph{Bernoulli Sequence}\label{sec:bernoulli_sequence}\hfill

Random Sequence (\S\ref{sec:random_sequence})

\emph{Infinite Bernoulli Sequences} -- cf. \emph{Collectives} (Von Mises57); a
solution to the ``Reference Class Problem'' of Frequentist Probability Theory;
cf. (Martin-L\"of66)



\paragraph{Bernoulli Scheme}\label{sec:bernoulli_scheme}\hfill

or \emph{Bernoulli Shift}

more than two possible outcomes



\subsubsection{Markov Chain}\label{sec:markov_chain}

\fist (Continuous-time) Markov Process (\S\ref{sec:markov_process})

Markov Chain Monte Carlo (MCMC \S\ref{sec:mcmc})



\paragraph{Markov Property}\label{sec:markov_property}\hfill

``\emph{Memoryless-ness}'' (cf. Long Memory or Long-range Dependence
\S\ref{sec:long_range_dependence})

Mandelbrot97: a High-dimensional Process could be Markovian, while having
low-dimensional projections that need not be Markovian



\subsubsection{Scaling Limit}\label{sec:scaling_limit}

cf. Scale Parameter (\S\ref{sec:scale_parameter})

\emph{Donsker's Theorem} -- a Discrete Random Walk
(\S\ref{sec:simple_random_walk}) converges to true Brownian Motion (Wiener
Process \S\ref{sec:wiener_process}) in the Scaling Limit



% ------------------------------------------------------------------------------
\subsection{Continuous-time Stochastic Process}\label{sec:continuous_stochastic}
% ------------------------------------------------------------------------------

\subsubsection{Jump Process}\label{sec:jump_process}

\begin{itemize}
  \item Cauchy Process (\S\ref{sec:cauchy_process})
\end{itemize}



\subsubsection{Gaussian Process}\label{sec:gaussian_process}

a 1D Gaussian Random Field (\S\ref{sec:gaussian_random_field})

cf. Gaussian Random Walk (\S\ref{sec:gaussian_random_walk})

can be seen as the Infinite-dimensional generalization of Multivariate Normal
Distributions (\S\ref{sec:normal_distribution})

the Distribution of a Gaussian Process is the Joint Distribution of
\emph{Infinitely many} Random Variables, i.e. it is a Distribution over
Functions with a Continuous Domain

Machine Learning: Lazy Learning (1D Gaussian Distributions)

(Jacot, Gabriel, Hongler 2018): at initialization, ANNs (\S\ref{sec:ann}) are
equivalent to Gaussian Processes in the ``Infinite-width'' limit

Gaussain Process Regression (Kriging \S\ref{sec:gaussian_process_regression})

\fist Gauss-Markov Process (\S\ref{sec:gauss_markov_process})

\fist Donsker's Theorem (\S\ref{sec:donskers_theorem})



\paragraph{Fractional Brownian Motion}\label{sec:fractional_brownian}\hfill

Integral of Gaussian Processes (Fractional Gaussian Noise)

(\emph{fBm})

Covariance Function:
\[
  \expect\big(B_H(t) B_H(s)\big) =
    \frac{1}{2} (|t|^{2H} + |s|^{2H} - |t - s|^{2H})
\]

Mandelbrot, van Ness 1968 -- Model for prices that are ``Dependence-dominated''

$H \in (0,1) \subset \reals$ -- \emph{Hurst Exponent} (``Hurst Index''
\S\ref{sec:hurst_exponent})

$H = 1/2$ -- Wiener Process (Brownian Motion \S\ref{sec:wiener_process})

for $H > 1/2$, increments of the process are Positively Correlated, and exhibits
Long-range Dependence (\S\ref{sec:long_range_dependence})

for $H < 1/2$, increments of the process are Negatively Correlated

Hausdorff and Box Dimension of $2 - H$

\fist Multifractals (\S\ref{sec:multifractal_system}): generalized framework of
Fractional Brownian Motions

cf. Fractional L\'evy Flight (\S\ref{sec:fractional_levy}) -- Non-gaussian
increments

(Mandelbrot96) Fractional Brownian Motion of Multifractal Time -- Model of
Variation of Exchange Rates

(Mandelbrot97E) ``Unifractal'' Models of Price Variation: $L$-Stable Motion
(Infinite Variance, ``Tail-driven Variability'' \S\ref{sec:lsm}) + FBM
(Long-range Dependence)

\fist Fractal Time (\S\ref{sec:fractal_time}), Multifractal Time
(\S\ref{sec:multifractal_time}) -- Scaling/Dependence Exponent depends on Time
$t$; when $\tilde{Z}(\theta)$ is a Fractional Brownian Motion, the Compound
Process $\tilde{Z}(\theta(t))$ for Fractal or Multifractal, Non-decreasing
Function of Time $\theta(t)$ gives an approximation of Long-range Dependence
with Long-tailed Variability; in order for ``Physical Time'' to be a
Non-decreasing, Self-affine Function of ``Trading Time'', $t(\theta)$ is
required to be a L\'evy Staircase (\S\ref{sec:levy_staircase})

cf. Multifractal Functions (\S\ref{sec:multifractal_function}) -- Integral of
Positive Multifractal Measure

(wiki):

Weyl Integral (\S\ref{sec:weyl_integral}) with respect to White Noise Measure
(TODO: xref Bochner-Minlos Theorem for Nuclear Spaces)

Fractional Brownian Motion can be viewed as White Noise Filtered by
$s^{-H-\frac{1}{2}}$ (corresponding to Fractional Integration
\S\ref{sec:differintegral})

Power Spectral Density (\S\ref{sec:psd})

\emph{Simulation}

1997 - Dietrich, Newsam - \emph{Fast and Exact Simulation of Stationary Gausian
  Processes Through Circulant Embedding of the Covariance Matrix}

Mandelbrot97E, Ch.6:

Fractional Brownian Motion $B_H(t)$ is the Random Process with Gaussian
Increments that satisfy the Diffusion Rule, $\forall t, T$:
\[
  \expect(B_H(t+T) - B_H(t)) = 0 \ \ \ \ \expect(B_H(t+T) - B_H(t))^2 = T^{2H}
\]
(``Fickian Diffusion'' when $H = \frac{1}{2}$)

Cyclic but Non-periodic variability at all Time Scales

\emph{Uniscaling} (\S\ref{sec:scaling_distribution}) -- above definition implies
``Scale Factors'' based on Moments (\S\ref{sec:moment}) satisfy:
\[
  \Big(E(B_H(t + T) - B_H(t)^q)\Big)^{\frac{1}{q}} = c T^H
\]
for all Powers $q > -1$ where $c$ is some Constant, are \emph{independent} of
$q$, i.e.:
\[
  \Delta B_H \sim \Delta t^H
\]
and:
\[
  \frac{\ln|\Delta B_H|}{\ln \Delta{t}} \sim H
\]
(note that $\Delta t$ and $\Delta B_H$ are increments over a non-vanishing
Interval, i.e. not Infinitesimal, and so $H$ is a ``coarse'', not a ``local'',
quantity)

cf. \emph{Multiscaling} (\S\ref{sec:multiscaling}) -- the $q$th Scale Factor
\emph{depends} on $q$

the Past Average $\frac{B_H(0) - B_H(-T)}{T}$ and the Future Average
$\frac{B_H(T) - B_H(0)}{T}$ are Gaussian Variables with Correlation:
\[
  C = 2^{2H-1} - 1
\]
independent of $T$, a fact that follows from \emph{Self-affine Scaling}
(\S\ref{sec:self_affinity})



\subparagraph{Fractional Gaussian Noise}\label{sec:fractional_gaussian}\hfill

Increment Process $X(t) = B_H(t+1) - B_H(t)$

Mandelbrot97E, Ch.6:

Generalized Derivative $B'_H(t)$ as a ``continuing'' or ``humming'' form of
$\frac{1}{f}$ Noise (\S\ref{sec:pink_noise}) with Spectral Density
(\S\ref{sec:spectral_density}) Proportional to $f^{-2H+1}$



\subparagraph{Wiener Process}\label{sec:wiener_process}\hfill

Model of \emph{Brownian Motion} (or \emph{Pedesis})

\fist cf. Brownian Map (\S\ref{sec:brownian_map})

$H = 1/2$

Semimartingale (\S\ref{sec:semimartingale})

given a Wiener Process $W_t$ and Harmonic Function
(\S\ref{sec:harmonic_function}) $f$, the Process $f(W_t)$ is also a Martingale

Stable Process (\S\ref{sec:stable_process})

a Diffusion Process (\S\ref{sec:diffusion_process})

(wiki):
can be viewed as White Noise Filtered by $s^{-1}$ (i.e. Integrated)
--FIXME: clarify

\emph{Donsker's Theorem} (\S\ref{sec:donskers_theorem}) -- a Discrete Random
Walk (\S\ref{sec:simple_random_walk}) converges to true Brownian Motion in the
Scaling Limit (\S\ref{sec:scaling_limit})

\emph{Green's Function} (\S\ref{sec:greens_function}) -- Diffusion Equation
(\S\ref{sec:diffusion_equation})

(Mandelbrot97E):

Invariance Properties:
\begin{itemize}
  \item Stationarity (\S\ref{sec:stationary_process})
  \item Scaling (\S\ref{sec:scale_invariance})
\end{itemize}

other Properties:
\begin{itemize}
  \item Statistical Independence
  \item Continuous, No-where Differentiable
  \item changes over equally spaced Time increments are Independent Gaussian
    Variables
  \item absence of ``clustering'' of large changes in Time
  \item absence of cyclic behavior
\end{itemize}

Fickian Diffusion Rule for a Random Process $B(t)$ with Gaussian Increments $T$,
$\forall t, T$:
\[
  \expect(B(t+T) - B(t)) = 0 \ \ \ \ \expect(B(t+T) - B(t))^2 = T
\]
``Fickian Variance'' is a consequence of Independence of Increments, and Fickian
Variance guarantees the \emph{Orthogonality} (i.e. Un-correlatedness) of
Increments, and adding the Gaussian assumption guarantees Independence (FIXME:
clarify)



\subparagraph{Brownian Bridge}\label{sec:brownian_bridge}\hfill

(wiki):

Continuous-time Stochastic Process $B(t)$ with Probability Distribution equal to
the Conditional Probability Distribution of a Wiener Process $W(t)$, with the
condition (when Standardized) that $W(T) = 0$:
\[
  B_t := (W_t | W_T = 0), t \in [0,T]
\]

\fist Donsker's Theorem (\S\ref{sec:donskers_theorem}), Skorokhod Space
(\S\ref{sec:skorokhod_space})



\subparagraph{Geometric Brownian Motion (GBM)}\label{sec:gbm}\hfill

Stochastic Differential Equations (SDEs \S\ref{sec:sde})

Black-Scholes

(wiki):

GBM as a model of Stock Prices is unrealistic in that Stock Price Volatility
changes over time (possibly Stochastically), but in GBM, Volatility is assumed
Constant; also Stock Prices may have discontinous ``jumps'' in Price, whereas
GBM is Path Continuous

\emph{Local Volatility} -- treat Volatility as a Function of Price and Time

\emph{Stochastic Volatility} -- allow Volatility to be Stochastic



\subsubsection{L\'evy Process}\label{sec:levy_process}

Independent, Stationary Increments: displacements in pairwise Disjoint Time
Intervals are Independent, and Identically Distributed

&#x261e; a Sequence of IID (\S\ref{iid}) Random Variables can be seen as a
Discrete-time L\'evy Process; many L\'evy Processes can be seen as \emph{Limits}
of IID Variables (e.g. Wiener Process as the Limit of the Simple Random Walk)

\fist cf. L\'evy Flight (\S\ref{sec:levy_flight})

\begin{itemize}
  \item Wiener Process (\S\ref{sec:wiener_process})
  \item Poisson Process (\S\ref{sec:poisson_process})
\end{itemize}

aside from ``Brownian Motion with Drift'', all other proper (Non-deterministic)
L\'evy Processes have \emph{Discontinuous Paths}



\paragraph{Cauchy Process}\label{sec:cauchy_process}\hfill

\fist cf. Cauchy Flight (\S\ref{sec:cauchy_flight})

Stable (\S\ref{sec:stable_process})

Pure Jump Process (\S\ref{sec:jump_process})

can be seen as a Brownian Motion Subordinated (\S\ref{sec:compound_process}) to a
Process associated with a L\'evy Distribution (\S\ref{sec:levy_distribution})



% ------------------------------------------------------------------------------
\subsection{Stopped Process}\label{sec:stopped_process}
% ------------------------------------------------------------------------------

(wiki) Stochastic Process that assumes the same Value after a prescribed,
possibly Random, \emph{Stopping Time}

Stopping Time



\subsubsection{Localization}\label{sec:localization}

\begin{itemize}
  \item Local Martingale (\S\ref{sec:local_martingale})
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Stable Process}\label{sec:stable_process}
% ------------------------------------------------------------------------------

associated Probability Distributions (FIXME: clarify() are Stable Distributions
(\S\ref{sec:stable_distribution})

\begin{itemize}
  \item Wiener Process (\S\ref{sec:wiener_process}) -- Normal Distribution
  \item Cauchy Process (\S\ref{sec:cauchy_process}) -- Cauchy Distribution
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Stationary Process}\label{sec:stationary_process}
% ------------------------------------------------------------------------------

Stochastic Process for which the Unconditional (i.e. no reference to any
particular starting value) Joint Probability Distribution
(\S\ref{sec:joint_probability}) does not change when shifted in Time (TODO:
clarify)

\fist an Infinitely Exchangeable Sequence of Random Variables
(\S\ref{sec:infinitely_exchangeable}) is Strictly Stationary (wiki)

\begin{itemize}
  \item Ornstein-Uhlenbeck Process (\S\ref{sec:ornstein_uhlenbeck}) -- a
    Stationary Gauss-Markov Process (\S\ref{sec:gauss_markov_process})
  \item AutoRegressive Moving Average (ARMA \S\ref{sec:arma}) -- Weakly
    Stationary
  \item ...
\end{itemize}

if a Stochastic Process has a Unit Root (\S\ref{sec:unit_root}), i.e. if $1$ is
a Root of the Process's Characteristic Equation (FIXME: characteristic function
???), then the Process is Non-stationary, \emph{but} does not necessarily have a
``trend''

\fist Stationarity assumption underlies many procedures in Time-series Analysis
(\S\ref{sec:time_series})

\fist Statistical Signal Processing (\S\ref{sec:statistical_signal})

the \emph{Wold Decomposition Theorem} (\S\ref{sec:wold_decomposition}) for
Isometric Linear Operators on a given Hilbert Space implies that any Stationary
Discrete-time Stochastic Process can be \emph{Decomposed} into a pair of
Uncorrelated Processes where one is \emph{Deterministic} and the other is a
\emph{Moving Average Process}



\subsubsection{Trend-stationary Process}\label{sec:trend_stationary}

\subsubsection{Covariance-stationary Process}\label{sec:covariance_stationary}

or \emph{Weak-Sense Stationary} or \emph{Wide-Sense Stationary} (WSS)

\fist Order of Integration (Time Series \S\ref{sec:order_of_integration}) --
minimum number of ``differences'' required to obtain a Covariance-stationary
Series (\S\ref{sec:covariance_stationary})



\subsubsection{Difference Stationary Process}\label{sec:difference_stationary}

Unit Root Process (\S\ref{sec:unit_root})



\paragraph{$L$-Stable Motion (LSM)}\label{sec:lsm}\hfill

%FIXME: putting this here under the assumption that "difference stationary"
% means that the distributions of the incremental process random variables are
% stationary

Mandelbrot97E:

(Mandelbrot 1963)

allows for Non-gaussian (Long-tailed) Stable Distributions (Infinite Variance);
note all Stable Distributions (\S\ref{sec:stable_distribution}) besides the
Normal Distribution have Infinite Variance

%FIXME: is l-stable distribution synonymous with stable distribution ???

Integration of a Difference Stationary Process of Random Variables that are
also required to be \emph{Independent} (i.e. flat Frequency Spectrum) and
\emph{Scaling} (\S\ref{sec:scaling_distribution}; i.e. the Distribution of
changes over a short time interval resemble a scaled-down version of price
changes over a long time interval)

$\Lambda$ -- $L$-stable Distribution

$\ln Z(t)$ is an \emph{$L$-Stable Motion} if successive
$L(t, T) = \ln Z(t + T) - \ln Z(t)$ are Independent

Models of Price Variation: LSM (Infinite Variance, ``Tail-driven Variability'';
Stationary, Scaling) + FBM (Long-range Dependence \S\ref{sec:fbm})

\fist Fractal Time (\S\ref{sec:fractal_time}), Multifractal
(\S\ref{sec:multifractal_time}) -- Scaling/Dependence Exponent depends on Time
$t$; when $\tilde{Z}(\theta)$ is a Fractional Brownian Motion, the Compound
Process $\tilde{Z}(\theta(t))$ for Fractal or Multifractal, Non-decreasing
Function of Time $\theta(t)$ gives an approximation of Long-range Dependence
with Long-tailed Variability; in order for ``Physical Time'' to be a
Non-decreasing, Self-affine Function of ``Trading Time'', $t(\theta)$ is
required to be a L\'evy Staircase (\S\ref{sec:levy_staircase})

Ch.5

\fist Seven States of Randomness (\S\ref{sec:statistical_randomness})

Universality of Attraction to Non-Gaussian Limits -- if $U_n$ is in the Domain
of Universality of $\alpha < 2$, the Limit $\sum U_n$ is a Random Variable
called \emph{$L$-stable} as $N \to \infty$:
\[
  N^\frac{1}{\alpha} \sum_{n=1}^N U_n - N \expect{U}
\]
when $1 < \alpha < 2$ and:
\[
  N^\frac{1}{\alpha} \sum_{n=1}^N U_n
\]
when $0 < \alpha < 1$

Ch.6

the Sum of $N$ $L$-stable Variables is itself $L$-stable

Gaussian is the Limit case $\alpha = 2$

for a ``Weighted Index'' of Independent Variables $\sum W_g X_g$, when the
Weights are not Random, the Variables $X$ and the Weighted Index are $L$-stable
(FIXME: clarify)

$L$-stable Variables are Fixed Points in the operation consisting of
transforming Indpendent Random Variables by taking a Non-randomly Weighted
Average

Compound Processes (\S\ref{sec:compound_process}) -- when a Directing Function
is Self-affine, it must be an $L$-stable Non-decreasing Function or ``Stable
Subordinator''

a Wiener Process (\S\ref{sec:wiener_process}) as a Directed Function of a
Fractal Time (\S\ref{sec:fractal_time}) Directing Function yields an $L$-stable
Motion with $\alpha$ ``fed in'' by the L\'evy Staircase
(\S\ref{sec:levy_staircase})



\subsubsection{Conditional Stationarity}\label{sec:conditional_stationarity}

(Mandelbrot98N)

\fist Scaling Distributions: Uniscaling
(\S\ref{sec:scaling_distribution}), Multiscaling (\S\ref{sec:multiscaling})

\fist Sporadic Processes (\S\ref{sec:sporadic_process})



% ------------------------------------------------------------------------------
\subsection{Cyclostationary Process}\label{sec:cyclostationary_process}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Unit Root Process}\label{sec:unit_root}
% ------------------------------------------------------------------------------

if a Stochastic Process has a ``\emph{Unit Root}'', i.e. if $1$ is a Root
(\S\ref{sec:root}) of the Process's Characteristic Equation (FIXME:
characteristic function ???), then the Process is Non-stationary, but does not
necessarily have a ``trend''

\fist not to be confused with Root of Unity (\S\ref{sec:root_of_unity})

Difference Stationary Processes (\S\ref{sec:difference_stationary})



% ------------------------------------------------------------------------------
\subsection{Ergodic Process}\label{sec:ergodic_process}
% ------------------------------------------------------------------------------

a State in a Markov Process (\S\ref{sec:markov_process}) is \emph{Ergodic} if it
is:
\begin{itemize}
  \item Recurrent -- will eventually be returned to
  \item Positive -- has a Finite Mean Recurrence Time
  \item Aperiodic -- the GCD of the number of steps of any return is $1$
\end{itemize}
a Markov Process is Ergodic if all its States are Ergodic

\fist Time-series Analysis (\S\ref{sec:time_series_analysis})

\fist cf. Ergodic Systems Theory (\S\ref{sec:ergodic_theory})



% ------------------------------------------------------------------------------
\subsection{Self-similar Process}\label{sec:self_similar}
% ------------------------------------------------------------------------------

Self-similarity (\S\ref{sec:self_similarity})

sometimes described using Fat-tailed Distributions (\S\ref{sec:fat_tailed})

Long-range Dependence (\S\ref{sec:long_range_dependence})



% ------------------------------------------------------------------------------
\subsection{Random Walk}\label{sec:random_walk}
% ------------------------------------------------------------------------------

%FIXME: move this section ???

an ``unbiased'' Random Walk is an example of a Martingale
(\S\ref{sec:martingale})

cf. Ideal Chains in Polymer Science



\subsubsection{Lattice Random Walk}\label{sec:lattice_random_walk}

Random Walk on a Lattice Graph (\S\ref{sec:lattice_graph}), Paths are Lattice
Paths (\S\ref{sec:lattice_path})

\fist Mean-Field Theory (MFT \S\ref{sec:mft})



\paragraph{Simple Random Walk}\label{sec:simple_random_walk}\hfill

Independent Random Variables $Z_1, Z_2, \ldots$ with State Space $\{1, -1\}$ and
(Binomial) Probability $0.5$ for either value (i.e. each has Mean $0$ and
Variance $1$)

$\{ S_n \}$ where $S_0 = 0$ and $S_n = \sum_{j=1}^n Z_j$ --
\emph{Simple Random Walk} on $\ints$

$E(S_n) = \sum_{j=1}^n E(Z_j) = 0$

$E(S_n^2) = n$

the Expected Distance after $n$ steps, $|S_n|$, is:
\[
  E(|S_n|) = \frac{(n - (n+1)\mod{2})!!}{(n - 1 - (n+1)\mod{2})!!}
\]
where $!!$ is Semifactorial (\S\ref{sec:semifactorial}); this Distance is
related to $\sqrt{n}$, as suggested by the Expected Square Distance being equal
to $n$, by the ratio
$\lim_{n\to\infty} \frac{E(|S_n|)}{\sqrt{n}} = \sqrt{2/\pi}$

in Dimensions $1$ and $2$, the Probability of returning to the Origin is $1$,
but in Dimensions $3$ is is $0.34$, and decreases as the Dimension increases

two Random Walks in Dimensions $4$ or less will almost surely have Infinitely
many Intersections, but for Dimensions $5$ or higher they will almost surely
Intersect only Finitely often

Asymptotic Function for a Two-dimensional Random Walk as the number of steps
increases is given by the Rayleigh Distribution
(\S\ref{sec:rayleigh_distribution})

\emph{Gambler's Ruin} (\emph{Recurrence})-- the Random Walk will cross Zero an
Infinite number of times

\emph{Donsker's Theorem} -- a Simple Random Walk converges to true Brownian
Motion (Wiener Process \S\ref{sec:wiener_process}) in the Scaling Limit
(\S\ref{sec:scaling_limit})



\subparagraph{Simple Bordered Random Walk}\label{sec:simple_bordered_walk}\hfill

Simple Random Walk on a Finite State Space -- Transition Probabilities depend on
the State (Transitions on Border States are limited)



\paragraph{Self-avoiding Walk}\label{sec:selfavoiding_walk}\hfill

(wiki):

a \emph{Self-avoiding Polygon} is the Path of a Closed Self-avoiding Walk

cf. Excluded Volumes in Polymer Science

in two Dimensions, the Fractal Dimension of a Self-avoiding Random Walk is $4/3$

in three Dimensions, the Fractal Dimension of a Self-avoiding Random Walk is
``close to'' $5/3$

in four Dimensions and higher, the Fractal Dimension is $2$

the Lengths of a Self-avoiding Random Walk in the Erdos-R\'enyi Model are
Distributed according to a Gompertz Distribution
(\S\ref{sec:gompertz_distribution})



\subsubsection{Gaussian Random Walk}\label{sec:gaussian_random_walk}

or \emph{Rayleigh Flight}

Random Walk with step size varying according to a Normal Distribution
(\S\ref{sec:normal_distribution})

Model of Financial Markets

Anomalous Diffusion



\subsubsection{Law of Iterated Logarithm}\label{sec:iterated_logarithm}

describes magnitude of Fluctuations of a Random Walk

cf. Law of Large Numbers (\S\ref{sec:large_numbers})



\subsubsection{Markov Process}\label{sec:markov_process}

%FIXME: move this section ???

\fist (Discrete-time) Markov Chain (\S\ref{sec:markov_chain})

\fist Markov Population Model (Population Continuous-time Markov Chain
\S\ref{sec:markov_population})

\fist Markov Decision Process (\S\ref{sec:markov_decision})

(Mandelbrot97E) Probabilistic expression of ``Direct Causality''
(\S\ref{sec:causation})

Short-term Dependency (\S\ref{sec:dependence}); cf. Long-range Dependence
(\S\ref{sec:long_range_dependence})

a State in a Markov Process is \emph{Ergodic} (\S\ref{sec:ergodic_process}) if
it is:
\begin{itemize}
  \item Recurrent -- will eventually be returned to
  \item Positive -- has a Finite Mean Recurrence Time
  \item Aperiodic -- the GCD of the number of steps of any return is $1$
\end{itemize}
a Markov Process is Ergodic if all its States are Ergodic

%FIXME: does the following only apply to markov chains ???

(Wasserman04, \S23.2)

\emph{Markov Property} (``Memorylessness'' \S\ref{sec:memoryless_distribution})
-- Distribution of $X_i$ Depends only on $X_{i-1}$:
\[
  P(X_t = x | X_0, \ldots, X_{t-1}) = P(X_t = x | X_{t-1})
\]
for all $t$ and $x \in \mathcal{X}$

Density:
\[
  f(x_0, \ldots, x_t) = f(x_1)f(x_2|x_1)f(x_3|x_2) \cdots f(x_t|x_{t-1})
\]

a Markov Process can be represented as the DAG:
\[
  X_0 \longrightarrow X_1 \longrightarrow \cdots \longrightarrow X_n
    \longrightarrow \cdots
\]
where each Random Variable has a single parent (the previous Observation)

cf. Poisson Process (\S\ref{sec:poisson_process})

\fist can be seen as a special case of Petri Nets (\S\ref{sec:petri_net}) where
every Transition has a single Input and a single Output

``Equilibria'' -- a Discrete Markov Process where the Histogram (Density
Estimate) of States Converges is said to reach an ``Equilibrium''

a Markov Process is \emph{Homogeneous} if Transition Probabilities
$P(X_{n+1} = j | X_n = i)$ are Constant over time, i.e.:
\[
  P(X_{n+1} = j | X_n = i) = P(X_1 = j| X_0 = i)
\]

a Probability $p_{ij}$:
\[
  p_{ij} \equiv P(X_{n+1} = j | X_n = i)
\]
is called a \emph{Transition Probability}, and the Square Matrix $\mathbf{P}$ of
Transition Probabilities is called the \emph{Transition Matrix} (or
\emph{Stochastic Matrix});
$p_{ij} \geq 0$, and each Row is a Probability Mass Function (\S\ref{sec:pmf}),
since $\sum_i p_{ij} = 1$

an \emph{$n$-step Transition Probability}:
\[
  p_{ij}(n) = P(X_{m+n} = j | X_m = i)
\]
is the Probability of going from State $i$ to State $j$ in $n$ steps

for Homogeneous Markov Processes:

$\mathbf{P}^n$ -- $n$-step Transition Matrix, i.e. $\mathbf{P}$

\emph{Chapman-Kolmogorov Equations}:
\[
  p_{ij}(m + n) = \sum_k p_{ik}(m) p_{kj}(n)
\]
which is the same as Multiplication of the $m$- and $n$-step Transition
Matrices:
\[
  \mathbf{P}^{m+n} = \mathbf{P}^m \mathbf{P}^n
\]
Differential form of the Chapman-Kolmogorov Equation is called a
\emph{Master Equation}

the Marginal Probability that Markov Process is in State $i$ at Time $n$:
\[
  \mu_n(i) = P(X_n = i)
\]

let $\mu_n = [\mu_n(1), \ldots, \mu_n(N)]$ be a Row Vector (``Distribution'')

$\mu_0$ is the \emph{Initial Distribution}

to \emph{Simulate} (\S\ref{sec:stochastic_simulation}) a Markov Process, only
$\mu_0$ and $\mathbf{P}$ are needed:
\begin{enumerate}
  \item ``draw'' $X_0 \sim \mu_0$; therefore $P(X_0 = i) = \mu_0(i)$
  \item when the Outcome of (1.) is $i$, drawing $X_1 \sim \mathbf{P}$ gives
    $P(X_1 = j | X_0 = i) = p_{ij}$
  \item when the Outcome of (2.) is $j$, drawing $X_2 \sim \mathbf{P}$ gives
    $P(X_2 = k | X_1 = j) = p_{jk}$
  \item and so on...
\end{enumerate}

$\mu_n$ gives the Histogram of collecting all Outcomes at Time $n$

(Lemma) the Marginal Probabilities are given by $\mu_n = \mu_0 \mathbf{P}^n$

$j$ is \emph{Accessible} from $i$, $i \to j$, if $p_{ij}(n) > 0$ for
some $n$; if $i \to j$ and $j \to i$, then $i$ and $j$
\emph{Communicate}, $i \leftrightarrow j$

(Thm.) the Communication Relation Satisfies:
\begin{itemize}
  \item $i \leftrightarrow i$
  \item $i \leftrightarrow j \Longrightarrow j \leftrightarrow i$
  \item $i \leftrightarrow j \wedge j \leftrightarrow k \Longrightarrow
    i \leftrightarrow k$
  \item the State Space $\mathcal{X}$ can be written as a Disjoint Union of
    Communication Classes $\mathcal{X}_1 \cup \mathcal{X}_2 \cup \cdots$
    generated by the Communication Relation in which any two States $i$ and $j$
    Communicate with eachother if and only if they are in the same Class
\end{itemize}

if all States Communicate, the Markof Process is called \emph{Irreducible}

a Set of States is \emph{Closed} if once entered, the Process never leaves; a
Closed Set of States consisting of a single State is called an \emph{Absorbing
  State}

if in a State $i$, the Process will eventually return to State $i$ with
Probability $1$:
\[
  \exists n \geq 1 . P(X_n = i | X_0 = i) = 1
\]
then State $i$ is called \emph{Recurrent} or \emph{Persistent}, otherwise $i$ is
\emph{Transient}

(Thm.) a State $i$ is Recurrent if and only if:
\[
  \sum_n p_{ii}(n) = \infty
\]
a State $i$ is Transient if and only if:
\[
  \sum_n p_{ii} < \infty
\]

(Thm.)
\begin{itemize}
  \item if State $i$ is Recurrent and $i \leftrightarrow j$ then $j$ is
    Recurrent
  \item if State $i$ is Transient and $i \leftrightarrow j$ then $j$ is
    Transient
  \item a Finite Markov Process must have at least one Recurrent State
  \item the States of a Finite, Irreducible Markov Process are all Recurrent
\end{itemize}

\emph{Decomposition Theorem}:
the State Space $\mathcal{X}$ can be written as the Disjoint Union:
\[
  \mathcal{X} = \mathcal{X}_T \cup \mathcal{X}_1 \cup \mathcal{X}_2 \cup \cdots
\]
where $\mathcal{X}_T$ are the Transient States and each $\mathcal{X}_i$ is a
Closed, Irreducible Set of Recurrent States

\emph{Recurrence Time}

\emph{Mean Recurrence Time}

a Recurrent State is \emph{Null} if the Mean Recurrence Time is Infinite;
otherwise it is \emph{Positive} (or \emph{Non-null})

(Lemma) if a Sate is Null and Recurrent, then $p_{ii}^n \to 0$

(Lemma) in a Finite State Markov Process, all Recurrent States are Positive

State $i$ has \emph{Period} $d$ if any return to State $i$ \emph{must} occur in
Multiples of $d$ time steps; $d$ is the largest Integer such that
$p_{ii}(n) = 0$ whenever $n$ is not Divisible by $d$ ($\neg d | n$), i.e.
$d = gcd\{n : p_{ii}(n) > 0 \}$

State $i$ is \emph{Periodic} if $d(i) > 1$ and \emph{Aperiodic} if $d(i) = 1$

an Irreducible Markov Process needs only one Aperiodic State to imply all States
are Aperiodic

every State of a Bipartite Graph (\S\ref{sec:bigraph}) has an Even Period

(Lemma) if a State $i$ has Period $d$ and $i \leftrightarrow j$, then $j$ has
Period $d$

a State is \emph{Ergodic} (cf. Ergodic Theory \S\ref{sec:ergodic_theory}) if it
is:
\begin{itemize}
  \item Recurrent -- will eventually be returned to
  \item Positive -- has a Finite Mean Recurrence Time
  \item Aperiodic -- the GCD of the number of steps of any return is $1$
\end{itemize}
a Markov Process is Ergodic if all its States are Ergodic

a Distribution $\pi = [\pi_i : i \in \mathcal{X}]$ is \emph{Stationary} (or
\emph{Invariant}) if $\pi = \pi \mathbf{P}$; i.e. if the Process ever ``has
Distribution'' (FIXME: clarify) $\pi$, then it will continue to have
Distribution $\pi$ forever

a Markov Process has \emph{Limiting Distribution} $\pi$ if:
\[
  P^n \to \begin{bmatrix}
    \pi \\
    \pi \\
    \vdots \\
    \pi \\
  \end{bmatrix}
\]
for some $\pi$, i.e. $\pi_j = \lim_{n\to\infty} \mathbf{P}_{ij}^n$
exists and is independent of $i$

\textbf{Thm.} (Convergence) \emph{
  An Irreducible, Ergodic Markov Process has a
  unique Stationary Distribution $\pi$, and a Limiting Distribution equal to
  $\pi$, and for any Bounded Function $g$, with Probability $1$:
\[
  \lim_{N\to\infty} \frac{1}{N} \sum_{n=1}^N g(X_n) \to E_\pi(g)
    \equiv \sum_j g(j) \pi_j
\]
}

note that a Markov Process having a Stationary Distribution does not imply
Convergence

\emph{Detailed Balance}

\fist Markov Chain Monte Carlo (MCMC \S\ref{sec:mcmc}) -- Estimate the Integral
$\int h(x) f(x) dx$ using a Markov Chain with Stationary Distribution $f$



\paragraph{Birth-death Process}\label{sec:birth_death}\hfill

\subparagraph{Birth Process}\label{sec:birth_process}\hfill

(or \emph{Pure Birth Process})

Zero Deaths

equivalent to a Poisson (Point) Process (\S\ref{sec:point_poisson}) on the Real
Line



\paragraph{Diffusion Process}\label{sec:diffusion_process}\hfill

(wiki):

a Continuous-time Markov Process with Continuous Sample Paths for which the
Kolmogorov Forward Equation is the Fokker-Planck Equation (TODO: xrefs)

solution to a Stochastic Differential Equation (\S\ref{sec:sde})

cf. Diffusion Equation (\S\ref{sec:diffusion_equation})

\begin{itemize}
  \item Brownian Motion (Wiener Process \S\ref{sec:wiener_process})
  \item Reflected Brownian Motion
  \item Ornstein-Uhlenbeck Processes (\S\ref{sec:ornstein_uhlenbeck})
\end{itemize}



\subparagraph{It\^o Diffusion}\label{sec:ito_diffusion}\hfill

Stochastic Drift (\S\ref{sec:stochastic_drift})

\emph{Driftless Diffusion Process} -- ; is a Local Martingale
(\S\ref{sec:local_martingale}) but not necessarily a Martingale



\paragraph{Markov Arrival Process}\label{sec:markov_arrival_process}\hfill

\paragraph{Branching Process}\label{sec:branching_process}\hfill

\paragraph{Gauss-Markov Process}\label{sec:gauss_markov_process}\hfill

Gaussian Process (\S\ref{sec:gaussian_process})



\subparagraph{Ornstein-Uhlenbeck Process}\label{sec:ornstein_uhlenbeck}\hfill

a Stationary Gauss-Markov Process

or \emph{Damped Random Walk}

a Diffusion Process (\S\ref{sec:diffusion_process})



\paragraph{Higher-order Markov Process}\label{sec:higher_order_markov}\hfill

Memory $>1$



\paragraph{L\'evy Flight}\label{sec:levy_flight}\hfill

Random Walk with step lengths distributed according to a L\'evy Distribution
(\S\ref{sec:levy_distribution})

\fist L\'evy Process (\S\ref{sec:levy_process})



\subparagraph{Fractional L\'evy Flight}\label{sec:fractional_levy}\hfill

Dependence

\fist cf. Fractional Brownian Motion (\S\ref{sec:fractional_brownian})



\subparagraph{Cauchy Flight}\label{sec:cauchy_flight}\hfill

Random Walk with step lengths distributed according to a Cauchy Distribution
(\S\ref{sec:cauchy_distribution})

\fist Cauchy Process (\S\ref{sec:cauchy_process})



% ------------------------------------------------------------------------------
\subsection{Martingale}\label{sec:martingale}
% ------------------------------------------------------------------------------

a Random Sequence in which the Conditional Expectation of each successive Value
in the Sequence

may be Discrete-time or Continuous-time

an unbiased Random Walk (\S\ref{sec:random_walk}) is an example of a Martingale

\fist cf. Potential Theory (Potential Theory \S\ref{sec:potential_theory});
(Harmonic Functions \S\ref{sec:harmonic_function})

given a Wiener Process (\S\ref{sec:wiener_process}) $W_t$ and Harmonic Function
$f$, the Process $f(W_t)$ is also a Martingale



\subsubsection{Stopped Brownian Motion}\label{sec:stopped_brownian_motion}

\subsubsection{Bounded Martingale}\label{sec:bounded_martingale}

2019 - Taleb - \emph{Election Predictions as Martingales: An Arbitrage Approach}



\subsubsection{Local Martingale}\label{sec:local_martingale}

cf. Localization (\S\ref{sec:process_localization})

every Bounded Local Martingale is a Martingale, and every Martingale is a Local
Martingale, but not every Local Martingale is a Martingale, e.g. a Driftless
Diffusion Process (\S\ref{sec:ito_diffusion}) is a Local Martingale but not
necessarily a Martingale



\subsubsection{Semimartingale}\label{sec:semimartingale}

(wiki): can be decomposed as the sum of a Local Martingale and an Adaptive
Finite-variation Process (\S\ref{sec:adapted_process})

class of Semimartingales includes Wiener Processes (Brownian Motion
\S\ref{sec:wiener_process}) and Poisson Processes
(\S\ref{sec:poisson_process})

largest class of Processes for which the It\^o Integral
(\S\ref{sec:ito_integral}) and Stratanovich Integral can be defined



\paragraph{Submartingale}\label{sec:submartingale}\hfill

\paragraph{Supermartingale}\label{sec:supermartingale}\hfill

Doob's Convergence Theorems



% ------------------------------------------------------------------------------
\subsection{Counting Process}\label{sec:counting_process}
% ------------------------------------------------------------------------------

a Stochastic Process with values that are Non-negative, Non-decreasing Integers



\subsubsection{Poisson Process}\label{sec:poisson_process}

Counting occurrences of ``Events'' over time (e.g. traffic accidents,
radioactive decay; cf. Propensity Interpretation of Probability)

the Probability Distribution of the time Interval between Events is the
Exponential Distribution (\S\ref{sec:exponential_distribution})

Memoryless

Completely Random Process

Semimartingale (\S\ref{sec:semimartingale})

Properties of a Poisson Process on the Real Line: the number of Points
(``Events'') in Disjoint Intervals are Independent and have a Poisson
Distribution (\S\ref{sec:poisson_distribution})

cf. Markov Process (\S\ref{sec:markov_process}), L\'evy Process
(\S\ref{sec:levy_process})

Queueing Theory (\S\ref{sec:queueing_theory})

Poisson Point Process (\S\ref{sec:point_poisson}) -- spatial generalization of
Poisson Process to the Real Line

Spatial Poisson Process (\S\ref{sec:spatial_poisson}) -- to the Real Plane

(Wasserman04 \S 23.3)

\emph{Intensity Function} $\lambda(t)$

\emph{Homogenous Poisson Process}, \emph{Rate} $\lambda \equiv \lambda(t)$

\emph{Waiting Times} $W_n$, \emph{Interrarival (Sojourn) Times} $S_n$

(Thm.) Interrarival Times are IID Random Variables with Exponential Distribution
with Mean $1/\lambda$, i.e. PDF for $s \geq 0$:
\[
  f(s) = \lambda e^{-\lambda s}
\]
and the Waiting Time $W_n \sim Gamma(n, 1/\lambda)$, i.e. has PDF:
\[
  f(w) = \frac{1}{\Gamma(n)}\lambda^n w^{n-1} e^{-\lambda t}
\]
and therefore:
\begin{flalign*}
  E(W_n) & = \frac{n}{\lambda} \\
  V(W_n) & = \frac{n}{\lambda^2} \\
\end{flalign*}




\subsubsection{Binomial Process}\label{sec:binomial_process}

cf. \emph{Bernoulli Process} (\S\ref{sec:bernoulli_process})



\subsubsection{Renewal Theory}\label{sec:renewal_theory}



% ------------------------------------------------------------------------------
\subsection{Random Measure}\label{sec:random_measure}
% ------------------------------------------------------------------------------

a Measure-valued Random Element (\S\ref{sec:random_variable})

definition as Transition Kernels

\begin{itemize}
  \item $P_n(A) = \frac{1}{n}\sum_{i=1}^n \delta_{X_i}(A)$ --
    Empirical Measure (\S\ref{sec:empirical_measure})
  \item $\mu = \sum_{n=1}^N \delta_{X_n}$ -- Point Process
    (\S\ref{sec:point_process})
\end{itemize}



\subsubsection{Empirical Measure}\label{sec:empirical_measure}

$P_n(A) = \frac{1}{n}\sum_{i=1}^n \delta_{X_i}(A)$

where $\delta$ is the Dirac Measure (\S\ref{sec:dirac_measure})

the CDF (\S\ref{sec:cdf}) associated with the Empirical Measure of a Sample
(\S\ref{sec:sample}) is the \emph{Empirical Distribution Function}
(\S\ref{sec:empirical_distribution})

cf. Empirical Processes (\S\ref{sec:empirical_process})

\fist Mean-Field Theory (MFT \S\ref{sec:mft}) -- Limit Theorems generalize the
Central Limit Theorem for Empirical Measures



\subsubsection{Intensity Measure}\label{sec:intensity_measure}

(wiki) Non-random Measure defined as the Expectation Value (FIXME: expected
value ???) of the Random Measure of a Set, corresponding to the Average Volume
the Random Measure assigns to the Set



\subsubsection{Point Process}\label{sec:point_process}

a \emph{Point Process} (or \emph{(Random) Point Field}) is a Random Measure
(\S\ref{sec:random_measure}) of the form:
\[
  \mu = \sum_{n=1}^N \delta_{X_n}
\]
where $\delta$ is the Dirac Measure (\S\ref{sec:dirac_measure})

a Point Process is a Random Element (\S\ref{sec:random_variable}) whose values
are ``Point Patterns'' or \emph{Locally-finite Counting Measures}
(\S\ref{sec:counting_measure}) on a Set $S$

for most purposes, ``Point Patterns'' can be thought of as Countable Subsets of
$S$ that have no Limit Points (FIXME: clarify)



\paragraph{Poisson Point Process}\label{sec:point_poisson}\hfill

``spatial'' Poisson Process (\S\ref{sec:poisson_process}) on the Real Line

equivalent to a Birth Process (\S\ref{sec:birth_process})

cf. Spatial Poisson Process (\S\ref{sec:spatial_poisson})



\paragraph{Spatial Poisson Process}\label{sec:spatial_poisson}\hfill

Poisson Process (\S\ref{sec:poisson_process}) generalized to the Real Plane



% ------------------------------------------------------------------------------
\subsection{Random Field}\label{sec:random_field}
% ------------------------------------------------------------------------------

(wiki):

a Stochastic Process where the underlying Index Set does not need to be a Real
of Integer Valued ``Time'', but can be any Topological Space
(\S\ref{sec:topological_space})

for a Probability Space $(\Omega, \mathcal{F}, P)$, an \emph{$X$-valued
  Random Field}, $F$, is a collection of $X$-valued Random Variables indexed by
elements in a Topological Space $T$:
\[
  F = \{ F_t : t \in T \}
\]
where each $F_t$ is an $X$-valued Random Variable

Tensor-valued Random Fields

\fist Spatial Analysis (\S\ref{sec:spatial_analysis})



\subsubsection{Markov Random Field}\label{sec:markov_random_field}

(MRF)

Graphical Model (\S\ref{sec:graphical_model})

Boltzmann Machines (\S\ref{sec:boltzmann_machine})



\subsubsection{Gibbs Random Field}\label{sec:gibbs_random_field}

\subsubsection{Conditional Random Field}\label{sec:conditional_random_field}

Machine Learning: Sequence MOdelling



\subsubsection{Gaussian Random Field}\label{sec:gaussian_random_field}

(GRF)

a 1D GRF is a Gaussian Process (\S\ref{sec:gaussian_process})



\subsubsection{Brownian Map}\label{sec:brownian_map}

\url{https://johncarlosbaez.wordpress.com/2020/09/19/the-brownian-map/}

Causal Dynamical Triangulations -- approach to Quantum Gravity

\url{http://www.normalesup.org/~bettinel/simul.html}



\subsubsection{Multivariate Random Field}\label{sec:multivariate_random_field}

%FIXME: is this distinct from random fields in general ???

Covariance Function (\S\ref{sec:covariance_function}) is called the
\emph{Autocovariance}



% ------------------------------------------------------------------------------
\subsection{Empirical Process}\label{sec:empirical_process}
% ------------------------------------------------------------------------------

Empirical Measure (\S\ref{sec:empirical_measure}):

Empirical Distribution Function (\S\ref{sec:empirical_distribution}):

$P_n(A) = \frac{1}{n}\sum_{i=1}^n \delta_{X_i}(A)$

where $\delta$ is the Dirac Measure (\S\ref{sec:dirac_measure})

\fist Mean-Field Theory (MFT \S\ref{sec:mft}) -- Limit Theorems generalize the
Central Limit Theorem for Empirical Measures (\S\ref{sec:empirical_measure})



\subsubsection{Markov Population Model}\label{sec:markov_population}

\emph{Population Continuous-time Markov Chain}



\subsubsection{Donsker's Theorem}\label{sec:donskers_theorem}

a Discrete Random Walk (\S\ref{sec:simple_random_walk}) converges to true
Brownian Motion (Wiener Process \S\ref{sec:wiener_process}) in the Scaling Limit
(\S\ref{sec:scaling_limit})

\fist Brownian Bridge (\S\ref{sec:brownian_bridge}), Skorokhod Space
(\S\ref{sec:skorokhod_space})



% ------------------------------------------------------------------------------
\subsection{Dirichlet Process}\label{sec:dirichlet_process}
% ------------------------------------------------------------------------------

a Probabilty Distribution with Range over a Set of Probability Distributions

Bayesian Inference (\S\ref{sec:bayesian_inference})

Concentration Parameter (\S\ref{sec:concentration_parameter})



% ------------------------------------------------------------------------------
\subsection{Markov Model}\label{sec:markov_model}
% ------------------------------------------------------------------------------

Markov Chain (\S\ref{sec:markov_chain}) -- Autonomous, Fully Observable

Hidden Markov Model (HMM \S\ref{sec:hmm}) -- Autonomous, Partially Observable

Markov Decision Process (MDP \S\ref{sec:mdp}) -- Controlled, Fully Observable

Partially Observable Markov Decision Process (POMDP \S\ref{sec:pomdp}) --
Controlled, Partially Observable



\subsubsection{Hidden Markov Model (HMM)}\label{sec:hmm}

simplest Dynamic Bayes Network (\S\ref{sec:dynamic_bayes_network})



% ------------------------------------------------------------------------------
\subsection{Generalized Random Function}\label{sec:generalized_random}
% ------------------------------------------------------------------------------

(Mandelbrot98N)



\subsubsection{Sporadic Process}\label{sec:sporadic_process}

Conditional Stationarity (\S\ref{sec:conditional_stationarity})

forms of Scaling: Uniscaling (\S\ref{sec:scaling_distribution}), Multiscaling
(\S\ref{sec:multiscaling})



% ------------------------------------------------------------------------------
\subsection{Stochastic Simulation}\label{sec:stochastic_simulation}
% ------------------------------------------------------------------------------

approximation of Integrals (\S\ref{sec:numerical_integration})

approximation of Posteriors (\S\ref{sec:posterior_distribution}) in Bayesian
Inference (\S\ref{sec:bayesian_inference})

cf. Stochastic Gradient Descent (SGD \S\ref{sec:sgd})



\subsubsection{Monte Carlo Simulation}\label{sec:monte_carlo}

Computational Algorithms based on repeated Random Sampling
(\S\ref{sec:random_sample})

cf. ``Historical Simulation''

Monte Carlo Integration (\S\ref{sec:monte_carlo_integration}) -- Monte Carlo
Method applied to Numerical Integration

Importance Sampling (\S\ref{sec:importance_sampling}) can be used to reduce
Variance

Pseudo-random Number Sampling (\S\ref{sec:pseudorandom_sampling})



\paragraph{Markov Chain Monte Carlo (MCMC)}\label{sec:mcmc}\hfill

Markov Chain (\S\ref{sec:markov_chain})

(Wasserman04 \S24.4)

Estimate the Integral $\int h(x) f(x) dx$ using a Markov Chain with Stationary
Distribution $f$

\emph{Random-walk Metropolis-Hastings}

\emph{Independence Metropolis-Hastings} -- Importance-sampling
(\S\ref{sec:importance_sampling})

\emph{Gibbs Sampling} -- higher Dimensions; Multilevel Models
(\S\ref{sec:multilevel_model})



\subparagraph{Hybrid Monte Carlo}\label{sec:hybrid_monte_carlo}\hfill

or \emph{Hamiltonian Monte Carlo})



% ------------------------------------------------------------------------------
\subsection{Probability Monad}\label{sec:probability_monad}
% ------------------------------------------------------------------------------

1980 - Giry - \emph{A Categorical Approach to Probability Theory}

collapsing a Probability Distribution (Measure) of Probability Distrubtions to a
Probability Distribution is called the ``Giry Monad'' (TODO)

\url{https://ncatlab.org/nlab/show/Giry+monad}

assigns to a Space of Outcomes $X$ a new Space $P X$ containing Random Outcomes
of $X$

\url{https://golem.ph.utexas.edu/category/2019/05/partial_evaluations.html}
(Perrone 2018):

Partial Evaluations (\S\ref{sec:partial_evaluation}) as Conditional Expectations
(\S\ref{sec:conditional_expectation})



\subsection{Kantorovich Monad}\label{sec:kantorovich_monad}

(Breugel)

\url{https://golem.ph.utexas.edu/category/2019/03/the_kantorovich_monad.html}

Probability Monad on the Category of Metric Spaces; can be described purely in
terms of Combinatorics of Finite Sequences of Elements

2017 - Fritz, Perrone - \emph{A Probability Monad as the Colimit of Spaces of
  Finite Samples}



% ==============================================================================
\section{Statistical Mechanics}\label{sec:statistical_mechanics}
% ==============================================================================

Thermodynamics, ``Irreversibility''

Jarzynski Equality

Crooks' Fluctuation Theorem



% ------------------------------------------------------------------------------
\subsection{Non-equilibrium Statistical Mechanics}
\label{sec:nonequilibrium_statistical_mechanics}
% ------------------------------------------------------------------------------

Jarzynski



% ------------------------------------------------------------------------------
\subsection{Statistical Ensemble}\label{sec:statistical_ensemble}
% ------------------------------------------------------------------------------

a Probability Distribution (\S\ref{sec:probability_distribution}) for the state
of a Physical System



\subsubsection{Thermodynamic Ensemble}\label{sec:thermodynamic_ensemble}



% ------------------------------------------------------------------------------
\subsection{Mean-Field Theory (MFT)}\label{sec:mft}
% ------------------------------------------------------------------------------

no long-range Correlation

\fist Empirical Processes (\S\ref{sec:empirical_process}); Limit Theorems
generalize the Central Limit Theorem for Empirical Measures
(\S\ref{sec:empirical_measure})



\subsubsection{Landau Theory}\label{sec:landau_theory}

general theory of Second-order (i.e. \emph{Continuous}) Phase Transitions

appearance of Fractals in some Scale-free Properties



% ------------------------------------------------------------------------------
\subsection{Stochastic Loewner Evolution}\label{sec:stochastic_loewner}
% ------------------------------------------------------------------------------

Family of Random Planar Curves that are the Scaling Limit of a variety of
Two-dimensional Lattice Models:
\begin{itemize}
  \item Self-avoiding Walks (\S\ref{sec:selfavoiding_walk})
  \item ...
\end{itemize}



% ==============================================================================
\section{Geometric Probability}\label{sec:geometric_probability}
% ==============================================================================

``\emph{Continuous Combinatorics}'': analogies between \emph{Counting} and
\emph{Measure} (\S\ref{sec:measure}) \fist Combinatorics (Part
\ref{part:combinatorics}), Measure Theory (Part \ref{part:measure_theory})



% ------------------------------------------------------------------------------
\subsection{Integral Geometry}\label{sec:integral_geometry}
% ------------------------------------------------------------------------------

Theory of Measures (\S\ref{sec:measure}) on ``Geometrical Space'' Invariant
under Symmetry Group (\S\ref{sec:symmetry_group}) of that Space

Integral Transforms (\S\ref{sec:integral_transform}) as Equivariant
Transformations from the Function Space of one Geometrical Space to another
(e.g. Radon Transform)



% ------------------------------------------------------------------------------
\subsection{Stochastic Geometry}\label{sec:stochastic_geometry}
% ------------------------------------------------------------------------------



% ==============================================================================
\section{Information Geometry}\label{sec:information_geometry}
% ==============================================================================

Harper09 - \emph{The Replicator Equation as an Inference Dynamic}

Harper09 - \emph{Information Geometry and Evolutionary Game Theory}

\url{http://math.ucr.edu/home/baez/information/}

\url{https://johncarlosbaez.wordpress.com/2017/01/31/biology-as-information-dynamics/}

application of Differential Geometry
(\S\ref{sec:differential_geometry}) techniques to Probability Theory

2018 - Nielsen - \emph{An elementary introduction to information geometry}



% ------------------------------------------------------------------------------
\subsection{Statistical Manifold}\label{sec:statistical_manifold}
% ------------------------------------------------------------------------------

Riemannian Manifold (\S\ref{sec:riemannian_manifold}) with the
\emph{Fisher Information Metric} as the Riemannian Metric
(\S\ref{sec:riemannian_metric})



\subsubsection{Fisher Information Metric}\label{sec:fisher_metric}

$I$

Riemannian Metric (\S\ref{sec:riemannian_metric}) for a Statistical Manifold

Score Function (\S\ref{sec:score})

Fisher Information Matrix

Jeffrey's Prior (\S\ref{sec:prior_distribution})

\fist \textbf{Fisher's Fundamental Theorem of Natural Selection},
Quasi-linkage Equilibrium: approximation in the case of Weak Selection
and Weak Epistasis -- Evolutionary Optimization
(\S\ref{sec:evolutionary_optimization}) %FIXME

\url{https://golem.ph.utexas.edu/category/2018/05/the_fisher_metric_will_not_be.html}



% ==============================================================================
\section{Quantum Probability Theory}\label{sec:quantum_probability}
% ==============================================================================

Quantum Logic (\S\ref{sec:quantum_logic})

\emph{Quantum Logic and Probability Theory} (2002) -
\url{https://plato.stanford.edu/entries/qt-quantlog/}

Quantum Systems (\S\ref{sec:quantum_system})

(Witten18): Quantum Information Theory doesn't have a good analog to defining a
Conditional Probability Distribution as in Classical Information Theory, but
does have an analog of \emph{Strong Subadditivity of Entropy}
(\S\ref{sec:entropy})

\url{https://ncatlab.org/nlab/show/quantum+probability+theory}

\emph{Quantum Probability}: classical Probability Theory generalized to
Non-commutative Probability Spaces (\S\ref{sec:quantum_probability_space})

\emph{Bayesian Interpretation of Quantum Mechanics}: that Quantum Physics is
Quantum Probability Theory

Quantum Probability as Probability Theory \emph{Internal} to the Bohr Topos
(\S\ref{sec:bohr_topos}) of a given Quantum Mechanical System



% ------------------------------------------------------------------------------
\subsection{Quantum Probability Space}\label{sec:quantum_probability_space}
% ------------------------------------------------------------------------------

or \emph{Non-commutative Probability Space}

e.g. Quantized Phase Space
