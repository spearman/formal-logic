%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Probability Theory}\label{part:probability_theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\fist Measure Theory (Part \ref{part:measure_theory})

\fist Probabilistic Logic (\S\ref{sec:probabilistic_logic}) --
2013 - \emph{Logic and Probability} -
\url{https://plato.stanford.edu/entries/logic-probability/} (Stanford
Encyclopedia of Philosophy)

\fist cf. Inductive Logic (\S\ref{sec:inductive_logic}) -- makes extensive use
of Probabilistic notions

\emph{Bayesian Epistemology}: Probability as a formal representation of Belief
(cf. Bayesian Inference \S\ref{sec:bayesian_inference})

\emph{Knowledge Representation}: Probability in Artificial Intelligence

\fist cf. Fuzzy Logic (\S\ref{sec:fuzzy_logic})

\fist cf. Quantum Logic (\S\ref{sec:quantum_logic}) --
\emph{Quantum Logic and Probability Theory} (2002) -
\url{https://plato.stanford.edu/entries/qt-quantlog/}

\fist Decision Theory (\S\ref{sec:decision_theory}) --
(wiki): Probabilistic Decision Theory is Sensitive
(\S\ref{sec:sensitivity_analysis}) to \emph{Assumptions} about Probabilities of
Events; Non-probabilistic Decision Rules (\S\ref{sec:decision_rule}), such as
Minimax (\S\ref{sec:minimax}), are \emph{Robust} (\S\ref{sec:robust_statistics})
in that they don't make such Assumptions (FIXME: clarify)

2018 - \emph{A Categorical Look at Random Variables} -
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html} (article):

$\cat{Prob}$ -- Category with Objects as Probability Spaces
(\S\ref{sec:probability_space}) and Morphisms are ``Almost-everywhere-equality
Equivalence Classes'' of Measure-preserving Maps

``Probability Theory is \emph{not} about the Category $\cat{Prob}$, in the sense
that Group Theory or Topology might be said (however incompletely) to be about
the Categories $\cat{Grp}$ or $\cat{Top}$''

\emph{Isomorphic Objects} in $\cat{Prob}$ are \emph{not} the same from the point
of view of \emph{Probability Theory}

example: the Distributions (\S\ref{sec:probability_distribution}) of a Uniform
Random Variable in an Interval, an Infinite Sequence of independent ``coin
flips'', and Brownian Motion $\{B_t : t \geq 0\}$ are \emph{different} things in
Probability Theory, but are Isomorphic in $\cat{Prob}$

the fundamental ``objects'' in Probability Theory are the Morphisms of
$\cat{Prob}$ and those Morphisms are \emph{Random Variables}
(\S\ref{sec:random_variable})

\fist Giry Monads (Probability Monads \S\ref{sec:probability_monad})

\asterism

1933 - Kolmogorov - \emph{Foundations of the Theory of Probability}

\emph{Field of Probabilities} (\emph{$\sigma$-algebra}
(\S\ref{sec:sigma_algebra})



% ==============================================================================
\section{Experiment}\label{sec:experiment}
% ==============================================================================

(wiki): any ``procedure'' that can be infinitely repeated and has a well-defined
Set of possible \emph{Outcomes} (\S\ref{sec:outcome})

when an Experiment is ``performed'' (or ``conducted'') one and only one possible
Outcome ``results'', and any Events (\S\ref{sec:probability_event}), i.e.
Subsets of the Sample Space, containing that Outcome are said to have
``occurred''

a \emph{Random Experiment} has more than one possible Outcome; a Random
Experiment with exactly two possible (Mutually Exclusive) outcomes is called a
\emph{Binomial (Bernoulli) Trial} (\S\ref{sec:bernoulli_trial})

a \emph{Deterministic Experiment} has only a single possible Outcome

a number of repetitions of an Experiment is called a \emph{Composed Experiment},
and the individual repetitions are called ``\emph{Trials}'' (\S\ref{sec:trial})

after conducting many Trials of the same Experiment, the \emph{Relative
  Frequency} (Empirical Probability \S\ref{sec:relative_frequency}) of the
various Outcomes and Events can be assessed



% ------------------------------------------------------------------------------
\subsection{Trial}\label{sec:trial}
% ------------------------------------------------------------------------------

an individual repetition of a Composed Experiment



\subsubsection{Binomial Trial}\label{sec:binomial_trial}

or \emph{Bernoulli Trial}

Binomial Distribution (\S\ref{sec:binomial_distribution}); special case:
Bernoulli Distribution (\S\ref{sec:bernoulli_distribution})

Mathematical Formalization: Bernoulli Process (\S\ref{sec:bernoulli_process})

\begin{enumerate}
  \item repeated Trials
  \item each Trial results in an Outcome
  \item Probability of Success is Constant
  \item each Trial is Independent
\end{enumerate}

Number of Successes in $n$ Bernoulli Trials is a \emph{Binomial Random
  Variable} (\S\ref{sec:binomial_random_variable})



% ------------------------------------------------------------------------------
\subsection{Outcome}\label{sec:outcome}
% ------------------------------------------------------------------------------

a possible result of an Experiment (or Trial)

a Subset of Outcomes in a Sample Space is called an \emph{Event}
(\S\ref{sec:probability_event})

if an actual Outcome is inside an Event, the Event is said to have
``\emph{occurred}''

\fist cf. \emph{Observation} (or \emph{Realization} \S\ref{src:observation}):
the ``Outcome'' of a \emph{Random Variable} (\S\ref{sec:random_variable}), i.e.
the Member of the Random Variable's State Space corresponding to an Outcome
which occurred in the Sample Space of a performed Experiment



% ------------------------------------------------------------------------------
\subsection{Sample Space}\label{sec:sample_space}
% ------------------------------------------------------------------------------

a.k.a. \emph{Possibility Space} or \emph{Event Space}

Set of all possible Outcomes of Statistical \emph{Experiment}
(\S\ref{sec:experiment})

$S$

an \emph{Event} (\S\ref{sec:probability_event}) is a Subset of a Sample Space

the Probability (\S\ref{sec:probability}) $P$ of an Event $E$ is usually defined
such that $P$ satisfies the Kolmogorov Axioms (\S\ref{sec:probability_axioms})
\fist \emph{Unit Measure Axiom}: the total Probability of the Sample Space is
$1 = P(S)$

Random Variable (\S\ref{sec:random_variable}): Function on a Sample Space to a
Measurable \emph{State Space}

a Statistical Model (\S\ref{sec:statistical_model}) $(S,\mathcal{P})$ is a
Sample Space $S$ together with a Set of Probability Distributions
(\S\ref{sec:probability_distribution}) $\mathcal{P}$ on $S$



% ------------------------------------------------------------------------------
\subsection{Event}\label{sec:probability_event}
% ------------------------------------------------------------------------------

Subset of a Sample Space (\S\ref{sec:sample_space})

if an actual Outcome is inside an Event (Subset), the Event is said to have
``\emph{occurred}''

\emph{Probability} (\S\ref{sec:probability})

(Kolmogorov33) analogy between the \emph{Measure} (\S\ref{sec:measure}) of a Set
and the Probability of an Event

(FIXME: cf. Observation \S\ref{sec:observation})



\subsubsection{Elementary Event}\label{sec:elementary_event}

or \emph{Atomic Event} or \emph{Simple Event} is an Event which contains only a
\emph{single Outcome} in the Sample Space, i.e. it is a Singleton Subset of the
Sample Space

the Unitarity Axiom (\S\ref{sec:probability_axioms}) states that the
Probability that at least one of the Elementary Events in the Entire Sample
Space will Occur is $1$



\subsubsection{Mutually Exclusive Event}\label{sec:mutually_exclusive}

$\sigma$-additivity Axiom (\S\ref{sec:probability_axioms}): the Probability of
a Countable Sequence of Disjoint Sets is equal to the Sum of the individual
Probabilities

a Quasiprobability Distribution (\S\ref{sec:quasiprobability_distribution})
violates the $\sigma$-additivity Axiom by not representing Probabilities of
Mutually Exclusive States



\subsubsection{Independent Event}\label{sec:independent_event}

\fist cf. Independence (\S\ref{sec:independence})

Independent if and only if $P(A \cap B) = P(A) P(B)$

in terms of Conditional Probability (\S\ref{sec:conditional_probability}), $A$
and $B$ are Independent if and only if $P(A|B) = P(A)$ or $P(B|A) = P(B)$

an Event is Self-independent if and only if $P(A) = 0$ or $P(A) = 1$

$n$ Events are Independent if:
\[
  P(A_i \cap A_j \cap \cdots \cap A_g) = P(A_i)P(A_j) \cdots P(A_g)
\]
for any distinct Events $i,j,\ldots,g$

Pairwise Independence does not imply $n$-way Independence

$P(A \cap B | C) = P(A|C)P(B|C)$

\fist Conditional Independence (\S\ref{sec:conditional_independence})

note that two Events may be Independent, but not \emph{Conditionally}
Independent, i.e. the Intersection of each Independent Event $A$ and $B$ with
the Conditioning Event $C$ may be Disjoint, making them \emph{Dependent}



% ==============================================================================
\section{Probability}\label{sec:probability}
% ==============================================================================

Probability of an Event (\S\ref{sec:probability_event}) $A$, $P(A)$ is the Sum
of Weights of all Sample Points in $A$

the Probability $P$ of an Event $E$ is usually defined such that $P$ satisfies
the Kolmogorov Axioms (\S\ref{sec:probability_axioms})

(Kolmogorov33) analogy between the \emph{Measure} (\S\ref{sec:measure}) of a Set
and the Probability of an Event

cf. Uncertainty (\S\ref{sec:uncertainty})

$\frac{|A|}{|S|}$

$P(A \cup B) = P(A) + P(B) - P(A \cap B)$

$P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) -
P(B \cap C) + P(A \cap B \cap C)$

Corollary: for Disjoint $A_1, A_2, \ldots$:
\[
  P(A_1 \cup A_2 \cup \ldots) = P(A_1) + P(A_2) + \ldots
\]

$P(A_1 \cap A_2 \cap \ldots \cap A_k) = P(A_1) P(A_2 | A_1) P(A_3 |
A_1 \cap A_2) \ldots P(A_k | A_1 \cap A_2 \cap \ldots \cap A_{k-1})$

\textbf{(Thm.) Continuity of Probabilities} \emph{If $A_n \rightarrow A$, then:}
\[
  P(A_n) \rightarrow P(A)
\]
\emph{as $n \rightarrow \infty$}.

cf. \emph{Probability Measure} (\S\ref{sec:probability_measure}),
\emph{Probability Measure Function} (\S\ref{sec:probability_measure_function})

\fist Algorithmic Probability (\S\ref{sec:algorithmic_probability})

(wiki):

two broad categories of \emph{Probability Interpretations}:
\begin{enumerate}
  \item \emph{Physical Probabilities} -- ``Objective'' or \emph{Frequency
    Probabilities} associated with ``Random'' Physical Systems
    \begin{enumerate}
      \item \emph{Frequentist Probability} (``Long-run Probability'') -- defines
        an Event's (\S\ref{sec:probability_event}) Probability as the Limit of
        its Relative Frequency (Empirical Probability
        \S\ref{sec:relative_frequency}) in a large number of Trials
        (\S\ref{sec:trial}); cf. Frequentist Inference
        (\S\ref{sec:frequentist_inference})
      \item \emph{Propensity Probability} (``Single-case Probability'') -- a
        Propensity (\S\ref{sec:propensity}) is not a Relative Frequency but a
        purported ``\emph{cause}'' or explanation of the observed stable
        Relative Frequencies; invokes the Law of Large Numbers
        (\S\ref{sec:large_numbers}) to explain stable \emph{long-run}
        Frequencies as a manifestation of invariant \emph{single-case}
        Probabilities
    \end{enumerate}
  \item \emph{Evidential Probabilities} -- \emph{Bayesian Probability};
    interpretation of Probability as ``reasonable'' \emph{Expectation}
    (\S\ref{sec:expectation}) or ``degree of belief''; assigns Probability to
    Statements even when no Random Process (\S\ref{sec:stochastic_process}) is
    involved; assigns Probability to Hypotheses (\S\ref{sec:hypothesis}), unlike
    Frequentist Inference which Tests Hypotheses without assigning Probability
    \begin{enumerate}
      \item \emph{Classical Interpretation}
      \item \emph{Subjective Interpretation}
      \item \emph{Inductive (Epistemic) Interpretation}
      \item \emph{Logical Interpretation}
      \item \emph{Intersubjective Interpretation}
    \end{enumerate}
\end{enumerate}

2011 - \emph{Interpretations of Probability} -
\url{https://plato.stanford.edu/entries/probability-interpret/}:
\begin{itemize}
  \item \emph{Classical Probability} (Laplace) -- Probability shared equally
    among ``possible outcomes'' (cf. Keynes ``Principle of Indifference'');
    issues include Infinite Probability Spaces and the elimination of
    Irrational-valued Probabilities; extension to Countable Infinities by
    generalizing the Principle of Indifference to the ``Principle of Maximum
    Entropy'' (Jaynes)-- select from the family of all Probability Functions
    consistent with evidence the Function that maximizes Entropy; for
    difficulties with Uncountable Infinities cf. the \emph{Bertrand Paradox}--
    Probabilities may not be Well-defined if the method that produces the Random
    Variable is not Well-defined, cf. \emph{Invariance Condition} (Jaynes): two
    problems with the same evidence should assign the same Probabilities
  \item \emph{Logical Probability} (``Non-deductive Logic''
    \S\ref{sec:probabilistic_logic}) -- generalizes Classical Interpretation to
    assigning unequal weights to possibilities, and Probabilities may be
    computed from asymmetric evidence; generalizes Deductive Logic and its
    notion of Implication to a complete theory of Inference with a notion of
    ``\emph{Degree of Implication}'' that relates Evidence to Hypotheses;
    Deductive Logic is the case where the Confirmation Function takes values 0
    and 1; Carnap-- choice of Language and Confirmation Function are in a sense
    arbitrary
  \item \emph{Subjective Probability} (``Subjective Bayesianism'', cf.
    Subjective Logic \S\ref{sec:subjective_logic}) --
    Probability as a \emph{degree of ``belief''}, cf. Doxastic Logic
    (\S\ref{sec:doxastic_logic}); betting analysis (de Finetti): ``operational''
    definition of Probability as a measurement of belief as a basis of action
    (Ramsey); Utilities (``desirabilities'') of outcomes, Probabilities of
    outcomes, and ``rational Preferences'' can be derived from one another in
    different ways-- (Ramsey26) derives Utilities and Probabilities from
    Preferences alone (``Logic of Partial Belief''); see also ``Expected Utility
    Representation'' (Savage54, Jeffrey66) ``Decision Theory''
    (\S\ref{sec:decision_theory}) in which ``rational choice'' maximizes
    Expected Utility;
    these accounts presuppose a connection between ``desire-like states'' and
    ``belief-like states'' rendered explicit in the connections between
    Preferences and Probabilities;
    \emph{Orthodox Bayesianism}, Conditioning (\S\ref{sec:conditioning});
    compare also Probabilistic Coherence (Regularity)--only \emph{a priori}
    falsehoods are assigned Probability 0--to Consistency in ordinary Doxastic
    Logic; cf. Moore's Paradox
  \item \emph{Frequency Interpretations} -- Relative Frequency (Empirical
    Probability \S\ref{sec:relative_frequency}); identifies the Probability of
    an Outcome with the Frequency of the Outcome in a suitable Sequence of
    ``trials''; differs from the Classical Interpretation in counting only the
    \emph{actual} Outcomes instead of the \emph{possible} Outcomes; Finite
    Frequentism (Venn)-- dominant view in Statistics; problems handling
    single-cases and ``unrepeatable'' events; Hypothetical Frequentism:
    extension of Relative Frequencies of an actual Sequence of ``Trials'' to
    counterfactual, limiting Relative Frequencies in case of an Infinite number
    of Trials; Reference Class Problem: Relative Frequencies must be
    ``Relativised'' to a ``Reference Class'' (this problem may exist for other
    interpretations as well)-- solutions restrict to certain Sequences of
    Outcomes, e.g. (Infinite) ``\emph{Collectives}'' (Von Mises57)--cf. Infinite
    Bernoulli Sequences (\S\ref{sec:bernoulli_sequence})--where a
    \emph{Place-selection} is an effective method of selecting indices of
    Members of a Sequence such that the selection or not of Index $i$ depends
    \emph{at most} on the first $i-1$ Outcomes (``attributes''), with the Axioms
    of Convergence (the limiting Relative Frequency of any Outcome exists) and
    Randomness (the limiting Relative Frequency of each Outcome in a Collective
    $\omega$ is the same in any Infinite Subsequence of $\omega$ determined by
    Place-selection; note that trivial Sequences such as $H,H,H,\ldots$ satisfy
    this ``Randomness'' Axiom; cf. the Principle of Maximum Entropy in Classical
    Probability), Algorithmic Randomness (\S\ref{sec:algorithmic_randomness});
    issues with limiting Relative Frequencies are that they violate Countable
    Additivity and the Domain of Definition is not a Set-field or a
    $\sigma$-algebra (de Finetti72)
  \item \emph{Propensity Interpretations} (Pierce10, Popper57) -- Probability as
    a ``physical'' tendency or disposition of a given ``physical situation'' to
    yield an Outcome of a certain kind, or to yield long-run Relative Frequency
    of such an Outcome; motivated by ``single-case'' Probability attributions
    (e.g. atom decay); distinction between \emph{long-run} and
    \emph{single-case} Propensities (Gillies00); \emph{Humphreys' Paradox}:
    Propensities as measures of ``causal tendencies'' violates Bayes' Theorem
    which allows the reversal of a Conditional Probability-- cf. alternative
    ``Probabilistic Causal Calculus'' (Fetzer81)
  \item \emph{Best-system Interpretations} (Lewis94) -- a Theory of the
    ``Physical Laws'' of the Universe ``optimally balances'' simplicity,
    strength, and ``fit'' (assigning a higher Probability to the ``actual''
    history of the Universe
\end{itemize}

(\url{https://plato.stanford.edu/entries/logic-probability/}):

Probabilistic Semantics (\S\ref{sec:probabilistic_semantics}) for Logical
Consequence Relation yields \emph{Probability Preserving} (dually,
\emph{Uncertainty Propagating}) Deductive Validity (\S\ref{sec:validity}),
rather than Truth Preserving (\S\ref{sec:truth_preservation})

\emph{Probability, Knowledge, and Meta-probability}:
\url{https://www.lesswrong.com/posts/2xmKZu73gZLDEQw7c/probability-knowledge-and-meta-probability}



% ------------------------------------------------------------------------------
\subsection{Probability Axioms}\label{sec:probability_axioms}
% ------------------------------------------------------------------------------

\emph{Kolmogorov Axioms}

the Probability $P$ of an Event $E$ is usually defined such that $P$ satisfies
the Kolmogorov Axioms

\begin{enumerate}
  \item (\emph{Non-negativity}) The Probability of an Event is a Non-negative
    (Finite) Real Number
  \item (\emph{Unit Measure}) The Probability that at least one of the
    Elementary Events in the entire Sample Space will Occur is $1$
  \item (Countable \emph{$\sigma$-additivity}) Any Countable Sequence of
    Disjoint Sets (Mutually Exclusive Events) $E_1, E_2, \ldots$ satisfies:
    \[
      P (\bigcup_{i=1}^\infty = \sum_{i=1}^\infty P(E_i)
    \]
\end{enumerate}

\fist Unit Measure: cf. \emph{Unitarity} in Physics is used as a synonym for
``Consistency'', esp. the condition that the Hamiltonian is bounded from below,
i.e. there is a State of Minimal Energy (the \emph{Ground State} or
\emph{Vacuum State}), which is needed for the Third Law of Thermodynamics to
hold

the Third Axiom is relaxed in Quasiprobability Distributions
(\S\ref{sec:quasiprobability_distribution}); to compensate sometimes they are
allowed to have regions of Negative Probability
(\S\ref{sec:negative_probability}) Density

\fist cf. Probabilistic Logic (\S\ref{sec:probabilistic_logic})



% ------------------------------------------------------------------------------
\subsection{Law of Total Probability}\label{sec:total_probability}
% ------------------------------------------------------------------------------

For a Countably Inifinite Partition of a Sample Space
(\S\ref{sec:sample_space}), $\{ B_n : n = 1,2,3,\ldots \}$, with each Event
$B_n$ being Measurable (\S\ref{sec:measure}), then for any Event $A$ in the same
Probability Space (\S\ref{sec:probability_space}):
\[
  P(A) = \sum_n P(A \cap B_n)
\]
or equivalently:
\[
  P(A) = \sum_n P(A|B_n) P(B_n)
\]
where terms such that $P(B_n) = 0$ are omitted from the summation.



% ------------------------------------------------------------------------------
\subsection{Conditional Probability}\label{sec:conditional_probability}
% ------------------------------------------------------------------------------

where Event $A$ is known to have occurred:

$P(B|A) = \frac{P(A \cap B)}{P(A)}$ when $P(A) > 0$

$P(A \cap B) = P(A) P(B|A)$ when $P(A) > 0$

$P(A|A) = 1$

note that Conditional Probability is only defined when the Conditioning Event
has a Non-zero (Positive) Probability

$A$ and $B$ are Independent (\S\ref{sec:independent_event}) if and only if
$P(A|B) = P(A)$

\fist Conditional Independence (\S\ref{sec:conditional_independence})

\fist Negative Probability (\S\ref{sec:negative_probability})

(Witten18): Quantum Information Theory doesn't have a good analog to defining a
Conditional Probability Distribution as in Classical Information Theory, but
does have an analog of \emph{Strong Subadditivity of Entropy}
(\S\ref{sec:entropy})



% ------------------------------------------------------------------------------
\subsection{Baye's Theorem}\label{sec:bayes_theorem}
% ------------------------------------------------------------------------------

or \emph{Bayes Rule}

\url{https://arbital.com/p/bayes_rule/?l=1zq}

\emph{Bayesian Inference} (\S\ref{sec:bayesian_inference})

\[
  P(A|B) = \frac{P(A)P(B|A)}{P(B)}
\]

for a Partition $A_1, \ldots, A_k$ of $\Omega$ such that $P(A_i) > 0$ for all
$i$, if $P(B) > 0$ then for $i \in \{1, \ldots, k\}$:
\[
  P(A_i|B) = \frac{
    P(B|A_i)P(A_i)
  }{
    \sum_j P(B|A_j)P(A_j)
  }
\]
where $A_i$ is the \emph{Prior Probability} of $A$ and $P(A_i|B)$ is the
\emph{Posterior Probability} of $A$ (FIXME: what is $A$ here ???)

\fist Relative Entropy (Kullback-Leibler Divergence
\S\ref{sec:relative_entropy})



% ------------------------------------------------------------------------------
\subsection{Independence}\label{sec:independence}
% ------------------------------------------------------------------------------

\emph{Property of Probabilistic Independence}

$P(A \cap B) = P(A)P(B)$

two Random Variables (\S\ref{sec:random_varible}) are \emph{Dependent}
(\S\ref{sec:dependence}) if they do not Satisfy the Property of
Probabilistic Independence:
\[
  P(X \in A, Y \in B) = P(X \in A) P(Y \in B)
\]

\fist cf. Independent Event (\S\ref{sec:independent_event})



\subsubsection{Conditional Independence}\label{sec:conditional_independence}

$P(A \cap B | C) = P(A|C)P(B|C)$

note that two Events may be Independent, but not \emph{Conditionally}
Independent, i.e. the Intersection of each Independent Event $A$ and $B$ with
the Conditioning Event $C$ may be Disjoint, making them \emph{Dependent}

\fist Conditional Probability (\S\ref{sec:conditional_probability})

\url{http://lesswrong.com/lw/pi/classical_configuration_spaces/}
-- ``Conditional Independence happens when the Joint Probability Distribution
is the Product of the individual Probability Distributions''



% ------------------------------------------------------------------------------
\subsection{Central Limit Theorem}\label{sec:central_limit}
% ------------------------------------------------------------------------------

``the Distribution of a Sum of Independent Random Variables can be approximated
by a Normal Distribution''

$z = \frac{\overline{x} - \mu}{\sfrac{\sigma}{\sqrt{n}}}$ as
$n \rightarrow \infty$ is $n(z; 0,1)$ %FIXME

\fist an instance of \emph{Renormalization} (\S\ref{sec:renormalization})

\fist origin of ``Multifractality'' (\S\ref{sec:multifractal_system}) in
Sequential (Time Series) data attributed to ``convergence effects'' related to
the Central Limit Theorem that have Foci of Convergence in the family of Tweedie
Exponential Dispersion Models (Probability Distributions
\S\ref{sec:tweedie_distribution})



% ------------------------------------------------------------------------------
\subsection{Negative Probability}\label{sec:negative_probability}
% ------------------------------------------------------------------------------

or \emph{Quasiprobability}

may apply to \emph{Unobservable Events} or \emph{Conditional Probability}
(\S\ref{sec:conditional_probability})

forbidden by the First Kolmogorov Axiom (\S\ref{sec:probability_axioms})

the Third Axiom ($\sigma$-additivity) is relaxed in Quasiprobability
Distributions (\S\ref{sec:quasiprobability_distribution}); to compensate
sometimes they are allowed to have regions of Negative Probability Density,
violating the First Law

Wigner Distribution in Phase Space (Quantum Corrections)



% ==============================================================================
\section{Probability Space}\label{sec:probability_space}
% ==============================================================================

$(\Omega, \Sigma, P)$

A \emph{Probability Space} is a Measure Space (\S\ref{sec:measure_space}) with a
\emph{Probability Measure} (\S\ref{sec:probability_measure}).

\fist cf. Measure-preserving Dynamical Systems
(\S\ref{sec:measure_preserving_system})

$\cat{Prob}$ -- Category with Objects as Probability Spaces and Morphisms are
``Almost-everywhere-equality Equivalence Classes'' of Measure-preserving Maps
--
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html}:
``Probability Theory is not about the Category $\cat{Prob}$''

$\cat{Prob}$ -- Category with Objects as Probability Spaces and Morphisms are
``Almost-everywhere-equality Equivalence Classes'' of Measure-preserving Maps
(\S\ref{sec:measure_preserving_map})

the fundamental ``objects'' of Probability Theory are the \emph{Morphisms} of
$\cat{Prob}$ and these Morphisms are \emph{Random Variables}
(\S\ref{sec:random_variable})



% ------------------------------------------------------------------------------
\subsection{Probability Measure}\label{sec:probability_measure}
% ------------------------------------------------------------------------------

A \emph{Probability Measure} is a Measure (\S\ref{sec:measure}) that assigns the
Value $1$ to the entire Measure Space (making it a Probability Space).

cf. \emph{Probability} (\S\ref{sec:probability})

\fist a \emph{Probability Distribution} (\S\ref{sec:probability_distribution})
is the Pushforward Measure (\S\ref{sec:pushforward_measure}) of a Random
Variable (\S\ref{sec:random_variable})



\subsubsection{Probability Measure Function}
\label{sec:probability_measure_function}



% ==============================================================================
\section{Random Variable}\label{sec:random_variable}
% ==============================================================================

a Measurable Function (\S\ref{sec:measurable_function}) on a Sample Space
(\S\ref{sec:sample_space}) mapping Outcomes (\S\ref{sec:outcome}) in the Sample
Space to some other Set of Values called the \emph{State Space}

$X : \Omega \rightarrow E$

Discrete Random Variable (\S\ref{sec:discrete_random_variable})

Continuous Random Variable (\S\ref{sec:continuous_random_variable})

\fist a \emph{Probability Distribution} (\S\ref{sec:probability_distribution})
is the Pushforward Measure (\S\ref{sec:pushforward_measure}) of $X$

a \emph{Dependence} (Association \S\ref{sec:association}) between two Random
Variables (``Bivariate Data'' \S\ref{sec:bivariate_distribution}) is any
``Statistical Relationship'' (which may or may not be Causal)

two Random Variables $X$ and $Y$ are \emph{Independent}, sometimes denoted $X
\coprod Y$, if they Satisfy the Property of \emph{Probabilistic Independence}
(\S\ref{sec:independence}):
\[
  P(X \in A, Y \in B) = P(X \in A) P(Y \in B)
\]
that is, for every $x$ and $y$, the Events $\{X \leq x\}$ and $\{Y \leq y\}$ are
Independent Events (\S\ref{sec:independent_event}); in terms of CDFs:
\[
  \forall x,y\ F_{X,Y}(x,y) = F_X(x)F_Y(y)
\]
or in terms of Probability Mass or Density Functions (if they exist):
\[
  \forall x,y\ f_{X,Y}(x,y) = f_X(x)f_Y(y)
\]

\textbf{Thm.} \emph{If the Range of Random Variables $X$ and $Y$ is a (possibly
  Infinite) Rectangle and $f_{X,Y}(x,y) = g(x)h(y)$ for arbitrary Functions $g$
  and $h$, then $X$ and $Y$ are Independent.}

\fist Relative Entropy (\S\ref{sec:relative_entropy}), Mutual Information
(\S\ref{sec:mutual_information})

cf. \emph{Statistical Randomness} (\S\ref{sec:statistical_randomness}),
\emph{Algorithmic Randomness} (\S\ref{sec:algorithmic_randomness})

a Discrete Random Variable $Y = r(X)$ that is a Transformation of a Discrete
Random Variable $X$, the Probability Mass Function is given by:
\[
  f_Y(y) = P(Y = y) = P(r(X) = y) = P(X \in r^{-1}(y))
\]
for Continuous Random Variables, the CDF is defined as the Integral of the PDF
$f_X(x)$ over the Set $A_y = \{x : r(x) \leq y\}$:
\[
  F_Y(y) = \int_{A_y} f_X(x) dx
\]
and the PDF can be defined as $f_Y(y) = F_Y'(y)$

for Continuous $X$ with CDF $F_X$, $Y = F_X(X)$ is called a \emph{Probability
  Integral Transform} (\S\ref{sec:probability_integral_transform}) and has a
Standard Uniform Distribution

\asterism

\emph{A Categorical Look at Random Variables} -
\url{https://golem.ph.utexas.edu/category/2018/09/a_categorical_look_at_random_v.html}:

$\cat{Prob}$ -- Category with Objects as Probability Spaces
(\S\ref{sec:probability_space}) and Morphisms are ``Almost-everywhere-equality
Equivalence Classes'' of Measure-preserving Maps
(\S\ref{sec:measure_preserving_map})

the fundamental ``objects'' of Probability Theory are the \emph{Morphisms} of
$\cat{Prob}$ and these Morphisms are \emph{Random Variables}

a Random Variable is defined as a Measurable Map
(\S\ref{sec:measurable_function}):
\[
  X : \Omega \rightarrow E
\]
where $(\Omega,\mathbb{P})$ is a Probability Space and $E$ is an arbitrary
Measurable Space

***

MIT 6.041SC Lec. 5 - \url{https://www.youtube.com/watch?v=3MOahpLxj6A}:

Functions of Random Variables are also Random Variables

Probability Mass Function (\S\ref{sec:pmf}) $p_X$ assigns
Probabilities to Elements of $x \in E$:
\[
  p_X(x) = P(X = x)
\]

$p_X(x) \geq 1$

$\sum_x p_X(x) = 1$

Expected Value (\S\ref{sec:expected_value}) of a Random Variable is a kind of
``average'' where Probabilities are treated like ``frequencies'':
\[
  E[X] = \sum_x xp_X(x)
\]
for a Function of a Random Variable $Y = g(X)$:
\[
  E[Y] = \sum_x g(x)p_X(x)
\]

for a PMF that is Symmetric around a certain point, that point is the Expected
Value



% ------------------------------------------------------------------------------
\subsection{Observation}\label{sec:observation}
% ------------------------------------------------------------------------------

An \emph{Observation} (\emph{Observed Value}, \emph{Realization}, or
\emph{Random Variate}) is the Element of a Random Variable's State Space
corresponding to the actual Outcome (\S\ref{sec:outcome}) resulting from
performing an Experiment (\S\ref{sec:experiment}).

\emph{``data point''}

\fist a \emph{(Statistical) Population} (\S\ref{sec:population}) is a totality
of Observations

\fist Curve Fitting (\S\ref{sec:curve_fitting}): the process of constructing a
Curve (or Function) that has the ``best Fit'' to a Series of data points
(Observations), possibly subject to constraints

\fist cf. \emph{Observable} (\S\ref{sec:observable})



% ------------------------------------------------------------------------------
\subsection{Expected Value}\label{sec:expected_value}
% ------------------------------------------------------------------------------

The \emph{Expected Value}, \emph{Expectation}, or \emph{Mean} (First Raw Moment
\S\ref{sec:moment}) of a Random Variable is a kind of ``average'' where
Probabilities are treated like ``frequencies''. (FIXME: clarify)

(Kolmogorov33) analogy between the \emph{Expectation} of a Random Variable, and
\emph{Lebesgue Integration} (\S\ref{sec:lebesgue_integral})

For a Random Variable $X$ defined on Probability Space $(\Omega,\Sigma,P)$, the
Expected Value $\mu_X = E[X]$ of $X$ is defined as the Lebesgue Integral:
\[
  \mu_X = E[X] = \int_\Omega X(\omega) dP(\omega)
\]

In terms of the Cumulative Distribution Function (\S\ref{sec:cdf}) $F_X$ of $X$
and a Radon Integral (\S\ref{sec:radon_integral}):
\[
  \mu_X = E[X] = \int\limits_{-\infty}^{\infty} x dF_X(x)
\]

note that some Distributions have no Expected Value, e.g. the Cauchy
Distribution (\S\ref{sec:cauchy_distribution})

For Discrete Random Variable $X$ with Probability Mass Function
(\S\ref{sec:pmf}) $f_X(x)$, the Expected Value of $X$ is:
\[
  E[X] = \sum_x x f_X(x)
\]
For a PMF that is Symmetric around a certain point, that point is the Expected
Value.

For a Continuous Random Variable $X$ with Probability Density Function
(\S\ref{sec:pdf}) $f_X(x)$, the Expected Value of $X$ is:
\[
  E[X] = \int x f(x) dx
\]

for a Function of a Random Variable $Y = g(X)$:
\[
  E[Y] = \sum_x g(x)p_X(x)
\]

for \emph{Linear Function} $g$:
\[
  E[g(X)] = g(E[X])
\]

Expectations of Constants (i.e. as ``degenerate'' Random Variables) are just
the Constants themselves: $E[a] = a$

Expectations of Random Variables multiplied by Constant is the Constant
multiplied by the Expectation of the Random Variable:
\[
  E[aX] = aE[X]
\]

Expectation of a Random Variable with the addition of a Constant is the
Constant added to the Expectation of the Random Variable:
\[
  E[X + b] = E[X] + b
\]

Law of Large Numbers (\S\ref{sec:large_numbers})

For Random Variable $X$ with Probability Distribution $f(x)$, the
Expected Value of a Measurable Function
(\S\ref{sec:measurable_function}) of $X$, $g(X)$, is:
\[
  \mu_{g(X)} = E[g(X)] = \int\limits_{-\infty}^{\infty} g(x) f(x) dx
\]

For Joint Probability Density Function:
\[
  E[X Y] = \int\int x y j(x,y) dx dy
\]
\fist Note that $E[X Y]$ is not necessarily equal to $E[X] E[Y]$, see Covariance
(\S\ref{sec:covariance}).

For $X$ and $Y$ Independent (\S\ref{sec:independence}), then
$E[X,Y] = E[X] E[Y]$

If $a$ and $b$ are Constants, then $E[aX +b] = a E[X] + b$

$E [g(X) \pm h(X)] = E[g(X)] \pm E[h(X)]$

$E [g(X,Y) \pm h(X,Y)] = E[g(X,Y)] \pm E[h(X,Y)]$

the Variance (Expected Value of the Squared Deviation \S\ref{sec:deviation}) of
a Random Variable $X$ is equal to:
\begin{align*}
  Var(X) & = E[(x - E[X])^2] \\
         & = E[X^2] - (E[X])^2 \\
\end{align*}

example of Probability as a special case of Expectation (Wasserman Ch. 3): for
Event $A$ with Indicator Function $I_A(x)$:
\[
  E(I_A(X)) = \int I_A(x)f_X(x)dx = \int_A f_X(x) dx = P(X \in A)
\]

the \emph{$k^{th}$ Moment} (\S\ref{sec:moment}) of $X$ is defined as $E(X^k)$
assuming that $E(|X|^k) < \infty$



\subsubsection{Law of Large Numbers}\label{sec:large_numbers}

\fist cf. Law of Iterated Logarithm (\S\ref{sec:iterated_logarithm})

\fist \emph{Propensity Probability} (``Single-case Probability''
\S\ref{sec:propensity}) -- invokes the Law of Large Numbers to explain stable
\emph{long-run} Relative Frequencies (\S\ref{sec:relative_frequency}) as a
manifestation of invariant \emph{single-case} Probabilities



% ------------------------------------------------------------------------------
\subsection{Variance}\label{sec:variance}
% ------------------------------------------------------------------------------

the \emph{Variance} is the Expected Value of the Squared Deviation of a Random
Variable

Second Central Moment (\S\ref{sec:moment})

Variances are always Non-negative

the Variance of a Random Variable $X$ is equal to:
\begin{align*}
  Var(X) & = E[(x - E[X])^2] \\
         & = E[X^2] - (E[X])^2 \\
\end{align*}
where $E[\cdot]$ is the Expected Value (\S\ref{sec:expected_value}) of a
Random Variable

Discrete Random Variable $X$:
\[
  Var(X) = \sigma_X^2 = \sum_{i=1}^n f(x_i) (x_i - \mu)^2 = \sum_{i=1}^n
  f(x_i) x_i^2 - \mu^2
\]
where $\mu = \sum_{i=1}^n f(x_i) x_i$

Continuous Random Variable $X$:
\[
  Var(X) = \sigma_X^2 = \int (x - \mu)^2 f(x) dx = \int x^2 f(x) dx -
  \mu^2
\]
where $\mu = \int x f(x) dx$

For Random Variables $X$, $Y$ with Joint Probability Distribution
$f(x,y)$ and $a$, $b$, $c$ are Constants, then:
\[
  \sigma^2_{a X + b Y + c} = a^2 \sigma^2_X + b^2 \sigma^2_Y + 2ab
  \sigma_{X Y}
\]



% ------------------------------------------------------------------------------
\subsection{Skewness}\label{sec:skewness}
% ------------------------------------------------------------------------------

Asymmetry %FiXME

``lopsided-ness''

Third Central Moment (\S\ref{sec:moment})



% ------------------------------------------------------------------------------
\subsection{Kurtosis}\label{sec:kurtosis}
% ------------------------------------------------------------------------------

Fourth Central Moment (\S\ref{sec:moment})

 Measure of the ``heaviness'' of the tail of a Distribution



% ------------------------------------------------------------------------------
\subsection{Dependence}\label{sec:dependence}
% ------------------------------------------------------------------------------

or \emph{Dependence}

any ``\emph{Statistical Relationship}'' between two Random Variables
(``Bivariate Data'')

may or may not be Causal

Random Variables are \emph{Dependent} if they do not Satisfy the Property of
\emph{Probabilistic Independence} (\S\ref{sec:independence})



\subsubsection{Correlation}\label{sec:statistical_correlation}

measure of how close two Random Variables are to having a \emph{Linear
  Relationship}

\fist Correlation Coefficient (\S\ref{sec:correlation_coefficient})



\paragraph{Correlation Coefficient}\label{sec:correlation_coefficient}\hfill

\emph{Pearson Product-moment Correlation Coefficient}

$\rho_{xy} = \frac{\sigma_{xy}}{\sigma_x \sigma_y}$



% ------------------------------------------------------------------------------
\subsection{Covariance}\label{sec:covariance}
% ------------------------------------------------------------------------------

$X$, $Y$, Joint Probability Distribution
(\S\ref{sec:joint_probability}) $f(x,y)$

Discrete:
\[
  \sigma_{xy} = E [(x - \mu_X)(y - \mu_Y)] = \sum_x \sum_y (x - \mu_X)
  (y - \mu_Y) f(x,y)
\]

Continuous:
\[
  \sigma_{xy} = E [(x - \mu_X)(y - \mu_Y)] =
  \int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty}
  (x - \mu_X) (y - \mu_Y) f(x,y) dx dy
\]



\subsubsection{Covariance Matrix}\label{sec:covariance_matrix}

Positive semi-definite (\S\ref{sec:positive_semidefinite})



% ------------------------------------------------------------------------------
\subsection{Moment-generating Function}\label{sec:moment_generating_function}
% ------------------------------------------------------------------------------

the Cauchy Distribution (\S\ref{sec:cauchy_distribution}) has no
Moment-generating Function



% ------------------------------------------------------------------------------
\subsection{Characteristic Function}\label{sec:characteristic_function}
% ------------------------------------------------------------------------------

for a Scalar Random Variable $X$, the \emph{Characteristic Function} is the
Expected Value of $e^{itX}$ where $i$ is the Imaginary Unit and $t \in \reals$
is the Argument of the ``Characteristic Function'' $\varphi_X : \reals
\rightarrow \comps$:
\[
  \varphi_X(t) = E[e^{itX}] = \int_\reals e^{itx} dF_X(x)
\]
where $F_X$ is the Cumulative Distribution Function (\S\ref{sec:cdf}) of $X$ and
the Integral is a Riemann-Sieltjes Integral (TODO: xref)

always exists even when the Moment-generating Function
(\S\ref{sec:moment_generating_function}) and Probability Density Function
(\S\ref{sec:pdf}) do not

like the Cumulative Distribution Function, completely determines the behavior
and properties of the Probability Distribution

if the Random Variable admits a Probability Density Function
(\S\ref{sec:pdf}) then the Characteristic Function is the
Fourier Transform (\S\ref{sec:fourier_transform}) of the Probability Density
Function and vice versa

if a Random Variable has a Moment-generating Function
(\S\ref{sec:moment_generating_function}) then the Characteristic Function can be
extended to the Complex Plane

\fist cf. Indicator Functions (\S\ref{sec:indicator_function})



% ------------------------------------------------------------------------------
\subsection{Discrete Random Variable}\label{sec:discrete_random_variable}
% ------------------------------------------------------------------------------

State Space is a Countable Set

has a Cumulative Distribution Function (\S\ref{sec:cdf}) that is Piecewise
Constant (\S\ref{sec:step_function})

\fist Discrete Probability Distributions (\S\ref{sec:discrete_probability})



\subsubsection{Probability Mass Function (PMF)}\label{sec:pmf}

for a Discrete Random Variable $X$, the \emph{Probability Mass Function} is
defined as:
\[
  f_X(x) = P(X = x)
\]
and has the Properties:
\begin{enumerate}
  \item $f_X(x) \geq 0$
  \item $\sum_x f_X(x) = 1$
\end{enumerate}

characterizes a Discrete Probability Distribution
(\S\ref{sec:discrete_probability})

related to the CDF (\S\ref{sec:cdf}) $F_X$ of $X$ by:
\[
  F_X(x) = P(X \leq x) = \sum_{x_i \leq x} f_X(x_i)
\]

for a Probability Mass Function that is Symmetric around a certain point, that
point is the Expected Value (\S\ref{sec:expected_value})



\paragraph{Probability Generating Function}
\label{sec:probability_generating_function}\hfill

(Ordinary) Generating Function (\S\ref{sec:generating_function})--i.e. Formal
Power Series representation--of the Probability Mass Function of a Discrete
Random Variable



\subsubsection{Binomial Random Variable}\label{sec:binomial_random_variable}

Binomial (Bernoulli) Trial (\S\ref{sec:binomial_trial})

Binomial Distribution (\S\ref{sec:binomial_distribution})

$X \sim B(n,p)$

Probability Mass Function:
\[
  f(k,n,p) = P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}
\]
for $k = 0,1,2, \ldots, n$



% ------------------------------------------------------------------------------
\subsection{Continuous Random Variable}\label{sec:continuous_random_variable}
% ------------------------------------------------------------------------------

has Probability $0$ of assuming a particular Value

\fist Continuous Probability Distributions (\S\ref{sec:continuous_probability})


\subsubsection{Probability Density Function (PDF)}\label{sec:pdf}


\emph{Probability Density Function} $f_X(x)$ of a Continuous Random Variable $X$
has the Properties:
\begin{enumerate}
  \item $\forall x \in \reals, f_X(x) \geq 0$
  \item $\int\limits_{-\infty}^{\infty} f_X(x) dx = 1$
  \item $\forall a \leq b, P (a < X < b) = \int\limits_a^b f(x) dx$
\end{enumerate}
the CDF (\S\ref{sec:cdf}) $F_X$ of $X$ can be defined in terms of $f_X$ as:
\[
  F_X(x) = \int_{-\infty}^x f_X(t)dt
\]
i.e. the CDF of a Continuous Random Variable gives the Area under the PDF from
$-\infty$ to $x$, and $f_X(x) = F'_X(x)$ at all Points $x$ at which $F_X$ is
Differentiable

characterizes a Continuous Probability Distribution
(\S\ref{sec:continuous_probability})

for a Random Variable that admits a Probability Density Function, the
Characteristic Function (\S\ref{sec:characteristic_function}) of the Random
Variable is the Fourier Transform (\S\ref{sec:fourier_transform}) of its
Probability Density Function and vice versa

\fist Probability Amplitude (Quantum Systems \S\ref{sec:probability_amplitude}):
Complex Number with Modulus Squared representing a Probability Density



\paragraph{Normalizing Constant}\label{sec:normalizing_constant}\hfill

used to reduce any Probability Function to a Probability Density Function with
total Probability $1$



% ------------------------------------------------------------------------------
\subsection{Multivariate Random Variable}\label{sec:random_vector}
% ------------------------------------------------------------------------------

or \emph{Random Vector}

$X = (X_1, \ldots, X_n)$

Multinomial Distribution (\S\ref{sec:multinomial_distribution})

Multivariate Normal Distribution (\S\ref{sec:multivariate_normal})



\subsubsection{Independent and Identically Distributed (IID)}\label{sec:iid}

if $X_1, \ldots, X_n$ are Independent and each has the same Marginal
Distribution (\S\ref{sec:marginal_distribution}) with CDF $F$, then $X_1,
\ldots, X_n$ are said to be \emph{Independent and Identically Distributed
  (IID)}, writing:
\[
  X_1, \ldots, X_n \sim F
\]
and if $F$ has Density $f$, then:
\[
  X_1, \ldots, X_n \sim f
\]
$X_1, \ldots, X_n$ are called a \emph{Random Sample} of Size $n$ from $F$ 

cf. Random Population Samples \S\ref{sec:random_sample}) -- in Statistics it is
commonly assumed that Observations are IID



% ==============================================================================
\section{Probability Distribution}\label{sec:probability_distribution}
% ==============================================================================

the Pushforward Measure (\S\ref{sec:pushforward_measure}) of a Random Variable
(\S\ref{sec:random_variable})

cf. Probability Measure (\S\ref{sec:probability_measure})

\emph{Probability Distribution Function} of a Random Variable $X$ often means
the Cumulative Distribution Function (\S\ref{sec:cdf}) $F_X$, but can also refer
to:
\begin{itemize}
  \item Probability Mass Function (\S\ref{sec:pmf}) -- Discrete Probability
    Distributions (\S\ref{sec:discrete_probability})
  \item Probability Density Function (\S\ref{sec:pdf}) -- Continuous Probability
    Distributions (\S\ref{sec:continuous_probability})
\end{itemize}

\fist cf. Probability Measure Function
(\S\ref{sec:probability_measure_function}), Distribution Function (Measure
Theory \S\ref{sec:distribution_function}), Distribution (Analysis
\S\ref{sec:distribution}), Frequency Distribution
(\S\ref{sec:frequency_distribution})

a Statistical Model (\S\ref{sec:statistical_model}) $(S,\mathcal{P})$ is a
Sample Space (\S\ref{sec:sample_space}) $S$ together with a Set of Probability
Distributions $\mathcal{P}$ on $S$

\fist Random Graphs (\S\ref{sec:random_graph}) -- Probability Distribution over
a Graph

collapsing a Probability Distribution (Measure) of Probability Distrubtions to a
Probability Distribution is called the ``Giry Monad'' (TODO)

(wiki): a Statistical (or Population) Parameter
(\S\ref{sec:population_parameter}) is a ``quantity'' that indexes a Family of
Probability Distributions

the Entropy (\S\ref{sec:entropy}) of a Distribution is the Mean number
of Bits-per-symbols in an Optimal Encoding (\S\ref{sec:encoding}) --
\url{https://golem.ph.utexas.edu/category/2017/02/functional_equations_iii_expla.html}

Cross Entropy (\S\ref{sec:cross_entropy}) measures the average number of Bits
needed to identify an Event drawn from an underlying Set of Events under two
Probability Distributions $p$ and $q$, if the ``coding scheme'' is optimized for
an ``unnatural'' Distribution $q$ rather than a ``true'' Distribution $p$
%FIXME: clarify

\emph{Principle of Maximum Entropy}; cf. Axiom of Randomness in Frequentist
Probability (Von Mises57)

(Witten18): Quantum Information Theory doesn't have a good analog to defining a
Conditional Probability Distribution (\S\ref{sec:conditional_probability}) as in
Classical Information Theory, but does have an analog of \emph{Strong
  Subadditivity of Entropy}

the Quantum analog of a Classical Probability Distribution is a \emph{Density
  Matrix} (\S\ref{sec:density_matrix}), a representation of the Linear
\emph{Density Operator} \S\ref{sec:density_operator})-- a Self-adjoint
(Hermitian), Positive Semi-definite, Trace One, and may be Infinite-dimensional
Matrix; every Matrix with these properties can be ``Purified'', meaning that it
is the Density Matrix of \emph{some} Pure State on some ``Bipartite'' System
$AB$; there is no ``classical analog'' for Purification, i.e. there is no way to
make Probability Distribution ``pure'' (one outcome with Probability $1$) by
adding more Variables



% ------------------------------------------------------------------------------
\subsection{Moment}\label{sec:moment}
% ------------------------------------------------------------------------------

the \emph{$k^{th}$ Moment} of $X$ is defined as $E(X^k)$ assuming that
$E(|X|^k) < \infty$

\textbf{Thm.} \emph{If $j < k$ and the $k$th Moment Exists, then the $j$th
  moment exists.}

Mean (Expected Value \S\ref{sec:expected_value}) -- First Raw Moment

Variance (\S\ref{sec:variance}) -- Second Central Moment

Skewness (\S\ref{sec:skewness}) -- Third Central Moment; ``lopsided-ness''

Kurtosis (\S\ref{sec:kurtosis}) -- Fourth Central Moment; Measure of the
``heaviness'' of the tail of a Distribution

\fist Moment-generating Function (\S\ref{sec:moment_generating_function})



% ------------------------------------------------------------------------------
\subsection{Cumulative Distribution Function (CDF)}\label{sec:cdf}
% ------------------------------------------------------------------------------

(wiki):

the \emph{Cumulative Distribution Function (CDF)} of a Real-valued Random
Variable $X$ evaluated at $x$ is equal to the Probability that $X$ will take a
value less than or equal to $x$:
\[
  \forall x \in \reals, F_X(x) = P(X \leq x)
\]
every CDF is Non-decreasing and Right-continuous

special case of Distribution Function (Measure Theory
\S\ref{sec:distribution_function}) with the boundary conditions
$\lim_t\rightarrow\infty F_X(t) = 0$ and $\lim_{t\rightarrow\infty}F_X(t) = 1$

every Function with these four Properties is a CDF, i.e. for every such Function
a Random Variable can be defined such that the Function is a CDF of that Random
Variable

a Random Variable $X$ with CDF $F$ is indicated by the notation $X \sim F$, but
note that this does not mean ``apprximate equality''

the CDF $F_X$ of a Discrete Random Variable can be related to its Probability
Mass Function (\S\ref{sec:pmf}) $f_X$ by:
\[
  F_X(x) = P(X \leq x) = \sum_{x_i \leq x} f_X(x_i)
\]

the CDF of a Continuous Random Variable can be expressed as the Integral of its
Probability Density Function (\S\ref{sec:pdf}) $f_X$:
\[
  F_X(x) = \int\limits_{-\infty}^x f_X(t) dt
\]
i.e. the CDF of a Continuous Random Variable gives the Area under the PDF from
$-\infty$ to $x$

if $F_X$ is Absolutely Continuous (\S\ref{sec:absolute_continuity}), then there
exists a Lebesgue-integrable Function $f_X(x)$ such that:
\[
  F_X(b) - F_X(a) = P(a < X \leq b) = \int_a^b f_X(x) dx
\]
for all Real Numbers $a, b$ and $f_X$ is the PDF of the Distribution of $X$
and equals the Derivative of $F_X$ almost everywhere



\subsubsection{Quantile Function}\label{sec:quantile_function}

\emph{Inverse CDF} $F^{-1}$

$F^{-1}(0.25)$ -- \emph{First Quartile}

$F^{-1}(0.5)$ -- \emph{Median} (or \emph{Second Quartile})

$F^{-1}(0.75)$ -- \emph{Third Quartile}



\paragraph{Probit}\label{sec:probit}\hfill

Quantile Function of the Normal Distribution



% ------------------------------------------------------------------------------
\subsection{Discrete Probability Distribution}
\label{sec:discrete_probability}
% ------------------------------------------------------------------------------

Probability Distribution of a Discrete Random Variable
(\S\ref{sec:discrete_random_variable})

characterized by a Probability Mass Function (\S\ref{sec:pmf})

Cumulative Distribution Function (\S\ref{sec:cdf}) increases only by Jump
Discontinuities

\begin{itemize}
  \item \emph{Point Mass Distribution} -- $X \sim \delta_a$ has CDF:
    \[
      F_X(x) = \begin{cases}
        0 & x <    a \\
        1 & x \geq a \\
      \end{cases}
    \]
    and PMF:
    \[
      f_X(x) = \begin{cases}
        1 & x = a \\
        0 & \text{otherwise} \\
      \end{cases}
    \]
  \item \emph{Discrete Uniform Distribution} (\S\ref{sec:uniform_distribution})
  \item \emph{Bernoulli Distribution} (\S\ref{sec:bernoulli_distribution}) --
    $X \sim Bernoulli(p)$
  \item \emph{Binomial Distribution} (\S\ref{sec:binomial_distribution}) --
    $X \sim Binomial(n,p)$
  \item \emph{Geometric Distribution} (\S\ref{Sec:geometric_distribution}) --
    $X \sim Geom(p)$
  \item \emph{Poisson Distribution} (\S\ref{Sec:poisson_distribution}) --
    $X \sim Poisson(\lambda)$
\end{itemize}



\subsubsection{Binomial Distribution}\label{sec:binomial_distribution}

Random Variable $X$ with Binomial Distribution where $n \in \nats$ and
$p \in [0,1]$:
\[
  X \sim B(n,p)
\]
describes the Probability of getting exactly $x$ ``successes'' in $n$ ``trials''
where the Probability of ``success'' is $p$:
\[
  P(x,n,p) = \binom{n}{x}p^x(1-p)^{n-x}
\]

Binomial Random Variable (\S\ref{sec:binomial_random_variable})

Binomial (Bernoulli) Trial (\S\ref{sec:binomial_trial})

generalized as Multinomial Distributions (\S\ref{sec:multinomial_distribution})

Mean $\mu = n p$

Variance $\sigma^2 = n p q$

Sample Proportion %FIXME



\paragraph{Bernoulli Distribution}\label{sec:bernoulli_distribution}\hfill

$n = 1$

for a Random Variable $X$ representing a Binary Outcome:
\begin{itemize}
  \item $P(X=1) = p$
  \item $P(X=0) = 1-p$
\end{itemize}
for some $p \in [0,1]$

PMF:
\[
  f(x) = p^x(1-p)^{1-x}
\]
or equivalently:
\[
  f(x) = \begin{cases}
    p   & x = 1 \\
    1-p & x = 0 \\
  \end{cases}
\]
for $x \in \{0, 1\}$

generalization: Categorical Distribution (\S\ref{sec:categorical_distribution})



\paragraph{Negative Binomial Distribution}\label{sec:negative_binomial}\hfill

$b^*(x; k,p) = \binom{x-1}{k-1} p^k 2^{k-k}$



\paragraph{Normal Approximation}\label{sec:normal_approximation}\hfill

For Binomial Random Variable $X$ with Mean $\mu = np$ and Variance
$\sigma^2 = npq$, then:
\[
  Z = \frac{X - np}{\sqrt{npq}}
\]
as $n \rightarrow \infty$ is the Standard Normal Distribution
(\S\ref{sec:normal_distribution}) $n(Z;0,1)$



\subsubsection{Multinomial Distribution}\label{sec:multinomial_distribution}

generalization of Binomial Distribution (\S\ref{sec:binomial_distribution}) to
Multivariate Distributions (\S\ref{sec:random_vector})

$k$ Outcomes $E_1, E_2, \ldots, E_k$

Probabilities $p_1, p_2, \ldots, p_k$

Probability Distribution of $x_1, x_2, \ldots, x_k$ number of
Occurences for $E_1, E_2, \ldots, E_k$ in $n$ Independent Trials:
\[
  f(x_1, x_2, \ldots, x_k) = \binom{n}{x_1, x_2, \ldots, x_k} =
  p_1^{x_1} p_2^{x_2} \cdots p_k^{x_k}
\]
and $\sum_{i=1}^k x_i = n$ and $\sum_{i=1}^k {p_i} = 1$

for $X = (X_1, \ldots, X_k) \sim Multinomial(n, p)$ and
$p = (p_1, \ldots, p_k)$, the Marginal Distribution
(\S\ref{sec:marginal_distribution}) of $X_j$ is $Binomial (n, p_j)$



\paragraph{Categorical Distribution}\label{sec:categorical_distribution}
\hfill

generalization of Bernoulli Distribution (\S\ref{sec:bernoulli_distribution})



\paragraph{Softmax Function}\label{sec:softmax}
\hfill

or \emph{Normalized Exponential Function}

generalization of Logistic Function (\S\ref{sec:softmax}); the Logistic Function
is the Derivative of Softplus --TODO

output can be used to represent a Categorical Distribution

often used as final layer of a Neural Network-based Classifier



\subsubsection{Poisson Distribution}\label{sec:poisson_distribution}

Poisson Process (\S\ref{sec:poisson_process})

$P(x; \lambda t) = \frac{e^{-\lambda t} (\lambda t)^x}{x!}$
where $\lambda$ is the average number of outcomes per unit time

models counts of rare events, e.g. radioactive decay, traffic accidents



\subsubsection{Geometric Distribution}\label{sec:geometric_distribution}

$P(X = k) = p(1-p)^{k-1}$ for $k \in \{1, 2, 3, \ldots\}$

where $X$ is the number of Trials needed until the first Success



\subsubsection{Hypergeometric Distribution}
\label{sec:hypergeometric_distribution}

$h(x; N, n, k) = \frac{\binom{k}{x} \binom{N-k}{n-x}}{\binom{N}{n}}$

Mean $\mu = \frac{nk}{N}$

Variance $\sigma^2 = \frac{N-n}{N-1} n \frac{k}{N}(1 - \frac{k}{N})$



\paragraph{Multivariate Hypergeometric Distribution}
\label{sec:multivariate_hypergeometric}\hfill



\subsubsection{Parabolic Fractal Distribution}
\label{sec:parabolic_fractal_distribution}

\subsubsection{Discrete Power Law Distribution}
\label{sec:discrete_power_law_distribution}

\fist Continuous Power Law Distributions
(\S\ref{sec:continuous_power_law_distribution})



\paragraph{Zipf Distribution}\label{sec:zipf_distribution}\hfill

\paragraph{Zeta Distribution}\label{sec:zeta_distribution}\hfill

Normalization of the Zipf Distribution

\paragraph{Yule-Simon Distribution}
\label{sec:yule_simon_distribution}\hfill



% ------------------------------------------------------------------------------
\subsection{Continuous Probability Distribution}
\label{sec:continuous_probability}
% ------------------------------------------------------------------------------

Probability Distribution of a Continuous Random Variable
(\S\ref{sec:continuous_random_variable})

characterized by a Probability Density Function
(\S\ref{sec:probability_density})

has a Continuous Cumulative Distribution Function (\S\ref{sec:cdf})

\fist Discrete Power Law Distributions
(\S\ref{sec:discrete_power_law_distribution})

\begin{itemize}
  \item \emph{Uniform Distribution} (\S\ref{sec:uniform_distribution}) --
    $X \sim Uniform(a,b)$
  \item \emph{Normal (Gaussian) Distribution} (\S\ref{sec:normal_distribution})
    -- $X \sim N(\mu, \sigma^2)$
  \item \emph{Exponential Distribution} (\S\ref{sec:exponential_distribution})
    -- $X \sim Exp(\beta) = Gamma(1, \beta)$
  \item \emph{Gamma Distribution} (\S\ref{sec:gamma_distribution})
    -- $X \sim Gamma(\alpha, \beta)$
  \item \emph{Beta Distribution} (\S\ref{sec:beta_distribution})
    -- $X \sim Beta(\alpha, \beta)$
  \item \emph{$t$-distribution} (\S\ref{sec:t_distribution})
    -- $X \sim t_\nu$
  \item \emph{Cauchy-Lorenz Distribution} (\S\ref{sec:cauchy_distribution})
    -- $X \sim t_\nu=1$
  \item \emph{$\chi^2$-distribution} (\S\ref{sec:chi_squared})
    -- $X \sim \chi^2_p$
\end{itemize}



\subsubsection{Normal Distribution}\label{sec:normal_distribution}

(or \emph{Gaussian Distribution})

\[
  n (x; \mu, \sigma) =
  \frac{1}{\sqrt{2\pi \sigma}} e^{-\frac{1}{2 \sigma^2}(x - \mu)^2}
\]

a Normal Distribution corresponds to a $t$-distribution
(\S\ref{sec:t_distribution}) with $\nu = \infty$ Degrees of Freedom

the Ratio $X_1/X_2$ of two Normally Distributed Independent Random Variables
$X_1, X_2 \sim N(0,1)$ is a Cauchy Distribution

\emph{Central Limit Thoerem} (\S\ref{sec:central_limit_theorem}) -- ``the
Distribution of a Sum of Independent Random Variables can be approximated by a
Normal Distribution''

\fist Gaussian Processes (\S\ref{sec:gaussian_process}) can be seen as
Infinite-dimensional generalizations of Multivariate Normal Distributions

2018 - Eric Jang
- \emph{Normalizing Flows Tutorial}
- \url{https://blog.evjang.com/2018/01/nf1.html}



\paragraph{Standard Normal Distribution}\label{sec:standard_normal}\hfill

Mean $\mu = 0$

Variance $\sigma^2 = 1$

by convention Standard Normal Random Variables are denoted by $Z$, PDF by
$\phi(z)$ and CDF by $\Phi(z)$

there is no Closed-form Expression (\S\ref{sec:closed_form_expression}) for
$\Phi$ (requires use of the Error Function \S\ref{sec:error_function})



\paragraph{Multivariate Normal Distribution}\label{sec:multivariate_normal}
\hfill

Multivariate Random Variable (\S\ref{sec:random_vector})



\subsubsection{$t$-distribution}\label{sec:t_distribution}

(or \emph{Student's $t$-distribution})

$\nu$ -- Degrees of Freedom

a Normal Distribution (\S\ref{sec:normal_distribution}) corresponds to a
$t$-distribution with $\nu = \infty$ Degrees of Freedom



\paragraph{Cauchy Distribution}\label{sec:cauchy_distribution}\hfill

or \emph{Cauchy-Lorentz Distribution}

$\nu = 1$

Expected Value (\S\ref{sec:expected_value}) and Variance (\S\ref{sec:variance})
are undefined; the ``average'' of $n$ Independent Cauchy Random Variables with
$x_0 = 0$ \emph{does not} Converge to $0$ as $n \rightarrow \infty$ with
Probability $1$-- ``it'' stays a Cauchy Distribution of the same size; however
$0$ is the Median and Mode (FIXME: clarify)
--\url{https://stats.stackexchange.com/questions/36027/why-does-the-cauchy-distribution-have-no-mean}

\url{https://stats.stackexchange.com/questions/232967/what-makes-the-mean-of-some-distributions-undefined/233950#233950}:
the Cauchy Distribution is a ``disguised'' form of the Uniform Distribution on a
Circle

has no Moment-generating Function (\S\ref{sec:moment_generating_function})

the Ratio $X_1/X_2$ of two Normally Distributed Independent Random Variables
$X_1, X_2 \sim N(0,1)$ is a Cauchy Distribution



\subsubsection{Log-normal Distribution}\label{sec:lognormal_distribution}

\subsubsection{Gamma Distribution}\label{sec:gamma_distribution}

Gamma Function (\S\ref{sec:gamma_function})

Continuous Random Variable $X$ with parameters $\alpha > 0$ and $\beta
> 0$:
\[
  f(x; \alpha, \beta) =
  \begin{cases}
  \frac{1}{\beta^\alpha \Gamma(\alpha)} x^{\alpha-1} e^{\sfrac{-x}{\beta}}
        & \quad x > 0 \\
  0     & \quad\text{else} \\
  \end{cases}
\]

Mean $\mu = \alpha \beta$

Variance $\sigma^2 = \alpha \beta^2$



\paragraph{Exponential Distribution}\label{sec:exponential_squared}\hfill

a $Gamma(1,\beta)$ Distribution

Continuous Random Variable $X$ with parameter $\beta > 0$:
\[
  f(x; \beta) =
  \begin{cases}
  \frac{1}{\beta} e^{\sfrac{-x}{\beta}}     & \quad x > 0 \\
  0     & \quad\text{else} \\
  \end{cases}
\]

models lifetimes of electronic components, wait times between rare events



\paragraph{$\chi^2$ Distribution}\label{sec:chi_squared}\hfill

Non-symmetric

\[
  f(x; v) =
  \begin{cases}
    \frac{1}{2^{\sfrac{v}{2}}\Gamma(\sfrac{v}{2})}
      x^{\sfrac{v}{2-1}} e^{\sfrac{-x}{2}}
          & \quad x > 0 \\
    0     & \quad\text{else} \\
  \end{cases}
\]



\subsubsection{Beta Distribution}\label{sec:beta_distribution}

Gamma Function (\S\ref{sec:gamma_function})



\subsubsection{Continuous Power Law Distribution}
\label{sec:continuous_power_law_distribution}

Scale Invariance (\S\ref{sec:scale_invariance})



\paragraph{Pareto Distribution}\label{sec:pareto_distribution}\hfill

prototypical Power Law Distribution



% ------------------------------------------------------------------------------
\subsection{Symmetric Probability Distribution}
\label{sec:symmetric_probability}
% ------------------------------------------------------------------------------

\subsubsection{Uniform Distribution}\label{sec:uniform_distribution}

for a Finite Sample Space $\Omega$:
\[
  P(A) = \frac{\|A\|}{\|\Omega\|}
\]

a Uniform Distribution is defined by a rectangle formed on the interval Interval
$[min,max]$ such that the area is $1$

$Uniform(0,1)$ -- \emph{Standard Uniform Distribution}

\url{https://stats.stackexchange.com/questions/232967/what-makes-the-mean-of-some-distributions-undefined/233950#233950}:
the Cauchy Distribution (\S\ref{sec:cauchy_distribution}) is a ``disguised''
form of the Uniform Distribution on a Circle



\paragraph{Probability Integral Transform}
\label{sec:probability_integral_transform}\hfill

for Continuous $X$ with CDF $F_X$, $Y = F_X(X)$ is called a \emph{Probability
  Integral Transform} and has a Standard Uniform Distribution

\emph{Universal Random Number Generator} (Wasserman04 Ch.2 Exercise 15) -- TODO



% ------------------------------------------------------------------------------
\subsection{Joint Probability Distribution}\label{sec:joint_probability}
% ------------------------------------------------------------------------------

$f(x,y,\ldots)$ for two or more Random Variables $X,Y,\ldots$

Discrete Random Variables:
\begin{enumerate}
  \item $f(x,y) \geq 0$
  \item $\sum_x \sum_y f(x,y) = 1$
  \item $P(X = x, Y = y) = f(x,y)$
\end{enumerate}

Continuous Random Variables:
\begin{enumerate}
  \item $\forall (x,y) \in X \times Y, f(x,y) \geq 0$
  \item $\int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty}
    f(x,y) dx dy = 1$
  \item $P[(X,Y) \in B] = \iint\limits_B f(x,y) dA$
\end{enumerate}

Conditional Independence (\S\ref{sec:conditional_independence}) happens when
the Joint Probability Distribution is the Product of the individual Probability
Distributions
--\url{http://lesswrong.com/lw/pi/classical_configuration_spaces/}

\fist a Stationary Process (\S\ref{sec:stationary_process}) is a Stochastic
Process whose Unconditional Joint Probability Distribution is unchanged in Time



\subsubsection{Bivariate Distribution}\label{sec:bivariate_distribution}

$P(X = x, Y = y)$



\subsubsection{Kalman Filter}\label{sec:kalman_filter}

a series of papers on ``Kalman Folding'':
\url{http://vixra.org/author/brian_beckman}



% ------------------------------------------------------------------------------
\subsection{Conditional Distribution}
\label{sec:conditional_distribution}
% ------------------------------------------------------------------------------

for Discrete Random Variables $X$, $Y$:

\[
  P(X = x | Y = y) = P(X = x, Y = y)/P(Y = y)
\]
the Conditional Probability Mass Function, assuming $f_Y(y) > 0$:
\[
  f_{X|Y}(x|y) = P(X = x|Y = y) =
    \frac{P(X = x, Y = y)}{P(Y = y)} =
    \frac{f_{X,Y}(x,y)}{f_Y(y)}
\]

for Continuous Random Variables $X$, $Y$, the Conditional Probability Density
Function:
\[
  f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}
\]
and:
\[
  P(X \in A| Y = y) = \int_A f_{X|Y}(x|y) dx
\]

cf. \emph{Borel-Kolmogorov Paradox} -- Conditional Probability Density Functions
need not be Invariant under Coordinate Transformations



% ------------------------------------------------------------------------------
\subsection{Marginal Distribution}\label{sec:marginal_distribution}
% ------------------------------------------------------------------------------

Marginal Probability Mass Functions:

$f_X(x) = P(X = x) = \sum_y P(X = x, Y = y) = \sum_y P(X = x | Y = y) P(Y = y)$

$f_Y(y) = P(Y = y) = \sum_x P(X = x, Y = y) = \sum_x P(Y = y | X = x) P(X = x)$

Marginal Probability Density Functions:

$f_X(x) = \int f_{X,Y}(x,y) dy$

$f_Y(y) = \int f_{X,Y}(x,y) dx$



% ------------------------------------------------------------------------------
\subsection{Asymptotic Distribution}
\label{sec:asymptotic_distribution}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Sampling Distribution}\label{sec:sampling_distribution}
% ------------------------------------------------------------------------------

Probability Distribution of a Statistic (\S\ref{sec:statistic})

Statistical Inference (\S\ref{sec:inferential_statistics})

Standard Error (\S\ref{sec:standard_error})



% ------------------------------------------------------------------------------
\subsection{Tweedie Distribution}\label{sec:tweedie_distribution}
% ------------------------------------------------------------------------------

(wiki): \emph{Tweedie Convergence Theorem}: describes the Convergence of certain
Statistical Processes towards the Family of Statistical Models known as
\emph{Tweedie Distributions}; Variance-to-Mean Power Law (TODO: xref); cf.
Taylor's Power Law, \emph{Fluctuation Scaling}; alternative paradigm to explain
Power Law manifestations attributed to ``Self-organized Criticality''
(SOC \S\ref{sec:soc})

Pink ($1/f$) Noise

\fist origin of ``Multifractality'' (\S\ref{sec:multifractal_system}) in
Sequential (Time Series) data attributed to ``convergence effects'' related to
the Central Limit Theorem (\S\ref{sec:central_limit}) that have Foci of
Convergence in the family of Tweedie Exponential Dispersion Models



% ------------------------------------------------------------------------------
\subsection{Quasiprobability Distribution}
\label{sec:quasiprobability_distribution}
% ------------------------------------------------------------------------------

relaxation of the Third Kolmogorov Axiom ($\sigma$-additivity
\S\ref{sec:probability_axioms})

to compensate some Quasiprobability Distributions have regions of Negative
Probability (\S\ref{sec:negative_probability}) Density, contradicting the First
Axiom

regions Integrated under them do not represent Probabilities of Mutually
Exclusive States (\S\ref{sec:mutually_exclusive})

cf. Phase Space (\S\ref{sec:phase_space}) Formulation of Quantum Mechanics:
Position and Momentum Variables on equal footing in Phase Space (cf.
Schr\"odinger formulation uses Position \emph{or} Momentum representations)

\fist Time-Frequency Analysis (\S\ref{sec:time_frequency_analysis}): analysis
of Signals with Time-varying Statistics (cf. Entropy \S\ref{sec:entropy}), e.g.
Transient Signals (\S\ref{sec:transient})



% ==============================================================================
\section{Population}\label{sec:population}
% ==============================================================================

\emph{Statistical Population}

totality of Observations (\S\ref{sec:observation})

Value of a Random Variable $X$ having some Probability
Distribution $f(x)$

Paired Observation (Dependent) (???)

(wiki):

\emph{Statistical Population} -- a Set of ``similar items'' or Events
(\S\ref{sec:probability_event}) of interest

Descriptive Statistics (\S\ref{sec:descriptive_statistics}): a Subset of the
Population is a \emph{Statistical Sample} (\S\ref{sec:statistical_sample})



% ------------------------------------------------------------------------------
\subsection{Population Parameter}\label{sec:population_parameter}
% ------------------------------------------------------------------------------

or \emph{Statistical Parameter}

(wiki): a ``quantity'' that indexes a Family of Probability Distributions
(\S\ref{sec:probability_distribution})

can be regarded as a ``numerical characteristic'' of a Population or a
Statistical Model (\S\ref{sec:statistical_model}) \fist cf. Parametric
Statistical Models (\S\ref{sec:parametric_model})

example: the Family of Normal Distributions (\S\ref{sec:normal_distribution})
are Parameterized by the Mean and Standard Deviation

$\mu$, $\sigma$

\fist \emph{Estimation Theory} (\S\ref{sec:estimation_theory}) deals with
``\emph{Estimating}'' the values of Statistical Parameters
based on data that has a ``\emph{random component}'' (FIXME: clarify)



\subsubsection{Proportion}\label{sec:statistical_proportion}

\paragraph{Lexis Ratio}\label{sec:lexis_ratio}\hfill



% ------------------------------------------------------------------------------
\subsection{Sample}\label{sec:sample}
% ------------------------------------------------------------------------------

Subset of a Population

Statistical Sample (Descriptive Statistics \S\ref{sec:statistical_sample})



\subsubsection{Random Sample}\label{sec:random_sample}

\fist cf. \emph{Random Sample} (Independent and Identically Distributed Random
Vector \S\ref{sec:iid}) $X_1, \ldots, X_n \sim F$ -- in Statistics it is
commonly assumed that Observations are IID

Statistical Sample (Descriptive Statistics \S\ref{sec:statistical_sample})

cf. \emph{Statistical Randomness} (\S\ref{sec:statistical_randomness}),
\emph{Algorithmic Randomness} (\S\ref{sec:algorithmic_randomness})

\fist Monte Carlo Simulation (\S\ref{sec:monte_carlo})



\paragraph{Simple Random Sample}\label{sec:simple_random_sample}\hfill

\paragraph{Stratified Random Sample}\label{sec:stratified_random_sample}\hfill



% ------------------------------------------------------------------------------
\subsection{Statistic}\label{sec:statistic}
% ------------------------------------------------------------------------------

Function of the Random Variable (\S\ref{sec:random_variable}) constituting a
Random Sample (\S\ref{sec:random_sample})

$\overline{x}$, $\sigma^2$

The Probability Distribution (\S\ref{sec:probability_distribution}) of
a Statistic is a Sampling Distribution
(\S\ref{sec:sampling_distribution})

Estimator (\S\ref{sec:estimator})



\subsubsection{Robust Statistic}\label{sec:robust_statistic}

\fist Info-gap Decision Theory (\S\ref{sec:info_gap}) -- Non-probabilistic
Decision Theory seeking to optimize Robustness to ``failure'' under severe
Uncertainty (\S\ref{sec:uncertainty_analysis})



\subsubsection{Sufficient Statistic}\label{sec:sufficient_statistic}



% ==============================================================================
\section{Descriptive Statistics}\label{sec:descriptive_statistics}
% ==============================================================================

Summary of Data: Mean, Median, Mode, Standard Deviation

cf. Test Statistics (\S\ref{sec:test_statistic})



% ------------------------------------------------------------------------------
\subsection{Statistical Sample}\label{sec:statistical_sample}
% ------------------------------------------------------------------------------

Sample (\S\ref{sec:sample}), Random Sample (\S\ref{sec:random_sample})

\fist cf. Frequency Distribution (\S\ref{sec:frequency_distribution})



\subsubsection{Order Statistic}\label{sec:order_statistic}



% ------------------------------------------------------------------------------
\subsection{Summary Statistics}\label{sec:summary_statistics}
% ------------------------------------------------------------------------------

\subsubsection{Measure of Location}\label{sec:location_measure}

\paragraph{Median}\label{sec:median}\hfill

\paragraph{Mode}\label{sec:mode}\hfill

cf. \emph{Unimodality}



\paragraph{Arithmetic Mean}\label{sec:arithmetic_mean}\hfill

\emph{Arithmetic Mean} $\overline{x} = \frac{1}{n}\sum_{i=1}^n x_i$



\paragraph{Geometric Mean}\label{sec:geometric_mean}\hfill

using the Product of Values instead of Sum as in Arithmetic Mean



\paragraph{Trimmed Mean}\label{sec:trimmed_mean}\hfill

\paragraph{Sample Median}\label{sec:median}\hfill



\subsubsection{Statistical Dispersion}\label{sec:statistical_dispersion}

measured by Statistics of the Distribution of Deviations (\S\ref{sec:deviation})

cf. \emph{Uncertainty}

2018 - \emph{Uncertainty: a Tutorial} -
\url{https://blog.evjang.com/2018/12/uncertainty.html}



\paragraph{Sample Variance}\label{sec:variability}\hfill

$s^2$

Degrees of Freedom, Linear Independence, Biased/Unbiased Estimator
(\S\ref{sec:unbiased_estimate})

Unbiased Sample Variance:
\[
  s^2 = \frac{n}{n-1}\sigma^2_y =
  \frac{1}{n-1} \sum_{i=1}^n (y_i - \overline{y})^2
\]



\paragraph{Standard Deviation}\label{sec:standard_deviation}\hfill

Variance (\S\ref{sec:variance})

Deviation (\S\ref{sec:deviation})

\emph{Uncorrected Standard Deviation}:
\[
  s_n = \sqrt{\frac{1}{n}\sum_{i=1}^n (x_i - \overline{x})^2}
\]

\emph{Corrected Standard Deviation}

\emph{Unbiased Standard Deviation}



\subparagraph{Chebyshev's Inequality}\label{sec:chebyshevs_inequality}
\hfill

Probability that a Random Variable $X$ will assume Value within $k$ Standard
Deviations

Random Variable $X$ with Finite Expected Value (\S\ref{sec:expected_value})
$\mu$ and Finite Non-zero Variance $\sigma^2$, for any $k \in \reals : k > 0$:
\[
  P(k\sigma \leq |X - \mu|) \leq \frac{1}{k^2}
\]



% ------------------------------------------------------------------------------
\subsection{Earthmover Distance}\label{sec:earthmover_distance}
% ------------------------------------------------------------------------------

%FIXME: does this section belong here?

a measure of ``nearness'' for Probability Distributions

\url{https://jeremykun.com/2018/03/05/earthmover-distance/}



% ==============================================================================
\section{Inferential Statistics}\label{sec:inferential_statistics}
% ==============================================================================

Probabilistic Inference
(\S\ref{sec:probabilistic_inference}), Inductive Inference
(\S\ref{sec:inductive_inference})

Probabilistic Classification (\S\ref{sec:probabilistic_classification}) -- use
of Statistical Inference to solve a Statistical Classification
(\S\ref{sec:statistical_classification})

Random Variation: Sampling Variation, Observational Error

Wasserman04 - \emph{All of Statistics}



% ------------------------------------------------------------------------------
\subsection{Statistical Assumption}\label{sec:statistical_assumption}
% ------------------------------------------------------------------------------

a Statistical Model (\S\ref{sec:statistical_model}) is a Set of Statistical
Assumptions



% ------------------------------------------------------------------------------
\subsection{Statistical Model}\label{sec:statistical_model}
% ------------------------------------------------------------------------------

a Set of Statistical Assumptions (\S\ref{sec:statistical_assumption})

or \emph{Probabilistic Model}

\emph{Statistical Population} (\S\ref{sec:population}) -- Set of ``similar
items'' or Events (\S\ref{sec:probability_event}) of interest

\fist Descriptive Statistics (\S\ref{sec:descriptive_statistics}): a Subset of
the Population is a \emph{Statistical Sample} (\S\ref{sec:statistical_sample})

Statistical Parameters (Population Parameters \S\ref{sec:population_parameter})

Data

Estimate (\S\ref{sec:estimation_theory}): Data $\rightarrow$ Parameters

\emph{Regression} (\S\ref{sec:regression_analysis}) is the Estimation of
Parameters of a Statistical Model

cf. Regression Model (\S\ref{sec:regression_model})

(wiki):

$(S, \mathcal{P})$

$S$ -- Sample Space

$\mathcal{P}$ -- Probability Distributions
(\S\ref{sec:probability_distribution}) on $S$

\emph{Regression} (\S\ref{sec:regression_analysis}) is the Estimation
(\S\ref{sec:estimation_theory}) of Parameters of a Statistical Model

\asterism

MIT 6.041SC - \emph{Probabilistic Systems Analysis and Applied Probability}

Probability Laws -- describes ``beliefs'' about which outcomes are more likely
than others; should obey Probability Axioms (\S\ref{sec:probability_axioms})

Sample Space (\S\ref{sec:sample_space}) $\Omega$ -- description of possible
outcomes

a ``list'' of Events should be Mutually Exclusive
(\S\ref{sec:mutually_exclusive}, for $\sigma$-additivity Axiom) and exhaustive
(for Unitarity Axiom)

\emph{Discrete Uniform Law} (\S\ref{sec:discrete_uniform_law}): all Outcomes are
equally likely

\emph{Continuous Uniform Law} (\S\ref{sec:continuous_uniform_law}): equal Areas
have equal Probabilities

Discrete Models

Continuous Models -- any individual outcome has Zero Probability (TODO: explain)

Models based on Conditional Probabilities (\S\ref{sec:conditional_probability})



\subsubsection{Discrete Uniform Law}\label{sec:discrete_uniform_law}

MIT 6.041SC Lec. 4 - \url{https://www.youtube.com/watch?v=6oV3pKLgW2I}

every possible Outcome has the same Probability of Occurring

Sample Space $\Omega$

the Probability of an Event $A$:
\[
  P(A) = \frac{|A|}{|\Omega|}
\]

for $|\Omega| = N$, every Element of $\Omega$ has Probability $\frac{1}{N}$

for a Subset $A$ with Cardinality $|A| = n$:
\[
  P(A) = n \frac{1}{N}
\]


Basic Counting Principles

for a Set with Cardinality $n$:
\begin{itemize}
  \item $n^\ell$ -- Possible Sequences of Length $\ell$ (with repetitions)
  \item $2^n$ -- Possible Subsets
  \item $\binom{n}{k}$ -- Possible Subsets of $k$ Elements
  \item $n!$ -- Possible Permutations (Orderings with no repetitions)
  \item $\frac{n!}{(n-k)!}$ -- Possible Permutations of $k$ Elements
  \item $n^2$ -- Possible Ordered Pairs
  \item $\frac{n(n-1)}{2}$ -- Possible Unique Pairings (Handshake problem)
\end{itemize}


Binomial Probabilities \fist Binomial Distribution
(\S\ref{sec:binomial_distribution}) -- Probability of getting exactly $k$
``successes'' in $n$ Trials where the Probability of ``success'' is $p$:
\[
  P(k,n,p) = \binom{n}{k}p^k(1-p)^{n-k}
\]
(FIXME: clarify)



\subsubsection{Continuous Uniform Law}\label{sec:continuous_uniform_law}

\subsubsection{Variational Bayesian Method}
\label{sec:variational_bayesian_method}

Free Energy Principle -- implicit Minimization of Variational Free Energy;
Active Inference (Friston)



\subsubsection{Model Selection}\label{sec:model_selection}

\paragraph{Optimality Criterion}\label{sec:optimality_criterion}\hfill

\fist Decision Rules (Decision Theory \S\ref{sec:decision_rule}): makes a
Choice using an Optimality Critereon



\subsubsection{Parametric Model}\label{sec:parametric_model}

\emph{Parametric Statistics}

assumes that Sample Data comes from a Population that follows a Probability
Distribution based on a fixed Set of \emph{Statistical Parameters}
(Population Parameters \S\ref{sec:population_parameter})

example: the Family of Normal Distributions (\S\ref{sec:normal_distribution})
are Parameterized by the Mean and Standard Deviation



\subsubsection{Non-parametric Model}\label{sec:nonparametric_model}

Parameter Set (or \emph{Feature Set} in Machine Learning) is not fixed, i.e. it
may increase or decrease as new relevant information is collected



\subsubsection{Graphical Model}\label{sec:graphical_model}

\paragraph{Bayesian Network}\label{sec:bayesian_network}\hfill

or \emph{Probabilistic Directed Acyclic Graphical Model}

DAG (\S\ref{sec:dag}) -- dependency structure

representation of Probability Distributions based on \emph{Causal Dependencies}

\emph{Causality} (Pearl 2009) -- counterfactual reasoning

\url{https://golem.ph.utexas.edu/category/2018/07/bayesian_networks.html}



\subsubsection{Generalized Linear Model}\label{sec:generalized_linear_model}

not to be confused with General Linear Models (Multivariate Regression Models
\S\ref{sec:multivariate_regression})



\subsubsection{Discrete Choice Model}\label{sec:discrete_choice_model}

\paragraph{Binary Choice Model}\label{sec:binary_choice}\hfill

essentially the same as Binomial Regression
(\S\ref{sec:binomial_regression}) Models



\subsubsection{Logistic Model}\label{sec:discrete_uniform_law}

or \emph{Logit Model}

uses a Logistic Function (\S\ref{sec:logistic_function}) to Model a Binary
Dependent Variable

Logistic Regression (\S\ref{sec:logistic_regression})



% ------------------------------------------------------------------------------
\subsection{Hypothesis Testing}\label{sec:hypothesis_testing}
% ------------------------------------------------------------------------------

\emph{Statistical Hypothesis}: Assertion or Conjecture concerning one or more
Populations (\S\ref{sec:population})

in Bayesian Inference (\S\ref{sec:bayesian_inference}), a Hypothesis is assigned
a Probability, while in Frequentist Inference
(\S\ref{sec:frequentist_inference}), a Hypothesis is Tested without assigning a
Probability

\url{https://github.com/puolival/multipy} -- Python library

Methodology

Confidence Intervals (\S\ref{sec:confidence_interval})

Null Hypothesis $H_0$ represents any Hypothesis

If $H_0$ is Rejected then Alternate Hypothesis $H_1$ is Accepted

$H_1$ usually represents the question to be answered

\begin{enumerate}
  \item Sufficient Evidence: Reject $H_0$ in favor of $H_1$
  \item Insufficient Evidence: fail to Reject $H_0$
\end{enumerate}

\emph{Test Statistic}

\emph{Critical Region}, \emph{Critical Value}

Type I Error: Rejection of $H_0$ when it is True

Type II Error: Non-Rejection of $H_0$ when it is False

\emph{Level of Significance} $\alpha$: Probability of committing a
Type I Error

$\beta$: Probability of committing a Type II Error

\emph{Power} $1 - \beta$: Probability of Rejecting $H_0$ given that a
specific alternative is True

Confidence Intervals (\S\ref{sec:confidence_interval})

One-tailed Test

Two-tailed Test

Test on a single Mean

Test on a single Sample

$P$-value: lowest Level of Significance at which the observed Value of
the Statistic is Significant

\begin{itemize}
  \item Test for Statistical Randomness (\S\ref{sec:statistical_randomness})
\end{itemize}



\subsubsection{Test Statistic}\label{sec:test_statistic}

cf. Descriptive Statistic (\S\ref{sec:descriptive_statistics})

\begin{itemize}
  \item $t$-statistic
  \item $F$-test
  \item ...
\end{itemize}



\subsubsection{Null Hypothesis}\label{sec:null_hypothesis}

$H_0$



\subsubsection{Critical Region}\label{sec:critical_region}

or \emph{Region of Rejection}

set of Values of the Test Statistic for which the Null Hypothesis is rejected



% ------------------------------------------------------------------------------
\subsection{Estimation Theory}\label{sec:estimation_theory}
% ------------------------------------------------------------------------------

deals with ``\emph{Estimating}'' the values of Statistical Parameters
(\S\ref{sec:population_parameter}) based on data that has a ``\emph{random
  component}'' (FIXME: clarify)

an \emph{Estimator} (\S\ref{sec:estimator}) attempts to approximate unknown
Statistical Parameters using ``measured data''

\emph{Regression} (\S\ref{sec:regression_analysis}) is the Estimation of
Parameters of a Statistical Model (\S\ref{sec:statistical_model})

approaches:
\begin{itemize}
  \item \emph{Probabilistic} -- assume the ``measured data'' is ``random'' with
    a Probability Distribution (\S\ref{sec:probability_distribution}) dependent
    on the Statistical Parameters of interest
  \item \emph{Set-membership} (\S\ref{sec:set_estimation}) -- 
\end{itemize}

\fist cf. Approximation Theory (\S\ref{sec:approximation_theory})



\subsubsection{Estimator}\label{sec:estimator}

(wiki):

an \emph{Estimator} attempts to approximate unknown Statistical Parameters
(\S\ref{sec:statistical_paramaeter}) using ``measured data''

when the data consists of ``multiple variables'', Estimating the ``relation''
between them is \emph{Regression Analysis} (\S\ref{sec:regression_analysis})
--FIXME: clarify



\paragraph{Point Estimator}\label{sec:point_estimator}\hfill

\paragraph{Interval Estimator}\label{sec:interval_estimator}\hfill



\subsubsection{Deviation}\label{sec:deviation}

\fist the Distribution of Deviations are used as measures of Statistical
Dispersion (\S\ref{sec:statistical_dispersion})



\paragraph{Absolute Deviation}\label{sec:absolute_deviation}\hfill

\paragraph{Error}\label{sec:error}\hfill

\emph{Statistical Error}

Mean Squared Error (MSE) or Mean Squared Deviation (MSD)



\paragraph{Residual}\label{sec:residual}\hfill

or \emph{Fitting Deviation}

\fist Regression Residual (\S\ref{sec:regression_residual})



\subsubsection{Bias}\label{sec:bias}

\paragraph{Unbiased Estimate}\label{sec:unbiased_estimate}\hfill

\paragraph{Efficient Estimate}\label{sec:efficient_estimate}\hfill

Unbiased Estimator with Smallest Variance



\subsubsection{Standard Error}\label{sec:standard_error}

Sampling Distribution (\S\ref{sec:sampling_distribution})



\subsubsection{Pooled Estimate}\label{sec:pooled_estimate}

%FIXME



\subsubsection{Set Estimation}\label{sec:set_estimation}

Set-membership approach to Estimation Theory (cf. Probabilistic approach)



% ------------------------------------------------------------------------------
\subsection{Regression Analysis}\label{sec:regression_analysis}
% ------------------------------------------------------------------------------

\emph{Regression} is the Estimation (\S\ref{sec:estimation_theory}) of
Parameters of a Statistical Model

\fist cf. Curve Fitting (\S\ref{sec:curve_fitting})

Regression Variable, ``Regressor'', or ``Explanatory Variable'' -- Independent
Variable (\S\ref{sec:independent_variable}); Covariate

Response Variable, ``Regressand'', or ``Explained Variable'' -- Dependent
Variable (\S\ref{sec:dependent_variable}); Criterion

example of Pattern Recognition (assignment of some Output Value to a given Input
Value), other examples are Statistical Classification
(\S\ref{sec:statistical_classification}) and Cluster Analysis
(\S\ref{sec:cluster_analysis})

Statistical Classification: \emph{Features} (Properties of Observations
\S\ref{sec:observation} or \emph{Instances}) are Explanatory Variables
(Regressors) and possible values of the Dependent Variable are categories called
\emph{Outcomes}

Linear Regression, Ordinary Least Squares, Logistic Regression

cf. Numerical Analysis (\S\ref{sec:numerical_analysis}): Interpolation
(\S\ref{sec:interpolation}), Extrapolation (TODO)



\subsubsection{Regression Model}\label{sec:regression_model}

\emph{Regression Model}:
\begin{itemize}
  \item \emph{Unknown Parameters} ($\beta$) -- Statistical Parameters
    (\S\ref{sec:statistical_parameter})
  \item \emph{Independent Variables} ($X$) -- ``Regression Variable'',
    ``Regressor'', ``Covariate'', ``Explanatory Variable''
  \item \emph{Dependent Variable} ($Y$) -- ``Response Variable'',
    ``Regressand'', ``Criterion'', ``Explained Variable''; variable whose values
    are to be ``explained'' in terms of the Independent Variable
\end{itemize}

Linear Regression Models (\S\ref{sec:linear_regression})

...



\subsubsection{Regression Error}\label{sec:regression_error}

\fist cf. Statistical Error (Estimators \S\ref{sec:error})

Mean Squared Error (MSE) or Mean Squared Deviation (MSD)



\subsubsection{Regression Residual}\label{sec:regression_residual}

\fist cf. Residual (Estimators \S\ref{sec:residual})

Mean Squared Error (MSE) or Mean Squared Deviation (MSD)



\subsubsection{Fit}\label{sec:model_fit}

measures the discrepancy between Observed (\S\ref{sec:observation}) values and
Expected Values under the Statistical Model

%FIXME: move section ???

cf. Curve Fitting (\S\ref{sec:curve_fitting})



\subsubsection{Linear Regression}\label{sec:linear_regression}

\emph{Linear Regression Model}

Fit using:
\begin{itemize}
  \item Linear Least Squares (\S\ref{sec:linear_least_squares}): if errors are
    \emph{normally distributed}, Least Squares ($2$-norm Best Fit) should be
    used
  \item ...
\end{itemize}

Gradient Descent (\S\ref{sec:gradient_descent})

cf. Convex Optimization (\S\ref{sec:convex_optimization}) -- for Linear
Regression, a Mean-Square Error Loss Function is always \emph{Convex} (example
\url{https://towardsdatascience.com/introduction-to-machine-learning-algorithms-linear-regression-14c4e325882a}

cf. Linear Programming (\S\ref{sec:linear_programming})
-- article: \emph{Linear Programming for Linear Regression};
\url{https://lazyprogrammer.me/linear-programming-for-linear-regression/}

Simple Linear Regression -- single Regressor (Independent Variable)

Regression Coefficients

Error Term $\varepsilon$

$Y = \beta_0 + \beta_1 X + \varepsilon$



\subsubsection{Least Squares}\label{sec:least_squares}

$2$-norm Best Fit \fist cf. $1$-norm Best Fit (\S\ref{sec:1norm_best_fit}),
Chebyshev Approximation ($\infty$-norm Best Fit
\S\ref{sec:chebyshev_approximation})



\paragraph{Ordinary Least Squares}\label{sec:ordinary_least_squares}\hfill

estimating the Unknown Parameters of a Linear Regression Model
(\S\ref{sec:linear_regression})



\subparagraph{Linear Least Squares}\label{sec:linear_least_squares}\hfill

Overdetermined Systems (\S\ref{sec:overdetermined_system})

QR Decomposition (\S\ref{sec:qr_decomposition})



\subparagraph{Normal Equation}\label{sec:normal_equation}\hfill

UC Math 352 Lec. 7 \url{https://www.youtube.com/watch?v=ZWGIchXVbho}

$A\vec{x} = \vec{b}$

$\mathrm{min}_{\vec{x}} \|A_{\vec{x}} - \vec{b}\|$

\emph{Normal Equation}: $(A^TA)\vec{x} = A^T\vec{b}$ -- Condition Number
(\S\ref{sec:condition_number}) is $\kappa(A)^2$; see QR Factorization
(\S\ref{sec:qr_factorization}) for a better Conditioned solution

Project $\vec{b}$ onto the Column Space of $A$

\[
  \vec{x} = (A^TA)^{-1}A^T\vec{b}
\]

solve by Cholesky Factorization (\S\ref{sec:cholesky_decomposition}) ... TODO
\url{https://www.youtube.com/watch?v=VJ-04jOfu-E}



\subparagraph{QR Factorization}\label{sec:qr_factorization}\hfill

QR Decomposition (\S\ref{sec:qr_decomposition})

UC Math 352 Lec. 7 \url{https://www.youtube.com/watch?v=ZWGIchXVbho}

better Condition Number than Normal Equations (\S\ref{sec:normal_equation})

$A\vec{x} = \vec{b}$

$A = QR$ ($Q$ is Square, Orthogonal)

Residual $\vec{r} = A\vec{x} - \vec{b}$

\begin{align*}
     \vec{r} & = QR\vec{x} - \vec{b} \\
  Q^T\vec{r} & = R\vec{x} - Q^T\vec{b} \\
\end{align*}

because Orthogonal Matrices preserve Distances and $Q$ is Orthogonal:
\[
  \|Q^T\vec{r}\|_2 = \|\vec{r}\|_2
\]
minimizing $Q^T\vec{r} = \vec{\rho}$ is equivalent to minimizing $\vec{r}$

splitting $\vec{\rho}$ into:
\begin{enumerate}
  \item $\hat{\rho}   = \hat{R}\vec{x} - \hat{Q}^T\vec{b}$
  \item $\vec{\rho}_N = -Q_N^T\vec{b}$
\end{enumerate}
$\hat{rho}$ can be made Zero by solving $\hat{R}\vec{x} - \hat{Q}^T\vec{b}$ for
$\vec{x}$, which is an Upper Triangular Matrix that can be solved efficiently:
\[
  \vec{x} = \hat{R}^{-1}\hat{Q}^T\vec{b}
\]
and $\vec{rho}_N$ is independent of $\vec{x}$ so it is \emph{fixed}, so:
\[
  \|\vec{r}\|^2_2 = \|\hat{Q}_N^T\vec{b}\|_2^2
\]



\paragraph{Generalized Least Squares}\label{sec:generalized_least_squares}\hfill

\subparagraph{Weighted Least Squares}\label{sec:weighted_least_squares}\hfill



\paragraph{Non-linear Least Squares}\label{sec:nonlinear_least_squares}\hfill



\subsubsection{Multivariate Regression}\label{sec:multivariate_regression}

or \emph{General Linear Model}; not to be confused with Generalized Linear
Models (\S\ref{sec:generalized_linear_model})



\subsubsection{Binomial Regression}\label{sec:binomial_regression}

essentially the same as Binary Choice Models (\S\ref{sec:binary_choice_model})



\paragraph{Logistic Regression}\label{sec:logistic_regression}\hfill

or \emph{Logit Regression}

Logistic Model (\S\ref{sec:logistic_model}) -- uses a Logistic Function
(\S\ref{sec:logistic_function}) to Model a Binary Dependent Variable

Statistical Classification (\S\ref{sec:statistical_classification})



\subsubsection{Gaussian Process Regression}
\label{sec:gaussian_process_regression}

\emph{Kriging} or \emph{Wiener-Komogorov Prediction}

under ``suitable assumptions'' on the Priors, Kriging gives the \emph{Best
  Linear Unbiased Prediction} (BLUP \S\ref{sec:blup}) of the intermediate values

\fist Spatial Analysis (\S\ref{sec:spatial_analysis})



\subsubsection{Multiple Regression}\label{sec:multiple_regression}

Definite Quadratic Forms (\S\ref{sec:definite_quadratic})



% ------------------------------------------------------------------------------
\subsection{Uncertainty Analysis}\label{sec:uncertainty_analysis}
% ------------------------------------------------------------------------------

\fist Decision Theory (\S\ref{sec:decision_theory})

\fist Robust Statistics (\S\ref{sec:robust_statistic})



\subsubsection{Uncertainty}\label{sec:uncertainty}

cf. Probability (\S\ref{sec:probability})

(\url{https://plato.stanford.edu/entries/logic-probability/}): Probabilistic
Semantics (\S\ref{sec:probabilistic_semantics}) for Logical Consequence Relation
yields \emph{Probability Preserving} (dually, \emph{Uncertainty Propagating})
Deductive Validity (\S\ref{sec:validity}), rather than Truth Preserving
(\S\ref{sec:truth_preservation})



\subsubsection{Sensitivity Analysis}\label{sec:sensitivity_analysis}

\fist Info-gap Decision Theory (\S\ref{sec:info_gap}): application of
Sensitivity Analysis of the Stability Radius (\S\ref{sec:stability_radius}) type
to Perturbations in the value of a given Estimate of a Parameter of interest
(FIXME: clarify)



\subsubsection{Evidince Theory}\label{sec:evidence_theory}

or \emph{Dempster-Shafer Theory (DST)} or \emph{Theory of Belief Functions}

Transferable Belief Model



\subsubsection{Possibility Theory}\label{sec:possibility_theory}

alternative to Probability Theory for dealing with certain types of Uncertainty



% ------------------------------------------------------------------------------
\subsection{Asymptotic Theory}\label{sec:asymptotic_theory}
% ------------------------------------------------------------------------------

framework for assessing properties of Estimators (\S\ref{sec:estimator}) and
Statistical Tests (Hypothesis Testing \S\ref{sec:hypothesis_testing})

\fist cf. Asymptotic Analysis (\S\ref{sec:asymptotic_analysis})



\subsubsection{Large Deviations Theory}\label{sec:large_deviations_theory}

\paragraph{Rate Function}\label{sec:rate_function}\hfill



% ------------------------------------------------------------------------------
\subsection{Statistical Analysis}\label{sec:statistical_analysis}
% ------------------------------------------------------------------------------

%FIXME: move this section ?

Statistical Theory -- FIXME

Statistic (\S\ref{sec:statistic}) -- a Function of a Random Variable
(\S\ref{sec:random_variable}) constituting a Random Sample
(\S\ref{sec:random_sample})

Statistical Population (\S\ref{sec:population})

Statistical Parameter (\S\ref{sec:population_parameter})

Statistical Model (\S\ref{sec:statistical_model})

Statistical Inference (\S\ref{sec:inferential_statistics})

Statistical Learning Theory (\S\ref{sec:statistical_learning_theory})



\subsubsection{Cluster Analysis}\label{sec:cluster_analysis}

Unsupervised Learning

example of Pattern Recognition (assignment of some Output Value to a given Input
Value), other examples are Statistical Classification
(\S\ref{sec:statistical_classification}) and Regression Analysis
(\S\ref{sec:regression_analysis})



\paragraph{Hierarchical Clustering}\label{sec:hierarchical_clustering}\hfill



% ------------------------------------------------------------------------------
\subsection{Frequentist Inference}\label{sec:frequentist_inference}
% ------------------------------------------------------------------------------

Frequency Interpretation
(\url{https://plato.stanford.edu/entries/probability-interpret/#FreInt}) --
differs from the Classical Interpretation in counting only the \emph{actual}
Outcomes instead of the \emph{possible} Outcomes; Finite Frequentism (Venn)



\subsubsection{Relative Frequency}\label{sec:relative_frequency}

\emph{Empirical Probability} or \emph{Experimental Probability} or
\emph{Long-run Probability}

after conducting many Trials (\S\ref{sec:trial}) of the same Experiment
(\S\ref{sec:experiment}), the Relative Frequencies of the various Outcomes
(\S\ref{sec:outcome}) and Events (\S\ref{sec:probability_event}) can be assessed

\url{https://plato.stanford.edu/entries/probability-interpret/#FreInt}:

\emph{Hypothetical Frequentism}: extension of Relative Frequencies of an actual
Sequence of ``Trials'' to counterfactual, limiting Relative Frequencies in case
of an Infinite number of Trials

\emph{Reference Class Problem}: Relative Frequencies must be ``Relativised'' to
a ``Reference Class'' (other interpretations of Probability may have this
problem as well)--

solutions restrict to certain Sequences of Outcomes, e.g. (Infinite)
``\emph{Collectives}'' (Von Mises57)--cf. Infinite Bernoulli Sequences
\S\ref{sec:bernoulli_sequence})--where a \emph{Place-selection} is an effective
method of selecting indices of Members of a Sequence such that the selection or
not of Index $i$ depends \emph{at most} on the first $i-1$ Outcomes
(``attributes''), with the Axioms of \emph{Convergence} (the limiting Relative
Frequency of any Outcome exists) and \emph{Randomness} (the limiting Relative
Frequency of each Outcome in a Collective $\omega$ is the same in any Infinite
Subsequence of $\omega$ determined by Place-selection; note that trivial
Sequences such as $H,H,H,\ldots$ satisfy this ``Randomness'' Axiom; cf. the
Principle of Maximum Entropy in Classical Probability), Algorithmic Randomness
(\S\ref{sec:algorithmic_randomness});
issues with limiting Relative Frequencies are that they violate Countable
Additivity and the Domain of Definition is not a Set-field or a $\sigma$-algebra
(de Finetti72)



\subsubsection{Propensity}\label{sec:propensity}

(wiki):

\emph{Chance} or \emph{Single-case Probability}

a purported ``\emph{cause}'' or explanation of an observed stable Relative
Frequency

invokes the Law of Large Numbers (\S\ref{sec:large_numbers}) to explain stable
\emph{long-run} Frequencies as a manifestation of invariant \emph{single-case}



\subsubsection{Frequency Distribution}\label{sec:frequency_distribution}

\subsubsection{Confidence Interval}\label{sec:confidence_interval}

Confidence Coefficient

Confidence Limit

Hypothesis Testing (\S\ref{sec:hypothesis_testing})

One-tail

Two-tail



% ------------------------------------------------------------------------------
\subsection{Bayesian Inference}\label{sec:bayesian_inference}
% ------------------------------------------------------------------------------

\emph{Evidential Probability} or \emph{Bayesian Probability} -- interpretation
of Probability as a ``reasonable'' \emph{Expectation} (\S\ref{sec:expecation})
or ``degree of belief''

Conditional Probabilities (\S\ref{sec:conditional_probability}), Bayes' Rule
(\S\ref{sec:bayes_theorem})

\fist Bayesian Network (Probabilistic Directed Acyclic Graphical Model
\S\ref{sec:bayesian_network})

Subjective Probability %FIXME: section
(\url{https://plato.stanford.edu/entries/probability-interpret/#SubPro}),
Conditioning (\S\ref{sec:conditioning})

\fist Subjective Logic (\S\ref{sec:subjective_logic})

\fist Aumann1987 - \emph{Correlated Equilibrium as an Expression of Bayesian
  Rationality} -- \emph{Correlated Equilibrium}
(\S\ref{sec:correlated_equilibrium}) ``does away with'' the ``dichotomy usually
perceived'' between the \emph{Bayesian} and \emph{Game-theoretic} world-views



\subsubsection{Conditioning}\label{sec:conditioning}

%FIXME: move under bayesian inference?

Subjective Probability
(\url{https://plato.stanford.edu/entries/probability-interpret/#SubPro}),
Orthodox Bayesianism (\S\ref{sec:bayesian_inference})

\fist not to be confused with Condition Numbers (Numerical Analysis
\S\ref{sec:condition_number})



\subsubsection{Prior Distribution}\label{sec:prior_distribution}

\subsubsection{Posterior Distribution}\label{sec:posterior_distribution}

\subsubsection{Credible Interval}\label{sec:credible_interval}

\subsubsection{Linear Quadratic Estimation (LQE)}\label{sec:lqe}

dual of Linear Quadratic Regulation (LQR \S\ref{sec:lqr})



% ------------------------------------------------------------------------------
\subsection{Predictive Inference}\label{sec:predictive_inference}
% ------------------------------------------------------------------------------

\subsubsection{Prediction}\label{sec:prediction}

\subsubsection{Predictability}\label{sec:predictability}

\fist Predictable Process (\S\ref{sec:predictable_process})



\subsubsection{Prediction Interval}\label{sec:prediction_interval}

Frequentist: Confidence Interval (\S\ref{sec:confidence_interval})

Bayesian: Credible Interval (\S\ref{sec:credible_interval})



\subsubsection{Best Linear Unbiased Prediction (BLUP)}\label{sec:blup}

under ``suitable assumptions'' on the Priors, Gaussian Process Regression
(Kriging \S\ref{sec:gaussian_process_regression}) gives the best BLUP of the
intermediate values



% ------------------------------------------------------------------------------
\subsection{Causal Inference}\label{sec:causal_inference}
% ------------------------------------------------------------------------------

\url{http://www.inference.vc/untitled/}



% ------------------------------------------------------------------------------
\subsection{Fiducial Inference}\label{sec:fiducial_inference}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Topological Inference}\label{sec:topological_inference}
% ------------------------------------------------------------------------------

Wasserman14 - \emph{Robust Topological Inference}

TDA (R package)



% ==============================================================================
\section{Statistical Randomness}\label{sec:statistical_randomness}
% ==============================================================================

cf. \emph{Algorithmic Randomness} (\S\ref{sec:algorithmic_randomness}) --
Universal Test, Universal Sequential Test (Martin-L\"of66)

cf. Quasi-random Sequences (\S\ref{sec:low_discrepancy})

Tests (\S\ref{sec:hypothesis_testing}):
\begin{itemize}
  \item Frequency test
  \item Serial Test
  \item Poker Test
  \item Gap Test
  \item ...
\end{itemize}



% ------------------------------------------------------------------------------
\subsection{Pseudorandom Process}\label{sec:pseudorandom_process}
% ------------------------------------------------------------------------------

Deterministic System (\S\ref{sec:deterministic_system}) exhibiting Statistical
Randomness

cf. \emph{Stochastic Process} (\S\ref{sec:stochastic_process})

\emph{Hash Functions} can create ``Random Numbers'' solely based on an Input
with no dependency on previous queries

2015 -
\url{http://blog.runevision.com/2015/01/primer-on-repeatable-random-numbers.html}
- \emph{Primer on Repeatable Random Numbers}



% ==============================================================================
\section{Stochastic Process}\label{sec:stochastic_process}
% ==============================================================================

or \emph{Random Process}

%FIXME: move section ???

\fist a \emph{Pseudorandom Process} (\S\ref{sec:pseudorandom_process}) is a
Determinstic Process exhibiting Statistical Randomness
(\S\ref{sec:statistical_randomness})

\fist Stochastic Calculus (\S\ref{sec:stochastic_calculus}):
\begin{itemize}
  \item Predictable Process (\S\ref{sec:predictable_process}) -- Process whose
    value is knowable at a prior time; smallest Class of Processes that is
    Closed under taking limits of Sequences (FIXME: clarify)
  \item Adapted Proces (Non-anticipative Process \S\ref{sec:adapted_process}) --
    cannot be Predicted into the Future (FIXME: clarify)
\end{itemize}

cf. Harmonic Functions (\S\ref{sec:harmonic_function})

\fist cf. Stochastic Optimization (\S\ref{sec:stochastic_optimization})

\fist cf. Non-deterministic Dynamical Systems
(\S\ref{sec:nondeterministic_dynamical_system})

\fist Stochastic Differential Equations (SDEs \S\ref{sec:sde}) -- a Differential
Equation in which one or more Terms is a Stochastic Process

First-hitting-time Model



% ------------------------------------------------------------------------------
\subsection{Statistical Fluctuation}\label{sec:statistical_fluctuation}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Random Walk}\label{sec:random_walk}
% ------------------------------------------------------------------------------

\subsubsection{Law of Iterated Logarithm}\label{sec:iterated_logarithm}

describes magnitude of Fluctuations of a Random Walk

cf. Law of Large Numbers (\S\ref{sec:large_numbers})



% ------------------------------------------------------------------------------
\subsection{Random Field}\label{sec:random_field}
% ------------------------------------------------------------------------------

(wiki): for a Probability Space $(\Omega, \mathcal{F}, P)$, an \emph{$X$-valued
  Random Field}, $F$, is a collection of $X$-valued Random Variables indexed by
elements in a Topological Space $T$:
\[
  F = \{ F_t : t \in T \}
\]
where each $F_t$ is an $X$-valued Random Variable

Tensor-valued Random Fields



\subsubsection{Markov Random Field}\label{sec:markov_random_field}

(MRF)



\subsubsection{Gibbs Random Field}\label{sec:gibbs_random_field}

\subsubsection{Conditional Random Field}\label{sec:conditional_random_field}

Machine Learning: Sequence MOdelling



\subsubsection{Gaussian Random Field}\label{sec:gaussian_random_field}

(GRF)

a 1D GRF is a Gaussian Process (\S\ref{sec:gaussian_process})



% ------------------------------------------------------------------------------
\subsection{Point Process}\label{sec:point_process}
% ------------------------------------------------------------------------------

\subsubsection{Poisson Process}\label{sec:poisson_process}

Memory-less

Poisson Distribution (\S\ref{sec:poisson_distribution})



\subsubsection{Binomial Process}\label{sec:binomial_process}

cf. \emph{Bernoulli Process} (\S\ref{sec:bernoulli_process})



% ------------------------------------------------------------------------------
\subsection{Markov Process}\label{sec:markov_process}
% ------------------------------------------------------------------------------

(or \emph{Markov Chain})

Markov Property (``Memorylessness'')

can be seen as a special case of Petri Nets (\S\ref{sec:petri_net})
where every Transition has a single Input and a single Output



% ------------------------------------------------------------------------------
\subsection{Discrete-time Stochastic Process}\label{sec:discretetime_stochastic}
% ------------------------------------------------------------------------------

\subsubsection{Bernoulli Process}\label{sec:bernoulli_process}

Mathematical Formalization of \emph{Binomial (Bernoulli) Trials}
(\S\ref{sec:binomial_trial})

Stochastic Computing

cf. \emph{Binomial Process} (Point Process \S\ref{sec:binomial_process})



\paragraph{Bernoulli Sequence}\label{sec:bernoulli_sequence}\hfill

\emph{Infinite Bernoulli Sequences} -- cf. \emph{Collectives} (Von Mises57); a
solution to the ``Reference Class Problem'' of Frequentist Probability Theory;
cf. (Martin-L\"of66)



% ------------------------------------------------------------------------------
\subsection{Continuous-time Stochastic Process}\label{sec:continuous_stochastic}
% ------------------------------------------------------------------------------

\subsubsection{Gaussian Process}\label{sec:gaussian_process}

a 1D Gaussian Random Field (\S\ref{sec:gaussian_random_field})

can be seen as the Infinite-dimensional generalization of Multivariate Normal
Distributions (\S\ref{sec:normal_distribution})

the Distribution of a Gaussian Process is the Joint Distribution of infinitely
many Random Variables, i.e. it is a Distribution over Functions with a
Continuous Domain

Machine Learning: Lazy Learning (1D Gaussian Distributions)

Gaussain Process Regression (Kriging \S\ref{sec:gaussian_process_regression})



\paragraph{Fractional Brownian Motion}\label{sec:fractional_brownian}\hfill

(\emph{fBm})

$H \in (0,1) \subset \reals$ -- Hurst index

$H = 1/2$ -- Wiener Process (Brownian Motion \S\ref{sec:wiener_process})

for $H > 1/2$, increments of the process are Positively Correlated, and exhibits
Long-range dependence

for $H < 1/2$, increments of the process are Negatively Correlated

Hausdorff and Box Dimension of $2 - H$

\fist Multifractals (\S\ref{sec:multifractal_system}): generalized framework of
Fractional Brownian Motions



\subparagraph{Wiener Process}\label{sec:wiener_process}\hfill

or \emph{Brownian Motion}

$H = 1/2$



% ------------------------------------------------------------------------------
\subsection{Stationary Process}\label{sec:stationary_process}
% ------------------------------------------------------------------------------

Stochastic Process for which the Unconditional Joint Probability Distribution
(\S\ref{sec:joint_probability}) does not change when shiften in Time (TODO:
xref)



% ------------------------------------------------------------------------------
\subsection{Stochastic Simulation}\label{sec:stochastic_simulation}
% ------------------------------------------------------------------------------

\subsubsection{Monte Carlo Simulation}\label{sec:monte_carlo}



% ------------------------------------------------------------------------------
\subsection{Probability Monad}\label{sec:probability_monad}
% ------------------------------------------------------------------------------

1980 - Giry - \emph{A Categorical Approach to Probability Theory}

collapsing a Probability Distribution (Measure) of Probability Distrubtions to a
Probability Distribution is called the ``Giry Monad'' (TODO)

\url{https://ncatlab.org/nlab/show/Giry+monad}

assigns to a Space of Outcomes $X$ a new Space $P X$ containing Random Outcomes
of $X$



\subsection{Kantorovich Monad}\label{sec:kantorovich_monad}

(Breugel)

\url{https://golem.ph.utexas.edu/category/2019/03/the_kantorovich_monad.html}

Probability Monad on the Category of Metric Spaces; can be described purely in
terms of Combinatorics of Finite Sequences of Elements

2017 - Fritz, Perrone - \emph{A Probability Monad as the Colimit of Spaces of
  Finite Samples}



% ==============================================================================
\section{Statistical Mechanics}\label{sec:statistical_mechanics}
% ==============================================================================

Thermodynamics, ``Irreversibility''

Jarzynski Equality

Crooks' Fluctuation Theorem



% ------------------------------------------------------------------------------
\subsection{Non-equilibrium Statistical Mechanics}
\label{sec:nonequilibrium_statistical_mechanics}
% ------------------------------------------------------------------------------

Jarzynski



% ------------------------------------------------------------------------------
\subsection{Statistical Ensemble}\label{sec:statistical_ensemble}
% ------------------------------------------------------------------------------

a Probability Distribution (\S\ref{sec:probability_distribution}) for the state
of a Physical System



\subsubsection{Thermodynamic Ensemble}\label{sec:thermodynamic_ensemble}



% ==============================================================================
\section{Multivariate Statistics}\label{sec:multivariate_statistics}
% ==============================================================================

% ------------------------------------------------------------------------------
\subsection{Multivariate Analysis}\label{sec:multivariate_analysis}
% ------------------------------------------------------------------------------

\subsubsection{Ordination}\label{sec:ordination}

\paragraph{Principal Components Analysis}
\label{sec:principal_components_analysis}\hfill

\paragraph{Multidimensional Scaling}\label{sec:multidimensional_scaling}\hfill

\paragraph{Correspondence Analysis}\label{sec:correspondence_analysis}\hfill

\subparagraph{Detrended Correspondence Analysis}
\label{sec:detrended_correspondence}\hfill

\subparagraph{Canonical Correspondence Analysis}
\label{sec:canonical_correspondence}\hfill



\paragraph{Bray-Curtis Ordination}\label{sec:bray_curtis_ordination}\hfill

\paragraph{Redundancy Analysis}\label{sec:redundancy_analysis}\hfill



% ==============================================================================
\section{Statistical Learning Theory}\label{sec:statistical_learning_theory}
% ==============================================================================

%FIXME start new document ???



% ------------------------------------------------------------------------------
\subsection{Statistical Classification}\label{sec:statistical_classification}
% ------------------------------------------------------------------------------

(wiki): an Algorithm (\S\ref{sec:algorithm}) that implements Classification is
called a \emph{Classifier}

often done with Logistic Regression (\S\ref{sec:logistic_regression})

\emph{Features} (Properties of Observations \S\ref{sec:observation} or
\emph{Instances}) are \emph{Explanatory Variables} (Regressors
\S\ref{sec:independent_variable}) and possible values of the Dependent Variable
(\S\ref{sec:dependent_variable}) are prediction categories (or \emph{Classes})
called \emph{Outcomes}

example of Pattern Recognition (assignment of some Output Value to a given Input
Value), other examples are Regression Analysis (\S\ref{sec:regression_analysis})
and Cluster Analysis (\S\ref{sec:cluster_analysis})



\subsubsection{Feature Vector}\label{sec:feature_vector}

\subsubsection{Linear Classifier}\label{sec:linear_classifier}

a \emph{Linear Predictor Function} assigns a ``score'' to each possible category
$k$ by taking the Dot Product of the Feature Vector with a Vector of
\emph{Weights}

\begin{itemize}
\item Logistic Regression (\S\ref{sec:logistic_regression})
\item Probit Regression (TODO: xref)
\item Perceptron Algorithm
\item ...
\end{itemize}



\subsubsection{Probabilistic Classification}
\label{sec:probabilistic_classification}

use of Statistical Inference (\S\ref{sec:statistical_inference})



% ==============================================================================
\section{Computational Learning Theory}\label{sec:computational_learning_theory}
% ==============================================================================

%FIXME start new document ???



% ------------------------------------------------------------------------------
\subsection{Vapnik-Chervonenkis Theory}\label{sec:vc_theory}
% ------------------------------------------------------------------------------

\emph{VC Theory}



% ==============================================================================
\section{Geometric Probability}\label{sec:geometric_probability}
% ==============================================================================

``\emph{Continuous Combinatorics}'': analogies between \emph{Counting} and
\emph{Measure} (\S\ref{sec:measure}) \fist Combinatorics (Part
\ref{part:combinatorics}), Measure Theory (Part \ref{part:measure_theory})



% ------------------------------------------------------------------------------
\subsection{Integral Geometry}\label{sec:integral_geometry}
% ------------------------------------------------------------------------------

% ------------------------------------------------------------------------------
\subsection{Stochastic Geometry}\label{sec:stochastic_geometry}
% ------------------------------------------------------------------------------



% ==============================================================================
\section{Information Geometry}\label{sec:information_geometry}
% ==============================================================================

Harper09 - \emph{The Replicator Equation as an Inference Dynamic}

Harper09 - \emph{Information Geometry and Evolutionary Game Theory}

\url{http://math.ucr.edu/home/baez/information/}

\url{https://johncarlosbaez.wordpress.com/2017/01/31/biology-as-information-dynamics/}

application of Differential Geometry
(\S\ref{sec:differential_geometry}) techniques to Probability Theory



% ------------------------------------------------------------------------------
\subsection{Statistical Manifold}\label{sec:statistical_manifold}
% ------------------------------------------------------------------------------

Riemannian Manifold (\S\ref{sec:riemannian_manifold}) with the
\emph{Fisher Information Metric} as the Riemannian Metric
(\S\ref{sec:riemannian_metric})



\subsubsection{Fisher Information Metric}\label{sec:fisher_metric}

Riemannian Metric (\S\ref{sec:riemannian_metric}) for a Statistical
Manifold

\fist \textbf{Fisher's Fundamental Theorem of Natural Selection},
Quasi-linkage Equilibrium: approximation in the case of Weak Selection
and Weak Epistasis -- Evolutionary Optimization
(\S\ref{sec:evolutionary_optimization}) %FIXME

\url{https://golem.ph.utexas.edu/category/2018/05/the_fisher_metric_will_not_be.html}


