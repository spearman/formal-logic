%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Probability Theory}\label{part:probability_theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ====================================================================
\section{Measure Theory}\label{sec:measure_theory}
% ====================================================================

% --------------------------------------------------------------------
\subsection{$\sigma$-algebra}\label{sec:sigma_algebra}
% --------------------------------------------------------------------

A \emph{$\sigma$-algebra} on a Set $X$ is a Non-empty Set $\mathcal{A}
\subset 2^X$ that is Closed under Set Operations of Complement
(\S\ref{sec:absolute_complement}) and Countable Union
(\S\ref{sec:union}).



% --------------------------------------------------------------------
\subsection{Measure}\label{sec:measure}
% --------------------------------------------------------------------

Measurable



\subsubsection{Radon Measure}\label{sec:radon_measure}



% --------------------------------------------------------------------
\subsection{Measurable Function}\label{sec:measurable_function}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Measure Space}\label{sec:measure_space}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Non-measurable Set}\label{sec:nonmeasurable_set}
% --------------------------------------------------------------------



% ====================================================================
\section{Probability Space}\label{sec:probability_space}
% ====================================================================

$(\Omega, \Sigma, P)$



% --------------------------------------------------------------------
\subsection{Sample Space}\label{sec:sample_space}
% --------------------------------------------------------------------

$S$

Set of all possible outcomes of Statistical Experiment



\subsubsection{Random Sample}\label{sec:random_sample}

\paragraph{Simple Random Sample}\label{sec:simple_random_sample}

\paragraph{Stratified Random Sample}\label{sec:stratified_random_sample}



\subsubsection{Experiment}\label{sec:experiment}

\paragraph{Bernoulli Trial}\label{sec:bernoulli_trial}
\hfill \\

Binomial Distribution (\S\ref{sec:binomial_distribution})

Bernoulli Distribution (\S\ref{sec:bernoulli_distribution})

\begin{enumerate}
  \item repeated Trials
  \item each Trial results in an Outcome
  \item Probability of Success is Constant
  \item each Trial is Independent
\end{enumerate}

Number of Successes in $n$ Bernoulli Trials is a \emph{Binomial Random
  Variable} (\S\ref{sec:binomial_random_variable})



% --------------------------------------------------------------------
\subsection{Event}\label{sec:event}
% --------------------------------------------------------------------

Subset of a Sample Space (\S\ref{sec:sample_space})



\subsubsection{Independent Event}\label{sec:independent_event}

$P(B|A) = P(B)$ or $P(A|B) = P(A)$

Independent if and only if $P(A \cap B) = P(A) P(B)$



% --------------------------------------------------------------------
\subsection{Random Variable}\label{sec:random_variable}
% --------------------------------------------------------------------

Variable (\S\ref{sec:variable})

$X : \Omega \rightarrow E$

Discrete Random Variable (\S\ref{sec:discrete_random_variable})

Continuous Random Variable (\S\ref{sec:continuous_random_variable})



\subsubsection{Characteristic}\label{sec:characteristic}

Function associating a Real Number to each Element in the Sample
Space.



\subsubsection{Discrete Random Variable}
\label{sec:discrete_random_variable}

\subsubsection{Continuous Random Variable}
\label{sec:continuous_random_variable}

has Probability $0$ of assuming a particular Value



\subsubsection{Expected Value}\label{sec:expected_value}

For Random Variable $X$ with Probability Distribution $f(x)$, the
\emph{Expected Value} (or \emph{Mean}) of $X$ is (Discrete):
\[
  \mu = E[X] = \sum_{i=1}^\infty x_i f(x_i)
\]
(Continuous):
\[
  \mu = E[X] = \int\limits_{-\infty}^{\infty} x_i f(x_i) dx
\]

Law of Large Numbers (\S\ref{sec:large_numbers})

For Random Variable $X$ with Probability Distribution $f(x)$, the
Expected Value of a Measurable Function
(\S\ref{sec:measurable_function}) of $X$, $g(X)$, is:
\[
  \mu_{g(X)} = E[g(X)] = \int\limits_{-\infty}^{\infty} g(x) f(x) dx
\]

For Joint Probability Density Function:
\[
  E[X Y] = \int\int x y j(x,y) dx dy
\]
\HandRight\; Note that $E[X Y]$ is not necessarily equal to $E[X]
E[Y]$, see Covariance (\S\ref{sec:covariance}).

For $X$ and $Y$ Independent (\S\ref{sec:independence}), then $E[X,Y] =
E[X] E[Y]$

If $a$ and $b$ are Constants, then $E[aX +b] = a E[X] + b$

$E [g(X) \pm h(X)] = E[g(X)] \pm E[h(X)]$

$E [g(X,Y) \pm h(X,Y)] = E[g(X,Y)] \pm E[h(X,Y)]$



\subsubsection{Variance}\label{sec:variance}

Discrete Random Variable $X$:
\[
  Var(X) = \sum_{i=1}^n f(x_i) (x_i - \mu)^2 = \sum_{i=1}^n f(x_i)
  x_i^2 - \mu^2
\]
where $\mu = \sum_{i=1}^n f(x_i) x_i$

Continuous Random Variable $X$:
\[
  Var(X) = \sigma^2 = \int (x - \mu)^2 f(x) dx = \int x^2 f(x) dx - \mu^2
\]
where $\mu = \int x f(x) dx$

For Random Variables $X$, $Y$ with Joint Probability Distribution
$f(x,y)$ and $a$, $b$, $c$ are Constants, then:
\[
  \sigma^2_{a X + b Y + c} = a^2 \sigma^2_X + b^2 \sigma^2_Y + 2ab
  \sigma_{X Y}
\]



\subsubsection{Covariance}\label{sec:covariance}

$X$, $Y$, Joint Probability Distribution
(\S\ref{sec:joint_probability}) $f(x,y)$

Discrete:
\[
  \sigma_{xy} = E [(x - \mu_X)(y - \mu_Y)] = \sum_x \sum_y (x - \mu_X)
  (y - \mu_Y) f(x,y)
\]

Continuous:
\[
  \sigma_{xy} = E [(x - \mu_X)(y - \mu_Y)] =
  \int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty}
  (x - \mu_X) (y - \mu_Y) f(x,y) dx dy
\]



\subsubsection{Correlation Coefficient}
\label{sec:correlation_coefficient}

\emph{Pearson Product-moment Correlation Coefficient}

$\rho_{xy} = \frac{\sigma_{xy}}{\sigma_x \sigma_y}$



\subsubsection{Binomial Random Variable}
\label{sec:binomial_random_variable}

Bernoulli Trial (\S\ref{sec:bernoulli_trial})

Binomial Distribution (\S\ref{sec:binomial_distribution})

$X ~ B(n,p)$

Probability Mass Function:
\[
  f(k,n,p) = P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}
\]
for $k = 0,1,2, \ldots, n$



% --------------------------------------------------------------------
\subsection{Probability}\label{sec:probability}
% --------------------------------------------------------------------

Probability of an Event $A$, $P(A)$ is the Sum of Weights of all
Sample Points in $A$

$\frac{|A|}{|S|}$

$P(A \cup B) = P(A) + P(B) - P(A \cap B)$

$P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) -
P(B \cap C) + P(A \cap B \cap C)$

Corollary: for Disjoint $A_1, A_2, \ldots$:
\[
  P(A_1 \cup A_2 \cup \ldots) = P(A_1) + P(A_2) + \ldots
\]

$P(A_1 \cap A_2 \cap \ldots \cap A_k) = P(A_1) P(A_2 | A_1) P(A_3 |
A_1 \cap A_2) \ldots P(A_k | A_1 \cap A_2 \cap \ldots \cap A_{k-1})$



\subsubsection{Conditional Probability}
\label{sec:conditional_probability}

$P(B|A) = \frac{P(A \cap B)}{P(A)}$ when $P(A) > 0$

$P(A \cap B) = P(A) P(B|A)$ when $P(A) > 0$



\subsubsection{Law of Total Probability}\label{sec:total_probability}

For a Countably Inifinite Partition of a Sample Space
(\S\ref{sec:sample_space}), $\{ B_n : n = 1,2,3,\ldots \}$, with each
Event $B_n$ being Measurable (\S\ref{sec:measure}), then for any Event
$A$ in the same Probability Space (\S\ref{sec:probability_space}):
\[
  P(A) = \sum_n P(A \cap B_n)
\]
or equivalently:
\[
  P(A) = \sum_n P(A|B_n) P(B_n)
\]
where terms such that $P(B_n) = 0$ are omitted from the summation.



\subsubsection{Baye's Theorem}\label{sec:bayes_theorem}

\[
  P(A|B) = \frac{P(A) P(B|A)}{P(B)}
\]


\subsubsection{Law of Large Numbers}\label{sec:large_numbers}

\subsubsection{Probability Measure Function}
\label{sec:probability_measure}



% --------------------------------------------------------------------
\subsection{Probability Distribution}
\label{sec:probability_distribution}
% --------------------------------------------------------------------

Probability Distribution Functions:
\begin{itemize}
  \item Probability Mass Function (\S\ref{sec:probability_mass})
  \item Probability Density Function (\S\ref{sec:probability_density})
  \item Cumulative Distribution Function
    (\S\ref{sec:cumulative_distribution})
\end{itemize}
See also Probability Measure Function
(\S\ref{sec:probability_measure}), Distribution (Analysis
\S\ref{sec:distribution})



\subsubsection{Discrete Probability Distribution}
\label{sec:discrete_probability}

\paragraph{Geometric Distribution}\label{sec:geometric_distribution}

\paragraph{Hypergeometric Distribution}
\label{sec:hypergeometric_distribution}

\paragraph{Binomial Distribution}\label{sec:binomial_distribution}
\hfill \\

Random Variable $X$ with Binomial Distribution where $n \in \nats$ and
$p \in [0,1]$:
\[
  X ~ B(n,p)
\]

Bernoulli Trial (\S\ref{sec:bernoulli_trial})



\subparagraph{Bernoulli Distribution}\label{sec:bernoulli_distribution}
\hfill \\

$n = 1$



\subsubsection{Joint Probability Distribution}
\label{sec:joint_probability}

$f(x,y,\ldots)$ for two or more Random Variables $X,Y,\ldots$

Discrete Random Variables:
\begin{enumerate}
  \item $f(x,y) \geq 0$
  \item $\sum_x \sum_y f(x,y) = 1$
  \item $P(X = x, Y = y) = f(x,y)$
\end{enumerate}

Continuous Random Variables:
\begin{enumerate}
  \item $\forall (x,y) \in X \times Y, f(x,y) \geq 0$
  \item $\int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty}
    f(x,y) dx dy = 1$
  \item $P[(X,Y) \in B] = \iint\limits_B f(x,y) dA$
\end{enumerate}


\subsubsection{Marginal Distribution}\label{sec:marginal_distribution}

\subsubsection{Conditional Distribution}
\label{sec:conditional_distribution}

\subsubsection{Probability Mass Function}\label{sec:probability_mass}

(or \emph{Probability Function})

for a Discrete Random Variable (\S\ref{sec:discrete_random_variable})
$X$:
\begin{enumerate}
  \item $f(x) \geq 0$
  \item $\sum_x f(x) = 1$
  \item $P(X = x) = f(x)$
\end{enumerate}



\subsubsection{Probability Density Function}
\label{sec:probability_density}

\emph{Probability Density Function} $f(x)$

for a Continuous Random Variable
(\S\ref{sec:continuous_random_variable}) $X$:
\begin{enumerate}
  \item $\forall x \in \reals, f(x) \geq 0$
  \item $\int\limits_{-\infty}^{\infty} f(x) dx = 1$
  \item $P (a < X < b) = \int\limits_a^b f(x) dx$
\end{enumerate}



\subsubsection{Cumulative Distribution Function}
\label{sec:cumulative_distribution}

Area under Probability Density Function

$\forall x \in \reals, F_X(x) = P(X \leq x) = \int\limits_{-\infty}^x
f(t) dt$



% --------------------------------------------------------------------
\subsection{Normalizing Constant}\label{sec:normalizing_constant}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Independence}\label{sec:independence}
% --------------------------------------------------------------------

\subsection{Conditional Independence}\label{sec:conditional_independence}



% ====================================================================
\section{Inferential Statistics}\label{sec:inferential_statistics}
% ====================================================================

Inductive Inference (\S\ref{sec:inductive_inference}), Statistical
Inference (\S\ref{sec:statistical_inference})

Random Variation: Sampling Variation, Observational Error



% --------------------------------------------------------------------
\subsection{Statistical Model}\label{sec:statistical_model}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Estimation Theory}\label{sec:estimation_theory}
% --------------------------------------------------------------------

\subsubsection{Estimator}\label{sec:estimator}

\subsubsection{Bias}\label{sec:bias}



% --------------------------------------------------------------------
\subsection{Regression Analysis}\label{sec:regression_analysis}
% --------------------------------------------------------------------

Regression Variable

Response Variable



% ====================================================================
\section{Descriptive Statistics}\label{sec:descriptive_statistics}
% ====================================================================

Summary of Data: Mean, Median, Mode, Standard Deviation



% --------------------------------------------------------------------
\subsection{Statistical Sample}\label{sec:statistical_sample}
% --------------------------------------------------------------------

Random Sample (\S\ref{sec:random_sample})



\subsubsection{Order Statistic}\label{sec:order_statistic}



% --------------------------------------------------------------------
\subsection{Summary Statistics}\label{sec:summary_statistics}
% --------------------------------------------------------------------

\subsubsection{Measure of Location}\label{sec:location_measure}

\paragraph{Arithmetic Mean}\label{sec:arithmetic_mean}
\hfill \\

\emph{Arithmetic Mean} $\overline{x} = \frac{1}{n}\sum_{i=1}^n x_i$



\paragraph{Trimmed Mean}\label{sec:trimmed_mean}

\paragraph{Sample Median}\label{sec:median}



\subsubsection{Statistical Dispersion}\label{sec:statistical_dispersion}

\paragraph{Sample Variance}\label{sec:variability}
\hfill \\

Degrees of Freedom, Linear Independence, Biased/Unbiased Estimator % FIXME



\paragraph{Standard Deviation}\label{sec:standard_deviation}
\hfill \\

Variance (\S\ref{sec:variance})

\emph{Uncorrected Standard Deviation}:
\[
  s_n = \sqrt{\frac{1}{n}\sum_{i=1}^n (x_i - \overline{x})^2}
\]

\emph{Corrected Standard Deviation}

\emph{Unbiased Standard Deviation}



\subparagraph{Chebyshev's Inequality}\label{sec:chebyshevs_inequality}
\hfill \\

Probability that a Random Variable $X$ will assume Value within $k$
Standdard Deviations

Random Variable $X$ with Finite Expected Value
(\S\ref{sec:expected_value}) $\mu$ and Finite Non-zero Variance
$\sigma^2$, for any $k \in \reals : k > 0$:
\[
  P(k\sigma \leq |X - \mu|) \leq \frac{1}{k^2}
\]



% ====================================================================
\section{Stochastic Process}\label{sec:stochastic_process}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Discrete-time Stochastic Process}
\label{sec:discretetime_stochastic}
% --------------------------------------------------------------------

\subsubsection{Bernoulli Process}\label{sec:bernoulli_process}

Bernoulli Trial (\S\ref{sec:bernoulli_trial})
