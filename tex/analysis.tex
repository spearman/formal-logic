%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Mathematical Analysis}\label{part:mathematical_analysis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{enumerate}
  \item \emph{Analyticity} -- Analytic Functions (\S\ref{sec:analytic_function})
  \item \emph{Holomorphy} -- Holomorphic Functions
    (\S\ref{sec:holomorphic_function})
  \item \emph{Harmonicity} -- Harmonic Functions
    (\S\ref{sec:harmonic_function})
  \item \emph{Conformality} -- Conformal Maps (\S\ref{sec:conformal_map})
\end{enumerate}
For the Complex Numbers (\S\ref{sec:complex_analysis}), the notions of
Analyticity, Holomorphy, Harmonicity, and Conformality \emph{coincide}; for the
Reals (\S\ref{sec:real_analysis}), and Quaternions
(\S\ref{sec:quaternionic_analysis}), not all notions are the same.

\fist cf. Multivariate Analysis (Statistics
\S\ref{sec:multivariate_analysis})



% ====================================================================
\section{Analytic Expression}\label{sec:analytic_expression}
% ====================================================================

Infinite Series (\S\ref{sec:infinite_series})

Continued Fraction

Gamma Function (\S\ref{sec:gamma_function}): extension of the Factorial
Function to Real and Complex Numbers

Bessel Function (\S\ref{sec:bessel_function})

Analytic Expressions exclude Differentials (\S\ref{sec:differential}),
Integrals (\S\ref{sec:integral}), Limits (\S\ref{sec:limits}), and Formal Power
Series (\S\ref{sec:formal_power_series})

Closed-form Expressions (TODO: xref) are a more restricted class of Mathematical
Expressions that can be Evaluated in a Finite number of Operations



% ====================================================================
\section{Asymptotic Analysis}\label{sec:asymptotic_analysis}
% ====================================================================

%FIXME move sequence, limit, etc. here ?



% ====================================================================
\section{Recurrence Relation}\label{sec:recurrence_relation}
% ====================================================================

Recursive Definition (\S\ref{sec:recursive_definition})



% --------------------------------------------------------------------
\subsection{Difference Equation}\label{sec:difference_equation}
% --------------------------------------------------------------------

\fist cf. Differential Equation (\S\ref{sec:differential_equation})



\subsubsection{Linear Difference Equation}\label{sec:linear_difference_equation}

\subsubsection{Homogeneous Difference Equation}
\label{sec:homogeneous_difference_equation}

cf. Homogeneous Differential Equation
(\S\ref{sec:homogeneous_differential_equation}), Homogeneous Polynomial
(\S\ref{sec:homogeneous_polynomial}), Homogeneous System of Linear Equations
(\S\ref{sec:homogeneous_system})



\paragraph{Characteristic Difference Equation}
\label{sec:characteristic_difference_equation}\hfill

cf. Characteristic Equation of a Homogeneous Linear Differential Equation
(\S\ref{sec:characteristic_equation})



\subsubsection{Matrix Difference Equation}\label{sec:matrix_difference_equation}

Difference Equation in which the Value of a Vector or Matrix of Variables at
one Point in Time is related to its own Value at one or more previous Points in
Time, using Matrices



% --------------------------------------------------------------------
\subsection{Logistic Map}\label{sec:logistic_map}
% --------------------------------------------------------------------



% ====================================================================
\section{Sequence}\label{sec:sequence}
% ====================================================================

A \emph{Sequence} can be defined as a Countable Totally Ordered
Multiset (\S\ref{sec:multiset}), that is, a collection of Elements (or
\emph{Terms}) in a given order where duplicate Elements are allowed.
The number of Elements in a Sequence is referred to as its
\emph{Length}.

A \emph{Finite Sequence} is called a \emph{Tuple} (\S\ref{sec:tuple}).

String (\S\ref{sec:string})

Series (\S\ref{sec:series})

Sequence Space (\S\ref{sec:sequence_space})

Sequence (Topology) (\S\ref{sec:sequence_topology})

$a_n : \nats \rightarrow \reals$



% --------------------------------------------------------------------
\subsection{Subsequence}\label{sec:subsequence}
% --------------------------------------------------------------------

A Sequence $a_n$ Converges (\S\ref{sec:convergent_sequence}) to $l$
if and only if all Subsequences of $a_n$ Converge to $l$.



% --------------------------------------------------------------------
\subsection{Tuple}\label{sec:tuple}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Limit}\label{sec:sequence_limit}
% --------------------------------------------------------------------

Can be defined in any Metric (\S\ref{sec:metric}) or Topological Space
(\S\ref{sec:topological_space}), generalized to a Topological Net
(\S\ref{sec:net}); see also Limits (\S\ref{sec:limit}) and Colimits
(\S\ref{sec:colimit}) in Category Theory.

The Limit of a Sequence is Unique

Bounded Sequence (\S\ref{sec:bounded_sequence})

$\lim a_n = 0 \Leftrightarrow \lim |a_n| = 0$

$\lim (a_n \pm b_n) = \lim a_n \pm \lim b_n$

$\lim (a_n b_n) = (\lim a_n) (\lim b_n)$

$\lim (\frac{a_n}{b_n}) = \frac{\lim a_n}{\lim b_n}$ for $\forall
n \in \nats, b_n \neq 0$ and $\lim b_n \neq 0$

$a_n \leq b_n$ for all $n$ Implies $\lim a_n \leq \lim b_n$, but it is
not the case that $a_n < b_n$ for all $n$ Implies $\lim a_n < \lim
b_n$ since $a_n$ and $b_n$ may still be equal in the Limit.

For an Open Interval $(x,y)$, $\lim a_n \in (x,y)$ Implies $a_n \in
(x,y)$ for all $n$, but for not for a Closed Interval.



\subsubsection{Limit Inferior}\label{sec:liminf}

$\liminf$

$\underline{\lim}$



\subsubsection{Limit Superior}\label{sec:limsup}

$\limsup$

$\overline{\lim}$



\subsubsection{Convergent Sequence}\label{sec:convergent_sequence}

$\forall \varepsilon > 0, \exists N : n \geq N \Rightarrow |(a_n - l)| <
\varepsilon$

A Sequence $a_n$ Converges to $l$ if and only if all Subsequences
(\S\ref{sec:subsequence}) of $a_n$ Converge to $l$.

If $\lim a_n = l$, then for $k \in \ints$, $\lim (a_{n+k}) = l$

If $a_n$ is Convergent then it is Bounded
(\S\ref{sec:bounded_sequence}).

If $F$ is a Closed Set (\S\ref{sec:closed_set}), then for any Sequence
$x_n$ in $F$ can Converge to $x$ if and only if $x$ is in $F$.

Intervals for Convergent Real Sequences are replaced by \emph{Discs} in the
case of Convergent Sequences of Complex Numbers (\S\ref{sec:complex_analysis})

Absolute Convergence (TODO)

if a Sequence of Analytic Functions Converges Uniformly
(\S\ref{sec:uniform_convergence}) in a region $S$ of the Complex Plane then the
Limit is Analytic in $S$-- this demonstrates that the Complex Functions are
more ``well-behaved'' than the Real Functions since the Uniform Limit of
Analytic Functions on a Real Interval do not need to be Differentiable
(\S\ref{sec:nowhere_differentiable})



\paragraph{Squeeze Theorem}\label{sec:squeeze_theorem}\hfill

For Sequences $a_n \leq b_n \leq c_n$ and $\lim a_n = l$ and $\lim c_n
= l$, then $\lim b_n = l$



\subsubsection{Divergent Sequence}\label{sec:divergent_sequence}



% --------------------------------------------------------------------
\subsection{Bounded Sequence}\label{sec:bounded_sequence}
% --------------------------------------------------------------------

If $a_n$ is Convergent (\S\ref{sec:convergent_sequence}) then it is
Bounded.



\subsubsection{Bolzano-Weierstrass Theorem}\label{sec:bolzano_weierstrass}

\emph{Sequential Compactness Theorem}

Lemma: Every Sequence $a_n$ of Real Numbers has a Monotone
Subsequence

The \emph{Bolzano-Weierstrass Theorem} states that a Bounded Sequence
$a_n$ has at least one Subsequence that Converges.



% --------------------------------------------------------------------
\subsection{Arithmetic Sequence}\label{sec:arithmetic_sequence}
% --------------------------------------------------------------------

(or \emph{Arithmetic Progression})

Arithmetic Series (\S\ref{sec:arithmetic_series})



% --------------------------------------------------------------------
\subsection{Geometric Sequence}\label{sec:geometric_sequence}
% --------------------------------------------------------------------

(or \emph{Geometric Progression})

Sum of Terms of a Geometric Sequence form a Geometric Series
(\S\ref{sec:geometric_series})



% --------------------------------------------------------------------
\subsection{Infinite Sequence}\label{sec:infinite_sequence}
% --------------------------------------------------------------------

\emph{Infinite Sequences} may be \emph{Singly Infinite}
(\S\ref{sec:singly_infinite}), having an initial Element but no final
Element, or \emph{Doubly Infinite} (\S\ref{sec:doubly_infinite})
having neither a first nor a last Element.



\subsubsection{Singly Infinite Sequence}\label{sec:singly_infinite}

A \emph{Singly Infinite Sequence} (or \emph{One-sided Infinite
  Sequence}) can be defined as a Function, $s$, with a Countably
Infinite Totally Ordered Set of Indices, $X$, for its Domain and a Set
of Elements, $Y$, for the Codomain:

  $s : X \rightarrow Y$ \\
where:

  $X = \{1,2,\ldots,n\}$

  $Y = \{a_1, a_2,\ldots,a_n\}$

  $s = \{(1,a_1), (2,a_2),\ldots, (n,a_n)\}$ \\
for some Countable $n \geq 0$.

Singly Infinite Sequences may be interpreted as Elements of the
Semigroup Ring of the Natural Numbers, $R[\mathbb{N}]$
(\S\ref{sec:group_ring}).



\subsubsection{Doubly Infinite Sequence}\label{sec:doubly_infinite}

A \emph{Doubly Infinite Sequence} (also \emph{Two-way Infinite} or
\emph{Bi-infinite Sequence}) may be defined as a Function from the Set
of all Integers $\mathbb{Z}$ into a Set, denoted
$(2n)^{\infty}_{n=-\infty}$.

Doubly Infinite Sequences may be interpreted as Elements of the Group
Ring of the Integers, $R[\mathbb{Z}]$ (\S\ref{sec:group_ring}.



% --------------------------------------------------------------------
\subsection{Monotone Sequence}\label{sec:monotone_sequence}
% --------------------------------------------------------------------

Monotone Function (\S\ref{sec:monotonic_function})

Increasing Sequence: $\forall n \in \nats, a_n \leq a_{n+1}$

An Increasing Sequence is Bounded above if and only if it is
Convergent.

Decreasing Sequence: $\forall n \in \nats, a_n \geq a_{n+1}$

A Decreasing Sequence is Bounded below if and only if it is
Convergent.



% --------------------------------------------------------------------
\subsection{Cauchy Sequence}\label{sec:cauchy_sequence}
% --------------------------------------------------------------------

Complete Metric Space (\S\ref{sec:complete_metric_space})



% --------------------------------------------------------------------
\subsection{Oscillation}\label{sec:oscillation}
% --------------------------------------------------------------------



% ====================================================================
\section{Series}\label{sec:series}
% ====================================================================

Sum of Terms of a Sequence (\S\ref{sec:sequence}) $a_n : \nats
\rightarrow \reals$



% --------------------------------------------------------------------
\subsection{Infinite Series}\label{sec:infinite_series}
% --------------------------------------------------------------------

Transcendental Numbers (\S\ref{sec:transcendental})

some examples:
\begin{itemize}
  \item $\frac{1}{4} - \frac{1}{16} + \frac{1}{64} - \frac{1}{256} \cdots
    = \frac{1}{4}$
  \item $\frac{1}{2} - \frac{1}{4} + \frac{1}{8} - \frac{1}{16} \cdots
    = \frac{1}{3}$
  \item $1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} \cdots  = \ln{2}$
  \item $1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} \cdots  = \frac{\pi}{4}$
  \item $1 + \frac{1}{4} + \frac{1}{9} + \frac{1}{16} \cdots = \frac{\pi^2}{6}$
  \item $\sum_{n=0}^\infty \frac{x^n}{n!} = e^x$
\end{itemize}



\subsubsection{Partial Sum}\label{sec:partial_sum}

Sequence $\{ a_1, a_2, a_3, \ldots \}$

$S_n = \sum_{k=1}^n a_k$



\subsubsection{Convergent Series}\label{sec:convergent_series}

Limit (\S\ref{sec:sequence_limit}) of Partial Sums $\{ S_1, S_2, S_3,
\ldots \}$ Converges (\S\ref{sec:convergent_sequence})



\subsubsection{Divergent Series}\label{sec:divergent_series}

\paragraph{Abelian Mean}\label{sec:abelian_mean}\hfill

\paragraph{Abel Summation}\label{sec:abel_summation}\hfill

Analytic Number Theory (\S\ref{sec:analytic_number_theory})

$a_n$ Sequence of Complex Numbers

$f(t)$ Differentiable Function (\S\ref{sec:differentiable_function})

$A(x) = \sum_{n \leq x} a_n$

$\sum_{n \leq x} a_n f(n) = A(x)f(x) - \int_1^x A(t)f'(t) dt$



% --------------------------------------------------------------------
\subsection{Arithmetic Series}\label{sec:arithmetic_series}
% --------------------------------------------------------------------

Arithmetic Progression (Arithmetic Sequence
\S\ref{sec:arithmetic_sequence})



% --------------------------------------------------------------------
\subsection{Geometric Series}\label{sec:geometric_series}
% --------------------------------------------------------------------

Constant Ratio between successive Terms

Terms form a Geometric Progression (Geometric Sequence
\S\ref{sec:geometric_sequence})

Sum Converges as long as Absolute Value of the Ratio of Terms is less
than $1$



\subsubsection{Hypergeometric Series}\label{sec:hypergeometric_series}

\paragraph{Hypergeometric Function}\label{sec:hypergeometric_function}\hfill

is a Solution of a Second-order Linear ODE
(\S\ref{sec:linear_differential_equation})

Hypergeometric Series (\S\ref{sec:hypergeometric_series})

Strict Subset of the Holonomic Functions (\S\ref{sec:holonomic_function})



\subparagraph{Generalized Hypergeometric Function}
\label{sec:generalized_hypergeometric_function}\hfill



% --------------------------------------------------------------------
\subsection{Harmonic Series}\label{sec:harmonic_series}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Alternating Series}\label{sec:alternating_series}
% --------------------------------------------------------------------

\[
  \sum_{n=0}^\infty (-1)^n a_n
\]
or:
\[
  \sum_{n=0}^\infty (-1)^{n-1} a_n
\]



% --------------------------------------------------------------------
\subsection{Telescoping Series}\label{sec:telescoping_series}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Power Series}\label{sec:power_series}
% --------------------------------------------------------------------

Infinite Series of the form:
\[
  f(x) = \sum_{n=0}^\infty a_n (x - c)^n
\]

\fist Formal Power Series (\S\ref{sec:formal_power_series})



\subsubsection{Taylor Series}\label{sec:taylor_series}

Centered at $0$: \emph{Maclaurin Series}

Polynomial formed by some initial Terms of a Taylor Series: Taylor
Polynomial (\S\ref{sec:taylor_polynomial}); Taylor Series is the Limit
(\S\ref{sec:sequence_limit}) of the Taylor Polynomials with increasing
Degree.

Note that a Function may not be equal to its Taylor Series even if its
Taylor Series Converges at every Point.

A Function is \emph{Analytic} (\S\ref{sec:analytic_function}) if and only if
its Taylor Series about $x_0$ Converges to the Function in some Neighborhood
for every $x_0$ in its Domain.

A Function that is equal to its Taylor Series in an Open Interval
(\S\ref{sec:interval}, or Disc \S\ref{sec:disc}) is an Analytic Function in
that Interval.

Maclaurin Series:
\[
  \sum_{n=0}^\infty f^{(n)}(0) \frac{x^n}{n!}
\]



\paragraph{Binomial Series}\label{sec:binomial_series}\hfill



% --------------------------------------------------------------------
\subsection{General Dirichlet Series}\label{sec:general_dirichlet}
% --------------------------------------------------------------------

%FIXME: move to subsection?



\subsubsection{Dirichlet Series}\label{sec:dirichlet_series}

the Riemann Zeta Function (\S\ref{sec:riemann_zeta}) is the Analytic
Continuation of the Dirichlet Series:
\[
  \zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s}
\]
for $s$ with Real part $\leq 1$



% --------------------------------------------------------------------
\subsection{Generating Function}\label{sec:generating_function}
% --------------------------------------------------------------------

cf. Riemann Zeta Function (\S\ref{sec:riemann_zeta})

\fist Weil Conjectures (\S\ref{sec:weil_conjectures})



% ====================================================================
\section{Infinite Product}\label{sec:infinite_product}
% ====================================================================

Converges when the Sequence converges to $1$

$\prod_{n=1}^\infty a_n$ Converges if and only if $\sum_{n=1}^\infty
ln(a_n)$ Converges

$q_n = (1 + u_1)(1 + u_2)\cdots(1 + u_n)$ Converges if and only if
$\sum u_n$ Converges.



% ====================================================================
\section{Real Analysis}\label{sec:real_analysis}
% ====================================================================

$R^1$ -- Real Line (\S\ref{sec:real_line}): 1-dimensional Real
Coordinate Space

(Infinitesimal) Calculus:
\begin{itemize}
\item Differential Calculus: Differentiable Functions
  (\S\ref{sec:differentiable_function})
\item Integral Calculus: Integrable Functions (\S\ref{sec:integrable_function})
\end{itemize}
uses notions of Convergent Infinite Sequences (\S\ref{sec:convergent_sequence})
and Convergent Infinite Series (\S\ref{sec:convergent_series}); related by
Fundamental Theorem of Calculus (\S\ref{sec:fundamental_calculus_theorem})

\fist cf. Calculus of Finite Differences
(\S\ref{sec:finite_differences_calculus})

\fist extension of Calculus in one Variable to Functions of several Variables:
Multivariable Calculus (\S\ref{sec:multivariable_calculus})



% --------------------------------------------------------------------
\subsection{Real Interval}\label{sec:real_interval}
% --------------------------------------------------------------------

Interval (\S\ref{sec:interval})

Interval Arithmetic (\S\ref{sec:interval_arithmetic})

$[a,b] = \bigcap_n (a - \frac{1}{n}, b + \frac{1}{n})$

Taylor06 - \emph{Interval Analysis Without Intervals}



\subsubsection{Interval Partition}\label{sec:interval_partition}

Closed Interval $[a,b]$

Finite Sequence (\S\ref{sec:sequence}) $(x_i) = \{ x_0, x_1, \ldots,
x_n \}$

$a = x_0 < x_1 < x_2 < \ldots < x_n = b$



% --------------------------------------------------------------------
\subsection{Critical Point}\label{sec:critical_point}
% --------------------------------------------------------------------

or \emph{Stationary Point}



\subsubsection{Maximum}\label{sec:maximum}

Upper Bound (\S\ref{sec:upper_bound})

Least Upper Bound (\S\ref{sec:least_upperbound})

Local Maxima

Second Derivative Test

Multivariable -- Gradient (\S\ref{sec:gradient}) equal to the Zero Vector:
$\nabla{f} = \vec{0}$

\fist \emph{Saddle Points} (\S\ref{sec:saddle_point}) are specific to
Multivariable Functions



\subsubsection{Minimum}\label{sec:minimum}

Lower Bound (\S\ref{sec:lower_bound})

Greatest Lower Bound (\S\ref{sec:greatest_lowerbound})

Local Minima

Second Derivative Test

Multivariable -- Gradient (\S\ref{sec:gradient}) equal to the Zero Vector:
$\nabla{f} = \vec{0}$

\fist \emph{Saddle Points} (\S\ref{sec:saddle_point}) are specific to
Multivariable Functions

Convex Functions (\S\ref{sec:convex_function}) have the property that Local
Minimum is necessarily a Global Minimum



\subsubsection{Second Derivative Test}\label{sec:second_derivative_test}

\fist multivariable Local Optimality Conditions (\S\ref{sec:local_optimality})



% --------------------------------------------------------------------
\subsection{Inflection Point}\label{sec:inflection_point}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Newton's Expansion}\label{sec:newtons_expansion}
% --------------------------------------------------------------------

% FIXME

$(1 + a)^n$ % ???



% --------------------------------------------------------------------
\subsection{Bernoulli's Inequality}\label{sec:bernoullis_inequality}
% --------------------------------------------------------------------

$n \in \nats$, $a \in \reals^+$, then:
\[
  (1 + a)^n \geq 1 + n a
\]


% --------------------------------------------------------------------
\subsection{Real Function}\label{sec:real_function}
% --------------------------------------------------------------------

or \emph{Real-valued Function}

\fist Vector-valued Functions (\S\ref{sec:vector_function})

\fist Root-finding Algorithms (\S\ref{sec:root_finding})



\subsubsection{Bounded Function}\label{sec:bounded_function}

a Bounded Function on a Compact Interval $[a,b]$ is Riemann Integrable
(\S\ref{sec:integrable_function}) if and only if it is Continuous
(\S\ref{sec:continuous_function}) ``Almost Everywhere'', i.e. Set of Points of
Discontinuity has Lebesgue Measure Zero (\S\ref{sec:lebesgue_measure})



\subsubsection{Function Limit}\label{sec:function_limit}

Limit Point (\S\ref{sec:limit_point}) of $D \in \reals$ is $a \in D$
such that:
\[
  \exists a_n \in D : a_n \neq a \wedge \lim a_n = a
\]

Function $f$ has a \emph{Limit} $l$ at $a$ if for all Sequences $a_n
\in D$ with $\lim a_n = a$ and $a_n \neq a$ for all $n$, $\lim f(a_n)
= l$



\subsubsection{Convex Function}\label{sec:convex_function}

\fist Convex Geometry (\S\ref{sec:convex_geometry})

\fist Convex Optimization (\S\ref{sec:convex_optimization}) -- Convex Functions
have the property that a Local Minimum is necessarily a Global Minimum, i.e.
Local Optimality Conditions (\S\ref{sec:local_optimality}) are \emph{Global}
Optimality Conditions

for $f : X \rightarrow \reals$ where $X$ is a Convex Set
(\S\ref{sec:convex_set}) in a Real Vector Space $\reals^m$, $f$ is
\emph{Convex} when $\forall x_1, x_2 \in X, \forall t \in [0,1]$:
\[
  f(tx_1 + (1-t)x_2) \leq tf(x_1) + (1-t)f(x_2)
\]
and \emph{Strictly Convex} when $\forall x_1 \neq x_2 \in X, \forall t \in
(0,1)$:
\[
  f(tx_1 + (1-t)x_2) < tf(x_1) + (1-t)f(x_2)
\]
where $tx_1 + (1-t)x_2$ is called a \emph{Convex Combination}
(\S\ref{sec:convex_combination}) of $x$ and $y$, and likewise $tf(x_1) +
(1-t)f(x_2)$ is a Convex Combination of $f(x_1)$ and $f(x_2)$

this means that the line segment connecting $f(x_1)$ and $f(x_2)$ is above the
curve $f(tx_1 + (1-t)x_2)$ at each point

a Function is Convex if and only if its Epigraph is a Convex Set

FIXME: relation to Second Derivative ???

Operations that conserve Convexity:
\begin{itemize}
  \item Multiplication by non-negative Scalar
  \item Addition of Convex Functions (extends to Infinite Sums, Integrals)
  \item Pre-composition with an affine Function: $f(Ax + b)$
  \item Pointwise Maximum, Pointwise Supremum of Convex Functions
  \item Composition rules: (can be derived from Vector Composition Rule and
    Affine Precomposition Rule ... TODO)
\end{itemize}

examples:
\begin{itemize}
  \item Affine (Linear) Functions $ax + b$ -- both Convex and Concave
  \item general Affine (Linear) Functions $a^T x + b$ -- both Convex and Concave
  \item Affine Functions on Matrices, i.e. Inner Product on Matrices
  \item Quadratic Function $x^2$ \fist Quadratic Forms
    (\S\ref{sec:quadratic_form})
  \item Exponential Function $e^x$
  \item Norms (\S\ref{sec:norm}), Spectral Norm (\S\ref{sec:spectral_norm})
  \item the Function for the maximum Eigenvalue of a Symmetric Matrix $X \in
    \mathsf{S}^n$:
    \[
      \lambda_{max}(X) = \mathrm{sup}_{\|\vec{y}\|_2=1} \vec{y}^T X \vec{y}
    \]
  \item $exp (g(x)$ of a Convex Function $g$
\end{itemize}



\subsubsection{Level Set}\label{sec:level_set}

a special case of a Fiber (\S\ref{sec:fiber})



% --------------------------------------------------------------------
\subsection{Real-valued Continuous Function}\label{sec:real_continuous}
% --------------------------------------------------------------------

$f : D \subseteq \reals \rightarrow \reals$

Continuous at $l \in D$ if for every Sequence $a_n \in D$ such that
$\lim a_n = l$, then $\lim f(a_n) = f(l)$

$\lim f (a_n) = f (\lim a_n)$

Equivalently: Continuous at $l$ if and only if:
\[
  \forall \varepsilon > 0, \exists \delta :
  |x - l| < \delta \Rightarrow |f(x) - f(l)| < \varepsilon
\]

Equivalently: Continuous at $a$ if and only if $f$ has Limit
(\S\ref{sec:function_limit}) $f(a)$ at $a$: $\lim_{x \rightarrow
  a}f(x) = f(a)$

Continuous on an Interval if and only if the Range on that Interval is
also a single Interval

For $f,g$ Continuous on $D$ at $a \in D$, then $(f + g)$, $f g$,
$\frac{f}{g}$ (when $g(a) \neq 0$) are Continuous at $a$.

For $g$ Defined on the Range of $f$, $\{ f(x); x \in D\}$, if $f$ is
Continuous at $a \in D$ and $g$ Continuous at $f(a)$, then $g \circ f$
is Continuous at $a$: $\lim g(f(a_n)) = g(f(a))$

Differentiable (\S\ref{sec:differentiable_function}) at $a$ Implies
Continuous at $a$

Continuously Differentiable $\subseteq$ Lipschitz Continuous $\subseteq$
$\alpha$-H\"older Continuous $\subseteq$ Uniformly Continuous = Continuous



\subsubsection{Local Extrema}\label{sec:local_extrema}

Local Maximum

Local Minimum

for Differentiable (\S\ref{sec:differentiable_function}) $f$ on an
Open Interval: $f'(a) = 0$ at Local Extrema



\paragraph{Second Derivative Test}\label{sec:second_derivative_test}\hfill

the Second Derivative Test is equivalent to testing the Determinants of the two
Submatrices of the Hessian Matrix (\S\ref{sec:hessian_matrix}) of Second-order
Partial Derivatives: a Matrix is Positive Definite
(\S\ref{sec:positive_definite}) if all Principal Minors (\S\ref{sec:minor}) are
Positive



\subsubsection{Intermediate Value Theorem}
\label{sec:intermediate_value}

For Function $f(x)$ Continuous on Closed Interval $[a,b]$, for any
$f(a) < c < f(b)$, there is a $d \in (a,b)$ such that $f(d) = c$.



\subsubsection{Extreme Value Theorem}\label{sec:extreme_value}

\subsubsection{Modulus of Continuity}\label{sec:continuity_modulus}



% --------------------------------------------------------------------
\subsection{Differentiable Function}\label{sec:differentiable_function}
% --------------------------------------------------------------------

For $f$ defined on Open Interval $(a,b) \subset \reals$, $f$ is
Differentiable at $x \in (a,b)$ if Limit $f'(x) = \lim_{h \rightarrow
  0} \frac{f (x+h) - f(x)}{h}$ exists.

Differentiable at $a$ Implies Continuous (\S\ref{sec:continuous_function}) at
$a$

a Complex Differentiable Function is called \emph{Holomorphic}
(\S\ref{sec:holomorphic_function})

\fist Differential Equation (\S\ref{sec:differential_equation})

\fist cf. Locally Linear Transformation (\S\ref{sec:locally_linear})

A Polynomial (\S\ref{sec:polynomial}), being the Sum of Differentiable
Functions, is Differentiable everywhere

For $f$ Differentiable on an Interval $I$, if $\forall x \in I, f'(x)
> 0$, $f$ is Strictly Increasing and if $\forall x \in I, f'(x) < 0$,
$f$ is Strictly Decreasing (see Monotonic Functions
\S\ref{sec:monotonic_function}).

Differentiation is a \emph{Product-preserving Functor}
(\S\ref{sec:product_preserving_functor})

Differential $df$ as a Morphism of Tangent Bundles (\S\ref{sec:tangent_bundle})
$df : T\reals \rightarrow T\reals$ (FIXME: explain)



\subsubsection{Derivative}\label{sec:derivative}

the Derivative is an Operator with Domain of the Set of all Functions that have
Derivatives at every Point of their Domain and, and with Range of a Set of
Functions:
\[
  D(f) = f'(x)
\]
(FIXME: clarify)

\fist Differential Operator (\S\ref{sec:differential_operator}): an Operator
defined as a Function of the Differentiation Operator


$(\frac{g}{f})' = \frac{f g' - f' g}{f^2}$

often viewed as a Quotient of \emph{Differentials} (\S\ref{sec:differential}):
\[
  \frac{dy}{dx}
\]

\fist Vector Derivative (\S\ref{sec:vector_derivative})

\emph{Differentiation Operator}

a Differential Operator (\S\ref{sec:differential_operator}) is an Operator
defined as a Function of the Differentiation Operator



\paragraph{Product Rule}\label{sec:product_rule}\hfill

\fist Integration by Parts (\S\ref{sec:integration_by_parts})



\subsubsection{Differential Operator}\label{sec:differential_operator}

$\nabla$

Operator defined as a Function of the Differentiation (Derivative
\S\ref{sec:derivative}) Operator

\emph{Basic Differential Operator} is a mapping from Differentiable Functions
to the Differentiable Functions consisting of Deriving the Function one or
several times:
\[
  \frac{d^i}{dx^i}
\]

\begin{itemize}
  \item Del (Gradient) Operator (\S\ref{sec:gradient})
  \item Laplacian Operator (\S\ref{sec:laplacian_operator})
  \item $\Theta$ (Homogeneity) Operator (TODO: xref)
\end{itemize}

\fist a \emph{Weyl Algebra} (\S\ref{sec:weyl_algebra}) is a Ring of
Differential Operators with Polynomial Coefficients in one Variable:
\[
  f_m(X)\partial^m_X + f_m{-1}(X)\partial^{m-1}_X + \cdots +
    f_1(X)\partial_X + f_0(X)
\]
and is Isomorphic to Quotient of the Free Algebra (\S\ref{sec:free_algebra}) on
two Generators, $X$ and $Y$, by the Ideal (\S\ref{sec:ring_ideal}) generated by
the Element $YX - XY - 1$



\paragraph{Linear Differential Operator}
\label{sec:linear_differential_operator}\hfill

a \emph{Linear Differential Operator} is a Linear Combination of Basic
Differential Operators with Differentiable Functions as Coefficients

is a Linear Transformation (\S\ref{sec:linear_transformation})

Linear Differential Operators form a Vector Space over the Real or Complex
Numbers, and also a Free Module over the Ring of Differentiable Functions



\paragraph{Theta Operator}\label{sec:theta_operator}\hfill

\paragraph{Elliptic Operator}\label{sec:elliptic_operator}\hfill

\subparagraph{Laplace Operator}\label{sec:laplace_operator}\hfill

$\Delta = \nabla^2$

Differential Operator (\S\ref{sec:differential_operator})

Discrete Laplace Operator (Graph Theory \S\ref{sec:discrete_laplace})

Harmonic Functions (\S\ref{sec:harmonic_function}) are exactly those Functions
that which lie in the Kernel of the Laplace Operator

\fist cf. Laplacian (\S\ref{sec:laplacian}), Laplace Transform
(\S\ref{sec:laplace_transform})
%FIXME same concepts?



\paragraph{Schwarzian Derivative}\label{sec:schwarzian_derivative}\hfill

Non-linear Differential Operator



\subsubsection{Antiderivative}\label{sec:antiderivative}

\emph{Indefinite Integral} or \emph{Primitive Integral}

If $f$ is Continuous on $[a,b]$ then:
\[
  F(x) = \int_a^x f
\]
for all $x \in [a,b]$ and $F$ is Differentiable on $(a,b)$ and $F' = f$.

\fist related to Definite Integrals (\S\ref{sec:definite_integral}) through the
Fundamental Theorem of Calculus (\S\ref{sec:fundamental_calculus_theorem})

solutions to Homogeneous Linear Differential Equations
(\S\ref{sec:homogeneous_linear_differential_equation}) may be expressed in
terms of Integrals

Richardson's Theorem (\S\ref{sec:richardsons_theorem}) makes a statement on the
solvability of the ``Integration Problem'' for a certain class of Expressions



\subsubsection{Differentiability Class}\label{sec:differentiability_class}

$\mathcal{C}^k$

$\mathcal{C}^1$ -- Continuous First Derivative: Continuously Differentiable
Function (\S\ref{sec:continuously_differentiable})

$\mathcal{C}^2$ -- Continuous Second Derivative

$\mathcal{C}^\infty$ -- Continuous for all Derivatives: Smooth Function
(\S\ref{sec:smooth_function})



\subsubsection{Continuously Differentiable}
\label{sec:continuously_differentiable}

A Function $f$ is \emph{Continuously Differentiable} if the Derivative $f'(x)$
exists and is a Continuous Function.

Differentiability Class (\S\ref{sec:differentiability_class}) $C^1$

Solutions to the One-dimensional Dynamical System
(\S\ref{sec:dynamical_system}) $\dot{x} = f(x)$ exist and are unique if $f(x)$
and $f'(x)$ are Continuous ($f$ is ``Continuously Differentiable'')



\subsubsection{Smooth Function}\label{sec:smooth_function}

Differentiability Class (\S\ref{sec:differentiability_class}) $C^{\infty}$

the Commutative Algebra of Smooth Functions on a Manifold $M$ is denoted
$C^\infty(M)$ %FIXME

any Closed Subset of $\reals^n$ is the Zero Set (\S\ref{sec:zero_set}) of a
Smooth Function on $\reals^n$



\paragraph{Analytic Function}\label{sec:analytic_function}\hfill

A Function is \emph{Analytic} if and only if its Taylor Series
(\S\ref{sec:analytic_function}) about $x_0$ Converges to the Function in some
Neighborhood for every $x_0$ in its Domain.

Complex Dynamics (\S\ref{sec:complex_dynamics})

Trigonometric Functions (\S\ref{sec:trigonometric_function})

a Complex Function is Analytic if and only if it is Holomorphic
(\S\ref{sec:holomorphic_function}), i.e. it is Complex Differentiable \fist
Cauchy-Riemann Conditions (\S\ref{sec:cauchy_riemann})

the Real and Imaginary parts of any Analytic Function define a \emph{Conformal
  Mapping} (\S\ref{sec:conformal_map}) --FIXME: clarify

if a Sequence of Analytic Functions Converges Uniformly
(\S\ref{sec:uniform_convergence}) in a region $S$ of the Complex Plane then the
Limit is Analytic in $S$-- this demonstrates that the Complex Functions are
more ``well-behaved'' than the Real Functions since the Uniform Limit of
Analytic Functions on a Real Interval do not need to be Differentiable
(\S\ref{sec:nowhere_differentiable})



\subparagraph{Analytic Continuation}\label{sec:analytic_continuation}



\subsubsection{Chain Rule}\label{sec:chain_rule}

(wiki):

Formula for computing the Derivative of the \emph{Composition} of two or more
Functions:
\[
  (f \circ g)' = (f' \circ g) g'
\]
or equivalently when $F(x) = f(g(x))$:
\[
  F'(x) = f'(g(x))g'(x)
\]

Leibniz Notation for Variable $z$ Dependent on Variable $y$ Dependent on
Independent Variable $x$:
\[
  \frac{dz}{dx} = \frac{dz}{dy} \cdot \frac{dy}{dx}
\]
and if $z = f(y)$ and $y = g(x)$ then:
\[
  \frac{dz}{dx} = \frac{dz}{dy} \cdot \frac{dy}{dx}
    = f'(y)g'(x) = f'(g(x))g'(x)
\]

\fist cf. \emph{Substitution Rule} (\S\ref{sec:substitution_rule}) for
Integration

Multivariable Chain Rule



\subsubsection{Cauchy Mean Value Theorem}
\label{sec:cauchy_mean_value}

For Functions $f$, $g$ Continuous on $[a,b]$, Differentiable on
$(a,b)$ then $\exists c \in (a,b)$ such that:
\[
  f'(c) (g(b) - g(a)) = g'(c) (f(b) - f(a))
\]



\subsubsection{Lagrange Mean Value Theorem}
\label{sec:lagrange_mean_value}

$f$ Continuous on $[a,b]$ and Differentiable on $(a,b)$ then $\exists
c \in (a,b)$ such that $f(b) - f(a) = f'(c)(b-a)$ or:
\[
  f'(c) = \frac{f(b) - f(a)}{b - a}
\]



\subsubsection{Rolle's Theorem}\label{sec:rolles_theorem}

for $f$ Continuous on $[a,b]$ and Differentiable on $(a,b)$ with $f(a)
= f(b)$, then $\exists c \in (a,b)$ such that $f'(c) = 0$



\subsubsection{Nowhere Differentiable Function}
\label{sec:nowhere_differentiable}

the Set of Nowhere-differentiable Real-valued Functions on the Closed Interval
$[0,1]$ is Comeagre (\S\ref{sec:comeagre}) in the Vector Space $C([0,1];
\reals)$ of Continuous Real-valued Functions on $[0,1]$ with the Topology of
Uniform Convergence (\S\ref{sec:uniform_convergence}); the collection of
Functions that are Differentiable at a single point of $[0,1]$ has Wiener
Measure (\S\ref{sec:wiener_measure}) $0$, even when taking Finite-dimensional
``slices'' of $C([0,1];\reals)$, in the sense that the Nowhere-differentiable
Functions form a Prevalent Subset (\S\ref{sec:prevalent_set}) of $C([0,1];
\reals)$

if a Sequence of Analytic Functions Converges Uniformly
(\S\ref{sec:uniform_convergence}) in a region $S$ of the Complex Plane then the
Limit is Analytic in $S$-- this demonstrates that the Complex Functions are
more ``well-behaved'' than the Real Functions since the Uniform Limit of
Analytic Functions on a Real Interval do not need to be Differentiable
(\S\ref{sec:nowhere_differentiable})



\paragraph{Weierstrass Function}\label{sec:weierstrass_function}\hfill

Continuous but Nowhere Differentiable

Fourier Series (\S\ref{sec:fourier_series})



% --------------------------------------------------------------------
\subsection{Integrable Function}\label{sec:integrable_function}
% --------------------------------------------------------------------

%FIXME: is this the same as Riemann-integrable ???

a Bounded Function (\S\ref{sec:bounded_function}) on a Compact Interval $[a,b]$
is Riemann Integrable if and only if it is Continuous
(\S\ref{sec:continuous_function}) ``Almost Everywhere'', i.e. Set of Points of
Discontinuity has Lebesgue Measure Zero (\S\ref{sec:lebesgue_measure})

cf. Integral Equation (\S\ref{sec:integral_equation})

\fist Integrable System (\S\ref{sec:integrable_system})

\fist Functional Integration (\S\ref{sec:functional_integration}): Integration
is done over a Domain which is a Function Space instead of a Domain of an
``ordinary'' Space

$f$ Bounded on Closed Bounded $[a,b]$, $\forall \varepsilon >0$, there
exists a Partition (\S\ref{sec:interval_partition}) $P$ of $[a,b]$
such that $0 \leq U(f,P) - L(f,P) < \varepsilon$ %FIXME xref upper lower

Monotone Functions (\S\ref{sec:monotonic_function}) and Continuous
Functions (\S\ref{sec:continuous_function}) are always (Riemann)
Integrable

$L(f,P) \leq \int_a^b f \leq U(f,P)$

For $c$ a Constant, if $f$ is Integrable then $cf$ is Integrable: $c
\int_a^b f = \int_a^b c f$

For $f$, $g$ Integrable on $[a,b]$, then $f + g$ is Integrable:
$\int_a^b (f+g) = \int_a^b f + \int_a^b g$

For $f$ Integrable on $[a,b]$ and $a < c < b$ then $f$ is Integrable
on $[a,c]$ and $[c,b$ and $\int_a^b f = \int_a^c f + \int_c^b f$

For $f$, $g$ Integrable on $[a,b]$ and $f \leq g$ on $[a,b]$, then
$\int_a^b f \leq \int_a^b g$

For Continuous $g$ and Integrable $f$, then $g \circ f$ is Integrable

For Integrable $f$, $|f|$ is Integrable and $|\int_a^b f| \leq
\int_a^b |f|$



\subsubsection{Integral}\label{sec:integral}

\emph{Integrand}

\fist Multiple Integral (\S\ref{sec:multiple_integral}) in Multivariable
Calculus

cf. Numerical Integration (\S\ref{sec:numerical_integration})

is a Linear Operator (\S\ref{sec:linear_operator}) --FIXME: clarify

\emph{Integration by Substitution} (\emph{$u$-substitution})



\paragraph{Definite Integral}\label{sec:definite_integral}\hfill

\fist related to Antiderivative (\S\ref{sec:antiderivative}) through the
Fundamental Theorem of Calculus (\S\ref{sec:fundamental_calculus_theorem})



\paragraph{Indefinite Integral}\label{sec:indefinite_integral}\hfill

\fist Antiderivative (\S\ref{sec:antiderivative})



\paragraph{Darboux Integral}\label{sec:darboux_integral}\hfill

Upper Darboux Sum

Lower Darboux Sum



\paragraph{Riemann Integral}\label{sec:riemann_integral}\hfill

$\int_a^b f(x) dx$

Interval Partition (\S\ref{sec:interval_partition})

Monotone Bounded Functions are Riemann Integrable

Continuous Functions are Reiemann Integrable

Riemann Integrable on $[a,b]$, Least Upper Bound of Lower Darboux Sums
is equal to the Greatest Lower Bound of the Upper Darboux Sums, value
denoted by $\int_a^b f$



\paragraph{Lebesgue Integral}\label{sec:lebesgue_integral}\hfill

\paragraph{Wallis Integral}\label{sec:wallis_integral}\hfill

\paragraph{Gaussian Integral}\label{sec:gaussian_integral}\hfill

or \emph{Euler-Poisson Integral}

Integral of the Gaussian Function (TODO) $e^{-x^2}$ over the entire Real Line

\fist Functional Integral (\S\ref{sec:functional_integral})



\paragraph{Integration by Parts}\label{sec:integration_by_parts}\hfill

TODO

\fist Product Rule (\S\ref{sec:product_rule})

$\int{uv'} = uv - \int{u'v}$



\subsubsection{Substitution Rule}\label{sec:substitution_rule}

Fundamental Theorem of Calculus (\S\ref{sec:fundamental_calculus_theorem})

\fist cf. \emph{Chain Rule} (\S\ref{sec:chain_rule}) for Differentiation



\subsubsection{Integral Mean Value Theorem}
\label{sec:integral_mean_value}

For $f$ Continuous on $[a,b]$, there is a $c \in [a,b]$ such that
$\int_a^b f = f(c)(b - a)$



\subsubsection{Integral Transform}\label{sec:integral_transform}

(wiki):

Transformation of an Equation from original Domain into another Domain where it
is solved more easily and then mapped back into the original Domain using the
Inverse of the Integral Transform

every Integral Transform is a Linear Operator (\S\ref{sec:linear_operator})

\emph{Schwartz Kernel Theorem}: if the Kernel of an Integral Transform is
allowed to be a Generalized Function (\S\ref{sec:generalized_function}) then
all Linear Operators are Integral Transforms

an \emph{Integral Transform} $T$ has the form:
\[
  (T f)(u) = \int_{t_1}^{t_2} f(t) K(t,u) dt
\]
mapping an input Function $f$ to another Function $T f$:
\[
  f \mapsto T f
\]
where $K$ is the \emph{Kernel Function} (or \emph{Integral Kernel} or
\emph{Nucleus}) of the Transform

some Kernels have associated an Inverse Kernel $K^{-1}(u,t)$, yielding an
Inverse Transform:
\[
  f(t) = \int_{u_1}^{u_2} (T f)(u) K^{-1}(u,t) du
\]

a \emph{Symmetric Kernel} is one that is unchanged when permuting the two
Variables



\paragraph{Fourier Transform}\label{sec:fourier_transform}\hfill

Fourier Transform is a single Projection ``out'' of a Laplace Transform
(\S\ref{sec:laplace_transform}) --FIXME: clarify

removes the requirement of Fourier Series (\S\ref{sec:fourier_series}) being
restricted to expressing functions on Finite Intervals to being able to express
functions on Infinite Intervals



\subparagraph{Continuous Fourier Trasform}
\label{sec:continuous_fourier_transform}\hfill

\subparagraph{Discrete-Time Fourier Trasform (DTFT)}\label{sec:dtft}\hfill



\paragraph{Laplace Transform}\label{sec:laplace_transform}\hfill

$\mathcal{L}\{f(t)\} = F(s)$

takes a Function $f(t)$ of a Real Variable $t$ (usually Time) to a Function
$F(s)$ of a Complex Variable $s$ (Complex Frequency
\S\ref{sec:complex_frequency})

\fist Fourier Transform (\S\ref{sec:fourier_transform}) is a single Projection
``out'' of a Laplace Transform (FIXME: clarify)

\fist cf. Laplacian (\S\ref{sec:laplacian}), Laplace Operator
(\S\ref{sec:laplace_operator}) %FIXME same concepts?

\url{https://www.quora.com/Intuitively-speaking-what-does-a-Laplace-transformation-represent}:

``A convenient way of turning a calculus into algebra, sin/cos/exp functions
into rational polynomials, and altogether making it faster to solve problems
that come up in differential equations.

Why? Because it turns differentiation into multiplication by $s$, integration
into division by $s$, and the sin/cos/exp functions into simple rational
polynomials in $s$.''

\[
  \mathcal{L} \{ f(t) \} = F(s) = \int_0^\infty f(t) e^{-st} dt
\]

$\mathcal{L}\{t^0\} = \frac{1}{s}$, $s > 0$

$\mathcal{L}\{t\} = \frac{1}{s^2}$

$\mathcal{L}\{t^2\} = \frac{2}{s^3}$

$\mathcal{L}\{t^3\} = \frac{6}{s^4}$

$\vdots$

$\mathcal{L}\{t^n\} = \frac{n!}{s^{n+1}}$

$\mathcal{L}\{e^{at}\} = \frac{1}{s-a}$, $s > a$

$\mathcal{L}\{e^{at}f(t)\} = F(s-a)$

$\mathcal{L}\{\sin at\} = \frac{a}{s^2+a^2}$

$\mathcal{L}\{ f'(t) \} = s \mathcal{L} \{f(t)\} - f(0)$

$\mathcal{L}\{ f''(t) \} = s^2 \mathcal{L} \{f(t)\} - sf(0) - f'(0)$

$\vdots$

Unit Step Function (\S\ref{sec:unit_step_function}) $u_c(t)$

$\mathcal{L}\{ u_c(t)f(t-c) \} = e^{-cs}\mathcal{L}\{f(t)\}$

Dirac Delta Function (\S\ref{sec:dirac_delta}) $\delta(t)$

$\mathcal{L}\{ \delta(t-c) \} = e^{-cs}$

$\mathcal{L}\{ \delta(t-c)f(t) \} = e^{-cs}f(c) $

Inverse Laplace Transform $\mathcal{L}^{-1}$

the Laplace Transform is a \emph{Linear Operator}
(\S\ref{sec:linear_operator}):
\[
  \mathcal{L} \{ c_1 f(t) + c_2 g(t) \}
    = c_1\mathcal{L}\{f(t)\} + c_2\mathcal{L}\{g(t)\}
\]

the Laplace Transform is a Holomorphic Function
(\S\ref{sec:holomorphic_function}) of the Variable $s$ with a Power Series
representation

Frequency-domain approach for Continuous Time Signals where the System may be
Stable \emph{or} Unstable (TODO: clarify)

in Control Theory (\S\ref{sec:control_theory}), Systems are often Transformed
from the Time Domain to the Frequency Domain using Laplace Transform and the
Transformed System's Zeros (\S\ref{sec:complex_zero}) and Poles
(\S\ref{sec:complex_pole}) are Analyzed in the Complex Plane:

Imaginary Component of Poles indicates what Frequency the System will Resonate
at, and Real Component of Poles indicates the magnitude of the Resonance, and
Zeros indicate Non-resonating Exponential Decays

Convolution (\S\ref{sec:convolution})



\paragraph{Legendre Transform}\label{sec:legendre_transform}\hfill

the Hamiltonian (\S\ref{sec:hamiltonian_system}) and the Routhian (TODO) can be
obtained from the Lagrangian (\S\ref{sec:lagrangan_system}) by the Legendre
Transform



% --------------------------------------------------------------------
\subsection{Fundamental Theorem of Calculus}
\label{sec:fundamental_calculus_theorem}
% --------------------------------------------------------------------

for Function $f$ Continuous (\S\ref{sec:continuous_function}) on the Interval
$[a,b]$, and $F$ with Derivative $f$:
\[
  F' = f
\]
on the Interval $(a,b)$, then:
\[
  \int_a^b f(x) dx = F(b) - F(a)
\]

Additionally, for every $x$ in the Interval $(a,b)$:
\[
  \frac{d}{dx}\int^x_a f(t) dt = f(x)
\]

\fist Subsitution Rule (\S\ref{sec:substitution_rule})

\fist Integral Theorems of Vector Calculus
(\S\ref{sec:integral_theorems}) in Multivariable Calculus



% --------------------------------------------------------------------
\subsection{Logistic Function}\label{sec:logistic_function}
% --------------------------------------------------------------------

%FIXME: move section ?

\fist generalization: Softmax Function (\S\ref{sec:softmax})



\subsubsection{Sigmoid Function}\label{sec:sigmoid_function}



% ====================================================================
\section{Complex Analysis}\label{sec:complex_analysis}
% ====================================================================

For the Complex Numbers (\S\ref{sec:complex_number}), the notions of
Analyticity, Holomorphy, Harmonicity, and Conformality \emph{coincide}; for the
Reals (\S\ref{sec:real_analysis}), and Quaternions
(\S\ref{sec:quaternionic_analysis}), not all notions are the same.

Finite-dimensional Associative Division Algebra
(\S\ref{sec:associative_division_algebra})

Commutative

Complex Differentiable Functions are automatically Analytic %FIXME

a Laplace Transform (\S\ref{sec:laplace_transform}) transforms a Function from
the Time Domain to the Complex Frequency Domain so it can be analyzed in the
Complex Plane

Complex Solutions to the Differential Equation $y'' + y = 0$

\emph{Euler's Formula}:
\[
  e^{ix} = \cos x + i \sin x
\]
\emph{Euler's Identity}:
\[
  e^{i\pi} + 1 = 0
\]

Convergence Sequences (\S\ref{sec:convergent_sequence}): Intervals
for Convergent Real Sequences are replaced by \emph{Discs} in the case of
Convergent Sequences of Complex Numbers

all Trigonometric Functions are related to $e^z$:
\[
  e^{iz} = \cos z + i \sin z
\]
as expressed in the Polar Form:
\[
  re^{i\theta}
\]


\emph{Weierstrass Approximation Theorem}\S\ref{sec:weierstrass_approximation}

any given Continuous Complex-Valued Function defined on a Closed Interval
$[a,b]$ can be Uniformly Approximated as closely as desired by a Polynomial
Function (\S\ref{sec:polynomial_function})



% --------------------------------------------------------------------
\subsection{Principal Value}\label{sec:principal_value}
% --------------------------------------------------------------------

Argument (Angle) -- usually restricted to the Interval $(-\pi,\pi]$, or else
$[0,2\pi)$ by adding $2\pi$ if the Value is Negative



% --------------------------------------------------------------------
\subsection{Complex Function}\label{sec:complex_function}
% --------------------------------------------------------------------

$f$

usual Limit Theorems hold

for a Complex Function to have a Derivative, the Directional Derivative must
exist in every direction and be the same

Integrating Complex Functions can be done by Line Integrals
(\S\ref{sec:line_integral}):
\[
  \int_{C} f(z) dz = \int_{t_0}^{t_1} f(z(t)) z'(t) dt
\]

if the Function $f(z)$ is Analytic on the enclosed Path, then the Line Integral
is Path Independent; cf. Exact Differentials (\S\ref{sec:exact_differential})

if $f$ is Analytic on and between Curves $C_1$ and $C_2$, then:
\[
  \oint_{c_1} f(z) dz = \oint_{c_2} f(z) dz
\]



\subsubsection{Zero}\label{sec:complex_zero}

\subsubsection{Pole}\label{sec:complex_pole}

a Meromorphic Function (\S\ref{sec:meromorphic_function}) Holomorphic
(\S\ref{sec:holomorphic_function}) on all of Domain except for a Set of
Isolated Points which are Poles of the Function



\subsubsection{Riemann Zeta Function}\label{sec:riemann_zeta}

Analytic Continuation of the Sum of the Dirichlet Series
(\S\ref{sec:dirichlet_series}) as a Function of a Complex Variable $s$:
\[
  \zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s}
\]
when the Real part of $s$ is $\leq 1$

\fist cf. Generating Functions (\S\ref{sec:generating_function})

\emph{Riemann Hypothesis}: the Riemann Zeta Function has Zeros only at Negative
Even Integers and Complex Numbers with Real part $\frac{1}{2}$



% --------------------------------------------------------------------
\subsection{Euler's Formula}\label{sec:eulers_formula}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Complex Frequency}\label{sec:complex_frequency}
% --------------------------------------------------------------------

the Imaginary Component $\omega$ of a Complex Frequency $s = -\sigma + i\omega$
corresponds to the ``usual'' concept of Frequency (i.e. the rate at which the
Sinusoid Cycles), and the Real Component $\sigma$ corresponds to the degree of
\emph{Damping} (i.e. an Exponential Decrease of Amplitude)

Complex Function of Frequency (as in Laplace or Fourier Transforms): the
Component of a Signal at any given Frequency is given by a Complex Number, the
Magnitude of which is the Amplitude of that Component and the Angle of which is
the relative Phase of the Wave (FIXME: clarify)

the response of a System as a Function of Frequency can also be described by a
Complex Function (FIXME: clarify)



% --------------------------------------------------------------------
\subsection{Complex Surface}\label{sec:complex_surface}
% --------------------------------------------------------------------

\subsubsection{Enriques-Kodaira Classification}
\label{sec:enriques_kodaira}

\subsubsection{Complex Plane}\label{sec:complex_plane}

or \emph{Argand Plane}

\emph{Fundamental Theorem of Algebra link between ``Algebra'' and
  ``Geometry''}: a Monic Polynomial (Univariate with Complex Coefficients
\S\ref{sec:monic_polynomial}), an Algebraic Object, is determined by the Set of
its Roots (\S\ref{sec:function_root}), a Geometric Object, in the Complex
Plane.



\subsubsection{Disc}\label{sec:disc}\hfill

\subsubsection{Extended Complex Plane}\label{sec:extended_complex_plane}

Complex Plane with Point at Infinity

Stereographic Projection (\S\ref{sec:stereographic_projection})

Riemann Sphere (\S\ref{sec:riemann_sphere})



% --------------------------------------------------------------------
\subsection{Holomorphic Function}\label{sec:holomorphic_function}
% --------------------------------------------------------------------

or ``\emph{Complex Differentiable}''

cf. Differentiable Function (\S\ref{sec:differentiable_function})

Complex-valued Function of one or more Complex Variables that is
Complex-differentiable in a Neighborhood (\S\ref{sec:neighborhood}) of
every Point in its Domain. Implies that any Holomorphic Function is
Infinitely Differentiable (\S\ref{sec:smooth_function}) and equal to
its own Taylor Series (\S\ref{sec:taylor_series}).

a Complex Function is Analytic (\S\ref{sec:analytic_function}) if and only if
it is Holomorphic, i.e. it is ``Complex Differentiable'':
\begin{align*}
  f(z)  & = u + iv \\
  f'(z) & = u_x + iv_x
\end{align*}
with the \emph{Cauchy-Riemann Conditions}:
\[
  u_x = v_y \text{ and } u_y = - v_x
\]

Real or Imaginary part of any Holomorphic Function is a Harmonic
Function (\S\ref{sec:harmonic_function})

a Regular Map (\S\ref{sec:regular_map}) between Complex Algebraic Varieties is
a Holomorphic Map


\begin{itemize}
  \item the Laplace Transform (\S\ref{sec:laplace_transform}) is a Holomorphic
    Function of the Variable $s$ with a Power Series representation
\end{itemize}


\subsubsection{Cauchy-Riemann Conditions}\label{sec:cauchy_riemann}

necessary and sufficient condition for a Complex Function to be Holomorphic
(Complex Differentiable)

\[
  u_x = v_y \text{ and } u_y = - v_x
\]



% --------------------------------------------------------------------
\subsection{Meromorphic Function}\label{sec:meromorphic_function}
% --------------------------------------------------------------------

Holomorphic on all of Domain except for a Set of Isolated Points which are
Poles (\S\ref{sec:pole}) of the Function

every Meromorphic Function on $D$ can be expressed as the ratio between two
Holomorphic Functions defined on $D$ and any Pole must correspond to a Zero in
the Denominator

since the Poles of a Meromorphic Function are \emph{Isolated}, there are at
most Countably many

if $D$ is Connected, the Meromorphic Functions form a Field Extension of the
Complex Numbers



\subsubsection{Elliptic Function}\label{sec:elliptic_function}

Meomorphic Function that is Periodic in two directions

cannot be Holomorphic

Double-periodic Functions (\S\ref{sec:double_periodic})

Pendulum (Non-linear Dynamical System \S\ref{sec:nonlinear_dynamical_system})



\subsubsection{$L$-function}\label{sec:l_function}

\subsubsection{Gamma Function}\label{sec:gamma_function}

$\Gamma(\alpha) = \int_0^{\infty} x^{\alpha -1} e^{-x} dx$

for $\alpha > 0$

\begin{enumerate}
\item $\Gamma(\alpha) = (\alpha - 1) \Gamma(\alpha -1)$
\item $\Gamma(n) = (n-1)!$
\item $\Gamma(1) = 1$
\item $\Gamma(\sfrac{1}{2}) = \sqrt{pi}$
\end{enumerate}

Gamma Distribution (\S\ref{sec:gamma_distribution})



% --------------------------------------------------------------------
\subsection{Conformal Map}\label{sec:conformal_map}
% --------------------------------------------------------------------

an Invertible Mapping (FIXME: bijective ???)

Locally Angle-preserving

if $f = u + iv$ is Analytic and $f'(z) \neq 0$, then:
\begin{align*}
  u & = u(x,y) \\
  v & = v(x,y)
\end{align*}
is \emph{Conformal}

the Real and Imaginary parts of any Analytic Function define a \emph{Conformal
  Mapping} (FIXME: clarify)

\begin{align*}
  u & = e^x \cos y \\
  v & = e^x \sin y
\end{align*}
is a \emph{Real Conformal Mapping} (FIXME: explain)

a Conformal Mapping preserves Laplace's Equation
(\S\ref{sec:laplaces_equation})-- only changes the Laplacian by a non-negative
factor



% --------------------------------------------------------------------
\subsection{Univalent Function}\label{sec:univalent_function}
% --------------------------------------------------------------------

Injective Holomorphic Function on an Open Subset of the Complex Plane



% --------------------------------------------------------------------
\subsection{Modular Form}\label{sec:modular_form}
% --------------------------------------------------------------------

Automorphic Form (\S\ref{sec:automorphic_form})



% --------------------------------------------------------------------
\subsection{Radical}\label{sec:radical}
% --------------------------------------------------------------------

\emph{Radical}

\emph{$n$th-root}

Algebraic Expressions (\S\ref{sec:algebraic_expression})



\subsubsection{Root of Unity}\label{sec:unity_root}

a Complex Number that gives $1$ when raised to some Positive Integer Power $n$

the Center (\S\ref{sec:center}) of $SL(n,F)$ is the Set of all Scalar Matrices
(\S\ref{sec:scalar_matrix}) with Unit Determinant and is Isomorphic to the
Group of $n$th Roots of Unity of the Field $F$



% --------------------------------------------------------------------
\subsection{Riemann Surface}\label{sec:riemann_surface}
% --------------------------------------------------------------------

One-dimensional Complex Manifold (\S\ref{sec:complex_manifold})

the Geometry of Riemann Surfaces is given by Two-dimensional Conformal
Geometry (\S\ref{sec:conformal_geometry})

there are three kinds of Simply-connected Riemann Surfaces, up to Conformal
Isomorphism:
\begin{itemize}
  \item Complex Plane
  \item Riemann Sphere
  \item Unit Disk or Hyperbolic Semiplane
\end{itemize}



\subsubsection{Riemann Mapping Theorem}
\label{sec:riemann_mapping_theorem}

\subsubsection{Riemann Sphere}\label{sec:riemann_sphere}

``simplest'' Riemann Surface

Model of the Extended Complex Plane
(\S\ref{sec:extended_complex_plane})

can be thought of as the \emph{Complex Projective Line}
$\mathbb{CP}^1$: the Projective Space (\S\ref{sec:projective_space} of
all Complex Lines in $\comps^2$

an example of an Algebraic Manifold (\S\ref{sec:algebraic_manifold})



\subsubsection{Bolza Surface}\label{sec:bolza_surface}

\subsubsection{Fundamental Polygon}\label{sec:fundamental_polygon}



% --------------------------------------------------------------------
\subsection{Countour Integration}\label{sec:contour_integration}
% --------------------------------------------------------------------

Residue Calculus (???) %FIXME



% ====================================================================
\section{Quaternionic Analysis}\label{sec:quaternionic_analysis}
% ====================================================================

the Quaternion Conjugate is Analytic everywhere in $\quats$
(note the Complex Conjugate is \emph{not} Analytic in $\comps$)

Homographies (\S\ref{sec:homography}): Screw Displacements ($SE(3)$
\S\ref{sec:special_euclidean})



% --------------------------------------------------------------------
\subsection{Quaternion Function}\label{sec:quaternion_function}
% --------------------------------------------------------------------

Maxwell's Equations

Affine Transformations of Quaternions have the form:
\[
  f(q) = aq + b, \;\;\; a,b,q \in \quats
\]

Derivation of Quaternion Functions requires a Direction-dependent Derivative
(FIXME: clarify)



% ====================================================================
\section{Functional Equation}\label{sec:functional_equation}
% ====================================================================

%FIXME: move this elsewhere ?

Functionals (\S\ref{sec:functional})

any Equation in which the Unknown (Variable \S\ref{sec:variable}) is a Function

e.g. an Additive Function (\S\ref{sec:additive_function}) $f$ is one satisfying
the Functional Equation $f(x + y) = f(x) + f(y)$


examples:
\begin{itemize}
  \item Schr\"oder's Equation (\S\ref{sec:schroeders_equation}): $\Psi(h(x)) =
    s\Psi(x)$ where $h(x)$ is a given Function and $\Psi(x)$ is Unknown;
    Solutions specify \emph{Flow} (\S\ref{sec:flow}), a generalization of
    Function Iteration Count (\S\ref{sec:iterated_function}) to a Continuous
    Parameter
\end{itemize}



% ====================================================================
\section{Differential Equation}\label{sec:differential_equation}
% ====================================================================

The \emph{Solution} to a Differential Equation $F(x,y,y',\ldots,y^{(n)}) = 0$
of Order $n$ is a \emph{Function} or \emph{Class of Functions} of the form $u :
I \subset \reals \rightarrow \reals$ where $u$ is an $n$-times Differentiable
Function (\S\ref{sec:differentiable_function}) on $I$ and $\forall x \in I$:
\[
  F(x,u,u',\ldots,u^{(n)}) = 0
\]
Such a $u$ defines an \emph{Integral Curve} (\S\ref{sec:integral_curve}) for
$F$.

\fist Family of Curves (\S\ref{sec:curve_family})

\fist cf. the Solution of a Polynomial Equation
(\S\ref{sec:polynomial_equation}) is a Value or Set of Values

\fist Algebraic $D$-modules (\S\ref{sec:algebraic_d_module}): Modules over the
Weyl Algebra (\S\ref{sec:weyl_algebra}) $A_n(K)$ over a Field $K$ of
Characteristic Zero; relates Weyl Algebra to Differential Equations

In a Dynamical System (\S\ref{sec:dynamical_system}), the \emph{Evolution
  Function} $\Phi^t$ is often the Solution of a Differential Equation of Motion
$\dot{x} = v(x)$ giving the Time Derivative of a Trajectory (Integral Curve)
$x(t)$ on the Phase Space starting at some Point $x_0$.

Extension, Maximal Solution, Global Solution, General Solution

\fist Partial Differential Equation (\S\ref{sec:pde}) in Multivariable Calculus

\fist Numerical Integration (\S\ref{sec:numerical_integration})

\fist Difference Equation (\S\ref{sec:difference_equation})

\fist Differential System (\S\ref{sec:differential_system})

\fist Integral Equations (\S\ref{sec:integral_equation}), Integro-differential
Equations (\S\ref{sec:integro_differential})

Exponential Models $y = Ce^{-kt}$, $y' = ky$

Logistic Models $y = \frac{y_0 k}{n_0 + (k-n_0)e^{-rt}}$,
  $y' = ky (1 - \frac{y}{k})$



% --------------------------------------------------------------------
\subsection{Differential}\label{sec:differential}
% --------------------------------------------------------------------

an Infinitesimally small quantity $dx$

cf. Derivative (\S\ref{sec:derivative}); often viewed as a \emph{Quotient} of
Differentials: $\frac{dy}{dx}$

\fist Dicrete equivalent: Finite Differences (\S\ref{sec:finite_difference})



\subsubsection{Exact Differential}\label{sec:exact_differential}

the Line Integral (\S\ref{sec:line_integral}) is determined only by the
endpoints



\subsubsection{Inexact Differential}\label{sec:inexact_differential}



% --------------------------------------------------------------------
\subsection{Ordinary Differential Equation}\label{sec:ode}
% --------------------------------------------------------------------

An \emph{Ordinary Differential Equation (ODE)} is an Equation containing one or
more Functions of one Independent Variable and its Derivatives. An equation of
the form:
\[
  F\Big(x,y,y',\ldots,y^{(n-1)}\Big) = y^{(n)}
\]
is an \emph{Order-$n$ Explicit Ordinary Differential Equation}, and:
\[
  F\Big(x,y,y',\ldots,y^{(n)}\Big) = 0
\]
is an \emph{Order-$n$ Implicit Ordinary Differential Equation}.

\fist a \emph{Linear Differential Equation}
(\S\ref{sec:linear_differential_equation}) is a Differential Equation defined
by a Linear Polynomial (a Polynomial of Degree $1$) in the Unknown Function and
its Derivatives:
\[
  y^{(n)} = \sum_{i=0}^{n-1} a_i (x) y^{(i)} + r(x)
\]
where $a_i(x)$ and $r(x)$ are Continuous Functions in $x$

\fist A \emph{Partial} Differential Equation (PDE
\S\ref{sec:pde}) is a Differential Equation
containing Unknown Multivariable Functions and their Partial Derivatives.

\fist System of ODEs (\S\ref{sec:system_of_odes})

\fist System of DAEs (\S\ref{sec:system_of_daes}): a System of Equations that
either contains Differential Equations and Algebraic (Polynomial) Equations
(\S\ref{sec:polynomial_equation}), or is equivalent to one; arises in
Constraints of Multibody Systems (\S\ref{sec:multibody_system}); differs from
ODE Systems in that the Jacobian Matrix (\S\ref{sec:jacobian_matrix}) of a DAE
is Singular (Non-invertible \S\ref{sec:singular_matrix})

\fist Flow (\S\ref{sec:flow})

A \emph{Solution} of an ODE $F$ is a Function $u : I \subset \reals \rightarrow
\reals$ called an \emph{Integral Curve} (\S\ref{sec:integral_curve}) for $F$
which is Tangent to the Slope Field defined by the ODE at every Point.

For $F$ a Function of $t$, $y$, and Derivatives (\S\ref{sec:derivative}) of
$y$, an Equation of the form:
\[
  F(t,y,y',\ldots,y^{(n-1)}) = y^{(n)}
\]
is a \emph{Explicit Ordinary Differential Equation} of \emph{Order $n$}, and an
\emph{Implicit Ordinary Differential Equation} (or \emph{Homogeneous Ordinary
  Differential Equation}) of Order $n$ has the form:
\[
  F(t,y,y',\ldots,y^{(n)}) = 0
\]
if $f(t)$ is a Solution to a Homogeneous ODE $F$ then $c\cdot{f(t)}$ is a
Solution to $F$ for any Constant $c$, and if $g(t)$ is also a Solution then
$f(t) + g(t)$ is a Solution


Domain of Solutions: there is no way in general to know what the Domain of the
Solution will be (MIT 18.03 2006 Lec. 1)

example:

for the Differential Equation $y' = \frac{-x}{y}$, setting $\frac{-x}{y}$ equal
to a Constant, $\frac{-x}{y} = C$, gives the \emph{Isoclines}
(\S\ref{sec:isocline}) of the Slope Field defined by the Differential Equation,
i.e. they are curves where the Family of Solutions are intersect the
curve with the indicated slope $C$ along its length

Standard First-order Form:
\[
  y' = p(x) y + q(x)
\]
cf. Standard Linear Form (\S\ref{sec:linear_differential_equation}):
\[
  y' + p(x) y = q(x)
\]

\emph{Local Existence and Uniqueness Theorem}: for a Differential Equation
\emph{in Standard Form}, when $f$ and $f_y$ are Continuous near $x_0$ and
$y_0$, there is one and only one Solution through a Point $(x_0, y_0)$

\emph{Global Existence and Uniqueness Theorem} (TODO)


\emph{Characteristic Equation}

an example of a System modelled by a First-order Ordinary Differential Equation
is an RC Circuit

an example of a System modelled by a Second-order Ordinary Differential
Equation is a Simple Harmonic Oscillator: the Phase Space consists of a
Velocity Dimension and a Position Dimension and the Orbit is Periodic



\subsubsection{Slope Field}\label{sec:slope_field}

When the Differential Equation is represented as a Vector Field or Slope Field
(\S\ref{sec:slope_field}), the corresponding Integral Curves
(\S\ref{sec:integral_curve}) are Tangent to the Field at each point.



\paragraph{Integral Curve}\label{sec:integral_curve}\hfill

An \emph{Integral Curve} is a Parametric Curve that represents a
\emph{specific} Solution of an Ordinary Differential Equation
(\S\ref{sec:ode}), or System of Equations (\S\ref{sec:system_of_odes}).

When the Differential Equation is represented as a Vector Field or Slope Field
(\S\ref{sec:slope_field}), the corresponding Integral Curves are Tangent to the
Field at each point.

Integral Curves intersect Isoclines (\S\ref{sec:isocline}) with the slope
indicated by the Isocline

(\emph{Existence and Uniqueness Theorem}) two Integral Curves cannot cross (at
an Angle) or touch (be Tangent)

In a Dynamical System (\S\ref{sec:dynamical_sytem}), the Integral Curves for
the Differential Equation governing the System are referred to as
\emph{Trajectories} (\S\ref{sec:trajectory}).

e.g. Electric Field or Magnetic Field Lines, Streamlines (Velocity Field of a
Fluid)

\emph{Flow}



\paragraph{Isocline}\label{sec:isocline}\hfill

Isoclines are intersected by Integral Curves (\S\ref{sec:integral_curve}) at
the slope indicated by the Isocline

example:

for the Differential Equation (\S\ref{sec:differential_equation}) $y' =
\frac{-x}{y}$, setting $\frac{-x}{y}$ equal to a Constant, $\frac{-x}{y} = C$
gives a Family of \emph{Isoclines} of the Slope Field defined by the
Differential Equation, i.e. they are curves where the Family of Solutions
intersect the curve with the indicated slope $C$ along its length



\subsubsection{Initial Value Problem (IVP)}\label{sec:ivp}

\fist cf. Boundary Value Problem (\S\ref{sec:boundary_value_problem}) defines
Values of the Solution at more than one Point

(wiki):

an ODE together with a Value of the Unknown Function called the \emph{Initial
  Condition} at a given Point in the Domain of the Solution

Differential Equation:
\[
  y'(t) = f(t, y(t))
\]
with $f : \Omega \subset \reals \times \reals^n \rightarrow \reals^n$ where
$\Omega$ is an Open Set of $\reals \times \reals^n$ and Initial Condition
\[
  (t_0, y_0) \in \Omega
\]
in the Domain of $f$

a \emph{Solution} to an Initial Value Problem is a Function $y : \reals
\rightarrow \reals^n$ that is a Solution to the Differential Equation and
satisfies $y(t_0) = y_0$

\fist Time Evolution (\S\ref{sec:time_evolution})

\fist Dynamical Systems (\S\ref{sec:dynamical_system})

\begin{itemize}
  \item the Trajectory $\vec{s}(t)$ of a Hamiltonian System is a Solution to
    the IVP defined by Hamilton's Equations and the Initial Condition
    $\vec{s}(0) = \vec{s}_0 \in \reals^{2N}$
\end{itemize}

First-order Initial Value Problems: \emph{Peano Existence Theorem} gives a set
of circumstances in which a solution exists

\emph{Picard-Lindel\"of Theorem}

Higher Dimensions (TODO)

for an $n$-th Order Linear Initial Value Problem:
\[
  f_n(x)\frac{d^ny}{dx^n} + \cdots + f_1(x)\frac{dy}{dx} + f_0(x)y = g(x)
\]
such that:
\begin{align*}
  y(x_0)   & = y_0   \\
  y'(x_0)  & = y_0'  \\
  y''(x_0) & = y_0''
\end{align*}
then for any Non-zero $f_n(x)$ and $\{f_0,f_1,\ldots\}$ and $g$ are Continuous
on some Interval containing $x_0$, $y$ is unique and exists



% --------------------------------------------------------------------
\subsection{Separable Differential Equation}\label{sec:separable}
% --------------------------------------------------------------------

a Differential Equation is \emph{Separable} if the Derivative $\frac{dy}{dx}$
can be written in terms of the product of separate functions of $x$ and $y$ as:
\[
  \frac{dy}{dx} = g(x)h(y)
\]
or equivalently, as long as $h(y) \neq 0$:
\[
  \frac{1}{h(y)} dy = g(x) dx
\]



\subsubsection{Separation of Variables}\label{sec:separation_of_variables}

\subsubsection{Homogeneous Differential Equation}
\label{sec:homogeneous_differential_equation}

If the Differential Equation:
\[
  \frac{dy}{dx} = f(x,y)
\]
can be rewritten as:
\[
  \frac{dy}{dx} = F\Big(\frac{y}{x}\Big)
\]
then it is \emph{Homogeneous} and a Variable Substitution allows the Equation to
be made \emph{Separable}.

cf. Homogeneous Difference Equation
(\S\ref{sec:homogeneous_difference_equation}), Homogeneous Polynomial
(\S\ref{sec:homogeneous_polynomial}), Homogeneous System of Linear Equations
(\S\ref{sec:homogeneous_system})

\emph{not} ``Homogeneous Linear Differential Equation''
(\S\ref{sec:homogeneous_linear_differential})



% --------------------------------------------------------------------
\subsection{Exact Differential Equation}\label{sec:exact_equation}
% --------------------------------------------------------------------

$\frac{d}{dx}\Psi(x,y) = \frac{\partial{\Psi}}{\partial{x}}
  + \frac{\partial{\Psi}}{\partial{x}}\frac{dy}{dx}$

$\Psi_{xy} = \Psi_{yx}$ -- if $\Psi$ and its Derivatives are Continuous over
some Domain

$\Psi_x + \Psi_y \frac{dy}{dx} = 0$

$\frac{d}{dx}\Psi(x,y) = 0$

$\Psi(x,y) = c$

$M(x,y) + N(x,y)\frac{dy}{dx} = 0$

$M_y = N_x$ if and only if $M(x,y) + N(x,y)\frac{dy}{dx} = 0$ is an Exact
Equation, implies: $\Psi_{xy} = M_y$, $\Psi_{yx} = N_x$

\emph{Potential Function}



\subsubsection{Integrating Factor}\label{sec:integrating_factor}

$u(x)$



% --------------------------------------------------------------------
\subsection{Linear Differential Equation}
\label{sec:linear_differential_equation}
% --------------------------------------------------------------------

An Ordinary Differential Equation is \emph{Linear} if $F$ can be written as a
Linear Polynomial (a Polynomial of Degree $1$) of the \emph{Unknown Function}
($y$ below) and its Derivatives:
\[
  a_0(x)y + a_1(x)y' + a_2(x)y'' + \cdots + a_n(x)y^{(n)} + r(x) = 0
\]
or:
\[
  y^{(n)} = \sum_{i=0}^{n-1} a_i(x) y^{(i)} + r(x)
\]
where $a_i(x)$ and $r(x)$ are Differentiable Functions in $x$ (not necessarily
Linear) and $r(x)$ is called the \emph{Source Term} (or sometimes
\emph{Constant Term}, even though it can be a non-constant Function).

First-order Linear Differential Equations (with non-constant coefficients) and
Homogeneous Linear Differential Equations
(\S\ref{sec:homgeneous_linear_differential_equation}) have solutions that may
be expressed in terms of Integrals (\S\ref{sec:antiderivative})

Second-order and higher Linear Differential Equations with non-constant
coefficients cannot in general be solved by Quadratures (i.e. Integrals --
Kovacic Algorithm for determining if this is possible)

Hypergeometric Functions (\S\ref{sec:hypergeometric_function}) are solutions of
Second-order Linear Differential Equations

Solutions of a Homogeneous Linear Differential Equation form a Vector Space,
ordinarily of Dimension equal to that of Order of the Equation; all Solutions
of a Linear Differential Equation are found by adding to a particular Solution
any Solution of the Associated Homgeneous Equation (FIXME: clarify)

cf. Linear Difference Equation (\S\ref{sec:linear_difference_equation})

\emph{First-order Linear Differential Equations}:
\[
  a(x) y' + b(x) y = c(x)
\]
Homogeneous:
\[
  a(x) y' + b(x) y = 0
\]
Standard Linear Form:
\[
  y' + p(x) y = q(x)
\]
cf. Standard First-order Form (\S\ref{sec:ode}):
\[
  y' = p(x) y + q(x)
\]

\emph{Second-order Linear Differential Equations}:
\[
  a(x) y'' + b(x) y' + c(x) y = d(x)
\]



\subsubsection{Homogeneous Linear Differential Equation}
\label{sec:homogeneous_linear_differential}

\emph{not} the same concept as general ``Homogeneous Differential Equations''
(\S\ref{sec:homogeneous_differential_equation})

Homogeneous Linear Differential Equations have the Constant Term $0$, i.e. it
is a Homogeneous Polynomial (\S\ref{sec:homogeneous_polynomial}) in the Unknown
Function and its Derivatives

Solutions of a Homogeneous Linear Differential Equation form a Vector Space,
ordinarily of Dimension equal to that of Order of the Equation; all Solutions
of a Linear Differential Equation are found by adding to a particular Solution
any Solution of the Associated Homgeneous Equation (FIXME: clarify)

an $n$-th Order Homogeneous Linear Differential Equation has Constant
Coefficients if it has the form:
\[
  a_0y + a_1y' + a_2y'' + \cdots + a_ny^{(n)} = 0
\]
(FIXME: otherwise it has polynomial coefficients ???)

e.g. $e^x$ is the unique solution to the Equation $f' = f$ such that $e^0 = 1$,
and it follows that the $n$th Derivative of $e^{cx}$ is $c^n e^{cx}$

Homogeneous Linear Differential Equations have solutions that may be expressed
in terms of Integrals (\S\ref{sec:antiderivative})

Solutions to (Systems of) Homogeneous Linear Differential Equations with
Polynomial Coefficients (FIXME: i.e. non-constant ???) are called
\emph{Holonomic Functions} (\S\ref{sec:holonomic_function}).

\emph{Second-order Homogeneous Linear Differential Equation}:

\[
  A y'' + B y' + C y = 0
\]

if $g(x)$ is a Solution, then $c\cdot{g(x)}$ is also a Solution

if $h(x)$ is also a Solution, then $g(x) + h(x)$ is also a Solution



\paragraph{Characteristic Equation}\label{sec:characteristic_equation}\hfill

cf. Characteristic Equation of a Homogeneous Difference Equation
(\S\ref{sec:characteristic_difference_equation})

$A y'' + B y' + C y = 0$

$y = e^{rx}$

Characteristic Equation: $Ar^2 + Br + C = 0$

$r = \frac{-B \pm \sqrt{B^2 - 4AC}}{2A}$

Real Roots: $r_1, r_2$

General Solution: $y = c_1e^{r_1x} + c_2e^{r_2x}$

Complex Roots: $\lambda \pm \mu i$

General Solution: $y = e^{\lambda x}(c_1 \cos\mu{x} + c_2 \sin\mu{x})$

Repeated Roots: $r$

\emph{Reduction of Order}: $y = c_1 x e^{rx} + c_2 e^{rx}$



\paragraph{Holonomic Function}\label{sec:holonomic_function}\hfill

a \emph{Holonomic Function} is an Element of a Holonomic Module
(\S\ref{sec:holonomic_module}) of Smooth Functions

\fist cf. Holonomy (\S\ref{sec:holonomy}), Holonomic Constraints
(\S\ref{sec:holonomic_constraint})

a Multivariable Smooth Function that is a solution to a (System of) Homogeneous
Linear Differential Equation(s) with Polynomial Coefficients

the Class of Holonomic Functions is ``stable'' (FIXME: closed ???) under Sums,
Products, Derivation, and Integration

Strict Superset of the Hypergeometric Functions
(\S\ref{sec:hypergeometric_function})

Holonomic Functions include all Algebraic Functions
(\S\ref{sec:algebraic_function}), some Transcendental Functions ($\sin x$,
$\cos x$, $e^x$, $\log x$), the Generalized Hypergeometric Function
(\S\ref{sec:generalized_hypergeometric_function}), Bessel Functions
(\S\ref{sec:bessel_function}), Airy Functions (TODO: xref), ``classical''
Orthogonal Polynomials (\S\ref{sec:orthogonal_polynomial})

Holonomic Functions form a Ring (\S\ref{sec:ring}), but are not closed under
Division (so they do not form a Field)



\subsubsection{Non-homogeneous Linear Differential Equation}
\label{sec:nonhomogeneous_linear_differential}

an \emph{$n$-order Non-homogeneous Linear Differential Equation} with Constant
Coefficients may be written:
\[
  y^{(n)}(x) + a_1y^{(n-1)}(x) + \cdots + a_{n-1}y'(x) + a_ny(x) = f(x)
\]
where $a_1,\ldots,a_n$ are Real or Complex Numbers, $f$ is a given Function of
$x$ and $y$ is the Unknown Function

Second-order Non-homogeneous Linear Differential Equation:
\[
  A y'' + B y' + C y = g(x)
\]

for $h$ a Solution for the Homogeneous Linear Differential Equation $Ah'' + Bh'
+ Ch = 0$

let $j(x)$ be a \emph{particular} Solution of $Aj'' + Bj' + Cj = g(x)$

then $k(x) = h(x) + j(x)$ is a Solution of $A y'' + B y' + C y = g(x)$

\emph{Method of Undetermined Coefficients}

for $A y'' + B y' + C y = f(x) + g(x) + \cdots$, the Solution is the General
Solution of the Homogeneous Equation plus the particular Solutions to each of
the individual RHS (FIXME: clarify)



% --------------------------------------------------------------------
\subsection{Stochastic Differential Equation}\label{sec:sde}
% --------------------------------------------------------------------

\fist Stochastic Partial Differential Equation (\S\ref{sec:spde})



% --------------------------------------------------------------------
\subsection{Functional Differential Equation}\label{sec:fde}
% --------------------------------------------------------------------

a Differential Equation with \emph{Deviating Argument}

TODO



\subsubsection{Differential Difference Equation}\label{sec:dde}



% --------------------------------------------------------------------
\subsection{Singular Solution}\label{sec:singular_solution}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Boundary Value Problem}\label{sec:boundary_value_problem}
% --------------------------------------------------------------------

%FIXME harmonic analysis? dirichlet problem?

\fist Intial Value Problem (IVP \S\ref{sec:ivp}) -- specifies Value in Solution
at only one Point (Initial Conditions)


\fist the \emph{Finite Element Method} (or \emph{FEM}
\S\ref{sec:finite_element_method}) is a technique for solving Boundary Value
Problems for Partial Differential Equations (\S\ref{sec:partial_differential})



% --------------------------------------------------------------------
\subsection{Bessel Function}\label{sec:bessel_function}
% --------------------------------------------------------------------

cf. Reverse Bessel Polynomials (\S\ref{sec:reverse_bessel_polynomial})

\fist Holonomic Function (\S\ref{sec:holonomic_function})



% ====================================================================
\section{Integral Equation}\label{sec:integral_equation}
% ====================================================================

generalization of Eigenvalue Equations (FIXME)

cf. Integrable Function (\S\ref{sec:integrable_function})

Fredholm Equation -- both Limits of Integration are Fixed

Volterra Equation -- one Limit of Integration is Variable

First Kind -- Unknown Function only occurs inside Integral

Second Kind -- Unknown Function occurs both inside and outside Integral

Homogeneous -- Known Function $f$ is identically Zero

Inhomogeneous -- Known Function $f$ is not identically Zero



% --------------------------------------------------------------------
\subsection{Fredholm Integral Equation}\label{sec:fredholm_integral}
% --------------------------------------------------------------------

both Limits of Integration are \emph{Fixed}

Fredholm Equation of the First Kind:
\[
  f(x) = \int_a^b K(x,t) \varphi(t) dt
\]
where $\varphi$ is an Unknown Function and $f$ and $K$ are Known Functions



% --------------------------------------------------------------------
\subsection{Integro-differential Equation}\label{sec:integro_differential}
% --------------------------------------------------------------------



% ====================================================================
\section{Multivariable Calculus}\label{sec:multivariable_calculus}
% ====================================================================

extension of (Infinitesimal) Calculus in one Variable to Functions with several
Variables

Calculus in one Variable:
\begin{itemize}
\item Differential Calculus: Differentiable Functions
  (\S\ref{sec:differentiable_function}), Differential Equations
  (\S\ref{sec:differential_equation})
\item Integral Calculus: Integrable Functions
  (\S\ref{sec:integrable_function}), Integral Equation
  (\S\ref{sec:integral_equation})
\end{itemize}

\fist Vector Fields (\S\ref{sec:vector_field})

\fist Differential Forms (\S\ref{sec:differential_form}): approach to
Multivariable Calculus that is \emph{independent} of Coordinates

\emph{Three-dimensional Graph}: Two-dimensional Input with One-dimensional
Output; Contour Plots (\S\ref{sec:contour})

Multivariable Chain Rule

2 Variables:
\[
  \frac{d}{dt} f(x(t),y(t)) =
    \frac{\partial{f}}{\partial{x}} \cdot \frac{dx}{dt}
      + \frac{\partial{f}}{\partial{y}} \cdot \frac{dy}{dt}
\]
Vector form where $\vec{v}(t) = [x(t),y(t)]$:
\[
  \frac{d}{dt}f(\vec{v}(t)) = \nabla{f(\vec{v}(t)}\bullet{\vec{v}'(t)}
\]
where $\nabla{f}$ is the Gradient (\S\ref{sec:gradient}) of $f$; this the same
as taking the Directional Derivative (\S\ref{sec:directional_derivative}):
\[
  \nabla_{\vec{v}'(t)}f(\vec{v}(t))
\]



% --------------------------------------------------------------------
\subsection{Contour}\label{sec:contour}
% --------------------------------------------------------------------

Contour Map



% --------------------------------------------------------------------
\subsection{Parametric Function}\label{sec:parametric_function}
% --------------------------------------------------------------------

\fist \emph{Vector Function} (\S\ref{sec:vector_function})

Line Integral (\S\ref{sec:line_integral})

\fist Curve (Topology \S\ref{sec:curve}) -- a Topological Space Homeomorphic to
a Line (\S\ref{sec:line})

\fist Parametric Curve (\S\ref{sec:parametric_curve})

\fist Parametric Surface (\S\ref{sec:parametric_surface})



\subsubsection{Space-filling Curve}\label{sec:space_filling_curve}

\subsubsection{Curvature}\label{sec:curvature}

Radius of Curvature $R$

\emph{Curvature} $\kappa = \frac{1}{R}$

for Unit Tangent Vector $\hat{T}$, Arclength $s$:
\[
  \kappa = \|\frac{d\hat{T}}{ds}\|
    = \|\frac{\frac{d\hat{T}}{dt}}{\frac{d\vec{r}}{dt}}\|
\]
where $\vec{r}(t)$ is some Parametric Function

for a Plane Curve (\S\ref{sec:plane_curve}) $\vec{r}(t) = [x(t),y(t)]$:
\[
  \kappa = \frac{x'(t)y''(t) - y'(t)x''(t)} {(x'(t)^2 + y'(t)^2)^{\frac{3}{2}}}
\]
where the Numerator is equal to $\vec{r}'(t) \times \vec{r}''(t)$ and:
\[
  \kappa = \frac{\vec{r}' \times \vec{r}''}{\|\vec{r}'\|^3}
\]

\fist Line (Geometry \S\ref{sec:line}) -- a Primitive Geometric Object of Zero
Curvature



\subsubsection{Parametric Equation}\label{sec:parametric_equation}

\fist Parametric Surface (\S\ref{sec:parametric_surface})



% --------------------------------------------------------------------
\subsection{Multivariate Continuity}\label{sec:multivariate_continuity}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Partial Derivative}\label{sec:partial_derivative}
% --------------------------------------------------------------------

the Matrix of all First-order Partial Derivatives of a Vector Function
(\S\ref{sec:vector_function}) is the \emph{Jacobian Matrix}
(\S\ref{sec:jacobian_matrix})

(\emph{Schwarz's Theorem}) if the Second Partial Derivative is Continuous at the
given Point, then the Partial Differentiations of the Function are Commutative
at that Point:
\[
  \frac{\partial^2f}{\partial{x}\partial{y}}
    = \frac{\partial^2f}{\partial{y}\partial{x}}
\]

Gradient (\S\ref{sec:gradient}): $\nabla f$

Partial Derivative of a Multivariable Vector-valued Function (TODO); Parametric
Surface (\S\ref{sec:parametric_surface})

Partial Derivative of Vector Fields (\S\ref{sec:vector_field}) ... TODO

the \emph{Hessian Matrix} (\S\ref{sec:hessian_matrix}) is the Square Matrix of
Second-order Partial Derivatives of a Scalar-valued Function



\subsubsection{Partial Differential}\label{sec:partial_differential}

three canonical Partial Differential Operators:
\begin{itemize}
  \item Laplacian (\S\ref{sec:laplacian})
  \item Heat Operator (TODO)
  \item Wave Operator (TODO)
\end{itemize}



\subsubsection{Partial Differential Equation}\label{sec:pde}

A \emph{Partial Differential Equation (PDE)} is a Differential Equation
containing Unknown Multivariable Functions and their Partial Derivatives.

\fist An \emph{Ordinary} Differential Equation (ODE \S\ref{sec:ode}) is a
Differential Equation with a single Independent Variable.

Finite Element Method (\S\ref{sec:finite_element_method}): solving
Boundary Value Problems (\S\ref{sec:boundary_value_problem}) for
Partial Differential Equations

\fist Numerical Integration (\S\ref{sec:numerical_integration})

\fist Hamilton-Jacobi-Bellman Equation (Optimal Control Theory
\S\ref{sec:hamilton_jacobi_bellman})

\fist Hodge Theory (\S\ref{sec:hodge_theory}) uses Partial Differential
Equations to study the Cohomology Groups (\S\ref{sec:cohomology_group}) of
Smooth Manifolds (\S\ref{sec:smooth_manifold})



\paragraph{Wave Equation}\label{sec:dirichlet_problem}\hfill

\subparagraph{Spherical Wave}\label{sec:spherical_wave}\hfill

Separation of Variables (Fourier Method \S\ref{sec:separation_of_variables})

Spherical Wave Transformation (\S\ref{sec:spherical_wave_transformation})
leaves the form of Spherical Waves Invariant in all Inertial Frames
(\S\ref{sec:inertial_frame})



\paragraph{Elliptic Partial Differential Equation}
\label{sec:elliptic_partial_differential}\hfill

\subparagraph{Poisson Equation}\label{sec:poisson_equation}\hfill

$\nabla^2 u = u_{xx} + u{yy} = f(x,y)$



\subparagraph{Laplace's Equation}\label{sec:laplaces_equation}\hfill

Second-order Elliptic Partial Differential Equation

written:
\[ \nabla^2 \varphi = 0 \]
or:
\[ \Delta \varphi = 0 \]

where $\Delta = \nabla^2$ is the Laplace Operator
(\S\ref{sec:laplace_operator}) and $\varphi$ is a Scalar Function
(\S\ref{sec:scalar_function})

a Conformal (Angle Preserving) Mapping (\S\ref{sec:conformal_map}) preserves
Laplace's Equation (\S\ref{sec:laplaces_equation})-- only changes the Laplacian
by a non-negative factor

a Harmonic Function (\S\ref{sec:harmonic_function}) is a Twice-continuously
Differentiable Function (\S\ref{sec:continuously_differentiable}) $f : U
\rightarrow Reals$, where $U$ is an Open Subset of $\reals^n$, satisfying
Laplace's Equation

$\nabla^2 u = u_{xx} + u_{yy} = 0$ %FIXME

Steady State Condition (TODO)



\paragraph{Boundary Value Problem}\label{sec:boundary_value_problem}\hfill

\fist cf. Initial Value Problem (\S\ref{sec:initial_value_problem})



\paragraph{Dirichlet Problem}\label{sec:dirichlet_problem}\hfill

\paragraph{Stochastic Partial Differential Equation}\label{sec:spde}\hfill

\fist Stochastic Differential Equation (\S\ref{sec:sde})



\subsubsection{Directional Derivative}\label{sec:directional_derivative}

$\frac{\partial{f}}{\partial{\vec{v}}}$

$\nabla_{\vec{v}} f = \vec{v}\bullet \nabla{f}$

Gradient (\S\ref{sec:gradient})

for a Complex Function (\S\ref{sec:complex_function}) to have a Derivative, the
Directional Derivative must exist in every direction and be the same

Derivation of Quaternion Functions (\S\ref{sec:quaternion_function}) requires a
Direction-dependent Derivative (FIXME: clarify)

\fist generalized as Covariant Derivative (\S\ref{sec:covariant_derivative})



\subsubsection{Covariant Derivative}\label{sec:covariant_derivative}

generalization of Directional Derivative (\S\ref{sec:directional_derivative})

\fist Affine Connection (\S\ref{sec:affine_connection}): means of
``Transporting'' Vectors Tangent to a Manifold from one Point to another along
a Curve; a way of specifying a Derivative of a Vector Field along another
Vector Field on a Manifold



% --------------------------------------------------------------------
\subsection{Iterated Integral}\label{sec:iterated_integral}
% --------------------------------------------------------------------

\fist Fubini's Theorem (\S\ref{sec:fubinis_theorem}): conditions under which it
is possible to compute a Double Integral (\S\ref{sec:double_integral}) using
Iterated Integrals



% --------------------------------------------------------------------
\subsection{Multiple Integral}\label{sec:multiple_integral}
% --------------------------------------------------------------------

Integral (\S\ref{sec:integral})

Multiple Integration



\subsubsection{Double Integral}\label{sec:double_integral}

Volume under a Surface

Area Differential, Volume Differential

Bounded Domain



\paragraph{Fubini's Theorem}\label{sec:fubinis_theorem}\hfill

conditions under which it is possible to compute a Double Integral using
Iterated Integrals (\S\ref{sec:iterated_integral})



\subsubsection{Triple Integral}\label{sec:triple_integral}

Volume Differential, Mass Differential

e.g. compute the Mass of a Volume of non-uniform Density with Density Function
$\rho(x,y,z)$



\subsubsection{Line Integral}\label{sec:line_integral}

Parametric Function (\S\ref{sec:parametric_function}) $\vec{c}(t) = p(t)\hat{i}
+ q(t)\hat{j}$

Parametric Surface (\S\ref{sec:parametric_surface}) defined by Multivariable
Real-valued Function $f(x,y)$

change in Arclength $ds = \sqrt{dx^2 + dy^2}$

\[
  \int_{t=a}^{t=b} f(p(t),q(t)) \sqrt{p'(t)^2 + q'(t)^2} dt
\]

Closed Line Integral $\oint$

Integrating Complex Functions (\S\ref{sec:complex_function})

for Exact Differentials (\S\ref{sec:exact_differential}), the Line Integral is
determined only by the endpoints



\paragraph{Green's Theorem}\label{sec:greens_theorem}\hfill

Curl (\S\ref{sec:curl})

for Vector Field $\vec{f}(x,y) = P(x,y)\hat{i} + Q(x,y)\hat{j}$ and Closed
Counter-clockwise Path $C$ in the Plane and $R$ the enclosed Region:
\[
  \oint_C \vec{f} d\vec{r} = \iint_R (\nabla \times \vec{f}) dA
\]

for a Clockwise Path:
\[
  \iint_R (\frac{\partial{P}}{\partial{y}} - \frac{\partial{Q}}{\partial{x}}) dA
\]

if $\vec{f}$ is Conservative (\S\ref{sec:conservative_vector_field}), $\oint_C
\vec{f} d\vec{r} = 0$

\fist 2D Divergence Theorem (\S\ref{sec:divergence_theorem})

\fist Stokes' Theorem (\S\ref{sec:stokes_theorem})

\[
  \oint_C \vec{f} \bullet \hat{n} dS = \iint_R (\nabla \cdot \vec{f}) dA
\]

the amount of the Flux flowing ``out'' of the closed Region is equal to the sum
of the Divergence over the Region; add a Mass Function $\rho$ so that $\vec{f}$
becomes:
\[
  \vec{f} = \rho(P\hat{i}) + \rho(Q\hat{j})
\]



\subsubsection{Surface Integral}\label{sec:surface_integral}

Parametric Surface (\S\ref{sec:parametric_surface})
$\vec{r}(s,t)$

Double Integral analog of the Line Integral

\[
  d\sigma =
    |\frac{\partial{\vec{r}}}{\partial{s}}
      \times \frac{\partial{\vec{r}}}{\partial{t}}| ds dt
\]

Surface Area

\[
  {\iint}_{\Sigma} d\sigma
\]

more generally:

\[
  {\iint}_{\Sigma} f(x,y,z) d\sigma
\]

``Flux Integral'' -- Flux (\S\ref{sec:flux}) through a 2D Surface; equivalent
notations:
\[
  \iint_{S} \vec{F} \bullet \hat{n} dS
\]

\[
  \iint_{S} \vec{F} \bullet d\vec{S}
\]

\[
  \iint_{R} \vec{F} \bullet (\vec{r}_u \times \vec{r}_v) du dv
\]
where $\vec{r}_u$ and $\vec{r}_v$ are the Partial Derivatives of the Parametric
Surface $\vec{r}(u,v)$



\subsubsection{Volume Integral}\label{sec:volume_integral}

used to calculate ``\emph{Flux Densities}'' (\S\ref{sec:flux}) %FIXME



% --------------------------------------------------------------------
\subsection{Exterior Derivative}\label{sec:exterior_derivative}
% --------------------------------------------------------------------

\fist Exterior Algebra (\S\ref{sec:exterior_algebra}), Exterior Product
(\S\ref{sec:exterior_product})

$\wedge$

``Oriented Density'' %FIXME



\subsubsection{Differential Form}\label{sec:differential_form}

approach to Multivariable Calculus (\S\ref{sec:multivariable_calculus})
that is \emph{independent} of Coordinates

\fist Contact Geometry (\S\ref{sec:contact_geometry}): geometric structure on
Smooth Manifolds given by a Hyperplane Distribution
(\S\ref{sec:tangent_bundle_distribution}) may be given (Locally) as the Kernel
of a Differential $1$-form and the \emph{Maximal Non-degeneracy Condition}) on
the Form

Bott-Tu1982 - \emph{Differential Forms in Algebraic Topology}

(ncat):

a Differential $n$-form on $X$ is a Smooth $n$-functor $P_n(X) \rightarrow
\mathbf{B}^n\reals$ from the Path $n$-groupoid f $X$ to the $n$-fold Delooping
of the Additive Lie Group of Real numbers (FIXME: explain, xref)



\paragraph{Tautological $1$-form}\label{sec:tautological_1form}\hfill

a \emph{Tautological $1$-form} is a $1$-form defined on the Cotangent Bundle
(\S\ref{sec:cotangent_bundle}) $T * Q$ of a Manifold $Q$

the Exterior Derivative of a Tautological $1$-form defines a \emph{Symplectic
  Form} (\S\ref{sec:symplectic_form}) giving $T * Q$ the structure of a
Symplectic Manifold (\S\ref{sec:symplectic_manifold})

relates the formalisms of Hamiltonian (\S\ref{sec:hamiltonian_system}) and
Lagrangian (\S\ref{sec:lagrangian_system}) Mechanics

in Canonical Coordinates:
\[
  \theta = \sum_i p_i dq^i
\]



\paragraph{Symplectic Form}\label{sec:symplectic_form}\hfill

%FIXME: move this section to bilinear forms ???

a Symplectic Manifold (\S\ref{sec:symplectic_manifold}) is a Differentiable
Manifold equipped with a Closed Non-degenerate $2$-form called the
\emph{Symplectic Form}

the Symplectic Form in Symplectic Geometry (\S\ref{sec:symplectic_geometry})
plays the role analagous to Metric Tensor (\S\ref{sec:metric_tensor}) in
Riemannian Geometry (\S\ref{sec:riemannian_geometry})

a Symplectic Bilinear Form (\S\ref{sec:symplectic_bilinear}) is a
Non-degenerate Alternating (Skew-symmetric) Bilinear Form
(\S\ref{sec:alternating_form})

Symplectic Vector Spaces (\S\ref{sec:symplectic_vectorspace}) are equipped with
a Symplectic Bilinear Form. If the underlying Field has Characteristic
(\S\ref{sec:ring_characteristic}) $\neq 2$, Alternation is \emph{equivalent} to
Skew-symmetry; for Characteristic $=2$, the Skew-symmetry is \emph{implied by}
(but does not imply) \emph{Alternation}-- every Symplectic Form is a
\emph{Symmetric Form} (\S\ref{sec:symmetric_form}) but not every Symmetric Form
is Symplectic.

$Sp(V)$ -- Symplectic Group (\S\ref{sec:symplectic_group}): Subgroup of the
General Linear Group $GL(V)$ which Preserves a Symplectic Form on $V$ (i.e. a
Non-degenerate Alternating Form \S\ref{sec:alternating_form})

the Exterior Derivative of a Tautological $1$-form
(\S\ref{sec:tautological_1form}) defined on the Cotangent Bundle
(\S\ref{sec:cotangent_bundle}) $T * Q$ of a Manifold $Q$ defines a Symplectic
Form giving $T * Q$ the Structure of a Symplectic Manifold

Canonical Symplectic Form (Poincar\'e $2$-form):
\[
  \omega = -d\theta = \sum_i dq^i \wedge dp_i
\]

\asterism

\url{https://mathoverflow.net/questions/19932/what-is-a-symplectic-form-intuitively}:

``...given a Direction that we want to think of as Position, it tells us what
the Momentum Direction is. What it gives us are pairs: given one Coordinate,
there's a second so that the pair are \emph{Canonically Conjugate}, which means
that, with respect to each other, they will \emph{act like} Position and
Momentum and that they'll ignore the 'other direction' (that is, things will
Poisson Commute)''

\asterism

Clifford Algebras (\S\ref{sec:clifford_algebra}) represent the same structure
for Non-degenerate Symmetric Bilinear Forms (\S\ref{sec:symmetric_bilinear})
that Weyl Algebras (Symplectic Clifford Algebras \S\ref{sec:weyl_algebra})
represent for Symplectic Bilinear Forms (\S\ref{sec:symplectic_form})



\paragraph{Frobenius' Theorem}\label{sec:frobenius_theorem}\hfill

Vector Field (\S\ref{sec:vector_field}) formulation:
the Subbundle (\S\ref{sec:subbundle}) of the Tangent Bundle
(\S\ref{sec:tangent_bundle}) of a Manifold is Integrable (or Involutive) if and
only if it arises from a \emph{Regular Foliation} (\S\ref{sec:foliation})

Differential Forms formulation: TODO



% --------------------------------------------------------------------
\subsection{Saddle Point}\label{sec:saddle_point}
% --------------------------------------------------------------------

Gradient (\S\ref{sec:gradient}) equal to the Zero Vector: $\nabla{f} = \vec{0}$

Maximum (\S\ref{sec:maximum}), Minimum (\S\ref{sec:minimum})

in the $x$ direction looks like a Maximum and in the $y$ direction looks like a
Minimum, or \emph{vice versa}

\emph{Second Partial Derivative Test} -- additionally need to look at
\emph{mixed} Partial Derivative Term
$\frac{\partial^2{f}}{\partial{y}\partial{x}}$:
\[
  H = f_{xx}(x_0,y_0)f_{yy}(x_0,y_0) - f_{xy}(x_0,y_0)^2
\]
if $H > 0$, then it is a Maximum or a Minimum

if $H < 0$, then it is a Saddle Point

if $H = 0$, then ??? ... FIXME



% --------------------------------------------------------------------
\subsection{Vector Calculus}\label{sec:vector_calclulus}
% --------------------------------------------------------------------

or \emph{Vector Analysis}

Gradient, Divergence, Curl

$\nabla$

FIXME:

Directional Derivative

Laplacian

Tensor Derivative



\subsubsection{Vector}\label{sec:linear_vector}

or \emph{Polar Vector}

\fist Vector (Abstract Algebra \S\ref{sec:vector})



\subsubsection{Pseudovector}\label{sec:linear_vector}

or \emph{Axial Vector}

\fist Pure Imaginary Quaternion (\S\ref{sec:quaternion})

Angular Velocity behaves like a Pseudovector

equivalent to Three-dimensional Bivectors (\S\ref{sec:bivector})



\subsubsection{Vector Function}\label{sec:vector_function}

or \emph{Vector-valued Function}

\fist Parametric Function (\S\ref{sec:parametric_function})

the Matrix of all First-order Partial Derivatives
(\S\ref{sec:partial_derivative}) of a Vector Function is the \emph{Jacobian
  Matrix} (\S\ref{sec:jacobian_matrix})

Partial Derivative of a Multivariable Vector-valued Function (TODO)



\paragraph{Root}\label{sec:function_root}\hfill

A \emph{Root} (or \emph{Zero}) of a Vector-valued Function (including Real- or
Complex-valued Functions) $f$ is an Element $x$ of the Domain of $f$ for which
$f(x)$ is \emph{Zero}.

\fist Root (Equations \S\ref{sec:equation_root})

\fist Root-finding Algorithms (\S\ref{sec:root_finding})

Any Polynomial (\S\ref{sec:polynomial}) with Odd Degree has at least
one Real Root.

(wiki):

The Fundamental Theorem of Algebra (\S\ref{sec:fundamental_algebra_theorem})
states that every Polynomial of Degree $n$ has $n$ Complex Roots, counted with
their Multiplicities (??? FIXME).

\emph{Link between ``Algebra'' and ``Geometry''}: a Monic Polynomial (one
Variable with Complex Coefficients \S\ref{sec:monic_polynomial}), an Algebraic
Object, is determined by the Set of its Roots, a Geometric Object, in the
Complex Plane (\S\ref{sec:complex_plane}).



\subparagraph{Zero Set}\label{sec:zero_set}\hfill

\fist Algebraic Geometry (Part \ref{sec:algebraic_geometry}): study of Zero
Sets of Systems of Polynomial Equations
(\S\ref{sec:system_of_polynomial_equations})

e.g. the Circle (\S\ref{sec:n_sphere}) $S^1 = \{ (x,y) \in \reals^2 | x^2 + y^2
- 1 = 0 \}$

(wiki):

any Closed Subset of $\reals^n$ is the Zero Set of a Smooth Function
(\S\ref{sec:smooth_function}) on $\reals^n$

an Affine Algebraic Set (Affine Variety \S\ref{sec:affine_variety}) is the
Intersection of the Zero Sets of a number of Polynomials in a Polynomial Ring
(\S\ref{sec:polynomial_ring}) $k[x_1,\ldots,\x_n]$ over a Field



\paragraph{Vector Derivative}\label{sec:vector_derivative}\hfill

$\frac{d\vec{r}(t)}{dt}$

the Vector Derivative represents a change of \emph{Length} (cf. Norm
\S\ref{sec:norm}) of the Vector



\subsubsection{Gradient}\label{sec:gradient}

Partial Derivative (\S\ref{sec:partial_derivative})

Directional Derivative (\S\ref{sec:directional_derivative})

Differential Operator (\S\ref{sec:differential_operator})

(wiki):

the \emph{Gradient} of a Scalar Field (\S\ref{sec:scalar_field}) $f$ is the
Vector Derivative (\S\ref{sec:vector_derivative}):
\[
  \nabla f =
    \frac{\partial f}{\partial x}\vec{e}_x +
    \frac{\partial f}{\partial y}\vec{e}_y +
    \frac{\partial f}{\partial z}\vec{e}_z
\]
that is, the Gradient of $f$ is a Vector Field (\S\ref{sec:vector_field})

when a Vector Field is the Gradient Field of some Scalar Field
(\S\ref{sec:scalar_field}), it is a \emph{Conservative} (\emph{Path
  Independent} \S\ref{sec:conservative_vector_field}) Vector Field and the Line
Integral of any Path between two Points is equivalent and the Line Integral of
a Closed Path from a Point to itself is Zero

FIXME: Matrix of Derivatives, Vector Field of Row Vectors

Jacobian (\S\ref{sec:jacobian})

Divergence (\S\ref{sec:divergence}) can be expressed as:
\[
  \nabla \cdot \vec{v} =
    \frac{\partial v_x}{\partial x} +
    \frac{\partial v_y}{\partial y} +
    \frac{\partial v_z}{\partial z}
\]

the Laplacian (\S\ref{sec:laplacian}) is the Divergence of the Gradient Field
of $f$: $\nabla \bullet \nabla f$

Curl (\S\ref{sec:curl}) can be expressed as:
\[
  \nabla\times\vec{v} =
    (\frac{\partial v_z}{\partial y}-\frac{\partial v_y}{\partial z})\vec{e}_x +
    (\frac{\partial v_x}{\partial z}-\frac{\partial v_z}{\partial x})\vec{e}_y +
    (\frac{\partial v_y}{\partial x}-\frac{\partial v_x}{\partial y})\vec{e}_z
\]

\emph{Critical Point} (\S\ref{sec:critical_point}): Gradient equal to the Zero
Vector; cf. Maxima, Minima, Saddle Points (\S\ref{sec:saddle_point})

(\emph{Local Optimality Conditions} \S\ref{sec:objective_function}) generally a
Real Function $f$ on $n$ Real Variables has local Minimum at $\vec{x}^*$ if its
Gradient $\nabla f$ is Zero and its Hessian Matrix (\S\ref{sec:hessian_matrix})
$H(f(\vec{x}^*))$ of Second-order Partial Derivatives is Positive Semi-definite
(\S\ref{sec:positive_semidefinite}) at that Point:
\begin{align*}
  \nabla f(\vec{x}^*) & =    \vec{0} \\
  H(f(\vec{x}^*))     & \geq \vec{0} \\
\end{align*}



\paragraph{Gradient Flow}\label{sec:gradient_flow}\hfill

cf. Flow (\S\ref{sec:flow}), Vector Flow (\S\ref{sec:vector_flow})

Geometric Flow (\S\ref{sec:geometric_flow})



\subsubsection{Jacobian}\label{sec:jacobian}

%FIXME: merge with jacobian matrix ?

generalizes the Gradient (\S\ref{sec:gradient}) of a Scalar-valued Function of
multiple Variables: the Jacobian of a Scalar-valued Multivariable Function is
the Gradient, and the Jacobian of a Scalar-valued Single Variable Function is
its Derivative

Jacobian Matrix (\S\ref{sec:jacobian_matrix})

\fist the Jacobian Matrix for a System of DAEs (\S\ref{sec:system_of_daes}) is
a Singular (Non-invertible) Matrix (\S\ref{sec:singular_matrix})

\fist Locally Linear Transformation (\S\ref{sec:locally_linear})



\subsubsection{Divergence}\label{sec:divergence}

wiki:

the \emph{Divergence} of a Vector Field (\S\ref{sec:vector_field})
$\vec{v}(x,y,z) = v_x\vec{e}_x + v_y\vec{e}_y + v_z\vec{e}_z$ is a
Scalar-valued Function (\S\ref{sec:scalar_function}):
\[
  \nabla \cdot \vec{v} =
    \frac{\partial v_x}{\partial x} +
    \frac{\partial v_y}{\partial y} +
    \frac{\partial v_z}{\partial z}
\]
where $\nabla$ is the Gradient Operator (\S\ref{sec:gradient})

\emph{Convergence}

...

\[
  \vec{v}(x,y,z) = \begin{bmatrix}
    p(x,y,z) \\
    q(x,y,z) \\
    r(x,y,z)
  \end{bmatrix}
\]

\[
  div\vec{v}(x,y,z)
    = \frac{\partial{p}}{\partial{x}}
    + \frac{\partial{q}}{\partial{y}}
    + \frac{\partial{r}}{\partial{z}}
\]

the Laplacian (\S\ref{sec:laplacian}) is the Divergence of the Gradient Field
of $f$: $\nabla \bullet \nabla f$

Green's Theorem (\S\ref{sec:greens_theorem}):

TODO



\paragraph{Laplacian}\label{sec:laplacian}\hfill

\fist cf. Laplace Operator (\S\ref{sec:laplace_operator}), Laplace Transform
(\S\ref{sec:laplace_transform}) %FIXME: same concepts?

the \emph{Laplacian}, $\Delta$, is the Divergence (\S\ref{sec:divergence}) of
the Gradient Field of $f$:
\[
  \Delta f = \nabla \bullet \nabla f
\]

analog of Second Derivative for Scalar-valued Multivariable Functions

\[
  \frac{\partial^2 f}{\partial{x_1^2}} +
  \frac{\partial^2 f}{\partial{x_2^2}} +
  \cdots +
  \frac{\partial^2 f}{\partial{x_n^2}}
\]

the Laplacian of a \emph{Harmonic Function} (\S\ref{sec:harmonic_function}) is
Zero everywhere; intuitively this means that the average value of Neighbors for
a given Point is equal to that Point

a Conformal Map (\S\ref{sec:conformal_map}) only changes the Laplacian by a
non-negative factor



\subsubsection{Curl}\label{sec:curl}

wiki:

the \emph{Curl} of a Vector Field (\S\ref{sec:vector_field}) $\vec{v}(x,y,z) =
v_x\vec{e}_x + v_y\vec{e}_y + v_z\vec{e}_z$ is a Vector-valued Function
(\S\ref{sec:vector_function}):
\[
  \nabla\times\vec{v} =
    (\frac{\partial v_z}{\partial y}-\frac{\partial v_y}{\partial z})\vec{e}_x -
    (\frac{\partial v_x}{\partial z}-\frac{\partial v_z}{\partial x})\vec{e}_y +
    (\frac{\partial v_y}{\partial x}-\frac{\partial v_x}{\partial y})\vec{e}_z
\]
where $\nabla$ is the Gradient Operator (\S\ref{sec:gradient}) associating each
Point in the Vector Field with the proportional ``on-axis'' Torque to which a
``tiny pinwheel'' would be subjected if it were centered at the Point and can
be realized as a Pseudo-determinant (\S\ref{sec:pseudo_determinant}):

TODO

Right-hand Rule

Counter-clockwise: Positive

Clockwise: Negative

Tangency ?

Green's Theorem (\S\ref{sec:greens_theorem}) -- FIXME: relation to curl ???

Stokes' Theorem (\S\ref{sec:stokes_theorem})

\[
  \oint_C \vec{f} d\vec{r}
    = \iint_S ((\nabla \times \vec{f}) \bullet \hat{n}_S) d\vec{S}
\]



\subsubsection{Local Linearization}\label{sec:local_linearization}

\fist cf. Locally Linear Transformation (\S\ref{sec:locally_linear})

$L(x_0,y_0) = f(x_0,y_0)$

$\frac{\partial{L}}{\partial{x}} = f_x(x_0,y_0)$

$\frac{\partial{L}}{\partial{y}} = f_y(x_0,y_0)$

a Quadratic Approximation (\S\ref{sec:quadratic_approximation}) adds Quadratic
Terms so that the Second Partial Derivative matches the original Function at
that Point

\fist Jacobian Matrix (\S\ref{sec:jacobian_matrix})

Matrix form:
\[
  \nabla f(\vec{x}_0) \bullet (\vec{x}-\vec{x}_0)
\]
(FIXME: correct ???)



\subsubsection{Quadratic Approximation}\label{sec:quadratic_approximation}

add Quadratic Terms to a Local Linearization so that Second Derivative matches
the original Function at that Point

$\frac{\partial^2{Q}}{\partial{x^2}}(x_0,y_0) =
  \frac{\partial^2{f}}{\partial{x^2}}(x_0,y_0)$

$\frac{\partial^2{Q}}{\partial{y}\partial{x}}(x_0,y_0) =
  \frac{\partial^2{f}}{\partial{y}\partial{x}}(x_0,y_0)$

$\frac{\partial^2{Q}}{\partial{y^2}}(x_0,y_0) =
  \frac{\partial^2{f}}{\partial{y^2}}(x_0,y_0)$

\fist Hessian Matrix (\S\ref{sec:hessian_matrix}) $\mathbf{H}$ -- Matrix of
Second-order Partial Derivatives

\fist Definite Quadratic (\S\ref{sec:definite_quadratic}), Positive-definite
Matrices (\S\ref{sec:positive_definite})

Matrix form:
\[
  Q_f(\vec{x}) = f(\vec{x}_0) + \nabla{f(\vec{x}_0)}\bullet (\vec{x}-\vec{x}_0)
  + \frac{1}{2}(\vec{x}-\vec{x}_0)^T\mathbf{H}_f(\vec{x}_0)(\vec{x}-\vec{x}_0)
\]



\subsubsection{Integral Theorems of Vector Calculus}
\label{sec:integral_theorems}

cf. Fundamental Theorem of Calculus (\S\ref{sec:fundamental_calculus_theorem})



\paragraph{Gradient Theorem}\label{sec:gradient_theorem}\hfill

\paragraph{Stoke's Theorem}\label{sec:stokes_theorem}\hfill

\fist Green's Theorem (\S\ref{sec:greens_theorem})

Curl (\S\ref{sec:curl})

Simple Closed Piecewise Smooth Boundary $C$

Piecewise Smooth Surface $S$

\[
  \oint_C \vec{f} d\vec{r}
    = \iint_S ((\nabla \times \vec{f}) \bullet \hat{n}) d\vec{S}
\]

\fist 3D Divergence Theorem (\S\ref{sec:divergence_theorem})



\paragraph{Divergence Theorem}\label{sec:divergence_theorem}\hfill

2D Divergence Theorem \fist cf. Green's Theorem (\S\ref{sec:greens_theorem})

3D Divergence Theorem \fist cf. Stokes' Theorem (\S\ref{sec:stokes_theorem})

``simple solid regions''



% --------------------------------------------------------------------
\subsection{Matrix Calculus}\label{sec:matrix_calculus}
% --------------------------------------------------------------------

\subsubsection{Matrix Derivative}\label{sec:matrix_derivative}

(wiki):

e.g. for a Quadratic Form augmented with Linear Terms, $x^TAx + 2b^Tx$, the
First-order Conditions for a Maximum or a Minimum are found by setting the
Matrix Derivative to the Zero Vector:
\[
  2Ax + 2b = 0
\]
giving:
\[
  x = -A^{-1}b
\]
assuming $A$ is Non-singular (Invertible); if the Quadratic Form (and hence
$A$) are Positive Definite, then the Second-order Conditions for a
Minimum are met at the Point



% --------------------------------------------------------------------
\subsection{Tensor Calculus}\label{sec:tensor_calculus}
% --------------------------------------------------------------------

or \emph{Tensor Analysis}



\subsubsection{Tensor}\label{sec:linear_tensor}

wikipedia: Geometric Objects (???) that describe Linear Relations
between Scalars, Vectors and other Tensors; Linear Relations such as
Dot Product, Cross Product, Linear Maps

%FIXME: merge with sec:tensor ???

\fist Tensor (Abstract Algebra \S\ref{sec:tensor})

\fist Metric Tensor (\S\ref{sec:metric_tensor})

must be independent of a particular choice of Coordinate System
(Coordinate-free \S\ref{sec:coordinate_free}): the particular Covariant
Transformation Law (\S\ref{sec:covariant_transformation}) determines
the \emph{Valence} (\S\ref{sec:valence}) of a Tensor

may be represented by:
\begin{itemize}
  \item Multidimensional Arrays (Basis Independence not apparent)
  \item Multilinear Maps (intrinsic Basis Independence)
  \item Elements of (Abstract) Tensor Products
\end{itemize}

\fist
\url{https://jeremykun.com/2014/01/17/how-to-conquer-tensorphobia/}
%FIXME cite

Tensors are Elements (Vectors) of a Vector Space given by
combining two ``smaller'' Vector Spaces via a Tensor Product

$v \otimes w \in V \otimes W$

Scalar Multiplication: $s(v \otimes w) = (sv \otimes w) = (v \otimes
sw)$; generalizing to  $n$-fold Tensor Products, Scalars can be moved
around all the coordinates freely

Addition Operation: $(v \otimes w) + (v' \otimes w) = (v + v') \otimes
w)$ \emph{or} $(v \otimes w) + (v \otimes w') = v \otimes (w + w')$,
otherwise $(x \otimes y) + (z \otimes w)$ is a ``new'' Tensor
(Vector); generalizing to $n$-fold Tensor Products, Addition can be
combined if all but one of the coordinates are the same in the
Addends.

Element of a Tensor Space $V_1 \otimes \cdots \otimes V_n$ as a Sum:
\[
  \Sigma_k a_{1,k} \otimes a_{2,k} \otimes cdots \otimes a_{n,k}
\]

A Rank $1$ or \emph{Pure Tensor} is one that can be expressed as a
One-term Sum, i.e. just $a_1 \otimes \cdots \otimes a_n$


\asterism


represented as an ``organized'' Multidimensional Array of Numerical
(?Scalar) Values

\emph{Order} (or \emph{Degree}) of a Tensor $x$ is the
Dimensionality of the Array needed to represent it or equivalently the
minimum number of Terms to represent $x$ as a Sum of Pure Tensors (the
Zero Element is Order $0$ by convention).

Order $0$ Tensor -- Scalar (\S\ref{sec:scalar})

Order $1$ Tensor -- Vector (\S\ref{sec:vector})

Order $2$ Tensor -- Linear Map (\S\ref{sec:linear_transformation}) ?
%FIXME correct?

Computing Tensor Order is $NP$-hard when $k = \rats$ and $NP$-complete
when $k$ is a Finite Field %FIXME


\asterism


Multilinear Maps


\asterism


a Type (\S\ref{sec:valence}) $(n,m)$ Tensor $T$ is defined as an
Element of the Tensor Product (\S\ref{sec:tensor_product}) of Vector
Spaces $V$ and Dual Spaces $V^*$:
\[
  T \in V_1 \otimes \cdots \otimes V_n
    \otimes V^*_1 \otimes \cdots \otimes V^*_m
\]

the Tensor Product is Initial with respect to Multilinear Mappings
from the Direct Product

Tensors (Abstract Algebra \S\ref{sec:tensor})

Tensor Products (Category Theory \S\ref{sec:tensor_product}):
\begin{itemize}
  \item Modules
  \item Vector Spaces
  \item Graded Vector Spaces
  \item $R$-algebras
  \item Sheaves of Modules
  \item Quadratic Forms
  \item Multilinear Form
  \item Topological Vector Spaces
\end{itemize}
are characterized by the Universal Property that they are the ``Freest''
(\S\ref{sec:free_object}) Bilinear Operators in each context
(FIXME: clarify)

Monoidal Category (\S\ref{sec:monoidal_category}): general context for
Tensor Products



\subsubsection{Module Tensor Product}\label{sec:module_tensor_product}

Balanced Product

\fist Tensor Product (\S\ref{sec:tensor_product})



\subsubsection{Valence}\label{sec:valence}

precise Covariant Transformation Law
(\S\ref{sec:covariant_transformation}) determines the \emph{Valence}
(or \emph{Type}) of a Tensor

Tensor Type: Pair of Natural Numbers $(n,m)$ where $n$ is the number
of Contravariant Indicies and $m$ is the number of Covariant Indices

\emph{Total Order} is the sum of $n$ and $m$



\subsubsection{Tensor Field}\label{sec:tensor_field}

Tensor assigned to each Point in a Space

cf. Scalar Field (\S\ref{sec:scalar_field})

cf. Vector Field (\S\ref{sec:vector_field})



\subsubsection{Tensor Algebra}\label{sec:tensor_algebra}

of a Vector Space



\subsubsection{Eigenconfiguration}\label{sec:eigenconfiguration}

\subsubsection{Ricci Calculus}\label{sec:ricci_calculus}

\subsubsection{Spinor}\label{sec:spinor}



% ====================================================================
\section{Harmonic Analysis}\label{sec:harmonic_analysis}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Potential Theory}\label{sec:potential_theory}
% --------------------------------------------------------------------

\subsubsection{Harmonic Function}\label{sec:harmonic_function}

Twice-continuously Differentiable Function
(\S\ref{sec:continuously_differentiable}) $f : U \rightarrow Reals$,
where $U$ is an Open Subset of $\reals^n$, satisfying \emph{Laplace's
  Equation} (\S\ref{sec:laplaces_equation})

Harmonic Functions are exactly those Functions that which lie in the Kernel of
the Laplace Operator (\S\ref{sec:laplace_operator})

Harmonic Functions on $\reals$ are exactly the Linear Functions
(\S\ref{sec:polynomial_function})

the Laplacian (\S\ref{sec:laplacian}) of a Harmonic Function is equal to Zero
everywhere; intuitively this means that the average value of Neighbors for a
given Point is equal to that Point

2016 - Samantha Davies - \emph{Voltage, Temperature, and Harmonic
  Functions} -
\url{https://jeremykun.com/2016/09/26/voltage-temperature-and-harmonic-functions/}

Physics: Simple Harmonic Motion is a type of ``Oscillation'' where the
Force that restores an object to its Equilibrium is directly
proportional to the Displacement

Stochastic Processes (\S\ref{sec:stochastic_process})

Potential Theory (Mathematical Physics) %FIXME create section?

the Real or Imaginary part of any Holomorphic Function
(\S\ref{sec:holomorphic_function}) is a Harmonic Function


\textbf{Mean Value Property}: the Value of a Harmonic Function at an
Interior Point is the Average of the Function's Values around the
Point

If $u$ is a Continuous Function satisfying the Mean Value Property on
a Region $\Omega$ then $u$ is Harmonic in $\Omega$

Any Function $\alpha$ on a Graph which satisfies the Mean Value
Property also satisfies the Discrete Laplacian
(\S\ref{sec:discrete_laplace})


\textbf{Maximum Principle}: a Non-constant Harmonic Function on a
Closed Bounded Region must attain Maximum and Minimum on its Boundary

Convex Optimization (\S\ref{sec:convex_optimization})


\textbf{Uniqueness}: if a Harmonic Function is Continuous on the
Boundary of a Closed Bounded Set and Harmonic in the Interior then the
Interior Values are Uniquely Determined by the Values of the Boundary


\textbf{Solution to a Dirichlet Problem}
(\S\ref{sec:dirichlet_problem})



% --------------------------------------------------------------------
\subsection{Automorphic Form}\label{sec:automorphic_form}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Fourier Analysis}\label{sec:fourier_analysis}
% --------------------------------------------------------------------

\fist Convolution (\S\ref{sec:convolution}), Cross-correlation
(\S\ref{sec:cross_correlation})



\subsubsection{Periodic Function}\label{sec:periodic_function}

a Function $f$ is \emph{Periodic} with Nonzero \emph{Period} $P$ if:
\[
  f(x+P) = f(x)
\]
for all $x$

the least positive $P$ is called the \emph{Fundamental Period}

Geometrically, a Periodic Function is a Function with a Graph exhibiting
\emph{Translational Symmetry} (\S\ref{sec:translation});
can be extended to Tessellations of the Plane (\S\ref{sec:tessellation})



\paragraph{Trigonometric Function}\label{sec:trigonometric_function}\hfill

or \emph{Circular Function}

Hyperbolic Functions (\S\ref{sec:hyperbolic_function}) arise from the study of
the Equation $x^2 - y^2 = 1$; cf. Circular (Trigonometric) Functions arise from
the study of $x^2 + y^2 = 1$

cf. Elliptic Functions (\S\ref{sec:elliptic_function}): Meromorphic Function
that is Periodic in two directions

Analytic Functions (\S\ref{sec:analytic_function})


the Sine Wave is the only Periodic Waveform that has the Property that it
retains its ``wave shape'' when added to another Sine Wave of the same
Frequency and arbitrary Phase and Magnitude (FIXME: clarify)

$\sin x = \sum_{n=0}^\infty \frac{(-1)^n x^{2n+1}}{(2n + 1)!}$

$\cos\theta= \sin(\frac{\pi}{2} - \theta)$

$\tan\theta = \frac{\sin\theta}{\cos\theta}$

$\sec\theta = \frac{1}{\cos\theta}$

$\csc\theta = \frac{1}{\sin\theta}$

$\cot\theta = \frac{\cos\theta}{\sin\theta}$

Integrals:

$\int_0^{2\pi} \sin(mt)dt = 0$ for any Integer $m$

$\int_0^{2\pi} \cos(mt)dt = 0$ for any Non-zero Integer $m$

$\int_0^{2\pi} \sin(mt)\cos(nt)dt = 0$ for any Integers $m,n$

$\int_0^{2\pi} \sin^2(mt)dt = \pi$ for any Non-zero Integer $m$

$\int_0^{2\pi} \sin(mt)\sin(nt)dt = 0$ for Integers $m,n$ such that $m\neq{n}$
or $m\neq{-n}$

$\int_0^{2\pi} \cos(mt)\cos(nt)dt = 0$ for Integers $m,n$ such that $m\neq{n}$
or $m\neq{-n}$

$\int_0^{2\pi} \cos(mt)dt = \pi$ for any Non-zero Integer $m$

\fist Fourier Series (\S\ref{sec:fourier_series})

(Laczkovich03) refinement of Richardson's Theorem
(\S\ref{sec:richardsons_theorem}); the use of $\pi$ can be removed and the use
of Composition reduced:

given an Expression $A(x)$ in the Ring generated by the Integers, $x$, $\sin
x^n$, and $\sin(x \sin x^n)$, the question whether $A(x) > 0$ for some $x$ and
whether $A(x) = 0$ for some $x$ are \emph{Unsolvable}



\paragraph{Hyperbolic Function}\label{sec:trigonometric_function}\hfill

Hyperbolic Functions arise from the study of the Equation $x^2 - y^2 = 1$; cf.
Circular (Trigonometric) Functions arise from the study of $x^2 + y^2 = 1$

Hyperbolic Functions are Periodic with respect to the \emph{Imaginary}
Component

cf. Elliptic Functions (\S\ref{sec:elliptic_function}): Meromorphic Function
that is Periodic in two directions

$\sinh$

$\cosh$



\subsubsection{Double-periodic Function}\label{sec:double_periodic}

e.g. Elliptic Functions (\S\ref{sec:elliptic_function})



\subsubsection{Fourier Series}\label{sec:fourier_series}

representation of an arbitrary Periodic Function by a Series of weighted $cos$
and $sin$ (\S\ref{sec:trigonometric_function}) Terms

\fist Fourier Transform (\S\ref{sec:fourier_transform}) removes the requirement
of Fourier Series of being restricted to expressing functions on Finite
Intervals to being able to express functions on Infinite Intervals

(wiki):

for a Function $s(x)$ Integrable on an Interval $[x_0,x_0 + P]$ that is
Periodic outside the Interval with Period $P$ (Frequency $1/P$), then it can be
approximated on the entire Real Line as a Series of ``Harmonically related''
Sinusoidal Functions (FIXME: clarify)

the $N$th Partial Sum:
\[
  s_N(x) = \frac{a_0}{2} + \sum_{n=1}^N \left(
    a_n\cos(\frac{2\pi{nx}}{P}) + b_n\sin(\frac{2\pi{nx}}{P})
  \right)
\]
where $a_0,\ldots,a_N$ and $b_1,\ldots,b_N$ are \emph{Fourier Coefficients}
computed by:
\begin{align*}
  a_n & = \frac{2}{P}\int_{x_0}^{x_0+P}s(x) \cdot \cos(\frac{2\pi{nx}}{P}) dx \\
  b_n & = \frac{2}{P}\int_{x_0}^{x_0+P}s(x) \cdot \sin(\frac{2\pi{nx}}{P}) dx
\end{align*}

the Coefficient $\frac{a_0}{2} = \frac{1}{P}\int_{x_0}^{x_0+P}s(x)dt$
represents the \emph{Average} of $s(x)$ over the Interval $[x_0,P]$

equivalently the $N$th Partial Sum can be defined as:
\[
  s_N(x) = \sum_{n=-N}^N c_n \cdot e^i\frac{2\pi{nx}}{P}
\]
where:
\[
  c_n \defeq \begin{cases}
    \frac{1}{2}(a_n - ib_n) &\ \text{for n > 0} \\
    \frac{1}{2}a_0          &\ \text{for n = 0} \\
    c_{|n|}^*               &\ \text{for n < 0}
  \end{cases}
\]
(FIXME: $^*$ is the complex conjugate ???)

the Infinite Sum $s_\infty(x)$ is called the \emph{Fourier Series}
representation of $s(x)$

the Sines and Cosines in the Fourier Series are an example of an Orthonormal
Basis (\S\ref{sec:orthonormal_basis})

\begin{itemize}
  \item Weierstrass Function (\S\ref{sec:weierstrass_function}) -- Continuous,
    Nowhere Differentiable Function
\end{itemize}


\emph{Convolution Theorems}

Convolution (\S\ref{sec:convolution}), Cross-correlation
(\S\ref{sec:cross_correlation})



% --------------------------------------------------------------------
\subsection{Spherical Harmonics}\label{sec:spherical_harmonics}
% --------------------------------------------------------------------



% ====================================================================
\section{Functional Analysis}\label{sec:functional_analysis}
% ====================================================================

Inner Product Spaces (Normed Vector Spaces
\S\ref{sec:innerproduct_space})

Hilbert Space (\S\ref{sec:hilbert_space})

Topological Vector Space (\S\ref{sec:topological_vector})



% --------------------------------------------------------------------
\subsection{Functional Integration}\label{sec:functional_integration}
% --------------------------------------------------------------------

(wiki):

Integral (\S\ref{sec:integral}) with a Domain of a Space of Functions
(\S\ref{sec:function_space})

Sums a Functional (Higher-order Function \S\ref{sec:higher_order_function})
$G[f]$ over a Continuous Range or Space of Functions $f$

most Functional Integrals cannot be Evaluated exactly and require Evaluation
using Perturbation Methods (\S\ref{sec:perturbation_method})

for each Function, the Integrand (the Function to be Integrated) returns a
``Value'' to add up (FIXME: clarify)

most Functional Integrals are Infinite, but the \emph{Quotient} of two
Functional Integrals may be Finite

exactly Solvable Functional Integrals usually begin with a Gaussian Integral
(\S\ref{sec:gaussian_integral})

cf. Dirac Delta Distribution (\S\ref{sec:dirac_delta})

Wiener Integral; assigned to a class of Brownian Motion Paths



% --------------------------------------------------------------------
\subsection{Adjoint Operator}\label{sec:adjoint_operator}
% --------------------------------------------------------------------

The \emph{Adjoint Operator} (or \emph{Hermitian Adjoint}) of a
Linear Operator $A : H_1 \rightarrow H_2$ between Hilbert Spaces
(\S\ref{sec:hilbert_space}) is the Linear Operator $A^\dag : H_2 \rightarrow
H_1$ satisfying:
\[
  \langle{Ah_1,Ah_2}\rangle_{H_2} = \langle{h_1,A^{\dag}h_2}\rangle_{H_1}
\]
where $\langle\cdot,\cdot\rangle_{H_i}$ is the Inner Product Space in Hilbert
Space $H_i$.

%FIXME: not required to be an endomorphism (operator) ???

Bounded Linear Operator (\S\ref{sec:bounded_linear_operator})

Complex Hilbert Space (\S\ref{sec:hilbert_space})



\subsubsection{Self-adjoint Operator}\label{sec:self_adjoint_operator}

A Linear Operator $A$ on a Hilbert Space (\S\ref{sec:hilbert_space}) is
\emph{Self-adjoint} if it is equal to its Hermitian Adjoint.

A Projection is Orthogonal (\S\ref{sec:orthogonal_projection}) if and only if
it is Self-adjoint.



% --------------------------------------------------------------------
\subsection{Closed Linear Span}\label{sec:closed_linear_span}
% --------------------------------------------------------------------

Linear Span (\S\ref{sec:linear_span})



% --------------------------------------------------------------------
\subsection{Sequence Space}\label{sec:sequence_space}
% --------------------------------------------------------------------

Vector Space (\S\ref{sec:vector_space}) whose Elements are Infinite Sequences
(\S\ref{sec:sequence}) of Real or Complex Numbers, or equivalently a Function
Space whose Elements are Functions from $\nats$ to the Field $K$ of Real or
Complex Numbers



% --------------------------------------------------------------------
\subsection{Banach Space}\label{sec:banach_space}
% --------------------------------------------------------------------

A \emph{Banach Space} is a Vector Space (\S\ref{sec:vector_space}) $X$ over the
Field of Real or Complex Numbers

a Complete (\S\ref{sec:complete_metric_space}) Normed Vector Space
(\S\ref{sec:normed_vectorspace})

Topological Vector Space (\S\ref{sec:topological_vector})



\subsubsection{$L^p$ Space}\label{sec:lp_space}



% --------------------------------------------------------------------
\subsection{Banach Algebra}\label{sec:banach_algebra}
% --------------------------------------------------------------------

an Associative Algebra (\S\ref{sec:associative_algebra}) over the Real or
Complex Numbers (or over a Non-archimedean Complete Normed Field
\S\ref{sec:nonarchimedean_field}) that is also a Banach Space

\emph{Banach Rings} (FIXME: ???)



\subsubsection{C$^*$-algebra}\label{sec:cstar_algebra}

A \emph{C$^*$-algebra} a Complex Algebra $A$ of Continuous Linear
Operators (\S\ref{sec:continuous_linear}) on a Complex Hilbert Space
(\S\ref{sec:hilbert_space}) with the additional Properties that $A$ is
Topologically Closed in the Norm Topology of Operators and Closed
under the Operation of taking Adjoints of Operators

Involutive Algebra (\S\ref{sec:involutive_algebra})

Involution Semigroup (\S\ref{sec:involution_semigroup})

(wiki):

Linear Logic (\S\ref{sec:linear_logic}) can be seen as the refining
the Interpretation of Classical Logic by replacing Boolean Algebras
(\S\ref{sec:boolean_algebra}) by C$^*$-algebras

the Uniform Closure of Complex Continuous Functions over a Compact Space is a
C$^*$ Algebra



\paragraph{Dual C$^*$-algebra}\label{sec:cstar_dual}\hfill

or \emph{Dual} or \emph{Spectrum} of a C$^*$-algebra is the Set of Unitary
Equivalence Classes of Irreducible $*$-representations of $A$ (FIXME: clarify)

cf. Ring Spectrum (\S\ref{sec:ring_spectrum})



\paragraph{von Neumann Algebra}\label{sec:vonneumann_algebra}\hfill



% --------------------------------------------------------------------
\subsection{Cross-correlation}\label{sec:cross_correlation}
% --------------------------------------------------------------------

or \emph{Sliding Dot Product}

Similarity Measure (\S\ref{sec:similarity_measure}) of two Series as a Function
of the Displacement of one relative to the other

for Continuous Signals the Cross-correlation Operator is the Adjoint Operator
of the Convolution (\S\ref{sec:convolution}) Operator

\fist Fourier Analysis (\S\ref{sec:fourier_analysis})



\subsubsection{Autocorrelation}\label{sec:autocorrelation}



% --------------------------------------------------------------------
\subsection{Convolution}\label{sec:convolution}
% --------------------------------------------------------------------

$(f * g)(t) = \int_0^t f(t-\tau) g(\tau) d\tau$

Operation on two Functions giving a modified Function giving the Integral of
the Pointwise Multiplication of the two Functions as a Function of the amount
that one of the original Functions is Translated (\S\ref{sec:translation})

for Continuous Signals the Cross-correlation (\S\ref{sec:cross_correlation})
Operator is the Adjoint Operator of the Convolution Operator

Image Processing

\fist Fourier Analysis (\S\ref{sec:fourier_analysis})

Laplace Transform (\S\ref{sec:laplace_transform})



% --------------------------------------------------------------------
\subsection{Coherence Space}\label{sec:coherence_space}
% --------------------------------------------------------------------

note: not the same as Coherent Space (Spectral Space)

cf. Linear Logic (\S\ref{sec:linear_logic}) Semantics



% --------------------------------------------------------------------
\subsection{Spectral Theory}\label{sec:spectral_theory}
% --------------------------------------------------------------------

Hilbert Space (\S\ref{sec:hilbert_space})



\subsubsection{Spectrum}\label{sec:spectrum}

generalization of Matrix Spectrum (Set of Eigenvalues
(\S\ref{sec:matrix_spectrum}) of a Matrix to general \emph{Operators}

\fist Note that ``Spectrum'' is a highly overloaded term and may otherwise
refer to:
\begin{itemize}
  \item Graph Spectrum (Spectral Graph Theory \S\ref{sec:graph_spectrum}) --
    Spectrum of the Adjacency Matrix (\S\ref{sec:adjacency_matrix}) of a Graph

  \item Spectral Norm (\S\ref{sec:spectral_norm}) -- Schatten $\infty$-norm of
    a Matrix (\S\ref{sec:spectral_norm})

  \item Ring Spectrum (\S\ref{sec:ring_spectrum}) -- the Set (Space) of all
    Prime Ideals (\S\ref{sec:prime_ideal}) of a Ring
  \item C$^*$-algebra Spectrum (Dual \S\ref{sec:cstar_dual}) -- Set of Unitary
    Equivalence Classes of Irreducible $*$-representations of a C$^*$-algebra
    (similar notion to Ring Spectrum)

  \item Cohomology Spectrum (\S\ref{sec:cohomology_spectrum}) -- represents a
    Generalized Cohomology Theory (\S\ref{sec:generalized_cohomology_theory})

  \item Polygon Spectrum (\S\ref{sec:polygon_spectrum}) -- the Set of all $n$
    for which an $n$-equidissection (\S\ref{sec:equidissection}) of a Polygon
    $P$ exists

  \item Sentence Spectrum (\S\ref{sec:sentence_spectrum}) -- the Set of Natural
    Numbers occurring as the size of a Finite Model
    (\S\ref{sec:finite_model_theory}) in which a given Sentence is True
  \item Theory Spectrum (\S\ref{sec:theory_spectrum}) -- the number of
    Isomorphism Classes of Models of various Cardinalities
\end{itemize}



\subsubsection{Pseudospectrum}\label{sec:pseudospectrum}

Set containing the Spectrum of the Operator and the numbers that are ``almost''
Eigenvalues



% ====================================================================
\section{Convex Analysis}\label{sec:convex_analysis}
% ====================================================================

\fist Convex Optimization (\S\ref{sec:convex_optimization})



% --------------------------------------------------------------------
\subsection{Convex Set}\label{sec:convex_set}
% --------------------------------------------------------------------

%FIXME: move section ???

\fist Convex Geometry (\S\ref{sec:convex_geometry})

every Affine Set (\S\ref{sec:affine_set}) is also Convex

Line Segment between Points $x_1$ and $x_2$:
\[
  x = \theta x_1 + (1-\theta) x_2
\]
with $0 \leq \theta \leq 1$

\fist in an Affine Set, $\theta$ can vary over the entire Real Line: $\theta
\in \reals$

a Function is Convex (\S\ref{sec:convex_function}) if and only if its Epigraph
is a Convex Set

Operations that conserve Convexity:
\begin{itemize}
  \item Intersection
  \item Affine Functions (\S\ref{sec:affine_transformation})
  \item Perspective Functions (FIXME: xref ???)
  \item Linear-fractional Functions (FIXME: xref ???)
\end{itemize}

(\emph{Seperating Hyperplane Theorem}) for two general disjoint Convex Sets,
there is a Hyperplane for which each Convex Set lies entirely in each Halfspace

(\emph{Supporting Hyperplane Theorem}) at every boundary point of a Convex Set
there is a Supporting Hyperplane

examples of Convex Sets:
\begin{itemize}
  \item Hyperplanes (\S\ref{sec:hyperplane}) are Affine and Convex
  \item Halfspaces (\S\ref{sec:half_space}) are Convex
  \item Ellipsoids (\S\ref{sec:ellipsoid}), Euclidean Balls (\S\ref{sec:ball})
  \item Norm Balls, Norm Cones (\S\ref{sec:norm})
  \item Convex Polyhedra (\S\ref{sec:convex_polyhedra})
  \item Convex Cones (\S\ref{sec:convex_cone}), Positive Semidefinite Cones
    (\S\ref{sec:positive_semidefinite_cone})
  \item the Set $\mathsf{S}^n$ of Symmetric $n \times n$ Matrices is Affine and
    Convex
  \item the Set $\mathsf{S}_+^n$ of Positive Semi-definite $n \times n$
    Matrices is a Convex Cone and hence is a Convex Set
  \item the Set $\mathsf{S}_{++}^n$ of Positive Definite $n \times n$ Matrices
    (FIXME: is also a convex cone ???)
\end{itemize}



\subsubsection{Convex Cone}\label{sec:convex_cone}

the Set $\mathsf{S}_+^n$ of Positive Semi-definite $n \times n$ Matrices is a
Convex Cone

\emph{Proper Cone}: Closed, Solid, Pointed (contains no Line)

Generalized Inequality



\paragraph{Positive Semidefinite Cone}
\label{sec:positive_semidefinite_cone}\hfill



\subsubsection{Dual Cone}\label{sec:dual_cone}

defined for any Cone (not necessarily Convex)

$\reals_+^n$ and $\mathsf{S}_+^n$, and the Euclidean Norm Cone are Self-dual

the Dual Cone of the $1$-norm Cone is the $\infty$-norm Cone

the Dual Cones of Proper Cones are Proper

for a Proper Cone, the Dual Cone of a Dual Cone is the original Cone



\subsubsection{Polar Cone}\label{sec:polar_cone}



% ====================================================================
\section{Algebraic Analysis}\label{sec:algebraic_analysis}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Generalized Function}\label{sec:generalized_function}
% --------------------------------------------------------------------

\emph{Schwartz Kernel Theorem}: if the Kernel of an Integral Transform
(\S\ref{sec:integral_transform}) is allowed to be a Generalized Function then
all Linear Operators (\S\ref{sec:linear_operator}) are Integral Transforms



\subsubsection{Distribution}\label{sec:distribution}

Continuous Linear Functional (\S\ref{sec:linear_form})



\paragraph{Dirac Delta Function}\label{sec:dirac_delta}\hfill

(wiki):

$\delta$

\emph{Unit Impulse Symbol}

\emph{heuristic} characterization: can be thought of as a Function on the Real
Line that is Zero everywhere except at the origin where it is Infinite and
Constrained to satisfy the identity:
\[
  \int_{-\infty}^\infty \delta(x) dx = 1
\]

note that \emph{no Function defined on the Real Numbers has this property}

can also be defined as a Measure (\S\ref{sec:measure})

\fist Functional Integration (\S\ref{sec:functional_integration})



% ====================================================================
\section{Numerical Analysis}\label{sec:numerical_analysis}
% ====================================================================

(wiki):

the goal of Numerical Analysis is to \emph{approximate the Continuum}
(\S\ref{sec:real_line})

Mimesis -- the quality of a Numerical Method that imitates some properties of
the ``Continuum Problem''

FIXME: explain



% --------------------------------------------------------------------
\subsection{Interval Arithmetic}\label{sec:interval_arithmetic}
% --------------------------------------------------------------------

\subsubsection{Unit Interval}\label{sec:unit_interval}

$[0,1]$, sometimes $I$

a Complete Metric Space (\S\ref{sec:complete_metric_space}),
Homeomorphic (\S\ref{sec:homeomorphism}) to the Extended Real Number
Line (\S\ref{sec:extended_real_line})



% --------------------------------------------------------------------
\subsection{Numerical Integration}\label{sec:numerical_integration}
% --------------------------------------------------------------------

methods for obtaining Numerical approximations to the solutions of
Time-dependent Ordinary (\S\ref{sec:differential_equation}) and Partial
(\S\ref{sec:pde}) Differential Equations

\emph{Explicit Methods} -- calculates the state of a system at a later time
from the state of the system at the current time:
\[
  Y(t+\Delta{t}) = F(Y(t))
\]
where $Y(t)$ is the current system state and $Y(t + \Delta{t})$ is the system
state after a (small) time step $\Delta{t}$

\emph{Implicit Methods} -- finds a solution by solving an equation involving
the current system state and a later system state:
\[
  G(Y(t), Y(t + \Delta{t})) = 0
\]

First-order Methods -- (Explicit) Euler Method, Symplectic (Semi-implicit) Euler

Second-order Methods

Higher-order Methods



\subsubsection{Explicit Integration Methods}\label{sec:explicit_integration}

calculates the State of a System at a later Time, $Y(t + \Delta{t})$, from the
State of the System at the current Time, $Y(t)$:
\[
  Y(t + \Delta{t}) = F(Y(t))
\]

Euler Method

\fist Symplectic (Semi-implicit) Euler (\S\ref{sec:symplectic_integrator})



\subsubsection{Implicit Integration Methods}\label{sec:implicit_integration}

calculates the State of a System at a later Time, $Y(t + \Delta{t})$, from the
both State of the System at the current Time, $Y(t)$, and the State of the
System at a later Time, $Y(t + \Delta{t})$:
\[
  G(Y(t), Y(t + \Delta{t})) = 0
\]

Backward Euler



\subsubsection{Geometric Integrator}\label{sec:geometric_integrator}

a Numerical Integration Method that preserves Geometric properties of the exact
\emph{Flow} (\S\ref{sec:integral_curve}) of a Differential Equation

by definition Geometric Integrators are \emph{Canonical Transformations}
(\S\ref{sec:canonical_coordinate}), i.e. preserving the form of Hamilton's
Equations



\paragraph{Symplectic Integrator}\label{sec:symplectic_integrator}\hfill

a Numerical Integration scheme for Hamiltonian Systems
(\S\ref{sec:hamiltonian_system})

forms the Subclass of Geometric Integrators that are by definition
\emph{Canonical Transformations}: a change of Canonical Coordinates that
preserves the form of Hamilton's Equations (\S\ref{sec:hamiltonian_system})
%FIXME xref

Semi-implicit (Symplectic) Euler



% --------------------------------------------------------------------
\subsection{Numerical Stability}\label{sec:numerical_stability}
% --------------------------------------------------------------------

Property of an Algorithm



\subsubsection{Condition Number}\label{sec:condition_number}

Property of a \emph{Problem}

\fist not to be confused with Conditioning (Probability
\S\ref{sec:conditioning})

\emph{Well-conditioned} -- a small error in Input will result in a small change
in Output

\emph{Ill-conditioned} -- a small error in Input will result in a large change
in Output

\url{https://www.youtube.com/watch?v=APh4ME3C7UI}

\begin{itemize}
  \item \emph{Normal Equations} (\S\ref{sec:normal_equation}): $(A^TA)\vec{x} =
    A^T\vec{b}$ -- Condition Number (\S\ref{sec:condition_number}) is
    $\kappa(A)^2$ (poor)
  \item \emph{QR Factorization} (\S\ref{sec:qr_factorization}): $\vec{x} =
    \hat{R}^{-1}\hat{Q}^T\vec{b}$ -- better Condition Number than Normal
    Equations
\end{itemize}



\paragraph{Absolute Condition Number}\label{sec:absolute_condition_number}
\hfill

\[
  \hat{\kappa} = \mathrm{sup}_{\Delta x} \frac{\|\Delta f\|}{\|\Delta x\|}
\]

if $f$ is Differentiable to First Order, $\Delta f = J(x) \Delta x$ where $J$
is the Jacobian Matrix (\S\ref{sec:jacobian_matrix}), and therefore:
\begin{align*}
  \hat{\kappa} & = \mathrm{sup}_{\Delta x} \frac{\|J\Delta x\|}{\|\Delta x\|} \\
  \hat{\kappa} & = \|J(x)\|
\end{align*}
that is, the Absolute Condition Number is equal to the Matrix Norm
(\S\ref{sec:matrix_norm}) of $J$



\paragraph{Relative Condition Number}\label{sec:relative_condition_number}
\hfill

\[
  \kappa = \mathrm{sup}_{\Delta x} \frac{
    \Big(\frac{\|\Delta f\|}{\|f(x)\|}\Big)
  }{
    \Big(\frac{\|\Delta x\|}{\|x\|}\Big)
  }
\]

if $f$ is Differentiable:
\begin{align*}
  \kappa & = \mathrm{sup}_{\Delta x}
    \frac{\|\Delta f\|}{\|\Delta x\|} \cdot \frac{\|x\|}{\|f(x)\|} \\
  \kappa & = \frac{\|J(x)\| \|x\|}{\|f(x)\|}
\end{align*}

example:

$f(x) = \frac{x}{2}$

$J(x) = f'(x) = \frac{1}{2}$

$\kappa = 1$ (Well-conditioned)

example 2:

$f(x) = \sqrt x$, $x > 0$

$J(x) = f'(x) = \frac{1}{2\sqrt{x}}$

$\kappa = 1/2$ (Well-conditioned)

$f(x,y) = x - y$

$J = \Big(
  \frac{\partial{f}}{\partial{x}}
  \frac{\partial{f}}{\partial{y}}
\Big) = [1 -1]$

$\kappa = \frac{2 \mathrm{max}(|x|,|y|)}{|x - y|}$ --
Problem is Ill-conditioned when $x$ is near $y$


\emph{Relative Condition Number for Matrix/Vector Multiplication}

$\kappa = \frac{\|A\|\|x\|}{\|Ax\|}$

worst case is the Sharp Inequality (i.e. is an Equality for \emph{some}
$\vec{x}$):
\[
  \kappa \leq \|A\| \|A^{-1}\|
\]
where $\|A\|\|A^{-1}\|$ is called the Condition Number $\kappa(A)$ of the
Matrix $A$


\emph{Relative Condition Number of Solving $A\vec{x} = \vec{b}$ for $\vec{x}$}:

$\vec{x} = A^{-1}\vec{b}$

Sharp Inequality (for some $\vec{b}$):
\[
  \kappa \leq \|A^{-1}\| \|A\|
\]


\emph{Relative Condition of a System of Equations}

Solving the System $A\vec{x} = \vec{b}$ for $\vec{x}$, considering
Perturbations in $A$, denoted by $\Delta A$

$(A + \Delta A)(\vec{x} + \Delta\vec{x}) = \vec{b}$

simplifies to:

$A(\Delta\vec{x}) + (\Delta A)\vec{x} = \vec{0}$

or:

$\Delta x = -A^{-1}(\Delta A)\vec{x}$

and:

$\|\Delta\vec{x}\| \leq \|A^{-1}\| \|\Delta{A}\| \|\vec{x}\|$

giving:

\[
  \frac{
    \frac{\|\Delta{x}\|}{\|\vec{x}\|}
  }{
    \frac{\|\Delta{A}\|}{\|A\|}
  }
  \leq \|A^{-1}\|\|A\| = \kappa(A)
\]

combining all the above, Solving $A\vec{x} = \vec{b}$ or Multiplying by $A$,
then it is expected to lose $\log_{10} \kappa(A)$ Digits of Accuracy; e.g. if
$\kappa(A) = 10000$, then Multiplying by $A$ will lose $4$ significant figures
of Accuracy; usually Well-conditioned Matrices have $\kappa$ in the Range $1$
to $100$



% --------------------------------------------------------------------
\subsection{Spline Function}\label{sec:spline}
% --------------------------------------------------------------------

\subsubsection{Spline Interpolation}\label{sec:spline_interpolation}

cf. Polynomial Interpolation (???) %FIXME



\subsubsection{Cubic Spline}\label{sec:cubic_spline}

\paragraph{B-spline}\label{sec:b_spline}\hfill



% --------------------------------------------------------------------
\section{Calculus of Finite Differences}\label{sec:finite_differences_calculus}
% --------------------------------------------------------------------

%FIXME: move to numerical analysis ?

\subsubsection{Finite Difference}\label{sec:finite_difference}

Discrete equivalent of Differentiation (\S\ref{sec:differential})



% --------------------------------------------------------------------
\subsection{Finite Volume Method}\label{sec:finite_volume_method}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Finite Element Method}\label{sec:finite_element_method}
% --------------------------------------------------------------------

\emph{Finite Element Method} or \emph{FEM} is a technique for solving Boundary
Value Problems (\S\ref{sec:boundary_value_problem}) for Partial Differential
Equations (\S\ref{sec:partial_differential})

GetFEM++ -- LGPL C++ library



% --------------------------------------------------------------------
\subsection{Meshfree Method}\label{sec:meshfree_method}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Perturbation Theory}\label{sec:perturbation_theory}
% --------------------------------------------------------------------

\subsubsection{Perturbation Method}\label{sec:perturbation_method}

used to Evaluate Functional Integrals (\S\ref{sec:functional_integral})

\emph{Perturbation Series} -- Formal Power Series
(\S\ref{sec:formal_power_series}) in some ``small'' Parameter quantifying the
deviation from the exactly Solvable problem



% ====================================================================
\section{Ordinal Analysis}\label{sec:ordinal_analysis}
% ====================================================================

Ordinal Numbers (\S\ref{sec:ordinal_number})

Proof-theoretic Ordinal (\S\ref{sec:proof_ordinal})



% ====================================================================
\section{Non-standard Analysis}\label{sec:nonstandard_analysis}
% ====================================================================

Hyperreals (\S\ref{sec:hyperreal})

Real Closed Field (\S\ref{sec:real_closed})

$\reals^\nats / \mathsf{M}$ where $\mathsf{M}$ is a Maximal Ideal
(\S\ref{sec:maximal_ideal}) not leading to a Field that is
Order-isomorphic (\S\ref{sec:order_isomorphism}) to $\reals$-- the
uniqueness of this Field is equivalent to the Continuum Hypothesis
(\S\ref{sec:continuum_hypothesis})



% ====================================================================
\section{Calculus of Variations}\label{sec:calculus_of_variations}
% ====================================================================

or \emph{Variational Calculus})

\fist Optimal Control Theory (\S\ref{sec:optimal_control})

\fist cf. Dynamic Programming (\S\ref{sec:dynamic_programming})

Hamilton-Jacobi Equation (\S\ref{sec:hamilton_jacobi}

Virtual Displacements



% --------------------------------------------------------------------
\subsection{Functional}\label{sec:functional}
% --------------------------------------------------------------------

a mapping from a Space $X$ into the Real Numbers or sometimes into the Complex
Numbers for the purpose of establishing a Calculus-like structure on $X$

\fist cf. ``Functional'' used to mean a Higher-order Function
(\S\ref{sec:higherorder_function})

\fist cf. Linear Functional (Linear Form \S\ref{sec:linear_form})

\fist Functional Equations (\S\ref{sec:functional_equation})

the \emph{Action} (\S\ref{sec:trajectory_action}) of a Physical System with
Equations of Motion is a Functional taking the Trajectory of the System and
producing a Real Number; the Hamilton's Principle Function $S$ in the
Hamilton-Jacobi Equation (\S\ref{sec:hamilton_jacobi}) is equal to the
\emph{Classical Action})



% ====================================================================
\section{Constructive Analysis}\label{sec:constructive_analysis}
% ====================================================================

\emph{Choice Sequence}

% ====================================================================
\section{Computable Analysis}\label{sec:computable_analysis}
% ====================================================================

% ====================================================================
\section{Algorithm Analysis}\label{sec:algorithm_analysis}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Linear Dominance}\label{sec:linear_dominance}
% --------------------------------------------------------------------

\[
    f \lesssim g \Leftrightarrow
    \exists x_0 \exists c : \forall x > x_0, |f(x)| \leq c |g(x)|
\]

Pointwise Domination implies Linear Dominance:
\[
    f \leq g \Rightarrow f \lesssim g
\]

\[
    f \lesssim g \wedge g \lesssim f \Leftrightarrow f \sim g
\]



\subsubsection{Big-O Notation}\label{sec:bigo_notation}

\[
    O(f) = \{ g : g \lesssim f \}
\]

\[
    \Omega(f) = \{ g : g \gtrsim f \}
\]

\[
    \Theta(f) = \{ g : g \sim f \}
\]

\[
    O(1) \subset O(x) \subset O(x^2) \subset O(x^2) \ldots
\]



% ====================================================================
\section{Spatial Analysis}\label{sec:spatial_analysis}
% ====================================================================

% FIXME

% --------------------------------------------------------------------
\subsection{Boundary Problem}\label{sec:boundary_problem}
% --------------------------------------------------------------------

% FIXME
