%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Formal Language}\label{sec:formal_language} \cite{hammel03}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A \emph{Formal Language}, $L$, is a possibly infinite Subset of an
infinite \emph{Vocabulary}, $\Sigma^*$, that is the Set of all
possible finite \emph{Expressions} (strings) over a possibly infinite
\emph{Alphabet} of \emph{Symbols}, $\Sigma$. This Set $\Sigma^*$ is
the \emph{Kleene star} or \emph{Free Monoid} (\S\ref{subsec:monoid})
of $\Sigma$; the smallest Superset of $\Sigma$ that is closed under
string concatenation.

The entire content of a Language is uniquely determined by the Set of
all \emph{Terminal Expressions} \emph{Generated} by the
\emph{Production} or \emph{Rewrite Rules} of a \emph{Generative
  Grammer} (\S\ref{subsec:generative_grammar}) or the Set of
Expressions \emph{Recognized} by a \emph{Determinative Grammar}
(\S\ref{subsec:determinative_grammar}). This possibly infinite Set of
Terminal Expressions will be a Subset of $\Sigma^*$.

For two Languages $L1$ and $L2$ over a common Alphabet $\Sigma$:
\begin{itemize}
    \item $L1 \cup L2$ is a Language (Set Union)
    \item $L1 \cap L2$ is a Language (Set Intersection)
    \item $L1 - L2$ is a Language (Set Difference)
    \item $(L1 - L2 \cup L2 - L1)$ is a Language (Symmetric Difference)
    \item $L1 \times L2$ is a Language (Cartesian Product)
\end{itemize}
If $L2 \subset L1$ then $L2$ is a \emph{Sublanguage} of $L1$.

For a given Language $L \subseteq \Sigma^*$ there exists a
\emph{Complement Language} $L^C = \Sigma^* - L$.



% ====================================================================
\section{Metalanguage}\label{sec:metalanguage}
% ====================================================================

A \emph{Metalanguage} is a Language used to describe another Language,
the \emph{Object Language}. A \emph{Metavariable} is a Variable
written in a Metalanguage that stands in for an Element in the Object
Language. Metavariables may be referred to as \emph{Schematic
  Variables} in the context of \emph{Axiom Schemata} and \emph{Rule
  Schemata} (\S\ref{subsec:deductive_apparatus}).

The use of an Object Language to describe itself is an \emph{Embedded
  Metalanguage} (e.g. the English words \emph{noun} and \emph{verb}
are used to describe English itself).

Note it is common to use Greek letters ($\Phi$, $\Psi$) for
Metavariables and Roman characters otherwise for Object Variables.



% ====================================================================
\section{Syntax}
% ====================================================================

\emph{Syntax} is the aspect of Formal Languages that refers only to
the literal strings of Symbols of a Language with no regard to the
meaning or \emph{Interpretation} (\S\ref{subsec:interpretation}); only
the condition that they can be identified and differentiated from
one-another is required. Syntactic methods can be carried very far;
all of Formal Language Theory as well as Automata Theory (Part
\ref{sec:automata_theory}), Symbolic Logic (Part
\ref{sec:formal_logic}), and Proof Theory (Part
\ref{sec:proof_theory}) are carried out Syntactically. The term
\emph{Syntax} may be used as a synonym for a \emph{Grammar}: that is a
Set of Rules through which the strings of a Language can be either
\emph{Generated} (\S\ref{subsec:generative_grammar}) or
\emph{Recognized} (\S\ref{subsec:determinative_grammar}).



% --------------------------------------------------------------------
\subsection{Syntactic Elements}
% --------------------------------------------------------------------

Within a Formal Language the Symbols will be divided into two disjoint
subsets according to whether they are \emph{Terminal} or
\emph{Non-terminal Symbols}.

The definition of a Non-terminal Symbol is one for which a Production
rule exists with that Symbol appearing in the input and replaced in
the output. Thus a Grammar is specified by a finite set of
Productions, $P$, a finite set of Non-terminal Symbols, $N$, and a
finite set of Terminal Symbols, $T$. Additionally, in certain Grammars
it is allowed for multiple Non-terminals to appear in an Expression.

\begin{description}

    \item[Symbol] \hfill \\
    an atomic unit of a Language

    \item[Alphabet ($\Sigma$)] \hfill \\
    a possibly infinite set of Symbols

    \item[Expression] \hfill \\
    a finite string of Symbols

    \item[Vocabulary ($\Sigma^{*}$)] \hfill \\
    set of all Expressions over an Alphabet of Symbols

    \item[Production] \hfill \\
    a Rewrite Rule specifying a Non-terminal Symbol substitution

    \item[Grammar] \hfill \\
    a finite set of Productions over the Expressions of a Vocabulary

\end{description}

Two special Symbols are recognized:

\begin{description}

    \item[Empty Symbol ($\varepsilon$)] \hfill \\
    the Symbol of zero length and a Terminal Symbol

    \item[Start Symbol ($S$)] \hfill \\
    a unique Non-terminal Symbol

\end{description}



% ====================================================================
\section{Formal Grammars}\label{sec:formal_grammar}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Generative Grammar}\label{subsec:generative_grammar}
% --------------------------------------------------------------------

A \emph{Generative Grammar} \emph{Generates} a Language by the
repeated application of its Production Rules beginning with the Start
Symbol. A sequence of rule applications is a \emph{Derivation}. A
Grammar may be formally defined as a 4-tuple:
\[
    G(N,T,P,S)
\]
where $N$ are Non-terminals, $T$ are Terminals, $P$ Production Rules
and $S$ the Start Symbol.

An unrestricted Production Rule has the form:
\[
    (N \cup T)^*N(N \cup T)^* \rightarrow (N \cup T)^*
\]
That is, a Production is a function from one Expression to
another, where the left Expression must contain at least one
Non-terminal Symbol. By convention, Non-terminal Symbols
will be denoted by capitals ($A,B,C,\cdots$), and Terminals by
lowercase ($a,b,c,\cdots$), and Expressions by Greek letters
($\alpha,\beta,\gamma$). Let:

\[
    \mathcal{A} = \{ Alphabets \},\: \mathcal{V} = \{ Vocabularies \}
\] \[
    \mathcal{G} = \{ Grammars \},\: \mathcal{L} = \{ Languages \}
\]

\begin{itemize}

\item Definition of the Kleene star over an Alphabet where $\circ$ is
  the operation to \emph{Concatenate} two Expressions:
\[
    \forall \: \Sigma \in \mathcal{A} \:
    \exists \: \Sigma^* \in \mathcal{V}
    : \Sigma^* = \bigcup_{i=0}^{|\Sigma|} \Sigma_i
    = (\Sigma,\circ)
\]

\item Definition of a Language in terms of a Vocabulary:
\[
    \forall \: L \in \mathcal{L} \:
    \exists \: \Sigma^* \in \mathcal{V}
    : L \subseteq \Sigma^*
\]

\item Existence of the Empty Symbol, $\varepsilon$:
\[
    \forall \: \Sigma^* \in \mathcal{V} \:
    \exists ! \: \varepsilon \in \Sigma^*
    : |\varepsilon|=0
\]

\end{itemize}



% --------------------------------------------------------------------
\subsection{Determinative Grammar}\label{subsec:determinative_grammar}
% --------------------------------------------------------------------

A \emph{Determinative Grammar} is a Grammar through which a Member of
$\Sigma^*$ can be determined to belong to a Language $L \subseteq
\Sigma^*$


% --------------------------------------------------------------------
\subsection{Chomsky Hierarchy}\cite{chomsky56}
% --------------------------------------------------------------------

Grammars are classified by how restrictive the Production Rules are.
By convention, they may be organized into a hierarchy of Classes under
Proper Inclusion, where \emph{Type-0} is an Unrestricted Grammar,
covering all possible Formal Grammars.
\[
    Type-0 \supset Type-1 \supset Type-2 \supset Type-3
\]
These different levels in the hierarchy are \emph{Recognizable} by
different kinds of \emph{Automata} (\S\ref{subsec:automata}).

\subsubsection{Type-0: Unrestricted}

\paragraph{Semi-decidable}\label{subsec:semidecidable}
Production Rules of an \emph{Unrestricted} Grammar have the form
\[
    \alpha \rightarrow \beta
\]
where $\alpha$ and $\beta$ are Expressions of $N \cup T$ and $\alpha
\neq \varepsilon$.

A completely unrestricted Grammar is called \emph{recursively
  enumerable} or \emph{Semi-decidable}. This means membership of the
Language can be decided by an algorithm, but non-membership cannot,
and the class of Languages having this property is called
$\mathsf{RE}$. Members of this class are also \emph{Diophantine} sets
and the Lattice of $\mathsf{RE}$ sets under inclusion is written
$\mathcal{E}$. % FIXME add a reference when sections describing these terms
               % are added

The complement of $\mathsf{RE}$ is the class of Languages for which
an algorithm may decide non-membership only and is termed
$\mathsf{coRE}$. The class of Automata capable of implementing these
algorithms are \emph{Turing Machines}(\S\ref{subsec:turing_machine}).

\paragraph{Decidable}\label{subsec:decidability}
A \emph{Decidable} or \emph{recursive} Language (as opposed to
recursively enumerable) is defined as the intersection of
$\mathsf{RE}$ and $\mathsf{coRE}$:
\[
    \mathsf{R} = \mathsf{RE} \cap \mathsf{coRE}
\]
That is, it can be decided whether a Symbol is a member or not by a
\emph{total computable function} (one which returns \emph{True} or
\emph{False} depending on membership). Decidable Languages are
Recognizable by a \emph{Decider} or \emph{Total Turing
  Machine}\cite{kozen97} (however determining whether an arbitrary
Turing Machine gives an answer for every input is an undecidable
decision problem).

\subsubsection{Type-1: Context-sensitive}

\paragraph{Context-sensitive}\label{subsec:context_sensitive}
\emph{Context-sensitive Grammars} have the restriction that the result
of a Production is not shorter than the input. Formally stated
Productions are of the form
\[
    \alpha \Gamma \beta \rightarrow \alpha \gamma \beta
\]
where $|\Gamma| \leq |\gamma|$. In this formulation $\alpha$ and
$\beta$ form the \emph{Context} of $\Gamma$.

Requiring that $S$ does not appear on the right of any Production
and allowing the rule
\[
    S \rightarrow \varepsilon
\]
makes the Context-sensitive Languages a proper superset of the
\emph{Context-free Languages}.

Context-sensitive Languages are equivalent to \emph{Linear
Bounded Automata} (\S\ref{subsec:linear_bounded_automata}).

\paragraph{Indexed}
An \emph{Indexed Grammar} has an extra set of \emph{Index Symbols},
$F$, with Productions of three possible forms,
\[
    A[\sigma] \rightarrow \alpha[\sigma]
\]\[
    A[\sigma] \rightarrow B[f\sigma]
\]\[
    A[f\sigma] \rightarrow \alpha[\sigma]
\]
where $f \in F$ and $\sigma$ is a string of Index Symbols. The Index
Symbols are used to form a \emph{stack} by the Production Rules where
Index Symbols are either pushed or popped from the stack.

An Indexed Language can be Recognized by a \emph{Nested Stack
  Automaton}\cite{aho69}.

\paragraph{Generalized Contex-free}
A \emph{Generalized Context-free Grammar} adds to the rewrite rules of
a Context-free Grammar a set of non-context-free \emph{composition
  functions} that combine tuples of symbols:
\[
    f(\langle x_1,\cdots,x_m\rangle,\cdots,\langle
    y_1,\cdots,y_n\rangle)=\gamma
\]
where $\gamma$ is a single tuple or another composition function that
reduces to a single tuple.

Rules are of the form:
\[
    A \rightarrow f(X,Y,\cdots)
\]
where $X$,$Y$,$\cdots$ are string tuples or Non-terminal Symbols.

There are several weakly equivalent Grammars to the composition
formulation:

\begin{description}
\item[Linear context-free rewriting system] \hfill \\
    Weakly equivalent to \emph{multi-component Tree-adjoining
      Grammars} where composition functions are both \emph{linear} and
    \emph{regular}. Can be Recognized by \emph{Thread
      Automata}\cite{villemonte02}.

\item[Tree-adjoining] \hfill \\
    Elementary rewriting unit is a tree rather than a Symbol. Can be
    Recognized by \emph{Embedded Pushdown
      Automata}\cite{vijayashanker88}.

\item[Linear indexed grammar] \hfill \\
    A modified Indexed Grammar where only one symbol receives the
    stack.

\item[Combinatory Categorical Grammar] \hfill \\
    A type of \emph{phrase Structure Grammar} using \emph{Combinatory
      Logic}(\S\ref{subsec:combinatory_logic}).

\item[Head grammar] \hfill \\
    A subset of the Linear context-free rewriting system and a Phrase
    Structure Grammar.

\end{description}

\subsubsection{Type-2: Context-free}\label{subsec:context_free_language}

\paragraph{Context-free}
\emph{Context-free Grammars} (\emph{CFG}s) have Production Rules of the form
\[
    V \rightarrow \alpha
\]
where $V$ is a single Non-terminal and $\alpha$ is a string of Terminals
and/or Non-terminals (or empty). Because $V$ is required to be a
single Non-terminal, the Production Rules can be applied regardless of
Context. Each Non-terminal in a Context-free Grammar, $G$, is said to
form a \emph{Sub-Language} of the language defined by $G$.

Multiple Context-free Grammars may generate the same Language, so
properties of CFGs may be termed \emph{extrinsic} while Language properties
are \emph{intrinsic}. The question of equality between CFGs is
undecidable.

A popular notation for Context-free Grammars (especially in Computer
Science) is \emph{Backus-Naur form} (\emph{BNF}).

In Linguistics, the term used for Context-free Grammar is \emph{Phrase
  Structure Grammar} which is also called \emph{constituency grammar}
due to the one-to-one-or-many correspondence between the Productions
(ultimately rooted in the \emph{subject-predicate} clause derived from
\emph{Term Logic}).

An alternative formulation to Phrase Structure Grammar is \emph{Dependency
  Grammar} in which the Verb is the root and there is a one-to-one
correspondence between Symbols and nodes in the syntax structure.

The Context-free Grammar is equivalent to \emph{Non-deterministic
Pushdown Automata}(\S\ref{subsec:pushdown_automata}).

\paragraph{Deterministic}\label{subsec:deterministic_cfg}
\emph{Deterministic Context-free Grammars} are derived from
\emph{Deterministic Pushdown Automata}(\S\ref{subsec:deterministic_pda})
and are always \emph{unambiguous}. They can be parsed in linear time
and a \emph{Parser} can be automatically generated from the Grammar by a
\emph{Parser Generator}(\S\ref{subsec:parser_generator}).

\paragraph{Visibly Pushdown}
\emph{Visibly Pushdown Grammars} are described by the 4-tuple
\[
    G = (V=V^0 \cup V^1,T,P,S)
\]
where $V^0$ and $V^1$ are disjoint sets of Non-terminals and there
are three kinds of Production Rules:
\[
    X \rightarrow \varepsilon
\]\[
    X \rightarrow aY
\]\[
    X \rightarrow \langle aZb \rangle Y
\]
where $Z \in V^0$ and if $X \in V^0$ then $Y \in V^0$

The resulting Language is a \emph{Regular Language} with \emph{nested
  words}, described by a \emph{Monadic Second-order Logic}. % FIXME ref

\subsubsection{Type-3: Regular} \label{subsec:regular_language}

\emph{Regular Languages} are more restricted than Context-free
Languages and satisfy a number of closure properties. For two Regular
Languages, $K$ and $L$, the following operations result in a Language
that is also Regular:
\[
    K \cup L, \quad
    K \cap L, \quad
    \overline{L}, \quad
    K - L, \quad
    K \circ L, \quad
    L^*, \quad
    K / L, \quad
    L^R
\]
A common formulation of Regular Languages is the \emph{Regular
  Expression} and conversely it is sometimes said that a Regular
Language is one that can be defined by a Regular Expression.

An algebraic description is as follows:
\[
    L = \{ w \in \Sigma^* | f(w) \in N \}
\]
where $f : \Sigma^* \rightarrow M$ is a \emph{Monoid homomorphism} of
\emph{Finite Monoid}, $M$, and $N \subseteq M$.
% FIXME ref monoids

\paragraph{Extended Regular}
\emph{Extended Regular Grammars} have Productions of either \emph{right
Regular} or \emph{left Regular} form.

Right:
\[
    B \rightarrow a
\]\[
    A \rightarrow B \nu
\]\[
    A \rightarrow \varepsilon
\]

Left:
\[
    A \rightarrow a
\]\[
    A \rightarrow B \nu
\]\[
    A \rightarrow \varepsilon
\]
where $a$ is a single Non-terminal and $\nu$ is an expression of only
Non-terminal characters.

\paragraph{Strictly Regular}
\emph{Strictly Regular Grammars} also have Productions of either right
Regular or left Regular form.

Right:
\[
    B \rightarrow a
\]\[
    B \rightarrow aC
\]\[
    B \rightarrow \varepsilon
\]

Left:
\[
    A \rightarrow a
\]\[
    A \rightarrow Ba
\]\[
    A \rightarrow \varepsilon
\]
where $a$ is a single Non-terminal.

There is a one-to-one correspondence between the rules of a
\emph{Strictly Left Regular Grammar} and those of a
\emph{Non-deterministic Finite Automaton}(\S\ref{subsec:ndfa}).

The \emph{pumping lemma} states that the middle section of an
Expression within a Regular Language may be repeated an arbitrary
number of times to produce another Expression in that same Language.

\paragraph{k-Testable}\label{subsec:k_testable}
A \emph{k-Testable Language} is one where membership of an Expression
depends on the first and last symbol and a set of factors of length
$k$. An example is a \emph{Local Language} which is a \emph{2-Testable
  Language} described by the \emph{regular expression}:
\[
    (Q\Sigma^* \cap \Sigma^*R)\setminus\Sigma^*F\Sigma^*
\]
where $Q,R \subseteq \Sigma$ and $F \subseteq \Sigma \times
\Sigma$. This requires for a \emph{Word} (Expression), $w$, that is a
member of a Local Language to have its first Symbol in $Q$, and its
second Symbol in $R$, and no factor of $w$ of length 2 is in $F$. A
Local Language is Recognized by a \emph{Local
  Automaton}(\S\ref{subsec:dfa}).

\paragraph{Star-free}
A \emph{Star-free Language} is one having a \emph{Generalized Star
  Height} equal to zero, that is, the minimal \emph{Star Height} of
all Expressions in the Language with the Star Height of an
Expression's \emph{Complement} being equal.

Star-free Languages are characterized as those with \emph{Aperiodic
  Syntactic Monoids}\cite{schutzenberger65} and also as the
\emph{Counter-free Langauges}\cite{mcnaughton-papert71} by the
\emph{Aperiodic Finite-state Automaton}, and \emph{Linear Temporal
  Logic}. % FIXME ref

% --------------------------------------------------------------------
\subsection{Affix Grammars}
% --------------------------------------------------------------------

\emph{Affix Grammars} are those of a Context-free Grammar with a
subset of the Non-terminals used as \emph{affix arguments}. If the
same affix appears multiple places in a Production, the value must be
the same.

% --------------------------------------------------------------------
\subsection{Two-Level Grammars}
% --------------------------------------------------------------------

\emph{Two-Level Grammars} are \emph{Grammar generators} that may
generate Grammars with infinite rules. Allowing the values for affixes
to be described by a Context-free Grammar results in a Two-Level
Grammar.


\begin{description}
\item[W-grammar] \emph{Van Wijngaarden Grammar} consists of a finite
  set of \emph{meta-rules} used to derive a possibly infinite set of
  Production Rules from a finite set of \emph{hyper-rules}.
\item[Extended Affix Grammar] is a restricted W-grammar.
\end{description}

% --------------------------------------------------------------------
\subsection{Attribute Grammars}
% --------------------------------------------------------------------

\emph{Attribute Grammars} allows affixes from arbitrary domains and
allows functions calculate values of affixes.

% --------------------------------------------------------------------
\subsection{Analytic Grammars}
% --------------------------------------------------------------------

\emph{Analytic Grammars} are used in \emph{Parsing} (\S
\ref{sec:parser}). A few examples:

\begin{description}
\item[Top-Down Parsing Language] \hfill \\
Formal representation of \emph{Recursive Descent Parser}. Production
rules of the form
\[
    A \leftarrow \varepsilon
\]\[
    A \leftarrow f
\]\[
    A \leftarrow a
\]\[
    A \leftarrow BC/D
\]
\item[Parsing Expression Generator] \hfill \\
A more generalized Top-Down Parsing Language.
\item[Link Grammar] \hfill \\
Dependency Grammar with directionality between Symbols.
\end{description}

% --------------------------------------------------------------------
\subsection{Adaptive Grammars}
% --------------------------------------------------------------------

\emph{Adaptive Grammars} allow for Production Rules to be manipulated
within the Grammar, including addition, deletion, and modification of
Rules.

\subsubsection{Imperative Adaptive Grammar}

Global

Rule changes are based on global state changing over time.

\begin{itemize}
\item Extensible Context-Free Grammars
\item Top-down Modifiable Grammars
\item Bottom-up Modifiable Grammars
\end{itemize}

\subsubsection{Declarative Adaptive Grammar}

Local

Rule changes only affect the position in the syntax tree of the
generation of a string.

\begin{itemize}
\item Christiansen Grammars
\item Recursive Adaptive Grammars
\end{itemize}

\subsubsection{Time-space (Hybrid) Adaptive Grammar}

\begin{itemize}
\item \S-Calculus
\end{itemize}

\subsubsection{Dynamic Grammars}

Boullier\cite{boullier94}



% ====================================================================
\section{Abstract Reduction Systems}\label{sec:abstract_rewrite}
% ====================================================================

The previous descriptions of Formal Grammars may be abstracted as
\emph{Abstract Reduction} or \emph{Rewrite Systems}. This is simply
    \[(A,\rightarrow)\]
where $A$ is a Set of objects and $\rightarrow \subseteq A \times A$
is a Binary Relation on those objects. This is equivalent to an
\emph{Unlabeled State Transition System}
(\S\ref{sec:state_transition_system}).

An \emph{Indexed Abstract Reduction System} differentiates Reductions
into Classes so that $\rightarrow$ is the Indexed Union of these
relations:
    \[(A, \rightarrow_1, \rightarrow_2, \cdots)\]
This is identical to a \emph{Labeled Transition System}.

\emph{Holism}

\emph{Reductionism}



% --------------------------------------------------------------------
\subsection{Notation}\label{subsec:rewrite_notation}
% --------------------------------------------------------------------

$\stackrel{*}{\rightarrow}$

$\leftrightarrow$

$\stackrel{*}{\leftrightarrow}$



% --------------------------------------------------------------------
\subsection{Normal Form}\label{subsec:normal_form}
% --------------------------------------------------------------------

An object of an Abstract Rewriting System $(A,\rightarrow)$ is in
\emph{Normal Form} or \emph{Irreducible} if it cannot be Rewritten
further. That is, $x \in A$ is in Normal Form if $\nexists y \in A : x
\rightarrow y$. Otherwise $x$ is \emph{Reducible}.

\emph{Untyped $\lambda$-calculus} (\S\ref{sec:untyped_lambda}) lacks
the Normalization Property.

\emph{Strong Normalization}

Systems of \emph{Typed $\lambda$-calculus} (\S\ref{sec:typed_lambda})
such as \emph{Simply-typed $\lambda$-calculus}
(\S\ref{subsec:simply_typed}) and \emph{Calculus of Constructions}
(\S\ref{subsec:coq}) are Strongly Normalizing.

\emph{Weak Normalization}



% --------------------------------------------------------------------
\subsection{Confluence}\label{subsec:rewrite_confluence}
% --------------------------------------------------------------------



% ====================================================================
\section{Parsers} \label{sec:parser}
% ====================================================================

A \emph{Parser} analyzes an Expression according to the rules of a Formal
Grammar, generating a \emph{Data Structure} describing the Syntax of
the input. An outline of the process follows.

% --------------------------------------------------------------------
\subsection{Lexical Analysis}
% --------------------------------------------------------------------

A Parser may be preceded by a \emph{Lexical Analyzer} which creates
\emph{Tokens} (Symbols) from an input Expression. Strings of Tokens
are referred to as Phrases. A Lexical Analyzer is a Parser itself and
usually the \emph{Lexical Grammar} is a Regular Language (other
methods are \emph{flags}, \emph{delimiters}, or \emph{dictionaries})
and the Tokens are parsed as a Context-free or \emph{Attribute Phrase
  Syntax}.

Prior to \emph{Scanning}, a \emph{Lexer} may perform its own
Tokenization.  The Scanning stage first recognizes the Token
strings as \emph{Lexemes}, usually achieved by a Finite State
Machine.

Lexemes are resolved into Tokens by an \emph{Evaluator} which assigns
values where needed-- this results in Tokens that are either a
\emph{Type-Value} pair, or just a \emph{Type}.

% --------------------------------------------------------------------
\subsection{Syntactic Analysis}
% --------------------------------------------------------------------

The Parser determines if and how the input can be derived from the
Start Symbol of the Grammar. Parsing can proceed in two directions:

\begin{description}
    \item[Top-down Parsing]
    starts with the highest level of the \emph{Parse Tree}. Proceeds greedily
    and may be \emph{Exponential} with \emph{Backtracking}.
    \item[Bottom-up Parsing]
    starts with the lowest level of the Parse Tree.
\end{description}

Further \emph{Semantic} Parsing may be performed after these steps. An
example of this would be the in the \emph{Compiler} of a
\emph{Programming Language}.

% --------------------------------------------------------------------
\subsection{Top-down Parsers}
% --------------------------------------------------------------------

\subsubsection{Recursive Descent Parser}

\subsubsection{LL Parser}

\subsubsection{Early Parser}

% --------------------------------------------------------------------
\subsection{Bottom-up Parsers}
% --------------------------------------------------------------------

\subsubsection{Precedence Parser}

\subsubsection{LR Parser}

\emph{Canonical LR} LR(1)

\paragraph{SLR Parser}

\paragraph{LALR Parser}

\paragraph{GLR Parser}

\subsubsection{CYK Parser}

\subsubsection{Recursive Ascent Parser}

% --------------------------------------------------------------------
\subsection{Parser Generators}\label{subsec:parser_generator}
% --------------------------------------------------------------------

A \emph{Parser Generator} takes as a Grammar (for example a BNF
Grammar) and outputs the source code of a Parser for the Language
specified by the Grammar.
