%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Information Theory}\label{part:information_theory} \cite{shannon48}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ====================================================================
\section{Channel}\label{sec:channel}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Channel Capacity}\label{sec:channel_capacity}
% --------------------------------------------------------------------

\fist Cf. \emph{Controllability} (Control Theory
\S\ref{sec:control_theory})



% ====================================================================
\section{Coding Theory}\label{sec:coding_theory}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Encoding}\label{sec:encoding}
% --------------------------------------------------------------------

the Entropy (\S\ref{sec:entropy}) of a Distribution
(\S\ref{sec:probability_distribution}) is the Mean number of
Bits-per-symbols in an Optimal Encoding --
\url{https://golem.ph.utexas.edu/category/2017/02/functional_equations_iii_expla.html}



% ====================================================================
\section{Entropy}\label{sec:entropy}
% ====================================================================

the Entropy of a Distribution (\S\ref{sec:probability_distribution})
is the Mean number of Bits-per-symbols in an Optimal Encoding
(\S\ref{sec:encoding}) --
\url{https://golem.ph.utexas.edu/category/2017/02/functional_equations_iii_expla.html}

\url{https://golem.ph.utexas.edu/category/2008/10/entropy_diversity_and_cardinal.html}
-- ``the \emph{Exponential} of Entropy is like Cardinality''



% --------------------------------------------------------------------
\subsection{Relative Entropy}\label{sec:relative_entropy}
% --------------------------------------------------------------------

\url{https://golem.ph.utexas.edu/category/2017/02/functional_equations_iv_a_simp.html}



% ====================================================================
\section{Signal Processing}\label{sec:signal_processing}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Signal}\label{sec:signal}
% --------------------------------------------------------------------

\subsubsection{Transient}\label{sec:transient}



% --------------------------------------------------------------------
\subsection{Time-Frequency Analysis}\label{sec:time_frequency_analysis}
% --------------------------------------------------------------------

techniques for characterizing and manipulting Signals with Statistics (cf.
Entropy \S\ref{sec:entropy}) that vary in Time, e.g. \emph{Transient Signals}

\fist Quasiprobability Distributions
(\S\ref{sec:quasiprobability_distribution})



\subsection{Time-Frequency Representation}
\label{sec:time_frequency_representation}
