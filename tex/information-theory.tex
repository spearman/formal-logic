%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Information Theory}\label{part:information_theory} \cite{shannon48}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ====================================================================
\section{Channel}\label{sec:channel}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Channel Capacity}\label{sec:channel_capacity}
% --------------------------------------------------------------------

\fist Cf. \emph{Controllability} (Control Theory
\S\ref{sec:control_theory})



% ====================================================================
\section{Coding Theory}\label{sec:coding_theory}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Encoding}\label{sec:encoding}
% --------------------------------------------------------------------

the Entropy (\S\ref{sec:entropy}) of a Distribution
(\S\ref{sec:probability_distribution}) is the Mean number of
Bits-per-symbols in an Optimal Encoding --
\url{https://golem.ph.utexas.edu/category/2017/02/functional_equations_iii_expla.html}



% ====================================================================
\section{Entropy}\label{sec:entropy}
% ====================================================================

the Entropy of a Distribution (\S\ref{sec:probability_distribution})
is the Mean number of Bits-per-symbols in an Optimal Encoding
(\S\ref{sec:encoding}) --
\url{https://golem.ph.utexas.edu/category/2017/02/functional_equations_iii_expla.html}
