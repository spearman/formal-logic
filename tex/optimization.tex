%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Optimization}\label{part:optimization}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ====================================================================
\section{Loss Function}\label{sec:loss_function}
% ====================================================================

%FIXME: move this section ?

% ====================================================================
\section{Unconstrained Nonlinear Optimization}
\label{sec:unconstrained_nonlinear}
% ====================================================================

\fist cf. Nonlinear Optimization (\S\ref{sec:nonlinear_optimization})



% ====================================================================
\section{Constrained Optimization}\label{sec:constrined_optimization}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Objective Function}\label{sec:objective_function}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Lagrange Multiplier}\label{sec:lagrange_multiplier}
% --------------------------------------------------------------------

\fist Lagrangian (\S\ref{sec:lagrangian})

$\lambda$

$\nabla f(x_m, y_m) = \lambda\nabla g(x_m, y_m)$



% --------------------------------------------------------------------
\subsection{Nonlinear Programming}\label{sec:nonlinear_programming}
% --------------------------------------------------------------------

Constrained Nonlinear Optimization

Barrier Methods

Penalty Methods

Sequential Quadratic programming

Successive Linear Programming



% ====================================================================
\section{Non-linear Optimization}\label{sec:nonlinear_optimization}
% ====================================================================

%FIXME: merge this section ???

\emph{Nonlinear Optimization}

Nonlinear Constraint Solving in Programming Languages: ATS (Xi16) uses
explicit Proof Construction to handle Nonlinear Constraints

\fist cf. Nonlinear Programming (\S\ref{sec:nonlinear_programming})



% ====================================================================
\section{Convex Optimization}\label{sec:convex_optimization}
% ====================================================================

Convex Analysis (\S\ref{sec:convex_analysis})

Maximum Principle (Harmonic Functions \S\ref{sec:harmonic_function})



% --------------------------------------------------------------------
\subsection{Linear Programming}\label{sec:linear_programming}
% --------------------------------------------------------------------

Constrained Linear Optimization

Objective Function and all the Hard Constraints are Linear; can be solved by
Simplex Method (\S\ref{sec:simplex_algorithm}) usually in Polynomial Time, or
by Interior Point Method (\S\ref{sec:interior_point}) in Polynomial Time



\subsubsection{Linear Inequality}\label{sec:linear_inequality}

Linear Integer Programming: NP-Complete



% --------------------------------------------------------------------
\subsection{Quadratic Programming}\label{sec:quadratic_programming}
% --------------------------------------------------------------------

all Hard Constraints are Linear but Objective Function is Quadratic

solvable by Ellipsoid Method in Polynomial Time if the Objective Funciton is
Convex; otherwise the problem is NP Hard



% --------------------------------------------------------------------
\subsection{Interior Point Method}\label{sec:interior_point}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Basis-exchange Algorithm}\label{sec:basis_exchange}
% --------------------------------------------------------------------

\subsubsection{Simplex Algorithm}\label{sec:simplex_algorithm}

Dantzig



% --------------------------------------------------------------------
\subsection{Ellipsoid Method}\label{sec:ellipsoid_method}
% --------------------------------------------------------------------



% ====================================================================
\section{Stochastic Optimization}\label{sec:stochastic_optimization}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Multi-armed Bandit}\label{sec:multiarmed_bandit}
% --------------------------------------------------------------------

\url{http://datagenetics.com/blog/october12017/index.html}

Epsilon-first Strategy

Epsilon-greedy Strategy

Epsilon-decreasing Strategy

Bayesian Bandits



% ====================================================================
\section{Combinatorial Optimization}
\label{sec:combinatorial_optimization}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Dynamic Programming}\label{sec:dynamic_programming}
% --------------------------------------------------------------------

or \emph{Dynamic Optimization}



% ====================================================================
\section{Evolutionary Optimization}\label{sec:evolutionary_optimization}
% ====================================================================

\fist Information Geometry (\S\ref{sec:information_geometry}), Fisher
Information Metric (\S\ref{sec:fisher_information})

\fist \textbf{Fisher's Fundamental Theorem of Natural Selection},
Quasi-linkage Equilibrium: approximation in the case of Weak Selection
and Weak Epistasis %FIXME



% --------------------------------------------------------------------
\subsection{Fitness Function}\label{sec:fitness_function}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Fitness Landscape}\label{sec:fitness_landscape}
% --------------------------------------------------------------------

A \emph{Fitness Landscape} (or \emph{Adaptive Landscape}) is an
evaluation of a Fitness Function for all candidate Solutions %FIXME



% ====================================================================
\section{Linear Complementarity Problem (LCP)}
\label{sec:linear_complementarity}
% ====================================================================

%FIXME an instance of linear optimization ???

Inequality Constraints and Limits %FIXME

Real Matrix -- $M$

Vector -- $q$

\emph{Linear Complementarity Problem} -- $LCP(M,q)$

find Vectors $z$, $w$ with constraints:

\begin{itemize}
  \item $0 \leq w_i,z_i$ -- each component of $w$ and $z$ is
    non-negative
  \item $z^T w = 0$ (or equivalently) $\sum_i w_i z_i = 0$ --
    \emph{Complementarity Condition}: Imples at most one of each pair
    $\{w_i,z_i\}$ can be Positive
  \item $w = M z + q$
\end{itemize}

Sufficient Condition for Existence and Uniqueness of a solution to LCP
is that $M$ is \emph{Symmetric} (\S\ref{sec:symmetric_matrix})
\emph{Positive-definite} (\S\ref{sec:positive_definite})

\fist Projected Gauss-Seidel (PGS \S\ref{sec:projected_gauss_seidel})


% --------------------------------------------------------------------
\subsection{Mixed Linear Complementarity Problem}\label{sec:mlcp}
% --------------------------------------------------------------------

Generalized LCP to include Free Variables



% ====================================================================
\section{Global Analysis}\label{sec:global_analysis}
% ====================================================================
