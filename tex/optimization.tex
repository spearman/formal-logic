%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Optimization}\label{part:optimization}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ====================================================================
\section{Root-finding Algorithm}\label{sec:root_finding}
% ====================================================================

%FIXME: move this section to analysis ?

% --------------------------------------------------------------------
\subsection{Bracketing Method}\label{sec:bracketing_method}
% --------------------------------------------------------------------

\subsubsection{Bisection Method}\label{sec:bisection_method}

\subsubsection{False Position Method}\label{sec:false_position}



% --------------------------------------------------------------------
\subsection{Iterative Method}\label{sec:iterative_rootfinding}
% --------------------------------------------------------------------

cf. \emph{Direct Methods}

\fist Iterative Methods (Numerical Linear Algebra \S\ref{sec:iterative_method})

\fist Systems of Nonlinear Equations
(\S\ref{sec:system_of_nonlinear_equations})

\fist cf. Nonlinear Programming (\S\ref{sec:nonlinear_programming}), Nonlinear
Optimization (\S\ref{sec:nonlinear_optimization})



\subsubsection{Newton's Method}\label{sec:newtons_method}

\subsubsection{Secant Method}\label{sec:secant_method}

\subsubsection{Inverse Interpolation Method}\label{sec:inverse_interpolation}



% ====================================================================
\section{Approximation Theory}\label{sec:approximation_theory}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Curve Fitting}\label{sec:curve_fitting}
% --------------------------------------------------------------------

\fist if errors are \emph{normally distributed}, Least Squares ($2$-norm Best
Fit \S\ref{sec:least_squares}) should be used

may be solved with Linear Programming (\S\ref{sec:linear_programming}) methods



\subsubsection{$1$-norm Best Fit}\label{sec:1norm_best_fit}

less sensitive to outliers



\subsubsection{Chebyshev Approximation}\label{sec:chebyshev_approximation}

UC Math 352 Lec. 10 - \url{https://www.youtube.com/watch?v=XII0GSmEAgg}

minimizes the worst-case deviation



% ====================================================================
\section{Optimization Problem}\label{sec:optimization_problem}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Continuous Optimization Problem}
\label{sec:continuous_optimization_problem}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Combinatorial Optimization Problem}
\label{sec:combinatorial_optimization_problem}
% --------------------------------------------------------------------

\fist Combinatorial Optimization (\S\ref{sec:combinatorial_optimization})



% --------------------------------------------------------------------
\subsection{Duality}\label{sec:optimization_duality}
% --------------------------------------------------------------------

(wiki):

Optimization Problems may be viewed as either the \emph{Primal Problem} or the
\emph{Dual Problem}

the Solution to the Dual Problem gives a Lower Bound to the Solution of the
Primal (Minimization) Problem

\emph{Duality Gap} -- difference between the Optimal Values of the Primal and
Dual Problems

\emph{Primal Constraints} -- Constraints of the original Problem

for Convex Optimization Problems (\S\ref{sec:convex_optimization}), the Duality
Gap is Zero under a ``Regularity Condition'' (Constraint Qualification
\S\ref{sec:constraint_qualification})

\begin{itemize}
  \item Lagrangian Dual Problem (\S\ref{sec:lagrangian_dual})
  \item Wolfe Dual Problem
  \item Fenchel Dual Problem
\end{itemize}



% ====================================================================
\section{Unconstrained Optimization}\label{sec:unconstrained_optimization}
% ====================================================================

(wiki):

for a Constrained Optimization Problem (\S\ref{sec:constrained_optimization})
with only Equality Constraints, the method of Lagrange Multipliers
(\S\ref{sec:lagrange_multiplier}) can be used to convert it into an
Unconstrained Problem with number of Variables equal to the original number
plus the original number of Equality Constraints

if the Constraints are all Equality Constraints and are all \emph{Linear}, they
can be ``solved'' for some of the Variables in terms of the others and have
those substituted \emph{out} of the Objective Function, leaving an
Unconstrained Problem in a smaller number of Variables (TODO: example)



% --------------------------------------------------------------------
\subsection{Unconstrained Nonlinear Optimization}
\label{sec:unconstrained_nonlinear}
% --------------------------------------------------------------------

\fist cf. Nonlinear Optimization (\S\ref{sec:nonlinear_optimization})

\fist cf. Iterative Methods (\S\ref{sec:iterative_method})



% ====================================================================
\section{Constrained Optimization}\label{sec:constrained_optimization}
% ====================================================================

(wiki)

general form:

\begin{align*}
  & f(\vec{x})
  & g_i(\vec{x}) = c_i
  & h_j(\vec{x}) \geq d_j
\end{align*}
where $f$ is the Objective Function to be Minimized (or Maximized), $g_i$ for
$i \in \{ 1, \ldots, n \}$ are Equality Constraints and $h_j$ for $j \in \{ 1,
\ldots, m \}$ are Inequality Constraints

\emph{note}: a Maximization Problem can always be converted to a Minimization
Problem by multiplying by $-1$; usually Problems are presented as Minimization
Problems

Points $\vec{x}$ Satisfying all Constriants are said to be \emph{Feasible}
and the Set of all Feasible Points is called the \emph{Feasible Region}

a Point $\vec{x}^*$ is \emph{Optimal} if there are no other Feasible Points
with $f(\vec{x}) < f(\vec{x}^*)$


\textbf{Equality Constraints}

a Constrained Problem with only Equality Constraints may be converted using the
method of Lagrange Multipliers (\S\ref{sec:lagrange_multiplier}) to an
Unconstrained Optimization Problem (\S\ref{sec:unconstrained_optimization})
with a number of Variables equal to the original number of Variables plus the
original number of Equality Constraints

if the Constraints are all Equality Constraints and are all \emph{Linear}, they
can be ``solved'' for some of the Variables in terms of the others and have
those substituted \emph{out} of the Objective Function, leaving an
Unconstrained Problem in a smaller number of Variables (TODO: example)


\textbf{Inequality Constraints}

\emph{Geometric Optimality Conditions} (FIXME: Geometric Programming ???
\S\ref{sec:geometric_programming})

\emph{Fritz John Conditions} -- necessary condition for a solution in Nonlinear
Programming; lemma for Karush-Kuhn-Tucker Conditions

\emph{Karush-Kuhn-Tucker Conditions} (\S\ref{sec:karush_kuhn_tucker}) --
First-order necessary condition for a solution in Nonlinear Programming,
provided some Regularity Conditions (\S\ref{sec:constraint_qualification});
allowing Inequality Constraints generalizes the method of Lagrange Multipliers



% --------------------------------------------------------------------
\subsection{Objective Function}\label{sec:objective_function}
% --------------------------------------------------------------------

\emph{Cost Function} (or \emph{Loss Function})

\emph{Reward Function}

\fist Optimality Criterion (\S\ref{sec:optimality_criterion}), Model Selection
(\S\ref{sec:model_selection}), Decision Rules (\S\ref{sec:decision_rule})

2018 - \url{https://blog.evjang.com/2018/04/aesthetic-lr.html} - \emph{Aesthetically
  Pleasing Learning Rates}:

``The optimal learning rate is commensurate with the scale of the smoothness of
the gradient of the loss function (or in fancy words, the 'Lipschitz constant'
of a function). The smoother the function, the larger the learning rate we are
allowed to take without the optimization 'blowing up'.''

\fist Lipschitz Continuity (\S\ref{sec:real_continuous})

Auto-correlated Noise seems to be beneficial for State-dependent Exploration

``waving'' Learning Rates up and down are good for Deep Learning

Pixel Values from natural images have both of the above properties



% --------------------------------------------------------------------
\subsection{Constraint Qualification}\label{sec:constraint_qualification}
% --------------------------------------------------------------------

or \emph{Regularity Condition}

\fist Karush-Kuhn-Tucker Conditions (\S\ref{sec:karush_kuhn_tucker})

for Convex Optimization Problems (\S\ref{sec:convex_optimization}), the Duality
Gap (\S\ref{sec:optimization_duality}) is Zero under a Constraint Qualification
Condition



% --------------------------------------------------------------------
\subsection{Lagrange Multiplier}\label{sec:lagrange_multiplier}
% --------------------------------------------------------------------

(wiki): for a Constrained Optimization Problem with only Equality Constraints,
the method of Lagrange Multipliers can be used to convert into Unconstrained
Problem (\S\ref{sec:unconstrained_optimization}) with number of Variables equal
to the original number of Variables plus the original number of Equality
Constraints (FIXME: details)

\fist Lagrangian (\S\ref{sec:lagrangian})

\fist cf. \emph{Karush-Kuhn-Tucker Conditions} (\S\ref{sec:karush_kuhn_tucker})
-- First-order necessary condition for a solution in Nonlinear Programming,
provided some Regularity Conditions (\S\ref{sec:constraint_qualification});
allowing Inequality Constraints generalizes the method of Lagrange Multipliers

\fist Convex Optimization (\S\ref{sec:convex_optimization})

cf. Shadow Prices (\S\ref{sec:shadow_price})

$\lambda$

$\nabla f(x_m, y_m) = \lambda\nabla g(x_m, y_m)$

\url{https://www.youtube.com/watch?v=dPMEUi77qZk}:

the Lagrange Multiplier represents the proportion that an increase in the
Constraint causes an increase in the Function being Optimized

(FIXME: clarify)

\[
  \mathcal{L}(x^*,s^*,\lambda^*) = f(x^*,y^*) - \lambda^*(C(x^*,y^*)-c)
\]

\[
  \mathcal{L}^*(x^*(c),s^*(c),\lambda^*(c), c)
    = f(x^*(c),y^*(c)) - \lambda^*(C(x^*(c),y^*(c))-c)
\]

\[
  \frac{d\mathcal{L}^*}{dc} = \frac{\partial{\mathcal{L}}}{\partial{c}} =
  \lambda^*(c)
\]



\subsubsection{Lagrangian Dual Problem}\label{sec:lagrangian_dual}

Dual Problem (\S\ref{sec:optimization_duality})

general Optimization Problem:

\begin{tabular}{r l}
  $\mathrm{min}_{\vec{x}}$ & $f(\vec{x})$      \\
  subject to               & $g_i(\vec{x}) = 0, i \in \{1,\ldots,m\}$ \\
                           & $h_j(\vec{x}) \leq 0, j \in \{1,\ldots,n\}$
\end{tabular}

with $\vec{x} \in \reals^n$

Lagrangian:
\[
  \mathcal{L}(\vec{x},\vec{\lambda},\vec{\nu}) =
    f(\vec{x}) + \sum_{i=1}^m\lambda_i g_i(x) + \sum_{j=1}^n \nu_j h_j(x)
\]
the Vectors $\lambda, \nu$ are \emph{Dual Variables}

Non-empty Domain $D$

\emph{Lagrange Dual Function}:
\[
  \Lambda(\vec{\lambda}, \vec{nu}) =
    \mathrm{inf}_{x \in D} \mathcal{L}(\vec{x},\vec{\lambda},\vec{\nu})
\]

if the Lagrangian is Unbounded below, then the Dual Function is said to take
the value Negative Infinity $\Lambda(\vec{\lambda}, \vec{\nu}) = -\infty$

the Lagrange Dual gives a Lower Bound on the Optimum of the original
Optimization Problem: if $\vec{\lambda} \geq \vec{0}$ then
$\Lambda(\vec{\lambda}, \vec{\nu}) \leq \vec{p}^*$ where $\vec{p}^*$ is the
Optimal Value of the original Problem

... TODO

the Problem of finding the Greatest Lower Bound on $\vec{p}^*$ from
$\Lambda(\vec{\lambda},\vec{\nu})$ is the \emph{Lagrange Dual Problem}:
\begin{tabular}{r l}
  $\mathrm{max}_{\vec{\lambda},\vec{\nu}}$ &
    $\Lambda(\vec{\lambda},\vec{\nu})$ \\
  subject to & $\vec{\lambda} \geq \vec{0}$ \\
\end{tabular}

$\vec{\lambda} \geq \vec{0}$ and $\Lambda(\vec{\lambda},\vec{\nu}) > -\infty$
  -- $\vec{\lambda}$, $\vec{\nu}$ are called ``Dual Feasible''

$(\vec{\lambda}^*, \vec{\nu}^*)$ -- called ``Dual Optimal'' if Optimizes the
Lagrange Dual Problem


Solution scenarios:
\begin{enumerate}
  \item the Primal is Unbounded: the Dual is Infeasible
  \item the Dual is Unbounded: the Primal is Infeasible
  \item the Primal and Dual may both be Infeasible
  \item both the Primal and the Dual have Solutions
\end{enumerate}
normally both the Primal and Dual have Solutions (4.)


\emph{Strong Duality}: both Primal and Dual have the same Optimal Objective


\emph{Complementary Slackness}: for a Problem with \emph{Strong Duality},
either a Dual Constraint is Binding (``Sharp'') or else the corresponding
Shadow Price (\S\ref{sec:shadow_price}) $x_j^* = 0$ (is Non-basic)


\emph{Examples}

\begin{itemize}
  \item Linear Programming (\S\ref{sec:linear_programming}): Standard Form LP
    and Inequality Form LP are Dual with \emph{Strong Duality} (have the same
    Optimum Objective) -- Standard Form LP:

    \begin{tabular}{r l}
      $\mathrm{max}_{\vec{\lambda},\vec{\nu}}$ &
        $-\vec{b}^T\vec{\nu}$ \\
      subject to & $A^T\vec{\nu} - \vec{\lambda} + \vec{c} = 0$ \\
                 & $\vec{\lambda} \geq \vec{0}$ \\
    \end{tabular}

    or equivalently:

    \begin{tabular}{r l}
      $\mathrm{max}_{\vec{\nu}}$ &
        $-\vec{b}^T\vec{\nu}$ \\
      subject to & $-A^T\vec{\nu} \leq \vec{c}$ \\
    \end{tabular}

    note this is the form of an \emph{Inequality Form LP}

    for Inequality Form LP:

    \begin{tabular}{r l}
      $\mathrm{max}_{\vec{\lambda}}$ & $-\vec{b}^T\vec{\lambda}$ \\
      subject to & $A^T\vec{\lambda} = -\vec{c}$ \\
                & $\vec{\lambda} \geq \vec{0}$  \\
    \end{tabular}

    note this is the form of a \emph{Standard Form LP}

\end{itemize}



% --------------------------------------------------------------------
\subsection{Nonlinear Programming}\label{sec:nonlinear_programming}
% --------------------------------------------------------------------

Constrained Nonlinear Optimization: an Optimization Problem defined by a System
of Equalities and Inequalities (Constraints) over a Set of unknown Real
Variables along with an Objective Function, in which some of the Constraints
\emph{or} the Objective Function are \emph{Non-linear}
(\S\ref{sec:system_of_nonlinear_equations})

\fist cf. Iterative Methods (\S\ref{sec:iterative_method})

Barrier Methods

Penalty Methods

Sequential Quadratic programming

Successive Linear Programming



\subsubsection{Karush-Kuhn-Tucker Conditions}\label{sec:karush_kuhn_tucker}

(KKT Conditions)

\emph{Karush-Kuhn-Tucker Conditions} -- First-order necessary condition for a
solution in Nonlinear Programming, provided some Regularity Conditions
(Constraint Qualification \S\ref{sec:constraint_qualification});
allowing Inequality Constraints generalizes the method of Lagrange Multipliers
(\S\ref{sec:lagrange_multiplier})

Fritz John Conditions -- lemma for KKT Conditions



\subsubsection{Sequential Quadratic Programming}
\label{sec:sequential_quadratic_programming}

SQP

\fist cf. Quadratic Programming (\S\ref{sec:quadratic_programming})



% --------------------------------------------------------------------
\subsection{Linear Programming}\label{sec:linear_programming}
% --------------------------------------------------------------------

\fist Convex Optimization (\S\ref{sec:convex_optimization})

Constrained Linear Optimization

Objective Function and all the Hard Constraints are Linear; can be solved by
Simplex Method (\S\ref{sec:simplex_algorithm}) usually in Polynomial Time, or
by Interior Point Method (\S\ref{sec:interior_point}) in Polynomial Time

all Linear Programs can be expressed as Semidefinite Programs
(\S\ref{sec:semidefinite_programming})

Ellipsoid Method (\S\ref{sec:ellipsoid_method}): when specialized for solving
feasible Linear Optimization Problems with Rational Data, the Ellipsoid Method
finds an Optimal Solution in a Finite number of steps

applications: Chebyshev Approximation ($\infty$-norm
\S\ref{sec:chebyshev_approximation}), $1$-norm Best-fit


UC Math 352 Lec. 9 - \url{https://www.youtube.com/watch?v=g3E38tYcU4E&t=243s}:

all of the Functions are \emph{Affine} (FIXME: ???)

\emph{General Form LP}

Objective Function:
\[
  \mathrm{min}_{\vec{x}} \vec{c}^T\vec{x} + d
\]
since $d$ is a Constant, the Minimization Problem $\vec{c}^T\vec{x}$ has the
same solution without $d$

Subject to:
\begin{align*}
  G\vec{x} & \leq \vec{h} \\
  A\vec{x} & = \vec{b}
\end{align*}

\emph{Inequality Form LP} -- only Inequality Constraints:

\begin{tabular}{r l}
  $\mathrm{min}_{\vec{x}}$ & $\vec{c}^T\vec{x}$      \\
  subject to               & $A\vec{x} \leq \vec{b}$ \\
\end{tabular}

\emph{Standard Form LP} -- Set of Equality Constraints and Non-negativity
Constraints:

\begin{tabular}{r l}
  $\mathrm{min}_{\vec{x}}$ & $\vec{c}^T\vec{x}$     \\
  subject to               & $A\vec{x} = \vec{b}$   \\
                           & $\vec{x} \geq \vec{0}$ \\
\end{tabular}

note that Inequality Form LP and Standard Form LP are \emph{Dual}
(\S\ref{sec:lagrangian_dual}) to one another (see below)

General Form LP can be converted to Standard Form by introducing extra
\emph{Slack Variables} $\vec{s}$

General Form:

\begin{tabular}{r l}
  $\mathrm{min}_{\vec{x}}$ & $\vec{c}^T\vec{x}$     \\
  subject to               & $G\vec{x} \leq \vec{h}$   \\
                           & $A\vec{x} = \vec{b}$ \\
\end{tabular}

an example Inequality $3x \leq 5$ can be split into:
\begin{align*}
  3x + s & = 5 \\
  s      & \geq 0
\end{align*}

\begin{tabular}{r l}
  $\mathrm{min}_{\vec{x}}$ & $\vec{c}^T\vec{x}$     \\
  subject to               & $G\vec{x} + \vec{s} = \vec{h}$   \\
                           & $A\vec{x} = \vec{b}$ \\
                           & $\vec{s} \geq 0$ \\
\end{tabular}

express $\vec{x}$ as the Difference of two Non-negative Variables $\vec{x}^+
\geq \vec{0}$ and $\vec{x}^- \geq \vec{0}$:
\[
  \vec{x} = \vec{x}^+ - \vec{x}^-
\]

Linear Program in Standard Form:

\begin{tabular}{r l}
  $\mathrm{min}_{[\vec{x} \ \vec{s}]}$ &
    $\vec{c}^T\vec{x}^+ - \vec{c}^T\vec{x}^-$     \\
  subject to               & $G\vec{x}^+ - G\vec{x}^- + \vec{s} = \vec{h}$   \\
                           & $A\vec{x}^+ - A\vec{x}^- = \vec{b}$ \\
                           & $\vec{x}^+ \geq 0$ \\
                           & $\vec{x}^- \geq 0$ \\
                           & $\vec{s}   \geq 0$ \\
\end{tabular}

or:

\begin{tabular}{r l}
  $\mathrm{min}_{[\vec{x} \ \vec{s}]}$ &
    $[\vec{c}^T \ -\vec{c}^T \ \vec{0}] [\vec{x} \ \vec{s}]$ \\
  subject to               &
    $\begin{bmatrix} G & -G & I \\ A & -A & 0 \\ \end{bmatrix}
      [\vec{x} \ \vec{s}] = [\vec{h} \ \vec{b}]^T$   \\
                           & $[\vec{x} \ \vec{s}] \geq 0$ \\
\end{tabular}


\emph{Properties of LP}

\begin{enumerate}
  \item if Optimum $\vec{x}^*$ exists, then \emph{an} Optimal Point exists at a
    \emph{Vertex}, i.e. the Intersection of $n$ Constraint Boundaries (in
    Configuration Space $\reals^n$); the number of such Vertices is
    $\binom{m}{n}$ in the number of Constraints $m$ and number of Variables $n$
  \item if there is more than one Optimum, then there is a Surface of Optimal
    Points
  \item the Problem may be \emph{Infeasible}, i.e. an Empty Feasible Region
  \item the Problem may be \emph{Unbounded}, i.e. an Infinite Feasible Region
    (Objective Function may be made arbitrarily large)
\end{enumerate}

the number of Vertices $\binom{m}{n}$ is Factorial:
\[
  \frac{m!}{n!(m-n)!}
\]

an efficient algorithm for solving large LP Problems is the Simplex Method
(\S\ref{sec:simplex_algorithm})


UC Math 352 Lec. 11 - \url{https://www.youtube.com/watch?v=ESzYPFkY3og}:


\emph{Fundamental Theorem of Linear Programming}

Assume $A$ is Full Rank; if a Feasible Solution exists, then a Basic Feasible
Solution Exists, and if an Optimal Feasible Solution exists, then an Optimal
Basic Feasible Solution exists.

(a Basic Solution only involves $n$ Linearly Independent Columns of $A$; see
Simplex Method for more details)

the implication is that only Basic Feasible Solutions need to be considered
when searching for an Optimum, i.e. an \emph{Optimal Basis} (Set of Columns)
$B$


\textbf{Lagrangian Dual Problems} (\S\ref{sec:lagrangian_dual})

Standard Form LP and Inequality Form LP are Lagrangian Duals for each other; in
both cases the number of Primal Constraints is equal to the number of Dual
Variables and vice versa

\emph{Standard Form LP}

\begin{tabular}{r l}
  $\mathrm{min}_{\vec{x}}$ & $\vec{c}^T\vec{x}$     \\
  subject to               & $A\vec{x} = \vec{b}$   \\
                           & $\vec{x} \geq \vec{0}$ \\
\end{tabular}

Lagrangian Dual:

\begin{align*}
  \mathcal{L}(\vec{x},\vec{\lambda},\vec{\nu}) & =
    \vec{c}^T\vec{x} + \vec{\nu}^T(A\vec{x} - \vec{b}) - \vec{\lambda}^T\vec{x} \\
  \mathcal{L}(\vec{x},\vec{\lambda},\vec{\nu}) & =
    -\vec{b}^T\vec{\nu} + (A^T\vec{\nu} - \vec{\lambda} + \vec{c})^T\vec{x}
\end{align*}

Dual Function:

\begin{align*}
  \Lambda(\vec{\lambda},\vec{\nu}) & = -\vec{b}^T\vec{\nu} +
    \mathrm{inf}_{\vec{x}}(A^T\vec{\nu} - \vec{\lambda} + \vec{c})^T\vec{x} \\
  \Lambda(\vec{\lambda},\vec{\nu}) & = \begin{cases}
    -\vec{b}^T\vec{\nu} & \ A^T\vec{\nu} - \vec{\lambda} + \vec{c} = \vec{0} \\
    -\infty             & otherwise \\
  \end{cases}
\end{align*}

Lagrange Dual Problem for Standard Form LP:

\begin{tabular}{r l}
  $\mathrm{max}_{\vec{\lambda},\vec{\nu}}$ &
    $-\vec{b}^T\vec{\nu}$ \\
  subject to & $A^T\vec{\nu} - \vec{\lambda} + \vec{c} = 0$ \\
             & $\vec{\lambda} \geq \vec{0}$ \\
\end{tabular}

or equivalently:

\begin{tabular}{r l}
  $\mathrm{max}_{\vec{\nu}}$ &
    $-\vec{b}^T\vec{\nu}$ \\
  subject to & $-A^T\vec{\nu} \leq \vec{c}$ \\
\end{tabular}


\emph{Inequality Form LP}

\begin{tabular}{r l}
  $\mathrm{min}_{\vec{x}}$ & $\vec{c}^T\vec{x}$      \\
  subject to               & $A\vec{x} \leq \vec{b}$ \\
\end{tabular}

since there are no Equality Constraints, only the $\vec{\lambda}$ Dual Variable
is needed

Lagrangian Dual:

\begin{align*}
  \mathcal{L}(\vec{x}, \vec{\lambda}) & =
    \vec{c}^T\vec{x} + \vec{\lambda}^T(A\vec{x} - \vec{b})
  \mathcal{L}(\vec{x}, \vec{\lambda}) & =
    -\vec{b}^T\vec{\lambda} + (A\vec{\lambda} + \vec{c})^T \vec{x}
\end{align*}

Dual Function:

\begin{align*}
  \Lambda(\vec{\lambda},\vec{\nu}) & = \begin{cases}
    -\vec{b}^T\vec{\lambda} & \ A^T\vec{\lambda} = -\vec{c} \\
    -\infty                 & otherwise \\
  \end{cases}
\end{align*}

Lagrange Dual Problem for Inequality Form LP:

\begin{tabular}{r l}
  $\mathrm{max}_{\vec{\lambda}}$ & $-\vec{b}^T\vec{\lambda}$ \\
  subject to & $A^T\vec{\lambda} = -\vec{c}$ \\
             & $\vec{\lambda} \geq \vec{0}$  \\
\end{tabular}

which is a \emph{Standard Form LP}


\emph{Optimality}

Standard Form LP and Inequality Form LP have the \emph{Strong Duality}
property: for a Primal in Standard Form with Optimal Basis $B$, if $\vec{\nu}$
is also Dual Feasible, then it must Solve the Dual, i.e. \emph{the Primal and
  Dual of LP have the same Optimum Objective}


\emph{Complementary Slackness}: either a Dual Constraint is Binding (``Sharp'')
or else the corresponding Shadow Price (\S\ref{sec:shadow_price}) $x_j^* = 0$
(is Non-basic)



\subsubsection{Linear Inequality}\label{sec:linear_inequality}

\subsubsection{Integer Linear Programming}\label{sec:integer_linear_programming}

ILP

NP-Complete



\subsubsection{Shadow Price}\label{sec:shadow_price}

cf. Lagrange Multipliers (\S\ref{sec:lagrange_multiplier})

UC Math 352 Lec. 15 - \url{https://www.youtube.com/watch?v=wNflFE4m17E}:

for a Standard Form LP, perturbing a RHS $b_i \rightarrow b_i + \Delta{b_i}$
may cause a change to the Optimal Objective
$\vec{p}^* \rightarrow \vec{p}^* + \Delta{\vec{p}^*}$ and the quantity:
\[
  -\frac{\Delta p_i^*}{\Delta b_i}
\]
is called the \emph{Shadow Price} of the $i$th Constraint $\vec{a}_i^T\vec{x} =
b_i$

\emph{assuming the Basis remains constant}, then the Dual Variable
$\vec{\nu}^*$ won't Change and:
\[
  \Delta \vec{p}^* = - \nu_i^* \Delta b_i
\]
so the Shadow Price of the $i$th Constraint is just the $i$th Optimal Dual
Variable $\nu_i^*$

\emph{Complementary Slackness}: either a Dual Constraint is Binding (``Sharp'')
or else the corresponding Shadow Price $x_j^* = 0$ (is Non-basic)

(Economics) Shadow Prices represent how much improvement can be made to the
Objective by ``loosening Constraints'', e.g. if a Constraint has a Shadow Price
of $\nu_i^* = \$10$, then loosening the Constraint by an amount $a$ results in
the Objective decreasing by $\$10 a$, i.e. if a Constraint can be loosened for
less than the Shadow Price, then the Objective can be improved by doing so; if
the Shadow Prices is \$0, then loosening a Constraint does not improve the
Objective



% --------------------------------------------------------------------
\subsection{Quadratic Programming}\label{sec:quadratic_programming}
% --------------------------------------------------------------------

all Hard Constraints are Linear but Objective Function is Quadratic

for Positive Definite (\S\ref{sec:positive_definite}) $Q$ (i.e. Convex
Objective Function) the problem is solvable by Ellipsoid Method
(\S\ref{sec:ellipsoid_method}) in Polynomial Time; otherwise the problem is NP
Hard

with Convex Objective Function and Linear Constraints \fist Convex Optimization
(\S\ref{sec:convex_optimzation})

\fist cf. Sequential Quadratic Programming (Iterative Method
\S\ref{sec:sequential_quadratic_programming})

2001 - Milenkovic, Schmidl - Optimization-Based Animation



\subsubsection{Quadratically Constrained Quadratic Programming}
\label{sec:quadratically_constrained}

QCQP

both Objective Function and Constraints are Quadratic

with Convex Quadratic Constraints (FIXME: and convex objective function ???)
\fist Convex Optimization (\S\ref{sec:convex_optimization})

if the $P_0,\ldots,P_m$ Matrices are all Positive-definite Matrices
(\S\ref{sec:positive_definite}) then the problem is Convex and can be solved
using Interior Point Methods (\S\ref{sec:interior_point_method}), as in
Semidefinite Programming (\S\ref{sec:semidefinite_programming})



% --------------------------------------------------------------------
\subsection{Geometric Programming}\label{sec:geometric_programming}
% --------------------------------------------------------------------

not Convex in general but may be transformed into Convex Problems by change of
Variables and a transformation of the Objective and Constraint Functions

Inequality Constraints are Posynomials (\S\ref{sec:posynomials})
$f_i(x) \leq 1$

Equality Constraints are Monomials (\S\ref{sec:monomials}) $h_i(x) = 1$



% --------------------------------------------------------------------
\subsection{Relaxation}\label{sec:relaxation}
% --------------------------------------------------------------------

\fist not to be confused with Iterative Methods of Relaxation (Stationary
Iterative Methods \S\ref{sec:stationary_iterative})

Lagrangian Relaxation

Linear Programming Relaxation



% ====================================================================
\section{Non-linear Optimization}\label{sec:nonlinear_optimization}
% ====================================================================

%FIXME: merge this section ???

\emph{Nonlinear Optimization}

Nonlinear Constraint Solving in Programming Languages: ATS (Xi16) uses
explicit Proof Construction to handle Nonlinear Constraints

\fist cf. Nonlinear Programming (\S\ref{sec:nonlinear_programming})

\fist cf. Iterative Methods (\S\ref{sec:iterative_method})



% ====================================================================
\section{Convex Optimization}\label{sec:convex_optimization}
% ====================================================================

Convex Analysis (\S\ref{sec:convex_analysis})

Maximum Principle (Harmonic Functions \S\ref{sec:harmonic_function})

for Convex Optimization Problems, the Duality Gap
(\S\ref{sec:optimization_duality}) is Zero under a Constraint Qualification
Condition (\S\ref{sec:constraint_qualification})

may be formulated as Convex Optimization Problems:
\begin{itemize}
  \item Lagrange Multipliers (\S\ref{sec:lagrange_multiplier})
  \item Linear Programming (\S\ref{sec:linear_programming})
  \item Quadratic Programming (\S\ref{sec:quadratic_programming}) with Convex
    Objective Function and Linear Constraints
  \item Quadratic Programming with Convex Quadratic Constraints
    (QCQP \S\ref{sec:quadratically_constrained})
\end{itemize}



% --------------------------------------------------------------------
\subsection{Interior Point Method}\label{sec:interior_point}
% --------------------------------------------------------------------

Linear Programming Problems (\S\ref{sec:linear_programming}) can be solved by
the Interior Point Method (\S\ref{sec:interior_point}) in Polynomial Time

Semidefinite Programming Problems (\S\ref{sec:semidefinite_programming})
can be solved efficiently by Interior Point Methods

Quadratically Constrained Quadratic Programming
(\S\ref{sec:quadratically_constrained}): if the $P_0,\ldots,P_m$ Matrices are
all Positive-definite Matrices (\S\ref{sec:positive_definite}) then the problem
is Convex and can be solved using Interior Point Methods, as in Semidefinite
Programming

any Convex Optimization Problem can be transformed into Minimizing a Linear
Function over a Convex Set by converting to the \emph{Epigraph Form}

\emph{Primal-dual Path-following Interior Point Methods}; Mehrotra's
Predictor-Corrector Algorithm



% --------------------------------------------------------------------
\subsection{Basis-exchange Algorithm}\label{sec:basis_exchange}
% --------------------------------------------------------------------

\subsubsection{Simplex Algorithm}\label{sec:simplex_algorithm}

\emph{Simplex Method}

Dantzig

Linear Programming (\S\ref{sec:linear_programming}) problems can be solved by
Simplex Method (\S\ref{sec:simplex_algorithm}), usually (but not guaranteed) in
Polynomial Time

UC Math 352 Lec. 11 - \url{https://www.youtube.com/watch?v=ESzYPFkY3og}:

Full Rank $A \in \reals^{m \times n}, m \leq n$ with Linearly Independent Rows

Standard Form LP:

\begin{tabular}{r l}
  $\mathrm{min}_{\vec{x}}$ & $\vec{c}^T\vec{x}$     \\
  subject to               & $A\vec{x} = \vec{b}$   \\
                           & $\vec{x} \geq \vec{0}$ \\
\end{tabular}

assume Variables written in an order such that the last $m$ Columns of $A$ are
Linearly Independent:
\begin{align*}
  A       & = [A_N \ A_B] \\
  \vec{x} & = [x_N \ x_B] \\
\end{align*}
where:
\begin{align*}
  A_N       & \in \reals^{m \times (n - m)} \\
  A_B       & \in \reals^{m \times m} \\
  \vec{x}_N & \in \reals^{n-m} \\
  \vec{x}_B & \in \reals^m \\
\end{align*}
then the Equality Constraints can be re-written as:
\[
  A_N\vec{x}_N + A_B\vec{x}_B = \vec{b}
\]
setting $\vec{x}_N = \vec{0}$, then this becomes:
\begin{align*}
  A_B\vec{x}_B & = \vec{b}
  \vec{x}_B    & = A_B^{-1}\vec{b}
\end{align*}

because $m \leq n$, this is an Underdetermined System so the resulting
$\vec{x}$ has at least $n - m$ Zero (at most $m$ Nonzero) elements and is
called a \emph{Basic Solution} where the $\vec{x}_N$ are called the
\emph{Non-basic Variables} and the $\vec{x}_B$ are called the \emph{Basic
  Variables}

more generally Basic Variables correspond to the Linearly Independent Columns
of $A$

\emph{Fundamental Theorem of Linear Programming}

Assume $A$ is Full Rank; if a Feasible Solution exists, then a Basic Feasible
Solution Exists, and if an Optimal Feasible Solution exists, then an Optimal
Basic Feasible Solution exists.

the implication is that only Basic Feasible Solutions need to be considered
when searching for an Optimum, i.e. an \emph{Optimal Basis} (Set of Columns)
$B$

Simplex Method: from a Basic Feasible Solution, try to \emph{improve} the
Solution (i.e. lower $\vec{c}^T\vec{x}$) by replacing one Basic Variable with a
Non-basic one, and repeat the process until no improvement to
$\vec{c}^T\vec{x}$ is possible

for the $k$-th Basic Feasible Solution $\vec{x}^{(k)}$, with Sets $B$, $N$ of
Basic and Non-basic Variables, computing $\vec{x}_B^{(k)} = A_B^{-1}\vec{b}$
the Cost:
\[
  \vec{c}^T\vec{x}^{(k)} =
  \vec{c}_N^T\vec{x}_N^{(k)} + \vec{c}_B^T\vec{x}_B^{(k)} =
  \vec{c}_B^T\vec{x}_B^{(k)}
\]
changing $\vec{x}_N$ makes it necessary to recompute $\vec{x}_B$ from Solving
$A_N\vec{x}_N + A_B\vec{x}_B = \vec{b}$:
\[
  \vec{x}_B = A_B^{-1}\vec{b} - A_B^{-1}A_N\vec{x}_N
\]
and the Cost can be expressed in terms of $\vec{x}_N$:
\begin{align*}
  \vec{c}^T\vec{x} & = \vec{c}_B^T\vec{x}_B + \vec{c}_N^T\vec{x}_N \\
                   & = \vec{c}^T\vec{x}^{(k)} + \vec{r}^T\vec{x}_N
\end{align*}
where $\vec{r} = (\vec{c}_N - A_N^T A_B^{-T} \vec{c}_B)$ called the \emph{Vector
  of Reduced Costs}

$\vec{r}$ quantifies how each Non-basic Variable affects the Cost; if there are
no Negative entries of $\vec{r}$, then no improvement to the Objective can be
made, and $\vec{x}^{(k)}$ is Optimal

otherwise choose the most Negative entry of $\vec{r}$ and choose to increase
the corresponding Non-basic Variable $x_e$ called the \emph{Entering Variable};
increasing $x_e$ means that one of the $\vec{x}_B$ entries will becomes
Negative (violating the Non-negativity Constraints), so the Variable that
becomes Negative (the \emph{Leaving Variable}) first will be replaced by $x_e$
in the Basis

(TODO: details)

Unbounded LP

\emph{Degeneracy} -- it is possible to return to a previously selected Basis
(\emph{Cycling}), a Basic Feasible Solution is called \emph{Degenerate} if $x_i
= 0$ for at least one $i \in B$; this occurs geometrically when two Basic
Solutions overlap, e.g. when more than two Constraints intersect at the same
Point

\emph{Cycling}: the Simplex Method Strictly reduces $\vec{c}^T\vec{x}$ each
iteration for which the Entering Variable $x_e$ is \emph{increased} to a
Strictly Positive Value; Cycling can occur when $x_e$ can't be increased above
$0$, resulting in a sequence of Bases that repeats; this requires that $B_1,
\ldots, B_k$ is Degenerate (the Entering Variable is $0$) and no $x_e$ is
allowed so all Basic Feasible Solutions are the same Point
(FIXME: clarify)

\emph{Bland's Anticycling Rules} (``Smallest Subscript Rule''):
\begin{enumerate}
  \item of all Non-basic Variables for which the $\vec{r}$ entry is Negative,
    choose the smallest Index to be the Entering Variable (instead of the most
    Negative)
  \item if there is a tie for Leaving Variable, choose the one with the
    smallest Index
\end{enumerate}
these rules \emph{only} need to be invoked if no decrease in $\vec{c}^T\vec{x}$
is obtained by a particular iteration

Terminateion Guarantee for Non-degenerate LP: since LP has a Finite number of
Vertices, or Basic Feasible Solutions, and if the Objective decreases at each
step, then it is not possible to revisit a previous Basis, so the Simplex
Algorithm terminates in a Finite number of steps


\emph{Finding an initial Basic Feasible Solution}

find any $\vec{x}$ Satisfying all Constraints \fist Constraint Satisfaction
Problem (CSP \S\ref{sec:constraint_satisfaction})

\begin{itemize}
  \item ``All Slacks Basic'' -- Inequality Form LP with $\vec{b} \geq \vec{0}$;
    set the Slack Variables to the initial Basis gives an initial Basic
    Feasible Solution
  \item ``Artificial Variables'' (Phase I Problem) -- Standard Form LP; force
    $\vec{b} \geq \vec{0}$ by multiplying any Constraint with $b_i < 0$ by
    $-1$; introduce \emph{Artificial Variables} $x_{n+1}, \ldots, x_{n+m}$ and
    add to the LHS of each Constraint and extend $A$ with the $m \times m$
    Identity Matrix $I_m$ forming a \emph{Phase I Problem}:
    \begin{align*}
      [A \ I_m][x_1 \ \cdots \ x_{n+m}]^T & = \vec{b}
                                  \vec{x} & \geq \vec{0}
    \end{align*}
    Solving the Phase I Problem yields an initial Basic Feasible Solution if
    one exists; if the Phase I Solution does not have:
    \[
      x_{n+1} = x_{n+2} = \cdots = x_{n+m} = 0
    \]
    (FIXME: explain this equation)
    then the original Constraints are \emph{Infeasible}; otherwise the
    ``obvious'' initial Basis for the Phase I Problem is $B = \{ n+1, \ldots,
    n+m \}$ and the Basis that \emph{Optimizes} the Phase I Problem can be used
    as the Initial Basis for the \emph{Phase II Problem} (the original LP)
  \item Single Artificial Variable -- choose an initial Basis $B$ for which
    $A_B^{-1}$ exists; if $\vec{x}_B \geq \vec{0}$ then $B$ is an Initial Basic
    Feasible Solution, otherwise let $x_j$ be the most Negative element of
    $\vec{x}_B$, then introduce an Artificial Variable $x_{n+1}$ with the
    corresponding Column of $A$:
    \[
      \vec{a}_{n+1} = \vec{b} - (\sum_{i\in{B}}\vec{a}_i) + \vec{a}_j
    \]
    and define a new Basis $B' = B \setminus \{j\} \cup \{n+1\}$ (swap out $j$
    for the new Artificial Variable), then the Sum over the new Basis Vectors
    (Columns of $A$) is equal to $\vec{b}$, and $B'$ is an initial Basis for
    the Phase I Problem:
    \begin{align*}
      [A \ \vec{a}_{n+1}][x_1 \ \cdots \ x_{n+1}]^T & = \vec{b}
                                [\vec{x} \ x_{n+1}] & \geq \vec{0}
    \end{align*}
    if $x_{n+1}$ is ``Non-basic in the Solution to the Phase I Problem'' (Cost
    = 0) then the Optimal Basis $B$ of the Phase I Problem can be used as an
    initial Basis for the Phase II Problem (FIXME: clarify)
\end{itemize}



% --------------------------------------------------------------------
\subsection{Ellipsoid Method}\label{sec:ellipsoid_method}
% --------------------------------------------------------------------

Iterative Method (\S\ref{sec:iterative_method})

when specialized for solving feasible Linear Optimization
(\S\ref{sec:linear_programming}) Problems with Rational Data, the Ellipsoid
Method finds an Optimal Solution in a Finite number of steps

a Quadratic Programming (\S\ref{sec:quadratic_programming}) problem can be
solved in Polynomial Time using the Ellipsoid method if the Objective Function
is Convex



% --------------------------------------------------------------------
\subsection{Cone Optimization}\label{sec:cone_optimization}
% --------------------------------------------------------------------

includes Linear Programming and Semidefinite Programming problems



\subsubsection{Semidefinite Programming}\label{sec:semidefinite_programming}

SDP

can be efficiently solved by Interior Point Methods

all Linear Programs can be expressed as SDPs

hierarchies of SDPs can approximate the solutions of Polynomial Optimization
problems



% ====================================================================
\section{Stochastic Optimization}\label{sec:stochastic_optimization}
% ====================================================================

% --------------------------------------------------------------------
\subsection{Multi-armed Bandit}\label{sec:multiarmed_bandit}
% --------------------------------------------------------------------

\url{http://datagenetics.com/blog/october12017/index.html}

Epsilon-first Strategy

Epsilon-greedy Strategy

Epsilon-decreasing Strategy

Bayesian Bandits



% ====================================================================
\section{Combinatorial Optimization}
\label{sec:combinatorial_optimization}
% ====================================================================

\fist Combinatorial Optimization Problem
(\S\ref{sec:combinatorial_optimization_problem})



% --------------------------------------------------------------------
\subsection{Dynamic Programming}\label{sec:dynamic_programming}
% --------------------------------------------------------------------

or \emph{Dynamic Optimization}



% ====================================================================
\section{Evolutionary Optimization}\label{sec:evolutionary_optimization}
% ====================================================================

\fist Information Geometry (\S\ref{sec:information_geometry}), Fisher
Information Metric (\S\ref{sec:fisher_information})

\fist \textbf{Fisher's Fundamental Theorem of Natural Selection},
Quasi-linkage Equilibrium: approximation in the case of Weak Selection
and Weak Epistasis %FIXME



% --------------------------------------------------------------------
\subsection{Fitness Function}\label{sec:fitness_function}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Fitness Landscape}\label{sec:fitness_landscape}
% --------------------------------------------------------------------

A \emph{Fitness Landscape} (or \emph{Adaptive Landscape}) is an
evaluation of a Fitness Function for all candidate Solutions %FIXME



% ====================================================================
\section{Constraint Satisfaction Problem (CSP)}\label{sec:csp}
% ====================================================================

%FIXME: merge with model theory constraint satisfaction

% --------------------------------------------------------------------
\subsection{Constraint Resolution}\label{sec:constraint_resolution}
% --------------------------------------------------------------------

Constraint Resolution on Finite Domains typically uses a form of \emph{Search}



% --------------------------------------------------------------------
\subsection{Constraint Satisfaction Problem (DCSP)}\label{sec:dcsp}
% --------------------------------------------------------------------



% ====================================================================
\section{Complementarity Theory}\label{sec:complementarity_theory}
% ====================================================================

cf. Topological Degree Theory (\S\ref{sec:degree_theory}) applications



% --------------------------------------------------------------------
\subsection{Linear Complementarity Problem (LCP)}
\label{sec:linear_complementarity}
% --------------------------------------------------------------------

%FIXME an instance of linear optimization ???

Inequality Constraints and Limits %FIXME

Real Matrix -- $M$

Vector -- $q$

\emph{Linear Complementarity Problem} -- $LCP(M,q)$

find Vectors $z$, $w$ with constraints:

\begin{itemize}
  \item $0 \leq w_i,z_i$ -- each component of $w$ and $z$ is
    non-negative
  \item $z^T w = 0$ (or equivalently) $\sum_i w_i z_i = 0$ --
    \emph{Complementarity Condition}: Imples at most one of each pair
    $\{w_i,z_i\}$ can be Positive
  \item $w = M z + q$
\end{itemize}

Sufficient Condition for Existence and Uniqueness of a solution to LCP
is that $M$ is \emph{Symmetric} (\S\ref{sec:symmetric_matrix})
\emph{Positive-definite} (\S\ref{sec:positive_definite})

\fist Projected Gauss-Seidel (PGS \S\ref{sec:projected_gauss_seidel})



\subsubsection{Mixed Linear Complementarity Problem}\label{sec:mlcp}

Generalized LCP to include Free Variables



% ====================================================================
\section{Global Analysis}\label{sec:global_analysis}
% ====================================================================
