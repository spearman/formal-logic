%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage{amssymb}
\usepackage{amsmath}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}

% --------------------------------------------------------------------

\title{Survey of Mathematical Logic}
\date{draft 2014}
\author{Shane Pearman}
\maketitle

% --------------------------------------------------------------------

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Formal Language}\label{sec:formal_language}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A \emph{Formal Language}, $L$, is a possibly infinite subset of an
infinite \emph{Vocabulary}, $\Sigma^*$, that is the set of all
possible finite \emph{Expressions} (strings) over a possibly infinite
\emph{Alphabet} of \emph{Symbols}, $\Sigma$. This set $\Sigma^*$ is
the \emph{Kleene star} or \emph{Free monoid} of $\Sigma$; the smallest
superset of $\Sigma$ that is closed under string concatenation.

The \emph{Syntax} is that part of the Language that refers only to the
literal strings of Symbols of the Language with no regard to their
meaning or interpretation; only the condition that they can be
identified and differentiated from one-another is required.

The entire content of a Language is uniquely determined by the set of
all \emph{Terminal Expressions} generated by the \emph{Production} or
rewrite rules of a \emph{Formal Grammer}. This possibly infinite set
of Terminals will be a subset of the Vocabulary over the Alphabet.

% --------------------------------------------------------------------
\section{Metalanguage}\label{sec:metalanguage}
% --------------------------------------------------------------------

A \emph{Metalanguage} is a Language used to describe another Language,
the \emph{Object Language}. A \emph{Metavariable} is a variable
written in a Metalanguage that stands in for an element in the Object
Language. Metavariables may be referred to as \emph{Schematic
  Variables} in the context of \emph{Axiom Schemata} and \emph{Rule
  Schemata} (\S \ref{subsec:deductive_apparatus}).

The use of an Object Language to describe itself is an \emph{Embedded
  Metalanguage} (eg the English words \emph{noun} and \emph{verb} are
used to describe English itself).

% --------------------------------------------------------------------
\section{Abstract Reduction Systems}\label{sec:abstract_rewrite}
% --------------------------------------------------------------------

The following descriptions of Formal Grammars and \emph{Automata} may
be abstracted as \emph{Reduction} or \emph{rewrite} systems. This is
simply
    \[(A,\rightarrow)\]
where $A$ is a set of objects and $\rightarrow \subseteq A \times
A$. This is equivalent to an \emph{unlabeled State Transition System}
(\S \ref{sec:state_transition_system}).

An \emph{Indexed Abstract Reduction System} differentiates Reductions
into classes so that $\rightarrow$ is the indexed union of these
relations
    \[(A, \rightarrow_1, \rightarrow_2, \cdots)\]
This is identical to a \emph{Labeled Transition System}.

% --------------------------------------------------------------------
\section{Syntactic Elements}
% --------------------------------------------------------------------

Within a Formal Language defined by a Formal Grammar over a given
Alphabet and Vocabulary, the Symbols will be divided into two disjoint
subsets according to whether they are \emph{Terminal} or
\emph{Non-terminal Symbols}.

The definition of a Non-terminal Symbol is one for which a Production
rule exists with that Symbol appearing in the input and replaced in
the output. Thus a Grammar is specified by a finite set of
Productions, $P$, a finite set of Non-terminal Symbols, $N$, and a
finite set of Terminal Symbols, $T$. Additionally, in certain Grammars
it is allowed for multiple Non-terminals to appear in an Expression.

    \begin{description}

    \item[Symbol] \hfill \\
    an atomic unit of a Language

    \item[Alphabet ($\Sigma$)] \hfill \\
    a possibly infinite set of Symbols

    \item[Expression] \hfill \\
    a finite string of Symbols

    \item[Vocabulary ($\Sigma^{*}$)] \hfill \\
    set of all Expressions over an Alphabet of Symbols

    \item[Production] \hfill \\
    a rewrite rule specifying a Non-terminal Symbol substitution

    \item[Grammar] \hfill \\
    a finite set of Productions over the Expressions of a Vocabulary

    \end{description}

\subsection{Special Symbols}
Two special Symbols are recognized:

    \begin{description}

    \item[Empty Symbol ($\varepsilon$)] \hfill \\
    the Symbol of zero length and a Terminal Symbol

    \item[Start Symbol ($S$)] \hfill \\
    a unique Non-terminal Symbol

    \end{description}

\subsection{Generative Grammar}

A Grammar \emph{generates} a Language by the repeated application of
its Production Rules beginning with the Start Symbol. A sequence of
rule applications is a \emph{Derivation}. Formal definition of a
Grammar as a 4-tuple:
\[
    G(N,T,P,S)
\]
The unrestricted form of a Production:
\[
    (N \cup T)^*N(N \cup T)^* \rightarrow (N \cup T)^*
\]
That is, a Production is a function from one Expression to
another, where the left Expression must contain at least one
Non-terminal Symbol. By convention, Non-terminal Symbols
will be denoted by capitals ($A,B,C,\cdots$), and Terminals by
lowercase ($a,b,c,\cdots$), and expressions by Greek letters
($\alpha,\beta,\gamma$). Let:

\[
    \mathcal{A} = \{ Alphabets \},\: \mathcal{V} = \{ Vocabularies \}
\] \[
    \mathcal{G} = \{ Grammars \},\: \mathcal{L} = \{ Languages \}
\]

    \begin{description}

    \item Definition of the Kleene star or Free monoid over an
      Alphabet where $\circ$ is the operation to \emph{Concatenate} two
      Expressions:
    \[
        \forall \: \Sigma \in \mathcal{A} \:
        \exists \: \Sigma^* \in \mathcal{V}
        : \Sigma^* = \bigcup_{i=0}^{|\Sigma|} \Sigma_i
        = (\Sigma,\circ)
    \]

    \item Definition of a Language in terms of a Vocabulary:
    \[
        \forall \: L \in \mathcal{L} \:
        \exists \: \Sigma^* \in \mathcal{V}
        : L \subseteq \Sigma^*
    \]

    \item Existence of the Empty Symbol, $\varepsilon$:
    \[
        \forall \: \Sigma^* \in \mathcal{V} \:
        \exists ! \: \varepsilon \in \Sigma^*
        : |\varepsilon|=0
    \]

    \end{description}

% --------------------------------------------------------------------
\section{Formal Grammars}
% --------------------------------------------------------------------

\subsection{Chomsky Hierarchy}

Grammars are classified by how restrictive the Production rules
are. By convention, they may be organized into a hierarchy of sets
under proper inclusion, where \emph{Type-0} is an unrestricted grammar,
covering all possible formal grammars.

\[
    Type-0 \supset Type-1 \supset Type-2 \supset Type-3
\]

These different levels in the hierarchy are \emph{Recognizable} by
different kinds of Automata (\S \ref{subsec:automata})

\subsection{Type-0: Unrestricted}

\subsubsection{Semi-decidable}\label{subsec:semidecidable}
Production rules of an \emph{Unrestricted} Grammar have the form
\[
    \alpha \rightarrow \beta
\]
where $\alpha$ and $\beta$ are Expressions of $N \cup T$ and $\alpha
\neq \varepsilon$.

A completely unrestricted Grammar is called \emph{recursively
  enumerable} or \emph{Semi-decidable}. This means membership of the
Language can be decided by an algorithm, but non-membership cannot,
and the class of Languages having this property is called
$\mathsf{RE}$. Members of this class are also \emph{Diophantine} sets
and the lattice of $\mathsf{RE}$ sets under inclusion is written
$\mathcal{E}$. % FIXME add a reference when sections describing these terms
               % are added

The complement of $\mathsf{RE}$ is the class of Languages for which
an algorithm may decide non-membership only and is termed
$\mathsf{coRE}$. The class of Automata capable of implementing these
algorithms are \emph{Turing Machines}(\S\ref{subsec:turing_machine}).

\subsubsection{Decidable}
A \emph{Decidable} or \emph{recursive} Language (as opposed to
recursively enumerable) is defined as the intersection of
$\mathsf{RE}$ and $\mathsf{coRE}$:
\[
    \mathsf{R} = \mathsf{RE} \cap \mathsf{coRE}
\]
That is, it can be decided whether a Symbol is a member or not by a
\emph{total computable function} (one which returns \emph{True} or
\emph{False} depending on membership). Decidable Languages are
recognizable by a \emph{decider} or \emph{Total Turing
  Machine}\cite{kozen97} (however determining whether an arbitrary
Turing Machine gives an answer for every input is an undecidable
decision problem).

\subsection{Type-1: Context-sensitive}

\subsubsection{Context-sensitive}\label{subsec:context_sensitive}
\emph{Context-sensitive Grammars} have the restriction that the result
of a Production is not shorter than the input. Formally stated
Productions are of the form
\[
    \alpha \Gamma \beta \rightarrow \alpha \gamma \beta
\]
where $|\Gamma| \leq |\gamma|$. In this formulation $\alpha$ and $\beta$ form
the \emph{Context} of $\Gamma$.

Requiring that $S$ does not appear on the right of any Production
and allowing the rule
\[
    S \rightarrow \varepsilon
\]
makes the Context-sensitive Languages a proper superset of the
\emph{Context-free Languages}.

Context-sensitive Languages are equivalent to \emph{Linear
Bounded Automata} (\S\ref{subsec:linear_bounded_automata}).

\subsubsection{Indexed}
An \emph{Indexed Grammar} has an extra set of \emph{Index Symbols},
$F$, with Productions of three possible forms,
\[
    A[\sigma] \rightarrow \alpha[\sigma]
\]\[
    A[\sigma] \rightarrow B[f\sigma]
\]\[
    A[f\sigma] \rightarrow \alpha[\sigma]
\]
where $f \in F$ and $\sigma$ is a string of Index Symbols. The Index
Symbols are used to form a \emph{stack} by the Production rules where
Index Symbols are either pushed or popped from the stack.

An Indexed Language can be recognized by a \emph{Nested Stack
  Automaton}\cite{aho69}.

\subsubsection{Generalized Contex-free}
A \emph{Generalized Context-free Grammar} adds to the rewrite rules of
a Context-free Grammar a set of non-context-free \emph{composition
  functions} that combine tuples of symbols:
\[
    f(\langle x_1,\cdots,x_m\rangle,\cdots,\langle
    y_1,\cdots,y_n\rangle)=\gamma
\]
where $\gamma$ is a single tuple or another composition function that
reduces to a single tuple.

Rules are of the form:
\[
    A \rightarrow f(X,Y,\cdots)
\]
where $X$,$Y$,$\cdots$ are string tuples or Non-terminal Symbols.

There are several weakly equivalent Grammars to the composition
formulation:

\begin{description}
\item[Linear context-free rewriting system] \hfill \\
    Weakly equivalent to \emph{multi-component Tree-adjoining
      Grammars} where composition functions are both \emph{linear} and
    \emph{regular}. Can be recognized by \emph{Thread
      Automata}\cite{villemonte02}.

\item[Tree-adjoining] \hfill \\
    Elementary rewriting unit is a tree rather than a Symbol. Can be
    recognized by \emph{Embedded Pushdown
      Automata}\cite{vijayashanker88}.

\item[Linear indexed grammar] \hfill \\
    A modified Indexed Grammar where only one symbol receives the
    stack.

\item[Combinatory Categorical Grammar] \hfill \\
    A type of \emph{phrase Structure Grammar} using \emph{Combinatory
      Logic}(\S\ref{subsec:combinatory_logic}).

\item[Head grammar] \hfill \\
    A subset of the Linear context-free rewriting system and a Phrase
    Structure Grammar.

\end{description}

\subsection{Type-2: Context-free}\label{subsec:context_free_language}

\subsubsection{Context-free}
\emph{Context-free Grammars} (\emph{CFG}s) have production rules of the form
\[
    V \rightarrow \alpha
\]
where $V$ is a single Non-terminal and $\alpha$ is a string of Terminals
and/or Non-terminals (or empty). Because $V$ is required to be a
single Non-terminal, the Production rules can be applied regardless of
Context. Each Non-terminal in a Context-free Grammar, $G$, is said to
form a \emph{Sub-Language} of the language defined by $G$.

Multiple Context-free Grammars may generate the same Language, so
properties of CFGs may be termed \emph{extrinsic} while Language properties
are \emph{intrinsic}. The question of equality between CFGs is
undecidable.

A popular notation for Context-free Grammars (especially in Computer
Science) is \emph{Backus-Naur form} (\emph{BNF}).

In Linguistics, the term used for Context-free Grammar is \emph{Phrase
  Structure Grammar} which is also called \emph{constituency grammar}
due to the one-to-one-or-many correspondence between the Productions
(ultimately rooted in the \emph{subject-predicate} clause derived from
\emph{Term Logic}).

An alternative formulation to Phrase Structure Grammar is \emph{Dependency
  Grammar} in which the Verb is the root and there is a one-to-one
correspondence between Symbols and nodes in the syntax structure.

The Context-free Grammar is equivalent to \emph{Non-deterministic
Pushdown Automata}(\S\ref{subsec:pushdown_automata}).

\subsubsection{Deterministic}\label{subsec:deterministic_cfg}
\emph{Deterministic Context-free Grammars} are derived from
\emph{Deterministic Pushdown Automata}(\S\ref{subsec:deterministic_pda})
and are always \emph{unambiguous}. They can be parsed in linear time
and a \emph{Parser} can be automatically generated from the Grammar by a
\emph{Parser Generator}(\S\ref{subsec:parser_generator}).

\subsubsection{Visibly Pushdown}
\emph{Visibly Pushdown Grammars} are described by the 4-tuple
\[
    G = (V=V^0 \cup V^1,T,P,S)
\]
where $V^0$ and $V^1$ are disjoint sets of Non-terminals and there
are three kinds of Production rules:
\[
    X \rightarrow \varepsilon
\]\[
    X \rightarrow aY
\]\[
    X \rightarrow \langle aZb \rangle Y
\]
where $Z \in V^0$ and if $X \in V^0$ then $Y \in V^0$

The resulting Language is a \emph{Regular Language} with \emph{nested
  words}, described by a \emph{Monadic Second-order Logic}. % FIXME ref

\subsection{Type-3: Regular} \label{subsec:regular_language}

\emph{Regular Languages} are more restricted than Context-free
Languages and satisfy a number of closure properties. For two Regular
Languages, $K$ and $L$, the following operations result in a Language
that is also Regular:
\[
    K \cup L, \quad
    K \cap L, \quad
    \overline{L}, \quad
    K - L, \quad
    K \circ L, \quad
    L^*, \quad
    K / L, \quad
    L^R
\]
A common formulation of Regular Languages is the \emph{Regular
  Expression} and conversely it is sometimes said that a Regular
Language is one that can be defined by a Regular Expression.

An algebraic description is as follows:
\[
    L = \{ w \in \Sigma^* | f(w) \in N \}
\]
where $f : \Sigma^* \rightarrow M$ is a \emph{Monoid homomorphism} of
\emph{Finite Monoid}, $M$, and $N \subseteq M$.
% FIXME ref monoids

\subsubsection{Extended Regular}
\emph{Extended Regular Grammars} have Productions of either \emph{right
Regular} or \emph{left Regular} form.

Right:
\[
    B \rightarrow a
\]\[
    A \rightarrow B \nu
\]\[
    A \rightarrow \varepsilon
\]

Left:
\[
    A \rightarrow a
\]\[
    A \rightarrow B \nu
\]\[
    A \rightarrow \varepsilon
\]
where $a$ is a single Non-terminal and $\nu$ is an expression of only
Non-terminal characters.

\subsubsection{Strictly Regular}
\emph{Strictly Regular Grammars} also have Productions of either right
Regular or left Regular form.

Right:
\[
    B \rightarrow a
\]\[
    B \rightarrow aC
\]\[
    B \rightarrow \varepsilon
\]

Left:
\[
    A \rightarrow a
\]\[
    A \rightarrow Ba
\]\[
    A \rightarrow \varepsilon
\]
where $a$ is a single Non-terminal.

There is a one-to-one correspondence between the rules of a
\emph{Strictly Left Regular Grammar} and those of a
\emph{Non-deterministic Finite Automaton}(\S\ref{subsec:ndfa}).

The \emph{pumping lemma} states that the middle section of an
Expression within a Regular Language may be repeated an arbitrary
number of times to produce another Expression in that same Language.

\subsubsection{k-Testable}\label{subsec:k_testable}
A \emph{k-Testable Language} is one where membership of an Expression
depends on the first and last symbol and a set of factors of length
$k$. An example is a \emph{Local Language} which is a \emph{2-Testable
  Language} described by the \emph{regular expression}:
\[
    (Q\Sigma^* \cap \Sigma^*R)\setminus\Sigma^*F\Sigma^*
\]
where $Q,R \subseteq \Sigma$ and $F \subseteq \Sigma \times
\Sigma$. This requires for a \emph{Word} (Expression), $w$, that is a
member of a Local Language to have its first Symbol in $Q$, and its
second Symbol in $R$, and no factor of $w$ of length 2 is in $F$. A
Local Language is recognized by a \emph{Local
  Automaton}(\S\ref{subsec:dfa}).

\subsubsection{Star-free}
A \emph{Star-free Language} is one having a \emph{Generalized Star
  Height} equal to zero, that is, the minimal \emph{Star Height} of
all Expressions in the Language with the Star Height of an
Expression's \emph{compliment} being equal.

Star-free Languages are characterized as those with \emph{Aperiodic
  Syntactic Monoids}\cite{schutzenberger65} and also as the
\emph{Counter-free Langauges}\cite{mcnaughton-papert71} by the
\emph{Aperiodic Finite-state Automaton}, and \emph{Linear Temporal
  Logic}. % FIXME ref

\subsection{Affix Grammars}
\emph{Affix Grammars} are those of a Context-free Grammar with a
subset of the Non-terminals used as \emph{affix arguments}. If the
same affix appears multiple places in a Production, the value must be
the same.

\subsection{Two-Level Grammars}
\emph{Two-Level Grammars} are \emph{Grammar generators} that may
generate Grammars with infinite rules. Allowing the values for affixes
to be described by a Context-free Grammar results in a Two-Level
Grammar.


\begin{description}
\item[W-grammar] \emph{Van Wijngaarden Grammar} consists of a finite
  set of \emph{meta-rules} used to derive a possibly infinite set of
  Production rules from a finite set of \emph{hyper-rules}.
\item[Extended Affix Grammar] is a restricted W-grammar.
\end{description}

\subsection{Attribute Grammars}
\emph{Attribute Grammars} allows affixes from arbitrary domains and
allows functions calculate values of affixes.

\subsection{Analytic Grammars}
\emph{Analytic Grammars} are used in \emph{Parsing} (\S
\ref{sec:parsers}). A few examples:

\begin{description}
\item[Top-Down Parsing Language] \hfill \\
Formal representation of \emph{Recursive Descent Parser}. Production
rules of the form
\[
    A \leftarrow \varepsilon
\]\[
    A \leftarrow f
\]\[
    A \leftarrow a
\]\[
    A \leftarrow BC/D
\]
\item[Parsing Expression Generator] \hfill \\
A more generalized Top-Down Parsing Language.
\item[Link Grammar] \hfill \\
Dependency Grammar with directionality between Symbols.
\end{description}

% --------------------------------------------------------------------
\section{Parsers} \label{sec:parsers}
% --------------------------------------------------------------------

A \emph{Parser} analyzes an Expression according to the rules of a Formal
Grammar, generating a \emph{Data Structure} describing the Syntax of
the input. An outline of the process follows.

\subsection{Lexical Analysis}
A Parser may be preceded by a \emph{Lexical Analyzer} which creates
\emph{Tokens} (Symbols) from an input Expression. Strings of Tokens
are referred to as Phrases. A Lexical Analyzer is a Parser itself and
usually the \emph{Lexical Grammar} is a Regular Language (other
methods are \emph{flags}, \emph{delimiters}, or \emph{dictionaries})
and the Tokens are parsed as a Context-free or \emph{Attribute Phrase
  Syntax}.

Prior to \emph{Scanning}, a \emph{Lexer} may perform its own
Tokenization.  The Scanning stage first recognizes the Token
strings as \emph{Lexemes}, usually achieved by a Finite State
Machine.

Lexemes are resolved into Tokens by an \emph{Evaluator} which assigns
values where needed-- this results in Tokens that are either a
\emph{Type-Value} pair, or just a \emph{Type}.

\subsection{Syntactic Analysis}
The Parser determines if and how the input can be derived from the
Start Symbol of the Grammar. Parsing can proceed in two directions:

\begin{description}
    \item[Top-down Parsing]
    starts with the highest level of the \emph{Parse Tree}. Proceeds greedily
    and may be \emph{Exponential} with \emph{Backtracking}.
    \item[Bottom-up Parsing]
    starts with the lowest level of the Parse Tree.
\end{description}

Further \emph{Semantic} Parsing may be performed after these steps. An
example of this would be the in the \emph{Compiler} of a
\emph{Programming Language}.

\subsection{Parser Generators}\label{subsec:parser_generator}

A \emph{Parser Generator} takes as a Grammar (for example a BNF
Grammar) and outputs the source code of a Parser for the Language
specified by the Grammar.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Automata Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% --------------------------------------------------------------------
\section{State Transition Systems} \label{sec:state_transition_system}
% --------------------------------------------------------------------
A \emph{State Transition System} can have an infinite number of
\emph{States} and \emph{Transitions}, represented as the pair
\[
    (S,\rightarrow)
\]
where $S$ is a set of States and $\rightarrow \subseteq S \times
S$. This is identical to an \emph{un-indexed Abstract Rewriting
  System}(\S \ref{sec:abstract_rewrite}).

\emph{Finite Automata} may be seen as State Transition Systems with an
initial State and a number of final \emph{Accept} states indicating
\emph{Word} (Expression) membership for a Language.

\emph{Labeled State Transition Systems} have an additional set of
\emph{Labels}, $\Lambda$
\[(S,\Lambda,\rightarrow)\]
and $\rightarrow \subseteq S \times \Lambda \times S$.

\emph{Action Programming Languages} add a set of \emph{Fluents}, $F$, and
\emph{Values}, $V$, and a function mapping $F \times S$ to $V$.

% --------------------------------------------------------------------
\section{Semiautomata}
A State Transition System may be formulated as a \emph{Semiautomata}
\[
    (Q,\Sigma,T)
\]
where $\Sigma$ is a non-empty \emph{input Symbols}, $Q$ is the set of
States, and $T$ is a \emph{transition function} $T:Q \times \Sigma
\rightarrow Q$.

A Semiautomaton induces a Monoid called the \emph{input Monoid}:
\[
    M(Q,\Sigma,T) = \{T_w | w \in \Sigma^*\}
\]

% --------------------------------------------------------------------
\section{Automata} \label{subsec:automata}
% --------------------------------------------------------------------

An \emph{Automaton} reads input strings, \emph{Words} (Expressions),
and either accepts or rejects depending on whether a Word is a member
of the Language recognized by that Automaton. By convention the
Vocabulary of Expressions will be re-cast as an Alphabet of Words,
$\Sigma$.

Automata may be arranged in a hierarchy according to increasing power:
\[
    DFA = NFA \subset DPDA-I \subset NPDA-I \subset LBA \subset DPDA-II =
\]\[
    = NPDA-II = DTM = NTM = PTM = MDTM
\]
where
\begin{itemize}
\item DFA = Deterministic Finite Automata
\item NFA = Non-deterministic Finite Automata
\item DPDA = Deterministic Push Down Automata with 1
  or 2 push-down stores
\item NPDA = Non-deterministic Push Down Automata
  with 1 or 2 push-down stores
\item LBA = Linear Bounded Automata
\item DTM = Deterministic Turing Machine
\item NTM = Non-deterministic Turing Machine
\item PTM = Probabilistic Turing Machine
\item MDTM = Multidimensional Turing Machine
\end{itemize}

\subsection{Finite Automata}
\emph{Finite Automata} are \emph{Finite State Machines} and take a
finite input string of Symbols and either accepts or rejects the
input depending on the final State of the computation. Finite
Automata are able to recognize Regular Languages(\S\ref{subsec:regular_language}).

\subsubsection{Deterministic Finite Automata}\label{subsec:dfa}
\emph{Deterministic Finite Automata} have the restriction that an
input Symbol has a transition function to a single State.
Deterministic Finite Automata recognize Regular
Languages(\S\ref{subsec:regular_language}).

Representation of a Deterministic Finite Automaton as a 5-tuple:
\[
    (Q,\Sigma,\delta,q_0,F)
\]
where
\begin{itemize}
\item $Q$ is a finite set of States
\item $\Sigma$ is the Alphabet
\item $\delta$ is the transition function $\delta: Q \times
  \Sigma \rightarrow Q$
\item $q_0 \in Q$ is the initial State
\item $F \subseteq Q$ is the set of final Accept States.
\end{itemize}

Running for a given input $w = a_1,a_2, \cdots , a_n \in \Sigma^*$
produces a sequence of States $q_0,q_1,q_2,\cdots , q_n$ where $q_i
\in Q$ such that $q_i = \delta (q_{i-1},a_i)$ and $w$ is accepted if
$q_n \in F$.

A recursive definition using \emph{composition} of transition
functions
\[
    \widehat{\delta}(q,\varepsilon) = q
\]\[
    \widehat{\delta}(q,wa) = \delta_a(\widehat{\delta}(q,w))
\]
where $w \in \Sigma^*$, $a \in \Sigma$ and $q \in Q$. Repeated
application describes the \emph{Transition Monoid} or
\emph{Transformation Semigroup}.

A kind of Deterministic Finite Automata that recognizes Local
Languages(\S\ref{subsec:k_testable}) is called a \emph{Local Automaton}.

\subsubsection{Nondeterministic Finite Automata}\label{subsec:ndfa}
\emph{Nondeterministic Finite Automata} are Finite State Machines that
may transition from one State to a number of different states, given
as an element of the powerset of $Q$, $\mathcal{P}(Q)$.

Representation of a Nondeterministic Finite Automaton as a
5-tuple:
\[
    (Q,\Sigma,\Delta,q_0,F)
\]
where
\begin{itemize}
\item $Q$ is a finite set of States
\item $\Sigma$ is the Alphabet
\item $\Delta$ is a \emph{transition relation} $\Delta: Q \times
  \Sigma \rightarrow \mathcal{P}(Q)$
\item $q_0 \in Q$ is the initial State
\item $F \subseteq Q$ is the set of final Accept States.
\end{itemize}

A Word, $w=a_1,a_2,\cdots,a_n$, is accepted when there exists a
sequence of States, $r_0,r_1,\cdots,r_n$ such that
\begin{enumerate}
\item $r_0 = q_0$
\item $r_{i+1} \in \Delta(r_i, a_{i+1})$, for $i = 0, \cdots, n-1$
\item $r_n \in F$
\end{enumerate}

A DFA may be seen as a NFA which restricts transitions to allow only
one State, and can be constructed from a NFA with $n$ States using
\emph{powerset construction}, requiring up to $2^n$ States. Both types
recognize the same Regular Languages(\S\ref{subsec:regular_language}).

\paragraph{NFA-$\varepsilon$} is a NFA that allows transitions
without consuming input Symbols. A transition that changes state
without consuming input is an $\varepsilon$ $move$. Each State $q$
defines an $\varepsilon$-\emph{closure}, $E(q)$, which is the set of
States that are reachable by $\varepsilon$ moves.

The Languages recognized by NFA-$\varepsilon$ are the same as NFA/DFA.

\subsection{Pushdown Automata}\label{subsec:pushdown_automata}
\emph{Pushdown Automata} add to Finite Automata a \emph{Stack} as a
parameter for choice of States and can recognize Context-free
Languages(\S\ref{subsec:context_free_language}).

Adding a second Stack makes a Pushdown Automata equal in power to a
Turing Machine.

Unlike Finite Automata, Deterministic PDA are not equivalent to
Nondeterministic PDA. The general representation for a PDA is
\[
    M = (Q, \Sigma, \Gamma, q_0, Z_0, F, \delta)
\]
where
\begin{itemize}
\item $Q$ is a finite set of States
\item $\Sigma$ is a finite set of input Symbols
\item $\Gamma$ is a finite set of Stack Symbols
\item $q_0 \in Q$ is the initial State
\item $Z_0 \in \Gamma$ is the initial Stack Symbol
\item $F \subseteq Q$ is the set of final Accept States
\item $\delta$ is the transition function $\delta: (Q \times (\Sigma
  \cup \{\varepsilon\}) \times \Gamma) \rightarrow \mathcal{P}(Q \times
  \Gamma^*)$
\end{itemize}

An element $(p,a,Z,q,\alpha)\in\delta$, with $M$ in State $p \in Q$,
input $a \in \Sigma \cup \{\varepsilon\}$, and top stack Symbol $Z \in
\Gamma$ results in the following:
\begin{enumerate}
\item read $a$
\item change state to $q$
\item pop $Z$
\item push $\alpha \in \Gamma^*$
\end{enumerate}

\subsubsection{Deterministic Pushdown Automata}\label{subsec:deterministic_pda}
\emph{Deterministic Pushdown Automata} have the restriction of only
one derivation per accepted input Word. This allows recognition of a
subset of Context-free Languages termed
Deterministic(\S\ref{subsec:deterministic_cfg}). Such Languages can be
parsed in linear time and Parsers for such Languages can be generated
automatically(\S\ref{subsec:parser_generator}).

A Pushdown Automata is Deterministic iff both
\begin{enumerate}
\item $\forall q \in Q, a \in \Sigma \cup {\varepsilon}, x \in
  \Gamma \vdash |\delta(q,a,x)| \leq 1$
\item $\forall q \in Q, x \in \Gamma \vdash |\delta(q,\varepsilon,x)|
  \neq 0 \Rightarrow \forall a \in \Sigma \vdash |\delta(q,a,x)|=0$
\end{enumerate}

\subsection{Linear Bounded Automata} \label{subsec:linear_bounded_automata}
\emph{Linear Bounded Automata} are Turing Machines restricted to an
input of finite length and are acceptors for Context-sensitive
Languages(\S\ref{subsec:context_sensitive}) which require that
Production rules do not increase the size of the Expression as a
result; therefore the size of the input is sufficient for calculation.

\subsection{Turing Machines}\label{subsec:turing_machine}
A Turing Machine operates on an infinite \emph{storage tape}, which
acts as the read input as well as write storage. Pushdown Automata
with 2 Stacks are equivalent to Turing Machines.

\subsubsection{Nondeterministic Turing Machines}
\emph{Nondeterministic Turing Machines} (\emph{NTM}s) can be defined
as
    \[
        M = (Q, \Sigma, q_0, \sqcup, A, \delta)
    \]
where
\begin{itemize}
\item $Q$ is a finite set of States
\item $\Sigma$ is the finite Alphabet
\item $q_0 \in Q$ is the initial State
\item $\sqcup \in \Sigma$ is the blank Symbol
\item $F \subseteq Q$ is the set of final Accept States
\item $\delta \subseteq (Q \setminus F \times \Sigma) \times (Q \times
  \Sigma \times \{L,R\})$ and $L$ and $R$ are left and right shift.
\end{itemize}

The operation of $M$ in State $q_i$ and current read input $a_j$ is a
transition function, $q_i a_j \rightarrow q_{i1} a_{j1} d_k$. Note
that for an NTM, $\delta$ is a relation and more than one function can
exist for each possible input/State combination. The result is to
write the new Symbol $a_{j1}$ in the current position and shift the
storage left or right as specified by $d_k$, afterwards assuming State
$q_{i1}$.

\subsubsection{Deterministic Turing Machines}
\emph{Deterministic Turing Machines} (\emph{DTM}s) have one possible
output transition per unique input/State combination, thus $\delta$ is
a \emph{partial function} rather than a \emph{relation}:
\[
    \delta : Q \setminus F \times \Sigma \rightarrow Q \times
    \Sigma \times {L,R}
\]
The computational power of DTMs and NTMs is equivalent (they can solve
the same problems) as NTMs include DTMs as a special case. An
equivalent accepting computation in a DTM is generally exponential to
the length of the shortest accepting computation of an NTM.

\subsubsection{Probabilistic Turing Machines}
A \emph{Probabilistic Turing Machine} adds to transitions a
probability distribution (or a tape with random Symbols). It is an
open question whether this is more powerful than a DTM
($\mathsf{BPP}=\mathsf{P}$ ?)  but it is useful in the definition of
\emph{interactive proof systems}. %FIXME ref

\subsubsection{Multidimensional Turing Machines}
\emph{Multidimensional Turing Machines} allow for tapes of varying
topologies. This requires additional shift directions (ie $\{L, R, U,
D\}$ for a 2-dimensional tape) but does not increase the computing
power; even an $\infty$-\emph{dimensional} Turing Machine can be
simulated by a DTM.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Symbolic Logic}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\emph{Formal Logic} applies Formal Language (Part
\ref{sec:formal_language}) to \emph{Formal Arguments} by means of
\emph{Inference Rules} (\S\ref{subsec:inference_rules}). A Formal
Argument is an Ordered Set of \emph{Formulas}.

% --------------------------------------------------------------------
\section{Terms}\label{sec:terms}
% --------------------------------------------------------------------

\begin{description}
\item[Universe] class containing elements of entities (objects)
  considered in a particular Logical discourse, also called
  \emph{Domain of Discourse}
\item[Constant] a named object from the Domain
\item[Variable] a placeholder that ranges over the objects in the
  Domain
\item[Function] $n$-ary functions maps $n$-tuples of objects in the
  Domain to objects
\item[Term] an object of the Domain (Variables, Constants and Compound
  Statements)
\item[Formula] a mathematical Fact
\end{description}
\hfill \\ Inductive definition of \emph{Terms} from \emph{Constants},
\emph{Variables}, and \emph{Functions}:

Given Terms, $T$, Variables, $V$, n-ary Functions, $F = F_0 \cup F_1
\cup F_2 \cup \cdots \cup F_n$, Constants, $C = F_0$:
\[
    V \subseteq T
\]\[
    C \subseteq T
\]\[
    \forall \tau_n=\{t_1,\cdots,t_n\} \in \mathcal{P}(T), \forall f \in F_n
    \exists f(t_1,\cdots,t_n) \in T
\]
Inductive definition of \emph{Formulas} from Terms and
\emph{Relations}:

Given Terms, $T = \{t_0,\ldots,t_n\}$, and Relations, $R = \{r_0,\ldots,r_m\}$:
\begin{itemize}
\item $t_i = t_j$ is a Formula
\item $r_k(t_0,\ldots,t_n)$ is a Formula and $r_k$ is an n-ary Relation
\end{itemize}
A Formula is \emph{Valid} if and only if it is True under every
\emph{Interpretation} (\S\ref{subsec:interpretation}).

% --------------------------------------------------------------------
\section{Systems of Logic} \label{sec:formal_systems}
% --------------------------------------------------------------------

Symbols may be divided into \emph{Logical} and \emph{Non-Logical
  Symbols}: Logical Symbols ($\forall$, $\vee$, $\rightarrow$, $\neg$,
etc., and \emph{Variables} $x_0$, $x_1$, etc.) always have the same
meaning while Non-Logical Symbols (\emph{Predicates} (Relations),
\emph{Functions}, and individual \emph{Constants}) only have meaning
under \emph{Interpretation} (\S\ref{subsec:interpretation}). The set of
Non-Logical Symbols used in a particular discourse is called the
\emph{Signature} of the discourse. The Signature may be defined as a
triple:
\[
    \sigma = (S_{func},S_{rel},ar)
\]
where
\[
    ar: S_{func} \cup S_{rel} \rightarrow \mathbb{N}_0
\]
\emph{Extra-logical Symbols} are those of a Metalanguage, such as the
symbol for \emph{Logical Consequence} (\emph{Entailment}), $\vdash$,
(read \emph{yields} or \emph{proves}) or Metavariables, $\varphi,
\psi, \ldots$.

A particular Formal System is required to be \emph{Consistent}; that
is the ability to derive only the affirmation or denial of a
particular statement, not both. Another way of stating Consistency is
that Falsity is not provable from no Assumptions.

\subsection{Deductive Apparatus}
\label{subsec:deductive_apparatus}

A Formal Language (described by a Formal Grammar) in combination with
a \emph{Deductive Apparatus} gives rise to a \emph{System of
  Logic}. Here, Expressions of Symbols are usually referred to as
\emph{Forumulas}, and Expressions that belong to the Language are
called ``\emph{Well-formed Formulas}'' (\emph{WFF}).

The Deductive Apparatus is a set of zero or more \emph{Axioms} and one
or more \emph{Inference Rules}. A System of Logic is termed
\emph{Effective} (ie Recursively Definable) if the set of Axioms and
the set of Inference Rules are Decidable or Semi-decidable. The notion
of \emph{Theorems}, however, is not in general Effective
(\S\ref{subsec:formal_proof}).

\subsubsection{Axioms}

\emph{Axioms} are given as WFFs, the truth value of which are assumed
for the purpose of performing \emph{analysis} within a System of
Logic. An Axiom is properly an \emph{Inference Rule} with no
\emph{Premises}, only a given \emph{Conclusion}; that is a
\emph{Logical Assertion}(\S\ref{subsec:sequent_notation}).

Axioms may be divided into two kinds: \emph{Logical Axioms} of a
tautological sort, and \emph{Non-logical Axioms}, hereafter referred
to as \emph{Postulates}, that play the role of assumptions: defining
properties of the domain of the theory in question.

An \emph{Axiom Schema} is properly a template for Axioms in which one
or more \emph{Schematic Variables} (Metavariables, \S
\ref{sec:metalanguage}) appear, standing for a subformula in the
Object Language of the system. For a Language with infinitely many
WFF, an Axiom Schema describes a countably infinite number of
Axioms. A system without Schema is termed \emph{finitely axiomatized}.

\subsubsection{Inference Rules} \label{subsec:inference_rules}

An \emph{Inference Rule} is a \emph{transformation rule}: it is the
\emph{Logical Form} of the \emph{Deduction} of a \emph{Conclusion}
(also called an \emph{Idiomatic}) based on \emph{Premises}-- Premises
and Conclusions being WFF in the Formal Language of the system. Axioms
are special cases of Inference Rules which have no Premises, only a
universally held Conclusion. Axioms may be further differentiated from
Rules by saying that Rules are statements \emph{about} the system,
Axioms are statements \emph{in} the system.

Inference Rules may be viewed as functions that take Premises and
return a Conclusion. An alternative formulation for Inference Rules is
as a \emph{Deducibility Relation}, $\vdash$, that holds between zero
or more Premises and a Conclusion. A Formal Argument is \emph{Valid}
if and only if the Conclusion is Entailed by the Premises. Inference
Rules, like Axioms, may be Schematic if they contain Metavariables,
and such an Argument is called an \emph{Argument Form}. Argument Forms
are Valid if and only if every Argument is Valid.

Taken individually, both Premises and Conclusions are
\emph{Propositions}. The Conclusion relies on the truth of the
Premises; if the Premises are left unsatisfied, then the derivation is
\emph{Hypothetical} and the Premises \emph{Hypotheses}. It can be said
that the Conclusion of a Deducibility Relation is reached by
\emph{Syntactic Consequence}, a form of \emph{Logical
  Consequence}. For more information, see section on \emph{Formal
  Proof} (\S\ref{subsec:formal_proof}).

Inference Rules may be identified as reduntant in two senses. An
\emph{Admissible Rule} is one which does not change the set of
\emph{Theorems} in a Formal System when it is added. A \emph{Derivable
  Rule} is a case of an Admissible Rule that has been \emph{Derived}
from existing rules.

\subsection{Zeroth-order - Propositional}\label{subsec:propositional}

\emph{Propositional Logic} (also called \emph{Sentential} or
\emph{Statement Logic}) is represented by a Formal Language with WFF
consisting only of \emph{Operators} (\emph{Logical Connectives}) and
\emph{Primitive Symbols} representing \emph{Propositions}.

Propositions are WFF that are assigned a truth value. An \emph{Atomic
  Proposition} contains no Operators. A \emph{Composite Proposition}
is composed by recursive application of Operators to Propositions by a
corresponding \emph{Concatenation Rule} that assigns a new truth value
to the Composite string.

Primitive Symbols are usually divided into three different categories:
\begin{description}
\item[Propositional Constants] \hfill \\
Represent particular Propositions: $A$, $B$, $C$, $\ldots$
\item[Propositional Variables] \hfill \\
Range over set of all Atomic Propositions: $p$, $q$, $r$, $\ldots$
\item[Schematic Variables] \hfill \\
Metavariables; range over set of all propositions: $\varphi$, $\psi$,
$\chi$, $\ldots$
\end{description}

The Domain of a Propositional Calculus is \emph{Truth} and
\emph{Falsity}, so Variables are not necessarily \emph{Bound} or
\emph{Free} as in \emph{Predicate Logic}. In fact, a Propositional
Variable is equivalent to a \emph{Nullary Predicate} in \emph{First
  Order Logic}.

Formal definition of a \emph{Propositional Calculus}:
\[
    \mathcal{S} = (\mathbf{A},\mathbf{\Omega},\mathbf{Z},\mathbf{I})
\]
where
\begin{itemize}
\item $\mathbf{A}$ is a finite set of Proposition symbols ($p$, $q$,
  $r$, $\ldots$)
\item $\mathbf{\Omega}$ is a finite set of Operator symbols ($\neg$,
  $\wedge$, $\vee$, $\ldots$)
\item $\mathbf{Z}$ is a finite set of Inference Rules
\item $\mathbf{I}$ is a finite set of Axioms
\end{itemize}
$\mathcal{S}$ is then inductively defined as follows, where
$\mathbf{\Omega_j}$ is the partition of $\mathbf{\Omega}$ containing
Operators of arity $\mathbf{j}$:
\begin{enumerate}
\item Any element of $\mathbf{A}$ is a Formula of $\mathcal{S}$
\item For Formulas $p_1, p_2, \cdots, p_j$ and $f \in
  \mathbf{\Omega_j}$ then $f(p_1, p_2, \cdots, p_j)$ is a formula
\end{enumerate}
Propositional Logic is closed under Truth-Functional Connectives, so
the above is sufficient to define all WFF: nothing else is a formula
of $\mathcal{S}$.

Formulas derived by the Axioms and Inference Rules of a Propositional
Logic are termed \emph{Theorems}. Allowing for Axiom Schema (an
infinite number of axioms) extends Propositional Logic; an example of
such a system is \emph{Skolem Arithmetic}\cite{skolem23}.

The set of WFF of a System, $\mathcal{S}$, may be defined inductively:
\begin{itemize}
\item Propositional Variables are WFF
\item If $\varphi$ is a WFF, then $\neg\varphi$ is a WFF
\item If $\varphi$ and $\psi$ are WFF and $\bullet$ is a binary Operator,
  then $\varphi \bullet \psi$ is a WFF.
\end{itemize}

\subsubsection{Argument Forms}

Inference Rules of a Propositional Logic define Valid \emph{Argument
  Forms} (\S\ref{subsec:inference_rules}). The simplest Argument Form
that is both necessary (and given a complete set of Axioms is
sufficient to define all other Argument Forms) is \emph{Modus Ponens},
shown here Schematicized:

$\textrm{1. }\varphi \rightarrow \psi$

$\textrm{2. }\varphi$

$\therefore\textrm{ }\psi$
\\
where lines one and two are Premises and line three is the Conclusion
(the symbol $\therefore$ is read as \emph{therefore}). This is written in
\emph{Sequent Notation}(\S\ref{subsec:sequent_notation}) as
\[(\varphi \rightarrow \psi), \varphi \vdash \psi\]
The Schematic representation of \emph{Modus Tollens}:

$\textrm{1. }\varphi \rightarrow \psi$

$\textrm{2. }\neg\psi$

$\therefore\textrm{ }\neg\varphi$

\subsubsection{Operators}

The minimal set of primitive Operators is the \emph{negation} symbol
($\neg$) plus a \emph{sole sufficient} Operator of either $\land$,
$\lor$ or $\rightarrow$. Choosing one of these Operators, the other
two, and any other Operator, can be defined in terms of it and
negation. It is also possible to construct functionally complete sets
of one element: $\mathbf{\Omega} = \{\uparrow\}$ or $\mathbf{\Omega} =
\{\downarrow\}$ ($\uparrow$ and $\downarrow$ being \emph{NAND} and
\emph{NOR}, respectively).
\\
Example simple Axiom system:

$\mathbf{\Omega} = \mathbf{\Omega_1} \cup \mathbf{\Omega_2}$

$\mathbf{\Omega_1} = \{\neg\}$

$\mathbf{\Omega_2} = \{\rightarrow\}$

$\mathbf{I} = \{ (p \rightarrow (q \rightarrow p)),$

$\qquad((p \rightarrow (q \rightarrow r)) \rightarrow
(( p \rightarrow q) \rightarrow (p \rightarrow r))),$

$\qquad(( \neg p \rightarrow \neg q ) \rightarrow (q \rightarrow p ))
\}$\\ with Modus Ponens as the sole inference rule (see Hilbert
Systems, \S\ref{subsec:hilbert_systems}).

In Propositional Logic, the Extra-logical Symbol for Entailment,
$\vdash$, and the Logical \emph{Implication Symbol}, $\rightarrow$,
coincide in that
\[(A \vdash B) \leftrightarrow (\vdash A \rightarrow B)\]
but the difference is that $\vdash$ describes a Deduction, that is a
relation between Sentences, and $\rightarrow$ is a Logical Connective
within a Formula.

Another possible system is a \emph{Natural Deduction
  System}\cite{jaskowski34} (\S \ref{subsec:natural_deduction})
which has no Axioms ($\mathbf{I}=\varnothing$) and ten Inference
Rules.

\subsection{First-order - Predicate}

Systems of \emph{First-order Predicate Logic} add \emph{Extensional
  Quantifiers} that may be applied to Variables, which may be Objects
of the Universe of discussion, or Relations or Functions. A
\emph{First-Order Theory} may be formed by a system of First-order
Logic together with a Domain of Discourse over which Variables may
range, plus finitely many Functions and \emph{Predicates} defined on
that Domain, and a recursive set of Axioms.

A Predicate in First-order Logic takes one or more Objects from the
Domain and returns either True or False, that is a Relation on the
Domain. A Predicate taking no Objects (a Nullary Predicate) is
equivalent to a Proposition in Zeroth-order Logic.

\emph{Higher-order Logic}(\S\ref{subsec:higher_order}) allows Predicates
to be applied to other Predicates or Functions, or Quantifiers may be
applied to Predicates or Functions. In First-order Logic, Predicates
are associated with Sets, in Higher-order Logic, with Sets of
Sets.
\\
The traditional Signature used in First-order Logic:
\begin{enumerate}
\item For $n \geq 0$, $n$-ary Predicate (also called Relation)
  Symbols: $p^{n}_0, p^{n}_1, p^{n}_2, p^{n}_2, p^{n}_3, \ldots$
\item For $n \geq 0$, $n$-ary Function Symbols: $f^{n}_0, f^{n}_1,
  f^{n}_2, f^{n}_2, f^{n}_3, \ldots$
\end{enumerate}
The contemporary Signature used:
\begin{enumerate}
\item Predicate Symbols denoted by uppercase letters $P$, $Q$, $R$,
  $\ldots$ with arity ($\geq 0$) specified by the \emph{Valence} of the
  parenthetical arguments, eg P(x), Q(x,y).
\item Function Symbols denoted by lowercase letters $f$, $g$, $h$,
  $\ldots$ with arity specified in the usual way.
\end{enumerate}
Here, Functions of Valence 0 are \emph{Constant Symbols} denoted by
letters $a$, $b$, $c$, $\ldots$.

\subsubsection{Properties}\label{subsec:first_order_properties}

First-order Logic may be used to devise Deductive Systems with
finite Domains that are \emph{Sound} and \emph{Complete}, but for
infinite Domains a system of Higher-order Logic is
required. First-order Logic is Semi-decidable(\S\ref{subsec:semidecidable}).

%FIXME ref Lowenheim-skolem thoerem
The \emph{L\"owenheim-Skolem theorem} implies that First-order Logic
is unable to characterize the concept of Countability (or
Uncountability).

%FIXME def/ref compactness theorem
The \emph{Compactness theorem} implies that if a Formula is derived
from a System of First-order Logic with an infinite set of Axioms,
then it can be derived from a finite number of those Axioms. This has
implications for the determination of \emph{Connected Components} of a
\emph{Directed Graph}. %FIXME ref Graph theory.

\subsubsection{Formation Rules}\label{subsec:formation_rules}

The \emph{Formation Rules} for WFF in a System of First-order Logic
generally describe a Context-free Grammar with a infinite Alphabet and
many Start Symbols.

Terms are limited to those derived from Variables and a finite number
of $n$-ary Function applications, but not Expressions involving a
Predicate Symbol. See Section \ref{sec:terms} for a recursive
definition of Terms.

Definition of \emph{Atomic Formulas} (no Logical Connectives or Quantifiers):
\begin{enumerate}
\item If $t_1$ and $t_2$ are Terms, then $t_1 = t_2$ is an Atomic Formula.
\item If $R$ is an $n$-ary Relation (Predicate), and $t_1,\ldots,t_n$
  are terms, then $R(t_1,\ldots,t_n)$ is an Atomic Formula.
\end{enumerate}
Atomic Formulas or their negations are also called \emph{Literals}. A
\emph{Clause} is a finite Disjunction of Literals.

Definition of WFF as a finite number of applications of the following rules:
\begin{enumerate}
\item $\neg \phi$ is a WFF when $\phi$ is a WFF
\item $(\phi \bullet \psi)$ is a WFF when $\phi$ and $\psi$ are WFF
  and $\bullet$ is a Binary Connective
\item $\exists x \phi$ is a WFF when $x$ is a Variable and $\phi$ is a WFF
\item $\forall x \phi$ is a WFF when $x$ is a Variable and $\phi$ is a WFF
\end{enumerate}

\subsubsection{Quantification}

A Quantifier limits (\emph{Binds}) a Variable to a certain quantity of
members of the Domain, the two fundamental Quantifiers being
\emph{Universal} ($\forall$) and \emph{Existential} ($\exists$).

Variables are \emph{Free Variables} if they are not Quantified in any
Formula, and \emph{Bound Variables} when they are Quantified.
Inductive definition of \emph{Free} and \emph{Bound Variables}:
\begin{enumerate}
\item A Variable $x$ is Free in Atomic Formula $\varphi$ if $x$ occurs
  in $\varphi$ (there are no Bound Variables in Atomic Formulas)
\item A Variable is Free or Bound in $\varphi \bullet \psi$ if $x$ is
  Free or Bound in either $\varphi$ or $\psi$, where $\bullet$ is a
  Binary Connective
\item A Variable $x$ is Free in $\forall y \varphi$ iff $x$ is Free in
  $\varphi$ and $x$ is not $y$. Conversely $x$ is Bound in $\forall y
  \varphi$ if $x$ is $y$ or $x$ is Bound in $\varphi$.
\end{enumerate}

A Term with no Free Variables is a \emph{Ground Term} and a Formula
with no Free Variables in First-order Logic is a \emph{First-order
  Sentence} (also called a \emph{Closed Formula}). First-order
Sentences have well-defined Truth values. Free Variables are
implicitly Universally Quantified.

\paragraph{Uniqueness Quantification}\hfill
\\
\emph{Unique Existential Quantification}, denoted by $\exists !$,
is expressed in natural language as ``there is one and only one.'' A
First-Order System requires the \emph{Equality Relation}
(\S\ref{subsec:first_order_equality}) in order to be able to express
Uniqueness Quantification.

\paragraph{Quantifier Rank}\hfill
\\
Inductive definition of \emph{Quantifier Rank} function $qr$:
\begin{itemize}
\item $qr(\varphi) = 0$ if $\varphi$ is Atomic
\item $qr(\varphi_1 \wedge \varphi_2) = qr(\varphi_1 \vee \varphi_2) = max(qr(\varphi_1),qr(\varphi_2))$
\item $qr(\neg \varphi) = qr(\varphi)$
\item $qr(\exists_x \varphi) = qr(\varphi) + 1$
\end{itemize}

\paragraph{Quantifier Nesting}\hfill
\\
% FIXME

\subsubsection{Inference Rules}

\paragraph{Universal Generalization}\label{subsec:universal_generalization} \hfill
\\
\[P(x) \vdash \forall x P(x)\]

\subsubsection{Equality Conventions}\label{subsec:first_order_equality}

\paragraph{First-order Logic with Equality}\hfill
\\ Including a primitive Logical Symbol for equality, $=$, interpreted
as the real equality relation between members of the Domain such that
``two'' given members are the same member. This adds the following
Axioms:

\begin{enumerate}
\item \textbf{Reflexivity}: $\forall x, x=x$
\item \textbf{Substitution for functions}: given a function, $f$,
  $\forall x \forall y, x = y \rightarrow f(\ldots,x,\ldots) =
  f(\ldots,y,\ldots)$
\item \textbf{Substitution for formulas (Leibniz's Law)}: given a
  formula $\varphi$ with Free occurrences of $x$, and $\varphi '$ with
  Free occurrences of $y$, $\forall x \forall y, x = y \rightarrow
  (\varphi \rightarrow \varphi ')$
\end{enumerate}

Defining a theory with a binary relation $A(x,y)$ that satisfies
Reflexivity and Leibniz's law is sufficient to derive any other
equality Theorems.

\paragraph{First-order Logic without Equality} \hfill
\\ An alternative convention is to consider the Equality Relation to
be a Non-logical Symbol, included as a part of the Signiature of a
particular Theory instead of as a Rule of Logic. This allows two
distinct individuals to be considered equal by an arbitraray
Equivalence Relation. If this convention is used, but no distinct
individuals, $a$ and $b$ satisfy $a=b$ then the interpretation is
termed a \emph{Normal Model} (that is equivalent to a First-order
Logic with Equality).


\subsubsection{Monadic First-order Logic}

\emph{Monadic First-order Logic}, also called \emph{Monadic Predicate
  Calculus} restricts First-order Logic to unary Relations and no
Function symbols. This weaker form of First-order Logic is fully
Decidable.

\subsubsection{Many-sorted First-order Logic}

\emph{Many-sorted First-order Logic} allows Variables to be Quantified
over different Domains, thus giving Variables different
\emph{Sorts}. With finitely many Sorts, Many-sorted First-order Logic
can be reduced to Single-sorted First-order Logic. This can be
accomplished by adding unary Predicates to a First-order Logic that
partition the Domain.

\subsubsection{Infinitary First-order Logic}

\emph{Infinitary Logic} allows Formulas of infinite length, through
either Conjunctons and Disjunctions, infinite-arity Relations and
Functions, or Quantification over infinitely many Variables.

\subsection{Higher-order - Plural}\label{subsec:higher_order}

\subsubsection{Second-order}

\emph{Second-order Logic} allows for Quantifiers to range over
Relations and Functions and thus \emph{Sorts} of Variables that range
over $k$-ary Relations and Functions. It is possible to leave out a
definition of Quantifiers for Functions since $k$-ary Functions can be
represented by $k+1$-ary Relations.\cite{shapiro00}

\subsubsection{Plural, Monadic Second-order Logic}

An alternative formulation of Second-order Logic is to allow Variables
to take on \emph{Plural} Values. It is equi-interpretable with
\emph{Monadic Second-order Logic}, which restricts Quantification to
Unary Relations (sets).

\subsection{Classical Logic}\label{subsec:classical_logic} \hfill
\\ \emph{Classical Logic} is the class of Propositional and
First-order Systems of Logic characterized by the following Inference
Rules:

\begin{description}

\item [Tertium non datur] (\emph{Law of excluded middle})
    \[\vdash(p \vee \neg p)\]

\item [Double Negation]
    \[p \vdash \neg\neg p\]

\item [Law of Non-contradiction]
    \[\vdash \neg(p \wedge \neg p)\]

\item [Ex falso quodlibet] (\emph{Principle of explosion},
  \emph{Principle of Psuedo-Scotus})
    \[\vdash 0 \rightarrow p\]

%FIXME finish properties and rules

\end{description}

\subsection{Modal (Intensional) Logic} \label{subsec:modal_logic}

\emph{Intensional Logic} adds to First-order Logic \emph{Sentential
  Functors} (\emph{Intensions}) that range over Terms. An Intension is
the \emph{Sense} in which a Logical Assertion is made, as opposed to
the \emph{Reference} to which the Assertion applies (\emph{ie
  Extensional Quantification}).

\emph{Modal Logic} extends Propositional and Predicate Logic to
include Operators expressing \emph{Modality}. Various meanings for
these Modal Operators include \emph{Alethic Modality}
(\emph{Necessity} and \emph{Possibility}), \emph{Temporal Modality}
(qualification in terms of time, eg \emph{always}, \emph{eventually},
\emph{until}), \emph{Deontic Modality} (\emph{Obligation} and
\emph{Permission}), and \emph{Doxastic Modality} (Modalities with
regards to \emph{Belief}).

An unary \emph{Primitive Modal Operator}, $\square$, defines a Dual
Operator, $\Diamond$, such that the following analogues of de Morgan's
laws hold:
    \[\Diamond P \leftrightarrow \neg \square \neg P\]
    \[\square P \leftrightarrow \neg \Diamond \neg P\]
Modal Logic with more than one Primitive Modal Operator, $\square _i,
i \in \{1, \ldots, n\}$ is \emph{Multimodal Logic}.

\subsubsection{Alethic Logic}

Most Systems of Alethic Logic are based on an extension of
Propositional Logic called $\mathbf{K}$ which has:

\begin{enumerate}
\item $\square$, unary operator for \emph{Necessity}.
\item $\mathbf{N}$, \emph{Necessitation Rule}: stating if $p$ is a
  Theorem, then $\square p$ is a Theorem.
\item $\mathbf{K}$, \emph{Distribution Axiom}: $\square(p \rightarrow
  q) \rightarrow (\square p \rightarrow \square q)$ (also called the
  \emph{Kripke schema})
\end{enumerate}

Adding further Axioms gives rise to a nested hierarchy of Systems of
\emph{Normal Modal Logic}:

\begin{itemize}
\item $K := \mathbf{K} + \mathbf{N}$
\item $T := K + \mathbf{T}$
\item $S4 := T + \mathbf{4}$
\item $S5 := S4 + \mathbf{5}$
\item $D := K + \mathbf{D}$
\end{itemize} \hfill \\
where

\begin{itemize}
\item $\Diamond$, unary operator for \emph{Possibly}
\item $\mathbf{T}$, \emph{Reflexivity Axiom}: $\square p \rightarrow p$
\item $\mathbf{4}$: $\square p \rightarrow \square \square p$
\item $\mathbf{B}$: $p \rightarrow \square \Diamond p$
\item $\mathbf{D}$: $\square p \rightarrow \Diamond p$
\item $\mathbf{5}$: $\Diamond p \rightarrow \square \Diamond p$
\end{itemize}

\subsubsection{Doxastic Logic}

\emph{Doxastic Logic} uses the unary Modal Operator, $\mathcal{B}$, to
denote \emph{Belief}. Example:
\[
    \mathcal{B} x
\]
has the meaning ``It is Believed that x is the case''. A set of
Beliefs is usually denoted
\[
    \mathbb{B}: \{ b_1, b_2, \ldots, b_n \}
\]

\subsubsection{Deontic Logic}

\emph{Standard Deontic Logic} ($\mathbf{SDL}$) adds the following
Axioms to Propositional Logic (\S\ref{subsec:propositional}):
    \[O(A \rightarrow B) \rightarrow (OA \rightarrow OB)\]
    \[PA \rightarrow \neg O \neg A\]
with Primitive Operators $O$ (\emph{Obligatory}) and $P$
(\emph{Permissible}). \emph{Forbidden} is defined as
    \[FA = O \neg A\]
or
    \[FA = \neg P A\]
Deontic Logic may be extended by Alethic Operators with the Axiom:
    \[OA \rightarrow \Diamond A\]
which has the meaning ``ought implies can''.

\subsubsection{Temporal Logic}

\paragraph{Tense Logic} \hfill \\

\emph{Tense Logic} is a 2-modal Logic that adds operators $[F]$ for
\emph{Future} and $[P]$ for \emph{Past} Modalities.

\paragraph{Linear Temporal Logic}

\paragraph{Computation Tree Logic}

\paragraph{Interval Temporal Logc}

\paragraph{Modal $\mu$-calculus}

\subsubsection{Dynamic Logic}

\emph{Dynamic Logic} adds Terms denoting \emph{Actions}:
\[[a]p\]
where after performing Action $a$ is necessitated that $p$ holds and
\[\langle a \rangle p\]
where after performing Action $a$ it is possible that $p$ holds.

\subsection{Intuitionistic Logic}\label{subsec:intuitionistic_logic}

\emph{Intuitionistic Logic} replaces Truth with the concept of
\emph{Constructive Provability}. Intuitionistic Logic is Modelled by
\emph{Heyting Algebra}.

\subsubsection{Minimal Logic}

\subsubsection{Combinatory Logic}\label{subsec:combinatory_logic}

\subsection{Substructural Logic}\label{subsec:substructural_logic}

\subsubsection{Relevance Logic}\label{subsec:relevance_logic}

\subsubsection{Linear Logic}\label{subsec:linear_logic}

\paragraph{Non-commutative Logic}\label{subsec:noncommutative_logic}

\subsection{Ordinal Logic}

Alan Turing's PhD Thesis \cite{turing38}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Proof Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Metatheory} \label{sec:metatheory}

\emph{Proof Theory} is itself \emph{Metamathematical} in that it
studies the form of Logical Consequence within Logical Systems, and
therefore is expressed as \emph{Metatheory}.

A \emph{Judgement} is an inductively definable assertion in the
Metatheory of a Logical System. That is, one that includes
Extra-logical Symbols, namely that of Logical Consequence, $\vdash$,
and commas used in \emph{Sequents}
(\S\ref{subsec:sequent_notation}). In this way, Axioms are Judgements,
and a \emph{Formal Proof} expresses a Judgement with the Premises
being a sequence of Judgements and the Conclusion also a Judgement.

\subsection{Formal Theory}\label{subsec:formal_theory}

A \emph{Formal Theory} is a Set of Sentences in some Formal Language
(Part \ref{sec:formal_language}). In a Deductive System, a Theory has
certain Sentences which are Axioms, and any Sentences which are a
Logical Consequence are also Sentences of that Theory. That is, a
Theory $\mathcal{T}$ which is an \emph{Inductive Class}. The Sentences
which are considered for a particular Theory are drawn from a
\emph{Conceptual Class} of \emph{Elementary Statements}. A Formal
Theory is said to be \emph{Complete} if for every Sentence in the
Language of that Theory, the Theory contains either that Sentence or
its Negation.

\subsection{Formal Proof} \label{subsec:formal_proof}

A Formal Proof is a \emph{Logical Derivation}: a finite sequence of
Well-formed Formulas of a Formal System that are either Axioms of a
Logical System or follow from the preceding Formulas by an Inference
Rule. The concluding Formula in the sequence is a \emph{Theorem}. A
Theorem used in the course of Deriving a further Theorem is called a
\emph{Lemma}.

For a Formal System, $\mathcal{S}$, of a set of Formulas, $\Gamma$,
there is a \emph{Syntactic Consequence}, $A$, if there is a
Formal Proof of $A$ from the set $\Gamma$:
\[
    \Gamma \vdash_{\mathcal{S}} A
\]
It will suffice for now to say that Syntactic Consequence as
differentiated from \emph{Material Consequence} should: % FIXME ref
                                % material consequence
\begin{enumerate}
\item Rely on the Logical Form (\S\ref{subsec:inference_rules}) of the
  Expressions
\item Be completely \emph{a priori}
\item Be \emph{Modal} (\S\ref{subsec:modal_logic}) (ie, Necessary)
\end{enumerate}
Another form of Logical Consequence, \emph{Semantic Consequence} will
be described under \emph{Model Theory} (Part \ref{sec:model_theory}).

Proof by Syntactic Consequence is a \emph{Deduction}; that is, the
production of a Theorem is said to be a \emph{Derivation}. Deduction
proper is the top-down, \emph{Reductive} process that starts with
general Axioms and Reduces to the specific Theorem that is being
proved. \emph{Mathematical Induction} is the bottom-up,
\emph{Implicative} process where a \emph{Base Case} is shown to extend
to the more general by means of Implication (the Inductive step). Note
that Mathematical Induction is not \emph{Inductive Reasoning} which is
an empirical or probabilistic Inference and not a form of Deduction.

An \emph{Theoretic Analytic Proof} begins with an assumption and
proceeds to an accepted truth (an Axiom, or contradiction as in
Analytic Tableau (\S\ref{subsec:tableau_calculus}). A \emph{Synthetic
  Proof} is the reverse of this process; beginning with known truths
and reasoning up to the desired Proof. A \emph{Problematic Analytic
  Proof} is constructed from given conditions that are to be
satisfied.

\subsubsection{Sequent Notation}\label{subsec:sequent_notation}

A \emph{Sequent} is a specific kind of Judgement of the form
\[\Gamma \vdash \Sigma \]
where the \emph{Antecedent}, $\Gamma$, is a Conjunctive sequence of
Formula, and the \emph{Succedent}, $\Sigma$, is a Disjunctive sequence
of Formulas. Together, Antecedents and Succedents are
\emph{Cedents}. The Extra-logical Operators, $\vdash$, and $,$
(comma), are called \emph{Structural Operators} and Rules which change
only Structural Operators are \emph{Structural Rules} (as opposed to
\emph{Logical Rules}. A sequence of Cedents may be called a
\emph{Context}, but \emph{the} Context for a specific Judgement is
usually meant to be the Antecedent.

\emph{Weakening} refers to a Rule that introduces arbitrary elements
to a Sequent. \emph{Contraction} refers to a Rule that removes
multiple occurences of some element and \emph{Permutation} refers to
the re-ordering of elements. Logics lacking Structural Rules are
\emph{Substructural Logics} (\S\ref{subsec:substructural_logic}). If
Sequents are defined as Sets or Multisets instead of Sequences (that
is, unordered Sets), then the Permutation rule is obsolete, likewise
the Contraction Rule would be obsolete for Sets instead of Sequences.

In a general \emph{Sequent Calculus} there may be any
number of Formulas on either side
\[
    A_1, \ldots, A_n \vdash B_1, \ldots, B_k
\]
is equivalent to
\[
    \vdash(A_1 \wedge \cdots \wedge A_n) \rightarrow (B_1 \vee \cdots \vee B_k)
\]
and the dual nature of Judgements and negation can be expressed by the
dual forms
\[
    \vdash \neg A_1 \vee \cdots \vee \neg A_n \vee B_1 \vee \cdots
    \vee B_k
\]
and
\[
    \vdash \neg(A_1 \wedge \cdots \wedge A_n \wedge \neg B_1 \wedge
    \cdots \wedge \neg B_k)
\]

A Sequent with no Succedent ($\Gamma \vdash$) is a
\emph{Contradiction} meaning it proves falsity which is
Inconsistent. A Sequent with no Antecedent ($\vdash \Sigma$) is a
\emph{Logical Assertion} and the Succedent is a
\emph{Tautology}. Theorems are those of the form $\vdash B$ which are
the Conclusion of a Valid Proof.

% --------------------------------------------------------------------
\section{Proof Calculi}
% --------------------------------------------------------------------

\emph{Proof Calculi} are families of Formal (Deductive) Systems
(\S\ref{sec:formal_systems}), specifying templates for forms of
\emph{Formal Inference} (Axioms and Inference Rules).

% --------------------------------------------------------------------
\subsection{Axiomatic Systems}
% --------------------------------------------------------------------

\subsubsection{Hilbert Systems} \label{subsec:hilbert_systems}

\emph{Hilbert Systems} are characterized by having a large number of
Axiom Schema and few Inference Rules-- just Modus Ponens for
Propositional Logics and Universal Generalization for Predicate
Logic. In a Hilbert System, Judgements and Formulas are not
differentiated. A Theorem in a Hilbert System is the Concluding
Judgement in a Derivation.

A Hilbert System is differentiated from Systems of \emph{Natural
 Deduction} by not having any Rules that change the Context of a
Formula.

% --------------------------------------------------------------------
\subsection{Structural Proof Theory}
% --------------------------------------------------------------------

\emph{Structural Proof Theory} studies Proof Calculi that support
\emph{Analytic Proof}; that is Proofs that are \emph{Cut-free} (they
do not use the \emph{Cut Rule}) or in \emph{Normal Form}.

\subsubsection{Natural Deduction}\label{subsec:natural_deduction} \hfill
\\
Systems of \emph{Natural Deduction}\cite{prawitz65}, contrasted with
Hilbert Systems, include many Inference Rules but few or no Axioms. A
Natural Deduction System allows Judgements with multiple Antecedents
and a single Succedent
\[
    A_1,\ldots,A_n \vdash B
\]
Inference Rules in Natural Deduction have the general notation
\[
    {
        \frac{J_1 \quad J_2 \quad \cdots \quad J_n}
        {J}
    } name
\]
where the Rule with name $name$ has Premises of zero or more
Judgements $J_i$ and the Judgement $J$ is the Conclusion.

Inference Rules that introduce a Logical Connective in the Conclusion
are called \emph{Introduction Rules}. Example
\[
    {
        \frac{A\;\mathrm{true} \quad B\;\mathrm{true}}
        {(A \wedge B)\;\mathrm{true}}
    } \wedge_I
\]
where $A$ and $B$ are Propositions.

Conversely, Inference Rules that remove Logical Connectives are
\emph{Elimination Rules}.
\[
    {
        \frac{A \wedge B\;\mathrm{true}}
        {A\;\mathrm{true}}
    } \wedge_E
\]

\emph{Hypothetical Derivations} (reasoning from \emph{Assumptions})
are required for Implication Introduction or Disjunction
Elimination. The general form of a Hypothetical Derivation with
Antecedents $D_i$ and Succedent $J$:
\[
    D_1 \quad D_2 \cdots D_n
\]\[
    \vdots
\]\[
    J
\]
Introduction Rules for Implication:
\[
    {
        \frac{}
        {A\;\mathrm{true}}
    } u
\]\[
    \vdots
\]\[
    {
        \frac{B\;\mathrm{true}}
        {A \rightarrow B\;\mathrm{true}}
    } \rightarrow_{I^u}
\]
The Premise $u$ here is considered \emph{discharged} by the Rule
$I^u$; that is the scope of $u$ does not extend past $I^u$.
Elimination Rule for Implication (Modus Ponens):
\[
    {
        \frac{A \rightarrow B\;\mathrm{true} \quad A\;\mathrm{true}}
        {B\;\mathrm{true}}
    } \rightarrow_{E}
\]
Disjunctive Elimination:
\[
    \frac{
    A \vee B\;\mathrm{true} \quad
    \begin{matrix}
        {
            \frac{}
            {A\;\mathrm{true}}
        }u \\
        \vdots \\
        C\;\mathrm{true}
    \end{matrix}
    \quad
    \begin{matrix}
        {
            \frac{}
            {B\;\mathrm{true}}
        }w \\
        \vdots \\
        C\;\mathrm{true}
    \end{matrix}
    }{ C\;\mathrm{true}}\wedge_{E^{u,w}}
\]
A Theory is \emph{Locally Consistent} (or \emph{Locally Reducible}) if
an Introduction of a Connective followed by its Elimination can be
equivalently Derived without these steps.  The dual to Local
Consistency is \emph{Local Completeness} which states that Elimination
rules can decompose a Connective into the forms of its Introduction
Rule. These correspond to $\beta$-reduction and $\eta$-conversion in
$\lambda$-Calculus (\S\ref{sec:lambda_calculus}) where Propositions
are \emph{Types} and Proofs are \emph{Programs}. If an entire
Derivation has only Eliminations followed by Introductions, it is said
to be in \emph{Normal Form}.

In a Formal Proof, the Judgements representing Antecedents are
presented as Rules with no Premises, named by a \emph{Proof Variable}
(from a countable set $V$ of variables):
\[
    \frac{}{J_1}u_1 \; \frac{}{J_2}u_2 \; \cdots \frac{}{J_n}u_n
\]\[
    \vdots
\]\[
    J
\]
where $u_i \in V$. Written in Sequent Notation:
\[
    u_1:J_1, u_2:J_2, \ldots, u_n:J_n \vdash J
\]
This convention is sometimes called \emph{Localized Hypotheses}. In
general, $\pi : A$ may be read ``$\pi$ is a proof of $A$''.

\subsubsection{Sequent Calculus}

In \emph{Sequent Calculus} a Formal Proof is a Sequence of Sequents
(\S\ref{subsec:sequent_notation}) where each successive Sequent is
Derivable from prior Sequents by Inference Rules.

The Rule for \emph{Cut} is as follows:
\[
    \frac{
        \Gamma \vdash \Delta, A \quad A, \Sigma \vdash \Pi
    }{
        \Gamma, \Sigma \vdash \Delta, \Pi
    }(Cut)
\]
It states that when a Formula $A$ that can be Concluded can also be
used as a Premise, it can be \emph{cut} out and the Derivations joined
together. That is, wherever the Lemma $A$ occurs, it can be
substituted for the Proof of $A$. This means that the Cut Rule is an
Admissible Rule (\S\ref{subsec:inference_rules}).

The \emph{Cut-elimination Theorem} states that any Judgement with a
Proof in Sequent Calculus that uses the Cut Rule may be expressed as a
\emph{Cut-free} Proof without using the Cut Rule. Usually,
demonstrating the existence of the Cut-elmination Theorem implies that
the System is Consistent since that would rule-out the possibility of
Proof of Contradiction.

\paragraph{$\mathbf{LK}$} \hfill \\

Formalization of Classical Logic (\S\ref{subsec:classical_logic})
(sound and complete in First-Order) with Sequents having zero or more
RHS Formulas. Allowing multiple RHS Formulas with a \emph{Right
  Contraction Rule} is equivalent to the admissibility of the
\emph{Law of the Excluded Middle}.

\paragraph{$\mathbf{LJ}$} \hfill \\

Formalization of Intuitionistic Logic
(\S\ref{subsec:intuitionistic_logic}) with Sequents having at most one
RHS Formula. The Cut Rule for $\mathbf{LJ}$:
\[
    \frac{
        \Gamma \vdash A \quad \Pi, A \vdash B
    }{
        \Gamma, \Pi \vdash B
    }(Cut)
\]

\paragraph{Substructural Rule Sets} \hfill \\

A Substructural Logic (\S\ref{subsec:substructural_logic}) lacking the
usual Structural Rules is usually weaker than $\mathbf{LK}$.

In Relevance Logic (\S\ref{subsec:relevance_logic}), Weakening Rules
are not included on the grounds that introduced Formulas are not
\emph{Relevant}.

In Linear Logic (\S\ref{subsec:linear_logic}), duplicate Formulas are
treated differently so Contraction and Weakening Rules are is absent
or controlled.

% --------------------------------------------------------------------
\subsection{Calculus of Structures}
% --------------------------------------------------------------------

\emph{Calculus of Structures} is a Proof Calculus with \emph{Deep
  Inference} for studying Non-commutative Logic
(\S\ref{subsec:noncommutative_logic}). Deep Inference is a
generalization of Structure to handle greater Structural complexity
\cite{schutte77}.

% --------------------------------------------------------------------
\subsection{Tableau Calculus}\label{subsec:tableau_calculus}
% --------------------------------------------------------------------

\emph{Tableau Calculus} (or \emph{Method of Analytic Tableau}) is
commonly used as a Proof procedure for Modal Logics
(\S\ref{subsec:modal_logic}). An Analytic Tableau is a tree with a
Formula at the root and a Subformula at each node. A specific Tableau
Calculus is a finite collection of Rules for breaking down Logical
Connectives into constituent parts. Rules can be expressed as Sets,
Multisets, Lists, or Trees of Formulas. If Sets of Formulas are used
at each node (\emph{Set-labeled Tableau}), they are taken in
Conjunction.

A \emph{Refutation Tableau} attempts to show that a negation of the
root Formula cannot be satisfied, thereby proving Logical Truth of the
Formula. Rules for handling Logical Connectives may produce a branch
in the tree and if a branch leads to a Contradiction, the branch is
closed and if all branches are closed the Proof is complete and the
root Formula is proved. Nodes on a single branch are considered in
Conjunction, Nodes on separate branches are considered Disjunctively.

\emph{Non-destructive Tableau Calculi} use Rules that only allow
addition of nodes, while \emph{Destructive Tableau Calculi} use Rules
that allow modification of existing nodes. \emph{Proof Confluence} is
the property of a Tableau Calculus that a closed Tableau (for an
un-satisfiable set of Propositions) can always be generated from an
arbitrary partially constructed Tableau regardless of which Rules are
chosen at each application (if a choice between Rules is available). A
\emph{Strongly Complete Tableau} is one in which every Formula in
every branch has been expanded.

A method of dealing with non-determinism of rules involving Universal
Quantification (in First-order Tableau) is called
\emph{Unification}. This allows Free Variables to be substituted in
the Rule for Eliminating Universal Quantifiers, which can later be
Unified by choosing an appropriate Term to close the branch.

\emph{Clause Tableau} (Tableau Method applied to sets of Clauses) may
be used for increased efficiency. \emph{Connection Tableau} restrict
expansion of Clause Tableau branches (not the bare root) to contain
only Literals that unify with a Literal already on the branch
(\emph{Weak Connectedness}) or a Literal in the current leaf
(\emph{Strong Connectedness}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Formal Semantics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\emph{Formal Semantics} is the general study of \emph{Interpretations}
(\S\ref{subsec:interpretation}) of \emph{Formal Languages} (Part
\ref{sec:formal_language}).

% --------------------------------------------------------------------
\section{Soundness}\label{sec:soundness}
% --------------------------------------------------------------------

An Argument in a System of Logic is \emph{Sound} if and only if the
Argument is Valid and all of its Premises are True. The Logical System
itself has the Soundness Property if and only if its Inference Rules
(\S\ref{subsec:inference_rules}) Prove only Valid Formulas under
Semantic Interpretation. This usually amounts to the simple
requirement that the Axioms are Valid and the Inference Rules preserve
Validity.

% --------------------------------------------------------------------
\section{Truth}\label{sec:semantic_truth}
% --------------------------------------------------------------------

\emph{Tarski's Undefinability Theorem} \cite{tarski36} uses the same
techniques as G\"odel's Incompleteness Theorems to show that Truth
cannot be defined in an Object Language
(\S\ref{sec:metalanguage}). The two related conceptions of Truth are
the \emph{Correspondence Theory} (\S\ref{subsec:correspondence_truth})
and \emph{Deflationary Theory} (\S\ref{subsec:deflationary_truth}).

Briefly, the Undefinability Theorem results in a \emph{Material
  Adequacy Condition} (called \emph{Convention T}) that any Theory of
Truth must entail:
\[
    \forall P (\mathrm{True}(S) \leftrightarrow P)
\]
where $S$ is the name of the Sentence $P$ in the Metalanguage which is
an Interpretation of $P$ in the Object Language. This is the
\emph{T-Schema} used in \emph{Tarski's Semantic Theory of Truth} to
Inductively define Truth, expressed as a First-order Sentence. When a
Modal Logic is based on the T-Schema it is said to give rise to
\emph{T-Theory}. Tarski's Semantic Theory of Truth is used as the
definition for Truth in \emph{Model Theory}
(\S\ref{sec:model_theory}).

An example sentence conforming to Convention T in Natural Language
where the Object Language is German and the Metalanguage is English:
\begin{description}
\item ``\emph{Der Schnee ist wei\ss} is True if and only if snow is
  white''.
\end{description}
Here the right side of the Biconditional ('snow is white') is the
\emph{Truth-Condition} of the left side.

Tarski considered this definition of Truth to be a type of
Correspondence Theory.

% --------------------------------------------------------------------
\subsection{Correspondence Theory}\label{subsec:correspondence_truth}
% --------------------------------------------------------------------

The \emph{Correspondence Theory of Truth} defines Truth of a Statement
by its relation and Correspondence with the world.

% --------------------------------------------------------------------
\subsection{Coherence Theory}
% --------------------------------------------------------------------

The \emph{Coherence Theory of Truth} defines Truth of a Statement by
its relation to other Statements.

% --------------------------------------------------------------------
\subsection{Deflationary Theory}\label{subsec:deflationary_truth}
% --------------------------------------------------------------------

A \emph{Deflationary Theory of Truth} is one that states that
ascribing Truth to a Statement does not attribute a property of Truth
to any such Statement in one of a number of different ways below.

% --------------------------------------------------------------------
\subsubsection{Redundancy Theory}
% --------------------------------------------------------------------

The \emph{Redundancy Theory of Truth} states that the Predicate of
Truth is Redundant in that it is equal to the Statement it is applied
to.\cite{ramsey27} Essentially, Truth is a \emph{periphrasis} of the
Sentence it is applied to.

% --------------------------------------------------------------------
\paragraph{Disappearance Theory}
% --------------------------------------------------------------------
\hfill \\ A \emph{Disappearance Theory of Truth} states that Truth is
both Redundant and there is no such Property of Truth. A.J. Ayer is
known for this Theory.

% --------------------------------------------------------------------
\subsubsection{Performative Theory}
% --------------------------------------------------------------------

The \emph{Performative Theory of Truth} is a Deflationary Theory that
sees the Predicate of Truth as a signal of agreement with the
Statement, for such reasons as arriving at Consensus or such others.

% --------------------------------------------------------------------
\subsubsection{Disquotational}
% --------------------------------------------------------------------

The \emph{Disquotational Theory of Truth} is a Deflationary
interpretation of Tarski's definition of Truth by W.V.O. Quine. It
states the Truth predicate has the effect of \emph{Dereferencing}
Sentences (removing the quotation marks). So
\[
    S \leftrightarrow True(``S``)
\]
that is, $S$ is equivalent to \emph{``$S$'' is true}.

The effect of adding \emph{is True} to an Assertion is then to convert
the Use of the Assertion to a Mention.

% --------------------------------------------------------------------
\subsubsection{Prosententialism}
% --------------------------------------------------------------------

\emph{Prosententialism} denies that ``is true'' is a Predicate and is
instead a \emph{Prosentence} (the Sentential analog to
\emph{Pronouns}) that stands in for another Sentence.

% --------------------------------------------------------------------
\subsubsection{Minimal}
% --------------------------------------------------------------------

\emph{Minimalism} defines Truth as a \emph{Metalinguistic} property
and that only Propositoins are Truth-bearing.

% --------------------------------------------------------------------
\subsection{Normative}
% --------------------------------------------------------------------

A \emph{Normative Theory of Truth} states that Truth is the Normative
goal of Assertion.

% --------------------------------------------------------------------
\section{Structure}\label{sec:mathematical_structure}
% --------------------------------------------------------------------

A \emph{Mathematical Structure} is composed of an arbitrary Set called
a \emph{Carrier Set} or \emph{Underlying Set} (or Domain or Universe)
with one or more \emph{Operators}. Allowing \emph{Infinitary
  Operators} leads to a Theory of \emph{Complete Lattices}.

Formal definition of a Structure:
\[
    \mathcal{A} = (A, \sigma, I)
\]
with Domain $A$, Signature $\sigma$, and \emph{Interpretation
  Function} $I$. The Domain of a Structure $\mathcal{A}$ may also be
written as $|\mathcal{A}|$.

The \emph{Signature} or \emph{Vocabulary} of a Structure is the Set of
Operators (Functions and Relations) that characterize it. The
Signature is a synonym for the \emph{Type} of the Structure
(Schematically represented by $\Omega$), and can be written as an
ordered sequence of Natural Numbers representing the arity of the
Operators. The arity, $n$, of a particular Operator symbol, $s$, may
be written $n=ar(s)$. Sometimes the Signature is given as a triple
\[
    (O,F,P)
\]
where $O$ are Constants, $F$ are Functions, and $P$ are Predicates
(Relations).

A Structure with no Relation Symbols is an \emph{Algebra}
(\S\ref{subsec:universal_algebra}). A Structure with no Functions may
be used as the basis for a \emph{Relational Model}
(\S\ref{sec:relational_model}) in \emph{Database Theory}.

A \emph{Reduct} of a Structure is created by omitting certain
Operations and Relations from the Signature. The converse is
\emph{Expansion}.

% --------------------------------------------------------------------
\subsection{Interpretation}\label{subsec:interpretation}
% --------------------------------------------------------------------

Roughly, an \emph{Interpretation} of a Formal Language is an
assignment of \emph{Meanings} to Symbols and \emph{Truth-Conditions}
(\S\ref{sec:semantic_truth}) to Sentences. An Interpretation of
First-order Logic maps Terms to Individuals in the Universe and
Propositions to Truth Values.

The Interpretation Function in a Mathematical Structure maps Function
and Relation Symbols of the Signature to actual Functions and
Relations on the Domain:
\[
    f^{\mathcal{A}} = I (f)
\]
\[
    R^{\mathcal{A}} = I (R) \subseteq A^{ar(R)}
\]
A Constant (Nullary) Symbol is identified with an Element of the
Domain:
\[
    I(c) \in A
\]

% --------------------------------------------------------------------
\subsection{Substructure}\label{subsec:model_substructure}
% --------------------------------------------------------------------

A Structure $\mathcal{A}$ is an \emph{Induced Substructure} of
Structure $\mathcal{B}$ when
\begin{itemize}
\item $\sigma(\mathcal{A}) = \sigma(\mathcal{B})$
\item $A \subseteq B$
\item $I_{\mathcal{A}}=I_{\mathcal{B}}$
\end{itemize}
denoted by the notation $\mathcal{A} \subseteq \mathcal{B}$ where
$\mathcal{B}$ is called the \emph{Extension} or \emph{Superstructure}
of $\mathcal{A}$.

A Substructure $A$ is an \emph{Elementary Substructure} of $B$ if $A$
and $B$ both \emph{Satisfy} (\S\ref{subsec:satisfaction}) the same
Sentences. Here $B$ would be an \emph{Elementary Extension} of $A$.

When a Structure is applied as a \emph{Model}
(\S\ref{sec:model_theory}) of a particular Theory
(\S\ref{subsec:formal_theory}), if no extensions of that Structure
result in Theories that are Consistent, that Theory is termed
\emph{Complete}. A Theory $T$ is called \emph{Model Complete}
(\S\ref{subsec:model_completion}) if every Substructure of a Model of
$T$ is itself a Model of $T$.

Induced Substructures (and \emph{Closed Subsets} described in the next
section) on a Structure form a \emph{Lattice}.

% --------------------------------------------------------------------
\subsubsection{Closed Subsets}
% --------------------------------------------------------------------

%FIXME: ref Finitary Closure Operator in Set Theory
A Subset of a Domain is a \emph{Closed Subset} if it is closed under
the Operators of the Structure. For any Subset, $B$, of a Domain,
$|\mathcal{A}|$, there is a \emph{smallest Closed Subset} of
$|\mathcal{A}|$ that contains $B$ called the \emph{Hull} of $B$
denoted by $\langle B \rangle$ or $\langle B \rangle_{\mathcal{A}}$,
which is said to be \emph{generated} by $B$. $\langle \rangle$ is the
\emph{Finitary Closure Operator}.

% --------------------------------------------------------------------
\subsubsection{Embedding}\label{subsec:sigma_embedding}
% --------------------------------------------------------------------

An \emph{$\sigma$-Embedding} of two $\sigma$-Structures $\mathcal{A}$
and $\mathcal{B}$ is given by an Injective Map $h: A \hookrightarrow
B$ (the ``hooked arrow'' is used to indicate the Map is an Embedding)
where
\begin{itemize}
\item for every $f_n \in \sigma$ and $a_1, \ldots, a_n \in A^n$,
  $h(f_{n}^A(a_1,\ldots,a_n)) = f_{n}^B(h(a_1),\ldots,h(a_n))$
\item for every $R_n \in \sigma$ and $a_1, \ldots, a_n \in A^n$, $A
  \vDash R(a_1, \ldots, a_n) \leftrightarrow B \vDash R(h(a_1),
  \ldots, h(a_n))$
\end{itemize}
Such an Embedding is an \emph{Elementary Embedding} if $h(A)$ is an
Elementary Substructure (\S\ref{subsec:model_substructure}) of $B$.

% --------------------------------------------------------------------
\section{Algebraic Logic}
% --------------------------------------------------------------------

\emph{Algebraic Logic} is the reasoning arising from the manipulation
of Equations with Free Variables. Algebraic Logic deals with
\emph{Algebraic Semantics} of Classes of Algebras which are the
specification of Semantics based on \emph{Abstract Algebra}
(\S\ref{sec:abstract_algebra}). This allows the matching of Logical
Systems with Structures that Model (\S\ref{sec:model_theory}) them.

% --------------------------------------------------------------------
\subsection{Abstract Algebraic Logic}
% --------------------------------------------------------------------

\emph{Abstract Algebraic Hierarchy} (also called the \emph{Leibniz Hierarchy})

% --------------------------------------------------------------------
\subsection{Term Algebra}\label{subsec:term_algebra}
% --------------------------------------------------------------------

A \emph{Term Algebra} (also termed \emph{Absolutely Free Algebra} or
\emph{Anarchic Algebra}) is an Algebraic Structure freely generated
over a given Signature. In Category Theory a Term Algebra is an
\emph{Initial Algebra} for the Category of all Algebras with a given
Signature.

A \emph{Free Algebra}, $\mathbf{A}$, is defined by a Set of \emph{Free
  Generators}, $S$, and a Type Signature, $\rho$, which Generate an
Underlying Set, $A$. If $\psi : S \rightarrow A$ is a Function,
$\mathbf{A}$ may be represented by the Free Algebra $(A,\psi)$ if for
every Algebra $\mathbf{B}$ of type $\rho$ with Function $\tau : S
\rightarrow B$, there exists a unique Homomorphism $\sigma : A
\rightarrow B$ such that $\sigma\psi = \tau$.

% --------------------------------------------------------------------
\subsubsection{Herbrand Universe}\label{subsec:herbrand_universe}
% --------------------------------------------------------------------
\hfill \\
A \emph{Herbrand Universe} is a Structure in Logic generated by a Set
of Clauses over a Set of Constant and Function Symbols. This results
in the Herbrand Universe being composed of all Ground Terms (Terms
without Variables).

A \emph{Herbrand Base} is the set of all \emph{Ground Atoms} (Atomic
Formulas (\S\ref{subsec:formation_rules}) in which only Ground Terms
appear).

% --------------------------------------------------------------------
\subsubsection{Quotient Algebra}\label{subsec:quotient_algebra}
% --------------------------------------------------------------------

For an Algebra $\mathbf{A}$ with Underlying Set $A$, the
\emph{Quotient Set}, $A / E$ is the Partitioning of $A$ into
Equivalence Classes by a \emph{Congruence Relation}
(\S\ref{subsec:congruence_relation}) $E$. Since the Operators are
Compatible with the Equivalence Classes of the Quotient Set, these
Classes are \emph{Quotient Algebras}.

% --------------------------------------------------------------------
\subsection{Universal Algebra}\label{subsec:universal_algebra}
% --------------------------------------------------------------------

%FIXME: ref Complete Lattices
Universal Algebra is the study of \emph{Algebraic Structure} (as
opposed to specific instances of Algebraic Systems). Universal Algebra
together with \emph{Category Theory} (Part \ref{sec:category_theory})
makes up \emph{Abstract Algebra} (\S\ref{sec:abstract_algebra}). An
Algebraic Structure differs from a general \emph{Mathematical
  Structure} in that its Signature consists of only Function Symbols
and no Relation Symbols.

An Algebra may be limited by Axioms of \emph{Equational Laws} (eg. the
Associative Axiom).

% --------------------------------------------------------------------
\subsubsection{Varieties}
% --------------------------------------------------------------------

%FIXME ref Fields, Homomorphism, Subalgebra, Direct Product
A \emph{Variety} is a \emph{Class} of Algebras defined only by Axioms
that are Identities satisfied by a given Signature
(\S\ref{sec:formal_systems}). This is equivalent to saying a Variety
is the Class of Algebraic Structures with the same Signature that is
closed under \emph{Homomorphic Images}, \emph{Subalgebras}, and
\emph{Direct Products}; a result known as the \emph{HSP Theorem} or
\emph{Birkhoff's Theorem}\cite{birkhoff35}. This rules out Logical
Connectives, Existential Quantification, and all Relations besides
Equality (thus excluding the Class of \emph{Fields}) and Identities
being implicitly Universally Quantified over the Domain.

Algebraic Structures in a Variety are Quotient Algebras
(\S\ref{subsec:quotient_algebra}) generated by the Set of Identities
on the Term Algebra generated from the Signature and Underlying Set.

A \emph{Subvariety} is a Subclass of a Variety with the same Signature
(eg. the Class of \emph{Abelian Groups} is a Subvariety of the Class
of \emph{Groups}). Classes of Finite Algebras (Algebras with a finite
Underlying Set) are sometimes called \emph{Pseudovarieties}.

An example of a Variety with Signature $\Omega = (2)$ is the Class of
all \emph{Semigroups} with an equation defining the Associative Law:
\[
    x(yz) = (xy)z
\]

%FIXME: ref homomorphism
A Homomorphism between two Algebras $A$ and $B$ is a function $h: A
\rightarrow B$ defined for $n$-ary Operations:
\[
\forall f_A \in A, f_B \in B, h(f_A(x_1, ..., x_n)) = f_B(h(x_1), ...,
h(x_n))
\]

A Subalgebra of an Algebra, $A$, is a Subset of $A$ that is closed
under all the operations of $A$.

The Product of a set of Algebraic Structures is the \emph{Cartesian
  Product} of the Sets with the Operations defined coordinatewise.

% --------------------------------------------------------------------
\subsection{Elementary Class}\label{subsec:elementary_class}
% --------------------------------------------------------------------

A Class of Structures, $K$, with Signature $\sigma$ is an
\emph{Elementary Class} if there is a First-order Theory, $T$, with
Signature $\sigma$ such that $K$ contains all Models of $T$.
Expressed with the \emph{Satisfaction Relation}
(\S\ref{subsec:satisfaction}):
\[
    \mathcal{M} \in \mathcal{E}_T \leftrightarrow \mathcal{M} \vDash T
\]
where $\mathcal{E}_T$ is an Elementary Class, $\mathcal{M}$ is a
Model, and $T$ is a Theory.

If $T$ has only a single Sentence, then $K$ is a \emph{Basic
  Elementary Class}. The Reduct (\S\ref{sec:mathematical_structure})
of an Elementary Class is a \emph{Pseudoelementary Class}.

Elementary Classes are termed \emph{Axiomatizable in First-Order
  Logic} (or simply \emph{Axiomatizable} when implicitly First-Order).

The notion of \emph{Strength} of Formal Systems is defined in terms of
Elementary Clases. A Logic $\alpha$ is equal to another Logic $\beta$
when every Elementary Class in $\beta$ is an Elementary Class in
$\alpha$.

% --------------------------------------------------------------------
\subsection{Ultraproducts}\label{subsec:ultraproducts}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\section{Model Theory}\label{sec:model_theory}
% --------------------------------------------------------------------

\emph{Model Theory}, Formal Language (Part \ref{sec:formal_language}),
and Formal Logic (\S\ref{sec:formal_systems}) together compose the
study of \emph{Metalogic}. One definition of Model Theory is the
combination of Formal Logic with \emph{Universal Algebra}
(\S\ref{subsec:universal_algebra}). An alternative view of Model
Theory equates it with \emph{Algebraic Geometry}
(\S\ref{subsec:algebraic_geometry}). The broadest definition of Model
Theory includes four divisions: Classical Model Theory, Model Theory
of Groups and Fields, Geometric Model Theory, and Computable Model
Theory (\S\ref{subsec:computable_model_theory}).

\emph{Models} are \emph{Interpretations}
(\S\ref{subsec:interpretation}) of Theories
(\S\ref{subsec:formal_theory}) in a Formal Language. That is, an
Interpretation is a Model if it assigns Truth values to the Sentences
of a Theory. Model Theory uses Tarski's Semantic Theory of Truth
(\S\ref{sec:semantic_truth}) as the definition of Truth. Model Theory
also forms the foundation of \emph{Formal (Truth-conditional)
  Semantics}-- a reduction of the Meaning of Assertions in Natural
Languages to their Truth-conditions.

% --------------------------------------------------------------------
\subsection{Satisfaction}\label{subsec:satisfaction}
% --------------------------------------------------------------------

When defining a Theory as a set of Sentences in a Formal Language, a
\emph{Model} is an \emph{Interpretation} that \emph{Satisfies} the
Sentences of that Theory. For a Formula $\phi$ and a Structure
$\mathcal{M}$, a \emph{Satisfaction Relation} is denoted:
\[
    \mathcal{M} \vDash \phi
\]
For $\mathcal{M}$ to be a Model of a Theory, $T$, it is required that:
\begin{itemize}
\item The Language of $\mathcal{M}$ is the same as the Language of $T$
\item Every Sentence in $T$ is Satisfied by $\mathcal{M}$
\end{itemize}
%FIXME ref completeness theorem
By the Completeness Theorem a Consistent Theory is Satisfiable, that
is, a Theory has a Model if and only if it is Consistent. The
Compactness Theorem (\S\ref{subsec:first_order_properties}) implies
that a Theory has a Model if and only if every Finite Subset of the
Sentences in that Theory also have Models.

% --------------------------------------------------------------------
\subsection{Quantifier Elimination}
% --------------------------------------------------------------------

Within a Theory $T$, if every First-order Formula $\varphi(x_1,
\ldots, x_n)$ with Quantifiers is equivalent to a First-order Formula
$\psi(x_1, \ldots, x_n)$ without Quantifiers, $T$ is said to have the
property of \emph{Quantifier Elimination}. A Theory without Quantifier
Elimination may be made to have it by adding Symbols to its Signature.

% --------------------------------------------------------------------
\subsection{Model Completion}\label{subsec:model_completion}
% --------------------------------------------------------------------

A First-order Theory $T$ is called \emph{Model Complete} if every
Embedding (\S\ref{subsec:sigma_embedding}) of Models of $T$ is an
Elementary Embedding.

A Theory $T^*$ is a \emph{Companion} of another Theory $T$ if every
Model of $T$ can be Embedded in a Model of $T^*$ and likewise every
Model of $T^*$ can be Embedded in a Model of $T$. A \emph{Model
  Companion} is a \emph{Companion} of a Theory that is \emph{Model
  Complete}.

%FIXME ref Amalgamation Property
A \emph{Model Completion} is a Model Companion $T^*$ of a Model $T$
that has the \emph{Amalgamation Property}. This means that every Model
of $T$ can be uniquiely Embedded in a Model of $T^*$.

% --------------------------------------------------------------------
\subsection{Categoricity}
% --------------------------------------------------------------------

%FIXME ref Cardinal, Lowenheim-Skolem
A Theory is termed \emph{Categorical} if all its Models are
Isomorphic. With this definition and the L\"owenheim-Skolem Theorem it
follows that any First-order Theory with a Model of infinite
Cardinality can't be Categorical.

For a Cardinal $\kappa$, a Theory $T$ is \emph{$\kappa$-Categorical}
if any two Models of $T$ of Cardinality $\kappa$ are Isomorphic to one
another. By \emph{Morley's Categoricity Theorem}\cite{morley65} if a
First-order Theory in a Countable Language is Categorical in an
Uncountable Cardinal $\kappa$, then it is Categorical in all
Uncountable Cardinalities. There are three possible cases for
$\kappa$-Categoricity:
\begin{description}
\item[Totally Categorical] $\kappa$-Categorical for all Infinite
  Cardinals
\item[Uncountably Categorical] $\kappa$-Categorical if and only if
  $\kappa$ is an Uncountable Cardinal
\item[Countably Categorical] $\kappa$-Categorical if and only if
  $\kappa$ is a Countable Cardinal
\end{description}
The special case of $\kappa = \aleph_0$ is called
\emph{$\omega$-Categorical}.

% --------------------------------------------------------------------
\subsection{Interpretability}
% --------------------------------------------------------------------

Given two Structures, $M$ and $N$, an \emph{Interpretation} of $M$ in
$N$ is a pair $(n,f)$ where
\begin{itemize}
    \item $n \in \mathbb{N}$
    \item $f:f_{dom} \subset N^n \rightarrow M$ such that the
      $f^k$-preimage of every set $X \subseteq M^k$ definable in $M$
      by a First-order Formula is definable in $N$ by a First-order
      Formula
\end{itemize}

Two Structures are \emph{Bi-interpretable} if they can be interpreted
in each other. This can be used to define an Equivalence Relation
between Structures.

% --------------------------------------------------------------------
\subsection{Abstract Model Theory}
% --------------------------------------------------------------------

\subsubsection{Abstract Logic}

An \emph{Abstract Logic} is a Formal System that consists of a Class
of Sentences with a Satisfaction Relation
(\S\ref{subsec:satisfaction}).

%FIXME compactness, lowenheim-skolem
\emph{Lindstr\"om's Theorem} states that First-order Logic is the
Strongest (\S\ref{subsec:elementary_class}) Logic which has both
Countable Compactness and the Downward L\"owenheim-Skolem Property.

\subsubsection{Institutional Model Theory}

\emph{Institutional Model Theory} generalizes First-order Model Theory
to arbitrary Logical Systems formalized as \emph{Institutions}
(\S\ref{subsec:institution_theory}).

% --------------------------------------------------------------------
\subsection{Finite Model Theory}
% --------------------------------------------------------------------

\emph{Finite Model Theory} (FMT) is a restriction of Model Theory to
Interpretations of Finite Structures.

A Finite Structure can always be described by a single First-order
Sentence. An example structure of $n$ Elements:
\[
    \exists x_1 \cdots \exists x_n ( \varphi_1 \wedge \cdots \wedge
    \varphi_m )
\]
This may be extended to a Finite number of Structures:
\[
    \exists x_1 \cdots \exists x_n ( \varphi_1 \wedge \cdots \wedge
    \varphi_m )
    \vee
    \cdots
    \vee
    \exists x_1 \cdots \exists x_p ( \psi_1 \wedge \cdots \wedge
    \psi_q )
\]
Note the difference here with Infinite First-order Model Theory in
which a Model cannot be uniquely determined by a set of First-order
Sentences because of the Compactness Theorem (For every Infinite Model
a Non-isomorphic Model exists).

The ability of a Property $P$ to be expressed in First-order Logic may
be determined by whether two Structures $A \in P$ and $B \notin P$
satisfy all the same First-order Sentences:
\[
    A \vDash \alpha \leftrightarrow B \vDash \alpha
\]

% --------------------------------------------------------------------
\subsection{Computable Model Theory}\label{subsec:computable_model_theory}
% --------------------------------------------------------------------

\cite{harizanov98}

% --------------------------------------------------------------------
\subsection{Geometric Model Theory}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsubsection{Classification Theory}
% --------------------------------------------------------------------

\emph{Classification Theory} is the division of Theories based on
their \emph{Stability} which is the ability of the Models of the
Theory to be \emph{Classified}.

% --------------------------------------------------------------------
\subsubsection{Types}
% --------------------------------------------------------------------

An \emph{$n$-type} of a Model, $\mathcal{M}$, over a (possibly empty)
Subset of Constants, $A \in M$, is a set of Formulas,
$p(x_1,\ldots,x_n) = p(\mathbf{x})$, with at most $n$ Free Variables
in the Language $L(A)$, formed by adding the members of $A$ to the
Language of $\mathcal{M}$:
\[
    L(A) = L \cup \{ c_a : a \in A \}
\]
such that for every Finite Subset $p_0(\mathbf{x}) \subseteq
p(\mathbf{x})$ there exist Elements $b_1,\ldots,b_n \in M$ with
$\mathcal{M} \vDash p_0(b_1,\ldots,b_n)$.

A \emph{Complete Type} is \emph{Maximal}
(\S\ref{subsec:formal_theory})) under Inclusion such that $\forall
\phi(\mathbf{x}) \in L(A,\mathbf{x})$ either $\phi(\mathbf{x}) \in
p(\mathbf{x})$ or $\neg \phi(\mathbf{x}) \in p(\mathbf{x})$. A
non-Complete type is called a \emph{Partial Type}.

An $n$-type is \emph{Realized} in $\mathcal{M}$ if there is an Element
$\mathbf{b} \in M^n$ such that $\mathcal{M} \vDash
p(\mathbf{b})$. This is guaranteed by the Compactness Theorem
(\S\ref{subsec:first_order_properties}) in either $\mathcal{M}$ or an
Elementary Extension (\S\ref{subsec:model_substructure}) of
$\mathcal{M}$. This is denoted by $tp_{n}^{\mathcal{M}}(\mathbf{b}/A)$
which is read as ``the Complete Type of $\mathbf{b}$ over $A$''.

A Type $p(\mathbf{x})$ is \emph{Isolated} by a Formula
$\varphi(\mathcal{x})$ if $\forall \psi(\mathbf{x}) \in
p(\mathbf{x})$, $\varphi (\mathbf{x}) \rightarrow
\psi(\mathbf{x})$. Isolated Types are Realized in every Elementary
Substructure or Extension.

\paragraph{Saturation}\label{subsec:model_saturation}\hfill
\\

A Model $\mathcal{M}$ is \emph{$\kappa$-saturated} (where $\kappa$ is
a Cardinal number) if for all $A \subseteq M$ of Cardinality $<
\kappa$, $M$ Realizes all Complete Types over $A$. A Model is
\emph{Saturated} if it is $|M|$-saturated where $|M|$ is the
Cardinality of $M$.

\subsubsection{Stability}\label{subsec:model_stability}

A Theory $T$ is \emph{$\kappa$-stable} for an Infinite Cardinal $\kappa$
if for every set $A$ such that $|A| = \kappa$, the Set of Complete
Types over $A$ has Cardinality $\kappa$. Theories are Classified with
the following terms:
\begin{description}
\item [Stable] $\kappa$-stable for some Infinite Cardinal $\kappa$
\item [Unstable] not $\kappa$-stable for all Infinite Cardinals $\kappa$
\item [Superstable] $\kappa$-stable for all sufficiently large
  Cardinals $\kappa$
\item [Totally Transcendental] \emph{Morley Rank}\cite{morley65} less
  than $\infty$
\end{description}

% --------------------------------------------------------------------
\section{Kripke Semantics}
% --------------------------------------------------------------------

\emph{Kripke Semantics} is the extension of Model Theory to
Non-classical Logic Systems, beginning with Modal Logic
(\S\ref{subsec:modal_logic}).

\begin{description}
\item [Kripke Frame] $\langle W,R \rangle$ where $W$ is a Non-empty
  Set of \emph{Nodes} (\emph{Worlds}) and $R$ is a Binary Relation
  called the \emph{Accessibility Relation}
\item [Kripke Model] $\langle W,R,\Vdash \rangle$ where $\Vdash$ is a
  \emph{Forcing Relation} for Nodes of $W$
\end{description}
Accessbility Relation % FIXME describe accessibility

The Forcing Relation $\Vdash$ (read as Satisfies or \emph{Forces}
(\S\ref{subsec:forcing})) has the following properties:
\begin{itemize}
\item $w \Vdash \neg A$ if and only if $w \nVdash A$
\item $w \Vdash A \rightarrow B$ if and only if $w \nVdash A$ or $w
  \Vdash B$
\item $w \Vdash \square A$ if and only if $u \Vdash A$ for all $u$
  such that $w R u$
\end{itemize}
\emph{Validity} of a Proposition is defined for
\begin{itemize}
\item Model $\langle W,R, \Vdash \rangle$ if $\forall w \in W,
  w \Vdash A$
\item Frame $\langle W,R \rangle$ if Valid in Model $\langle W,R,
  \Vdash \rangle$ for all choices of $\Vdash$
\item Classes of Frames or Models if Valid for all Frames or Models of
  the Class
\end{itemize}
$Thm(C)$ is defined as the Set of all Formulas Valid in $C$. For a Set
of Formulas $X$, $Mod(X)$ is defined as the Class of all Frames which
Validate every Formula in $X$.

% --------------------------------------------------------------------
\subsection{Boolean-valued Model}
% --------------------------------------------------------------------

\emph{Boolean-valued Models} are related to Heyting Algebras and
Intuitionistic Logic and is equivalent to the method of Forcing.

% --------------------------------------------------------------------
\section{Proof-theoretic Semantics}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\section{Truth-value Semantics}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\section{Game-theoretic Semantics}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\section{Probabilistic Semantics}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Algebraic Geometry}\label{subsec:algebraic_geometry}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\section{Denotational Semantics}
% --------------------------------------------------------------------

Semantic Consequence of a Logic System

Tautology

Material Consequence

Logical Harmony

Semantic Tableau

% --------------------------------------------------------------------
\section{Axiomatic Semantics}
% --------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Type Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Curry-Howard Correspondence

% --------------------------------------------------------------------
\section{$\lambda$-Calculus}\label{sec:lambda_calculus}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\section{Intuitionistic Type Theory}
% --------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Set Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% --------------------------------------------------------------------
\subsection{Congruence Relation}\label{subsec:congruence_relation}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Filters}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Forcing}\label{subsec:forcing}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\section{Order Theory}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\section{Relation Algebra}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\section{Descriptive Set Theory}
% --------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Graph Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Category Theory}\label{sec:category_theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% --------------------------------------------------------------------
\section{Abstract Algebra}\label{sec:abstract_algebra}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Relation Algebra}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Relational Algebra}
% --------------------------------------------------------------------

\emph{Domain Relational Calculus}

% --------------------------------------------------------------------
\subsection{Institution Theory}\label{subsec:institution_theory}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsection{Representation Theory}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\section{Initial Algebra}\label{sec:initial_algebra}
% --------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Topology}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Complexity Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% --------------------------------------------------------------------
\section{Algorithms}
% --------------------------------------------------------------------

An \emph{Algorithm} may be formalized as a sequence of operations that
can be simulated by a Turing-complete system and any function
that is computable by Algorithm is a \emph{computable function}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Database Theory}\label{sec:database_theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% --------------------------------------------------------------------
\section{Relational Model}\label{sec:relational_model}
% --------------------------------------------------------------------


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{99}

\bibitem{turing38}
    Alan Turing,
    \emph{Systems of Logic Based on Ordinals},
    Princeton,
    1938.

\bibitem{kozen97}
    Dexter C. Kozen,
    \emph{Automata and Computability},
    Springer,
    1997

\bibitem{aho69}
    Alfred V. Aho,
    \emph{Nested stack automata},
    Journal of the ACM,
    1969

\bibitem{villemonte02}
    \'Eric Villemonte de la Clergerie,
    \emph{Parsing mildly context-sensitive languages with thread automata},
    COLING '02 Proceedings,
    2002

\bibitem{vijayashanker88}
    K. Vijayashanker,
    \emph{A study of tree adjoining grammars},
    University of Pennsylvania,
    1988

\bibitem{schutzenberger65}
    Mercel-Paul Sch\"utzenberger,
    \emph{On finite monoids having only trivial subgroups},
    Information and Computation,
    1965

\bibitem{mcnaughton-papert71}
    Robert McNaughton, Seymour Papert,
    \emph{Counter-free Automata},
    MIT Press,
    1971

\bibitem{skolem23}
    Thoralf Skolem,
    \emph{The foundations of elementary arithmetic},
    1923,
    trans. Jean van Heijenoort,
    \emph{From Frege to G\"odel: A Source Book in Mathematical Logic, 1879-1931},
    Harvard Univ. Press,
    1967

\bibitem{jaskowski34}
    Stanislaw Ja\'skowski,
    \emph{On the Rules of Suppositions in Formal Logic},
    1934,
    ed. Storrs McCall,
    \emph{Polish logic 1920-39},
    Oxford,
    1967

\bibitem{shapiro00}
    S. Shapiro,
    \emph{Foundations without Foundationalism: A Case for Second-order
    Logic},
    Oxford University Press,
    2000

\bibitem{prawitz65}
    Dag Prawitz,
    \emph{Natural Deduction: A proof-theoretical study},
    A\&W Stockholm,
    1965

\bibitem{schutte77}
    Kurt Sch\"utte,
    \emph{Proof Theory},
    Springer-Verlag,
    1977

\bibitem{birkhoff35}
    Garrett Birkhoff,
    \emph{On the Structure of Abstract Algebras},
    Proceedings of the Cambridge Philosophical Society,
    1935

\bibitem{tarski36}
    Alfred Tarski,
    \emph{Der Wahtheitsbegriff in den formalisierten Sprachen},
    Studia Philosophica,
    1936

\bibitem{ramsey27}
    F.P. Ramsey,
    \emph{Facts and Propositions},
    Aristotelian Society Supplementary Volume 7,
    1927

\bibitem{morley65}
    Michael Morley,
    \emph{Categoricity in Power},
    Transactions of the American Mathematical Society, Vol. 114, No. 2,
    1965

\bibitem{harizanov98}
    Valentina Harizanov,
    \emph{Pure Computable Model Theory},
    Studies in Logic and the Foundations of Mathematics,
    1998

\end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
