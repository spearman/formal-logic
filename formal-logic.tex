%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}

% --------------------------------------------------------------------

\title{Mathematical Logic}
\date{}
\maketitle

% --------------------------------------------------------------------

\tableofcontents

% --------------------------------------------------------------------

\part{Formal Systems}

\section{Formal Language Syntax}

The $Syntactic$ structure of a $Language$ as defined by a $Grammar$ is
outlined below.

A $Formal$ $Language$, $L$, is a possibly infinite subset of an
infinite $Vocabulary$, $\Sigma^*$, that is the set of all possible
finite $Symbols$ over a possibly infinite $Alphabet$, $\Sigma$, whose
members will be called $Glyphs$ to differentiate from $Symbols$. This
set $\Sigma^*$ is the Kleene star or Free monoid of $\Sigma$; the
smallest superset of $\Sigma$ that is closed under string
concatenation.

The $Syntax$ is that part of the $Language$ that refers only to the
literal strings of characters or $Symbols$ of the $Language$ with no
regard to their meaning or interpretation; only the condition that
they can be identified and differentiated from one-another is
required.

The entire content of a $Language$ is uniquely determined by the set
of all $Terminal$ strings generated by the $Production$ or rewrite
rules of a $Grammar$. This possibly infinite set of $Terminals$ will
be a subset of the $Vocabulary$ over an $Alphabet$.

\subsection{Lexical Elements}

The definition of a $Grammar$ and hence a $Language$ determined by it
will not involve any units smaller than the $Symbol$ and because of
the finite size of the $Alphabet$ available in most situations,
$Symbols$ are composed of 0 or more of the $Glyphs$ that uniquely
determine the $Alphabet$. An alternative to the finite $Alphabet$ may
be achieved by indexed subscripting. $Alphabets$ of $Glyphs$ will be
termed '$Lexical$' to differentiate from $Syntactic$ $Elements$
($Vocabularies$ of $Symbols$).

    \begin{description}

    \item[Glyph] \hfill \\
    a single character or letter

    \item[Alphabet ($\Sigma$)] \hfill \\
    a possibly infinite set of all $Glyphs$ used to compose the
    $Symbols$ of a $Language$

    \end{description}

\subsection{Syntactic Elements}

Within a $Language$ defined by a $Grammar$ over a given $Vocabulary$,
the $Symbols$ will be divided into two disjoint subsets according to
whether they are $Terminal$ or $Non$-$terminal$ $Symbols$.

The definition of a $Non$-$terminal$ $Symbol$ is one for which a
$Production$ rule exists in the $Grammar$ with that $Symbol$ as the
input $Expression$ to the $Production$. Thus a $Grammar$ is specified
by a finite set of $Productions$, $P$, a finite set of $Non$-$terminal$
$Symbols$, $N$, and a finite set of $Terminal$ $Symbols$,
$T$. Additionally, in certain $Grammars$ it is allowed for multiple
$Non$-$terminals$ to appear in an $Expression$, that is one or more
$Symbols$ taken together. However, since the $Vocabulary$ is a closed
set under string concatenation, the set of $Symbols$ and $Expressions$
will be identical by members.

    \begin{description}

    \item[Symbol] \hfill \\
    a word consisting of a finite string (ordered set) of $Glyphs$
    over an $Alphabet$

    \item[Expression] \hfill \\
    a finite string of $Symbols$

    \item[Vocabulary ($\Sigma^{*}$)] \hfill \\
    set of all $Symbols$ and $Expressions$ over an $Alphabet$

    \item[Production] \hfill \\
    a rule specifying a $Non$-$terminal$ $Symbol$ substitution

    \item[Grammar] \hfill \\
    a finite set of $Productions$ over the $Symbols$ of a $Vocabulary$

    \end{description}

\paragraph{Special Symbols}

Two special $Symbols$ are recognized:

    \begin{description}

    \item[Empty Symbol ($\varepsilon$)] \hfill \\
    the $Symbol$ of zero length and a $Terminal$ $Symbol$

    \item[Start Symbol ($S$)] \hfill \\
    a unique $Non$-$terminal$ $Symbol$

    \end{description}

A $Grammar$ $generates$ a $Language$ by the repeated application
of its $Production$ $Rules$ beginning with the $Start$ $Symbol$. A
sequence of rule applications is a $Derivation$.

Formal definition of a $Grammar$ as a 4-tuple:
\[
    G(N,T,P,S)
\]

The unrestricted form of a $Production$:
\[
    (N \cup T)^*N(N \cup T)^* \rightarrow (N \cup T)^*
\]
That is, a function from one $Expression$ to another, where the left
$Expression$ must contain at least one $Non$-$terminal$ $Symbol$. By
convention, $Non$-$terminal$ $Symbols$ will be denoted by capitals
($A,B,C,\cdots$), and $Terminals$ by lowercase ($a,b,c,\cdots$), and
expressions by Greek letters ($\alpha,\beta,\gamma$).

Let:

\[
    \mathcal{A} = \{ Alphabets \},\: \mathcal{V} = \{ Vocabularies \}
\] \[
    \mathcal{G} = \{ Grammars \},\: \mathcal{L} = \{ Languages \}
\]

    \begin{description}

    \item Definition of the Kleene star or Free monoid over an
      $Alphabet$ where $++$ is the operation to $Concatenate$ two
      strings of $Glyphs$:
    \[
        \forall \: \Sigma \in \mathcal{A} \:
        \exists \: \Sigma^* \in \mathcal{V}
        : \Sigma^* = \bigcup_{i=0}^{|\Sigma|} \Sigma_i
        = (\Sigma,++)
    \]

    \item Definition of a $Language$ in terms of a $Vocabulary$:
    \[
        \forall \: L \in \mathcal{L} \:
        \exists \: \Sigma^* \in \mathcal{V}
        : L \subseteq \Sigma^*
    \]

    \item Existence of the $Empty$ $Symbol$, $\varepsilon$:
    \[
        \forall \: \Sigma^* \in \mathcal{V} \:
        \exists ! \: \varepsilon \in \Sigma^*
        : |\varepsilon|=0
    \]

    \end{description}

\subsection{Formal Grammars}

\subsubsection{Chomsky Hierarchy}

Possible $Grammars$ are classified by how restrictive the $Production$
rules are. By convention, They may be organized into a hierarchy of
sets under proper inclusion, where $Type$-$0$ is an unrestricted
grammar, covering all possible formal grammars.

\[
    Type-0 \supset Type-1 \supset Type-2 \supset Type-3
\]

 These different levels in the hierarchy are also $Recognizable$ by
 different formulations of $Automata$ described in the next section.

\paragraph{Type-0: Unrestricted}

    \subparagraph{Semi-decidable}
    $Production$ $rules$ of an $Unrestricted$ $Grammar$ have the form
    \[
        \alpha \rightarrow \beta
    \]
    where $\alpha$ and $\beta$ are $Expressions$ of $N \cup T$ and
    $\alpha \neq \varepsilon$.

    A completely unrestricted $Grammar$ is called $recursively$
    $enumerable$ or $Semi$-$decidable$. This means membership of the
    $Language$ can be decided by an algorithm, but non-membership
    cannot, and the class of $Languages$ having this property is
    called $\mathsf{RE}$. Members of this class are also $Diophantine$
    sets and the lattice of $\mathsf{RE}$ sets under inclusion is
    written $\mathcal{E}$.

    The complement of $\mathsf{RE}$ is the class of $Languages$ for
    which an algorithm may decide non-membership only and is termed
    $\mathsf{coRE}$. The class of automata capable of implementing
    these algorithms is the $Turing$ $Machine$.

    \subparagraph{Decidable}
    A $recursive$ (as opposed to $recursively$ $enumerable$) or
    $Decidable$ $Language$ is defined as the intersection of
    $\mathsf{RE}$ and $\mathsf{coRE}$:
    \[
        \mathsf{R} = \mathsf{RE} \cap \mathsf{coRE}
    \]
    That is, it can be decided whether a $Symbol$ is a member or not
    by a $total$ $computable$ $function$ (one which returns $True$ or
    $False$ depending on membership). $Decidable$ $Languages$ are
    recognizable by a $decider$ or $Total$ $Turing$ $Machine$.

\paragraph{Type-1: Context-sensitive}

    \subparagraph{Context-sensitive}
    $Context$-$sensitive$ $Grammars$ have the restriction that the
    result of a $Production$ is not shorter than the input. Formally
    stated $Productions$ are of the form
    \[
        \alpha A \beta \rightarrow \alpha \gamma \beta
    \]
    where $|A| => |\gamma|$. In this formulation $\alpha$ and $\beta$
    form the $Context$ of $A$.

    Requiring that $S$ does not appear on the right of any
    $Production$ and allowing the rule
    \[
        S \rightarrow \varepsilon
    \]
    makes the $Context$-$sensitive$ $Languages$ a proper superset of the
    $Context$-$free$ $Languages$.

    $Context$-$sensitive$ $Languages$ are equivalent to a $Linear$
    $Bounded$ $Automaton$ (a linear bounded non-deterministic $Turing$
    $Machine$).

    \subparagraph{Indexed}

    An $Indexed$ $Grammar$ has an extra set of $Symbols$ $F$, the
    $Indexed$ $Symbols$. $Productions$ are of three possible forms,
    \[
        A[\sigma] \rightarrow \alpha[\sigma]
    \]\[
        A[\sigma] \rightarrow B[f\sigma]
    \]\[
        A[f\sigma] \rightarrow \alpha[\sigma]
    \]
    where $f \in F$ and $\sigma$ is a string of $Index$ $Symbols$.

    In effect these are used to form a $stack$ by the $Production$
    rules where $Indices$ are either pushed or popped from the stack.

    A $Indexed$ $Language$ can be recognized by a $Nested$ $Stack$
    $Automaton$.

    \subparagraph{Generalized Contex-free}
    A $Generalized$ $Context$-$free$ $Grammar$ adds to the rewrite rules
    of a $Context$-$free$ $Grammar$ a set of non-context-free
    $composition$ $functions$ that combine tuples of symbols:
    \[
        f(\langle x_1,\cdots,x_m\rangle,\cdots,\langle
        y_1,\cdots,y_n\rangle)=\gamma
    \]
    where $\gamma$ is a single tuple or another composition function
    that reduces to a single tuple.

    Rules are of the form:
    \[
        A \rightarrow f(X,Y,\cdots)
    \]
    where $X$,$Y$,$\cdots$ are string tuples or $Non$-$terminal$ $Symbols$.

    There are several weakly equivalent to the composition formulation.

    \begin{description}
    \item[Linear context-free rewriting system]
    Weakly equivalent to $multi$-$component$ $Tree$-$adjoining$ $Grammars$
    where composition functions are both $linear$ and $regular$. Can
    be recognized by $Thread$ $Automata$.
    \item[Tree-adjoining]
    Elementary rewriting unit is a tree rather than a $Symbol$. Can be
    recognized by $Embedded$ $pushdown$ $automata$.
    \item[Linear indexed grammar]
    A modified $Indexed$ $Grammar$ where only one symbol receives the stack.
    \item[Combinatory Categorical Grammar]
    A type of $shrase$ $Structure$ $Grammar$ using $Combinatory$ $Logic$.
    \item[Head grammar]
    A subset of the $Linear$ $context$-$free$ $rewriting$ $system$ and a
    $Phrase$ $Structure$ $Grammar$.
    \end{description}

\paragraph{Type-2: Context-free}

    \subparagraph{Context-free}
    $Context$-$free$ $Grammars$ have production rules of the form
    \[
        V \rightarrow w
    \]
    where $V$ is a single $Non$-$terminal$ and $w$ is a string of
    $Terminals$ and/or $Non$-$terminals$ (or empty). Because $V$ is
    required to be a single $Non$-$terminal$, the $Production$ rules
    can be applied regardless of $Context$. Each $Non$-$terminal$ in a
    $Context$-$free$ $Grammar$, $G$, is said to form a
    $Sub$-$Language$ of the $language$ defined by $G$.

    Multiple $Context$-$free$ $Grammars$ may generate the same
    $Language$, so properties of $CFG$s may be termed $extrinsic$
    while $Language$ properties are $intrinsic$. The question of
    equality between $CFG$s is undecidable.

    A popular notation for $Context$-$free$ $Grammars$ is
    $Backus$-$Naur$ $form$ ($BNF$). The term used in $Linguistics$ for
    $Context$-$free$ $Grammar$ is $Phrase$ $Structure$ $Grammar$ which
    is also called $constituency$ $grammar$ due to the
    one-to-one-or-many correspondence between the $Productions$
    (ultimately rooted in the $subject$-$predicate$ clause deriving
    from $Term$ $Logic$). The alternative is $Dependency$ $Grammar$ in
    which the $Verb$ is the root and there is a one-to-one
    correspondence between $Symbols$ and nodes in the syntax
    structure.

    The $Context$-$free$ $Grammar$ is equivalent to
    $Non$-$deterministic$ $Pushdown$ $Automata$.

    \subparagraph{Deterministic}
    $Deterministic$ $Context$-$free$ $Grammars$ are derived from
    $Deterministic$ $Pushdown$ $Automata$ and are always
    $unambiguous$. They can be parsed in linear time and a parser can
    be automatically generated from the $Grammar$ by a
    $parser$-$generator$.

    \subparagraph{Visibly Pushdown}
    $Visibly$ $Pushdown$ $Grammars$ are described by the 4-tuple
    \[
        G = (V=V^0 \cup V^1,T,P,S)
    \]
    where $V^0$ and $V^1$ are disjoint sets of $Non$-$terminals$ and
    there are three kinds of $Production$ rules:
    \[
        X \rightarrow \varepsilon
    \]\[
        X \rightarrow aY
    \]\[
        X \rightarrow \langle aZb \rangle Y
    \]
    where $Z \in V^0$ and if $X \in V^0$ then $Y \in V^0$

    The resulting $Language$ is a $Regular$ $Language$ with $nested$
    $words$, described by a $Monadic$ $Second$-$order$ $Logic$.

\paragraph{Type-3: Regular}

    \subparagraph{Extended Regular}
    $Extended$ $Regular$ $Grammars$ have $Productions$ of either
    $right$ $Regular$ or $left$ $Regular$ form.

    $Right:$
    \[
        B \rightarrow a
    \]\[
        A \rightarrow Bw
    \]\[
        A \rightarrow \varepsilon
    \]
    $Left:$
    \[
        A \rightarrow a
    \]\[
        A \rightarrow Bw
    \]\[
        A \rightarrow \varepsilon
    \]
    where $a$ is a single $Non$-$terminal$ and $w$ is an expression of
    only $Non$-$terminal$ characters.

    \subparagraph{Strictly Regular}
    $Strictly$ $Regular$ $Grammars$ also have $Productions$ of either
    $right$ $Regular$ or $left$ $Regular$ form.

    $Right:$
    \[
        B \rightarrow a
    \]\[
        B \rightarrow aC
    \]\[
        B \rightarrow \varepsilon
    \]
    $Left:$
    \[
        A \rightarrow a
    \]\[
        A \rightarrow Ba
    \]\[
        A \rightarrow \varepsilon
    \]
    where $a$ is a single $Non$-$terminal$ and $w$ is an expression of
    only $Non$-$terminal$ characters.

    There is a one-to-one correspondence between the rules of a
    $Strictly$ $Left$ $Regular$ $Grammar$ and those of a
    $Non$-$deterministic$ $Finite$ $Automaton$.

    The $pumping$ $lemma$ states that the middle section of an
    $Expression$ within a $Regular$ $Language$ may be repeated an
    arbitrary number of times to produce another $Expression$ in that
    same $Language$.

    \subparagraph{Star-free}
    A $Star$-$free$ $Language$ is one having a $Generalized$ $Star$
    $Height$ equal to $Zero$, that is, the minimal $Star$ $Height$ of
    all $Expressions$ in the $Language$ with the $Star$ $Height$ of an
    $Expression$ $compliment$ being equal.

    $Star$-$free$ $Languages$ are characterized as those with
    $Aperiodic$ $Syntactic$ $Monoids$. Also as the $Counter$-$free$
    $Langauges$ by the $Aperiodic$ $Finite$-$state$ $Automaton$, and
    $Linear$ $Temporal$ $Logic$.

\subsubsection{Affix Grammars}

    $Affix$ $Grammars$ are those of a $Context$-$free$ $Grammar$ with
    a subset of the $Non$-$terminals$ used as $affix$ $arguments$. If
    the same $affix$ appears multiple places in a $Production$, the
    $value$ must be the same.

    \paragraph{Two-Level Grammars}
    Allowing the $values$ for $affixes$ to be described by a
    $Context$-$free$ $Grammar$ results in a $Two$-$Level$ $Grammar$.

    $Two$-$Level$ $Grammars$ are $Grammar$ generators that may
    generate $Grammars$ with infinite rules.

    \begin{description}
    \item[W-grammar] $Van$ $Wijngaarden$ $Grammar$
    Consists of a finite set of $meta$-$rules$ used to derive a
    possibly infinite set of $Production$ rules from a finite set of
    $hyper$-$rules$.
    \item[Extended Affix Grammar]
    A restricted $W-grammar$.
    \end{description}

    \paragraph{Attribute Grammars}
    $Attribute$ $Grammars$ allows $affixes$ from arbitrary domains and
    allows functions calculate values of $affixes$.

\subsubsection{Analytic Grammars}

    $Analytic$ $Grammars$ are used in $Parsing$ (see next section).

    \begin{description}
    \item[Top-Down Parsing Language] Formal representation of a
      $Recursive$ $Descent$ $Parser$. $Production$ rules of the form
    \[
        A \leftarrow \varepsilon
    \]\[
        A \leftarrow f
    \]\[
        A \leftarrow a
    \]\[
        A \leftarrow BC/D
    \]
    \item[Parsing Expression Generator]
    A more generalized $Top$-$Down$ $Parsing$ $Language$.
    \item[Link Grammar]
    $Dependency$ $Grammar$ with directionality between $Symbols$.
    \end{description}

\subsubsection{Automata}

\subsubsection{Parsers}

    A $Parser$ analyzes an $Expression$ according to the rules of a
    $Formal$ $Grammar$ generating a $Data$ $Structure$ describing the
    $Syntax$ of the input.

    \paragraph{Lexical Analysis}
    A $Parser$ may be preceded by a $Lexical$ $Analyzer$ which creates
    $Tokens$ ($Symbols$) from a string of input
    $Glyphs$. $Expressions$ of $Tokens$ are referred to as
    $Phrases$. A $Lexical$ $Analyzer$ is a $Parser$ itself and usually
    the $Lexical$ $Grammar$ is a $Regular$ $Language$ (other methods
    are $flags$, $delimiters$, or $dictionary$) and the $Tokens$ are
    parsed as a $Context$-$free$ or $Attribute$ $Phrase$ $Syntax$.

    Prior to $Scanning$, a $Lexer$ may perform its own $Tokenization$.
    The $Scanning$ stage first recognizes the $Token$ strings as
    $Lexemes$, usually achieved by a $Finite$ $State$ $Machine$.

    $Lexemes$ are resolved into $Tokens$ by an $Evaluator$ which
    assigns values where needed-- this results in $Tokens$ that are
    either a $Type$-$Value$ pair, or just a $Type$.

    \paragraph{Syntactic Analysis}

    The $Parser$ determines if and how the input can be derived from
    the $Start$ $Symbol$ of the $Grammar$.

    $Parsing$ can proceed in two directions:

    \begin{description}
    \item[Top-down Parsing]
    starts with the highest level of the $Parse$ $Tree$. Proceeds
    greedily and may be $Exponential$ with $Backtracking$.
    \item[Bottom-up Parsing]
    starts with the lowest level of the $Parse$ $Tree$.
    \end{description}

    Further $Semantic$ $Parsing$ may be performed after these
    steps. An example of this would be the in the $Compiler$ of a
    $Programming$ $Language$.

\subsection{Deductive Apparatus}

\subsubsection{Axiom Schemata}

\subsubsection{Inference Rules}

\section{Logic Systems}

A $Formal$ $Language$ in combination with a $Deductive$ $Apparatus$
gives rise to a $Logic$ $System$.

\subsection{Zeroth-order - Propositional}

\subsection{First-order - Predicate}

\subsection{Second-order - Plural}

\subsection{Higher-order}

\subsection{Algebraic Logic}


% --------------------------------------------------------------------

\part{Proof Theory}

% --------------------------------------------------------------------

\part{Model Theory}

% --------------------------------------------------------------------

\part{Formal Semantics}

% --------------------------------------------------------------------

\part{Set Theory}

% --------------------------------------------------------------------

\part{Graph Theory}

% --------------------------------------------------------------------

\part{Category Theory}

% --------------------------------------------------------------------

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
