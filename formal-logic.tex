%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage{amssymb}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}

% --------------------------------------------------------------------

\title{Survey of Mathematical Logic}
\date{draft 2014}
\author{Shane Pearman}
\maketitle

% --------------------------------------------------------------------

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Formal Language}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A \emph{Formal Language}, $L$, is a possibly infinite subset of an
infinite \emph{Vocabulary}, $\Sigma^*$, that is the set of all
possible finite \emph{Expressions} (strings) over a possibly infinite
\emph{Alphabet} of \emph{Symbols}, $\Sigma$. This set $\Sigma^*$ is
the \emph{Kleene star} or \emph{Free monoid} of $\Sigma$; the smallest
superset of $\Sigma$ that is closed under string concatenation.

The \emph{Syntax} is that part of the Language that refers only to the
literal strings of Symbols of the Language with no regard to their
meaning or interpretation; only the condition that they can be
identified and differentiated from one-another is required.

The entire content of a Language is uniquely determined by the set of
all \emph{Terminal Expressions} generated by the \emph{Production} or
rewrite rules of a \emph{Formal Grammer}. This possibly infinite set
of Terminals will be a subset of the Vocabulary over the Alphabet.

% --------------------------------------------------------------------
\section{Metalanguage}\label{sec:metalanguage}
% --------------------------------------------------------------------

A \emph{Metalanguage} is a Language used to describe another Language,
the \emph{Object Language}. A \emph{Metavariable} is a variable
written in a Metalanguage that stands in for an element in the Object
Language. Metavariables may be referred to as \emph{Schematic
  Variables} in the context of \emph{Axiom Schemata} and \emph{Rule
  Schemata} (\S \ref{subsec:deductive_apparatus}).

The use of an Object Language to describe itself is an \emph{Embedded
  Metalanguage} (eg the English words \emph{noun} and \emph{verb} are
used to describe English itself).

% --------------------------------------------------------------------
\section{Abstract Reduction Systems}\label{sec:abstract_rewrite}
% --------------------------------------------------------------------

The following descriptions of Formal Grammars and \emph{Automata} may
be abstracted as \emph{Reduction} or \emph{rewrite} systems. This is
simply
    \[(A,\rightarrow)\]
where $A$ is a set of objects and $\rightarrow \subseteq A \times
A$. This is equivalent to an \emph{unlabeled State Transition System}
(\S \ref{sec:state_transition_system}).

An \emph{Indexed Abstract Reduction System} differentiates Reductions
into classes so that $\rightarrow$ is the indexed union of these
relations
    \[(A, \rightarrow_1, \rightarrow_2, \cdots)\]
This is identical to a \emph{Labeled Transition System}.

% --------------------------------------------------------------------
\section{Syntactic Elements}
% --------------------------------------------------------------------

Within a Formal Language defined by a Formal Grammar over a given
Alphabet and Vocabulary, the Symbols will be divided into two disjoint
subsets according to whether they are \emph{Terminal} or
\emph{Non-terminal Symbols}.

The definition of a Non-terminal Symbol is one for which a Production
rule exists with that Symbol appearing in the input and replaced in
the output. Thus a Grammar is specified by a finite set of
Productions, $P$, a finite set of Non-terminal Symbols, $N$, and a
finite set of Terminal Symbols, $T$. Additionally, in certain Grammars
it is allowed for multiple Non-terminals to appear in an Expression.

    \begin{description}

    \item[Symbol] \hfill \\
    an atomic unit of a Language

    \item[Alphabet ($\Sigma$)] \hfill \\
    a possibly infinite set of Symbols

    \item[Expression] \hfill \\
    a finite string of Symbols

    \item[Vocabulary ($\Sigma^{*}$)] \hfill \\
    set of all Expressions over an Alphabet of Symbols

    \item[Production] \hfill \\
    a rewrite rule specifying a Non-terminal Symbol substitution

    \item[Grammar] \hfill \\
    a finite set of Productions over the Expressions of a Vocabulary

    \end{description}

\subsection{Special Symbols}
Two special Symbols are recognized:

    \begin{description}

    \item[Empty Symbol ($\varepsilon$)] \hfill \\
    the Symbol of zero length and a Terminal Symbol

    \item[Start Symbol ($S$)] \hfill \\
    a unique Non-terminal Symbol

    \end{description}

\subsection{Generative Grammar}

A Grammar \emph{generates} a Language by the repeated application of
its Production Rules beginning with the Start Symbol. A sequence of
rule applications is a \emph{Derivation}. Formal definition of a
Grammar as a 4-tuple:
\[
    G(N,T,P,S)
\]
The unrestricted form of a Production:
\[
    (N \cup T)^*N(N \cup T)^* \rightarrow (N \cup T)^*
\]
That is, a Production is a function from one Expression to
another, where the left Expression must contain at least one
Non-terminal Symbol. By convention, Non-terminal Symbols
will be denoted by capitals ($A,B,C,\cdots$), and Terminals by
lowercase ($a,b,c,\cdots$), and expressions by Greek letters
($\alpha,\beta,\gamma$). Let:

\[
    \mathcal{A} = \{ Alphabets \},\: \mathcal{V} = \{ Vocabularies \}
\] \[
    \mathcal{G} = \{ Grammars \},\: \mathcal{L} = \{ Languages \}
\]

    \begin{description}

    \item Definition of the Kleene star or Free monoid over an
      Alphabet where $\circ$ is the operation to \emph{Concatenate} two
      Expressions:
    \[
        \forall \: \Sigma \in \mathcal{A} \:
        \exists \: \Sigma^* \in \mathcal{V}
        : \Sigma^* = \bigcup_{i=0}^{|\Sigma|} \Sigma_i
        = (\Sigma,\circ)
    \]

    \item Definition of a Language in terms of a Vocabulary:
    \[
        \forall \: L \in \mathcal{L} \:
        \exists \: \Sigma^* \in \mathcal{V}
        : L \subseteq \Sigma^*
    \]

    \item Existence of the Empty Symbol, $\varepsilon$:
    \[
        \forall \: \Sigma^* \in \mathcal{V} \:
        \exists ! \: \varepsilon \in \Sigma^*
        : |\varepsilon|=0
    \]

    \end{description}

% --------------------------------------------------------------------
\section{Formal Grammars}
% --------------------------------------------------------------------

\subsection{Chomsky Hierarchy}

Grammars are classified by how restrictive the Production rules
are. By convention, they may be organized into a hierarchy of sets
under proper inclusion, where \emph{Type-0} is an unrestricted grammar,
covering all possible formal grammars.

\[
    Type-0 \supset Type-1 \supset Type-2 \supset Type-3
\]

These different levels in the hierarchy are \emph{Recognizable} by
different kinds of Automata (\S \ref{subsec:automata})

\subsection{Type-0: Unrestricted}

\subsubsection{Semi-decidable}\label{subsec:semidecidable}
Production rules of an \emph{Unrestricted} Grammar have the form
\[
    \alpha \rightarrow \beta
\]
where $\alpha$ and $\beta$ are Expressions of $N \cup T$ and $\alpha
\neq \varepsilon$.

A completely unrestricted Grammar is called \emph{recursively
  enumerable} or \emph{Semi-decidable}. This means membership of the
Language can be decided by an algorithm, but non-membership cannot,
and the class of Languages having this property is called
$\mathsf{RE}$. Members of this class are also \emph{Diophantine} sets
and the lattice of $\mathsf{RE}$ sets under inclusion is written
$\mathcal{E}$. % FIXME add a reference when sections describing these terms
               % are added

The complement of $\mathsf{RE}$ is the class of Languages for which
an algorithm may decide non-membership only and is termed
$\mathsf{coRE}$. The class of Automata capable of implementing these
algorithms are \emph{Turing Machines}(\S\ref{subsec:turing_machine}).

\subsubsection{Decidable}
A \emph{Decidable} or \emph{recursive} Language (as opposed to
recursively enumerable) is defined as the intersection of
$\mathsf{RE}$ and $\mathsf{coRE}$:
\[
    \mathsf{R} = \mathsf{RE} \cap \mathsf{coRE}
\]
That is, it can be decided whether a Symbol is a member or not by a
\emph{total computable function} (one which returns \emph{True} or
\emph{False} depending on membership). Decidable Languages are
recognizable by a \emph{decider} or \emph{Total Turing
  Machine}\cite{kozen97} (however determining whether an arbitrary
Turing Machine gives an answer for every input is an undecidable
decision problem).

\subsection{Type-1: Context-sensitive}

\subsubsection{Context-sensitive}\label{subsec:context_sensitive}
\emph{Context-sensitive Grammars} have the restriction that the result
of a Production is not shorter than the input. Formally stated
Productions are of the form
\[
    \alpha \Gamma \beta \rightarrow \alpha \gamma \beta
\]
where $|\Gamma| \leq |\gamma|$. In this formulation $\alpha$ and $\beta$ form
the \emph{Context} of $\Gamma$.

Requiring that $S$ does not appear on the right of any Production
and allowing the rule
\[
    S \rightarrow \varepsilon
\]
makes the Context-sensitive Languages a proper superset of the
\emph{Context-free Languages}.

Context-sensitive Languages are equivalent to \emph{Linear
Bounded Automata} (\S\ref{subsec:linear_bounded_automata}).

\subsubsection{Indexed}
An \emph{Indexed Grammar} has an extra set of \emph{Index Symbols},
$F$, with Productions of three possible forms,
\[
    A[\sigma] \rightarrow \alpha[\sigma]
\]\[
    A[\sigma] \rightarrow B[f\sigma]
\]\[
    A[f\sigma] \rightarrow \alpha[\sigma]
\]
where $f \in F$ and $\sigma$ is a string of Index Symbols. The Index
Symbols are used to form a \emph{stack} by the Production rules where
Index Symbols are either pushed or popped from the stack.

An Indexed Language can be recognized by a \emph{Nested Stack
  Automaton}\cite{aho69}.

\subsubsection{Generalized Contex-free}
A \emph{Generalized Context-free Grammar} adds to the rewrite rules of
a Context-free Grammar a set of non-context-free \emph{composition
  functions} that combine tuples of symbols:
\[
    f(\langle x_1,\cdots,x_m\rangle,\cdots,\langle
    y_1,\cdots,y_n\rangle)=\gamma
\]
where $\gamma$ is a single tuple or another composition function that
reduces to a single tuple.

Rules are of the form:
\[
    A \rightarrow f(X,Y,\cdots)
\]
where $X$,$Y$,$\cdots$ are string tuples or Non-terminal Symbols.

There are several weakly equivalent Grammars to the composition
formulation:

\begin{description}
\item[Linear context-free rewriting system] \hfill \\
    Weakly equivalent to \emph{multi-component Tree-adjoining
      Grammars} where composition functions are both \emph{linear} and
    \emph{regular}. Can be recognized by \emph{Thread
      Automata}\cite{villemonte02}.

\item[Tree-adjoining] \hfill \\
    Elementary rewriting unit is a tree rather than a Symbol. Can be
    recognized by \emph{Embedded Pushdown
      Automata}\cite{vijayashanker88}.

\item[Linear indexed grammar] \hfill \\
    A modified Indexed Grammar where only one symbol receives the
    stack.

\item[Combinatory Categorical Grammar] \hfill \\
    A type of \emph{phrase Structure Grammar} using \emph{Combinatory
      Logic}(\S\ref{subsec:combinatory_logic}).

\item[Head grammar] \hfill \\
    A subset of the Linear context-free rewriting system and a Phrase
    Structure Grammar.

\end{description}

\subsection{Type-2: Context-free}\label{subsec:context_free_language}

\subsubsection{Context-free}
\emph{Context-free Grammars} (\emph{CFG}s) have production rules of the form
\[
    V \rightarrow \alpha
\]
where $V$ is a single Non-terminal and $\alpha$ is a string of Terminals
and/or Non-terminals (or empty). Because $V$ is required to be a
single Non-terminal, the Production rules can be applied regardless of
Context. Each Non-terminal in a Context-free Grammar, $G$, is said to
form a \emph{Sub-Language} of the language defined by $G$.

Multiple Context-free Grammars may generate the same Language, so
properties of CFGs may be termed \emph{extrinsic} while Language properties
are \emph{intrinsic}. The question of equality between CFGs is
undecidable.

A popular notation for Context-free Grammars (especially in Computer
Science) is \emph{Backus-Naur form} (\emph{BNF}).

In Linguistics, the term used for Context-free Grammar is \emph{Phrase
  Structure Grammar} which is also called \emph{constituency grammar}
due to the one-to-one-or-many correspondence between the Productions
(ultimately rooted in the \emph{subject-predicate} clause derived from
\emph{Term Logic}).

An alternative formulation to Phrase Structure Grammar is \emph{Dependency
  Grammar} in which the Verb is the root and there is a one-to-one
correspondence between Symbols and nodes in the syntax structure.

The Context-free Grammar is equivalent to \emph{Non-deterministic
Pushdown Automata}(\S\ref{subsec:pushdown_automata}).

\subsubsection{Deterministic}\label{subsec:deterministic_cfg}
\emph{Deterministic Context-free Grammars} are derived from
\emph{Deterministic Pushdown Automata}(\S\ref{subsec:deterministic_pda})
and are always \emph{unambiguous}. They can be parsed in linear time
and a \emph{Parser} can be automatically generated from the Grammar by a
\emph{Parser Generator}(\S\ref{subsec:parser_generator}).

\subsubsection{Visibly Pushdown}
\emph{Visibly Pushdown Grammars} are described by the 4-tuple
\[
    G = (V=V^0 \cup V^1,T,P,S)
\]
where $V^0$ and $V^1$ are disjoint sets of Non-terminals and there
are three kinds of Production rules:
\[
    X \rightarrow \varepsilon
\]\[
    X \rightarrow aY
\]\[
    X \rightarrow \langle aZb \rangle Y
\]
where $Z \in V^0$ and if $X \in V^0$ then $Y \in V^0$

The resulting Language is a \emph{Regular Language} with \emph{nested
  words}, described by a \emph{Monadic Second-order Logic}. % FIXME ref

\subsection{Type-3: Regular} \label{subsec:regular_language}

\emph{Regular Languages} are more restricted than Context-free
Languages and satisfy a number of closure properties. For two Regular
Languages, $K$ and $L$, the following operations result in a Language
that is also Regular:
\[
    K \cup L, \quad
    K \cap L, \quad
    \overline{L}, \quad
    K - L, \quad
    K \circ L, \quad
    L^*, \quad
    K / L, \quad
    L^R
\]
A common formulation of Regular Languages is the \emph{Regular
  Expression} and conversely it is sometimes said that a Regular
Language is one that can be defined by a Regular Expression.

An algebraic description is as follows:
\[
    L = \{ w \in \Sigma^* | f(w) \in N \}
\]
where $f : \Sigma^* \rightarrow M$ is a \emph{Monoid homomorphism} of
\emph{Finite Monoid}, $M$, and $N \subseteq M$.
% FIXME ref monoids

\subsubsection{Extended Regular}
\emph{Extended Regular Grammars} have Productions of either \emph{right
Regular} or \emph{left Regular} form.

Right:
\[
    B \rightarrow a
\]\[
    A \rightarrow B \nu
\]\[
    A \rightarrow \varepsilon
\]

Left:
\[
    A \rightarrow a
\]\[
    A \rightarrow B \nu
\]\[
    A \rightarrow \varepsilon
\]
where $a$ is a single Non-terminal and $\nu$ is an expression of only
Non-terminal characters.

\subsubsection{Strictly Regular}
\emph{Strictly Regular Grammars} also have Productions of either right
Regular or left Regular form.

Right:
\[
    B \rightarrow a
\]\[
    B \rightarrow aC
\]\[
    B \rightarrow \varepsilon
\]

Left:
\[
    A \rightarrow a
\]\[
    A \rightarrow Ba
\]\[
    A \rightarrow \varepsilon
\]
where $a$ is a single Non-terminal.

There is a one-to-one correspondence between the rules of a
\emph{Strictly Left Regular Grammar} and those of a
\emph{Non-deterministic Finite Automaton}(\S\ref{subsec:ndfa}).

The \emph{pumping lemma} states that the middle section of an
Expression within a Regular Language may be repeated an arbitrary
number of times to produce another Expression in that same Language.

\subsubsection{k-Testable}\label{subsec:k_testable}
A \emph{k-Testable Language} is one where membership of an Expression
depends on the first and last symbol and a set of factors of length
$k$. An example is a \emph{Local Language} which is a \emph{2-Testable
  Language} described by the \emph{regular expression}:
\[
    (Q\Sigma^* \cap \Sigma^*R)\setminus\Sigma^*F\Sigma^*
\]
where $Q,R \subseteq \Sigma$ and $F \subseteq \Sigma \times
\Sigma$. This requires for a \emph{Word} (Expression), $w$, that is a
member of a Local Language to have its first Symbol in $Q$, and its
second Symbol in $R$, and no factor of $w$ of length 2 is in $F$. A
Local Language is recognized by a \emph{Local
  Automaton}(\S\ref{subsec:dfa}).

\subsubsection{Star-free}
A \emph{Star-free Language} is one having a \emph{Generalized Star
  Height} equal to zero, that is, the minimal \emph{Star Height} of
all Expressions in the Language with the Star Height of an
Expression's \emph{compliment} being equal.

Star-free Languages are characterized as those with \emph{Aperiodic
  Syntactic Monoids}\cite{schutzenberger65} and also as the
\emph{Counter-free Langauges}\cite{mcnaughton-papert71} by the
\emph{Aperiodic Finite-state Automaton}, and \emph{Linear Temporal
  Logic}. % FIXME ref

\subsection{Affix Grammars}
\emph{Affix Grammars} are those of a Context-free Grammar with a
subset of the Non-terminals used as \emph{affix arguments}. If the
same affix appears multiple places in a Production, the value must be
the same.

\subsection{Two-Level Grammars}
\emph{Two-Level Grammars} are \emph{Grammar generators} that may
generate Grammars with infinite rules. Allowing the values for affixes
to be described by a Context-free Grammar results in a Two-Level
Grammar.


\begin{description}
\item[W-grammar] \emph{Van Wijngaarden Grammar} consists of a finite
  set of \emph{meta-rules} used to derive a possibly infinite set of
  Production rules from a finite set of \emph{hyper-rules}.
\item[Extended Affix Grammar] is a restricted W-grammar.
\end{description}

\subsection{Attribute Grammars}
\emph{Attribute Grammars} allows affixes from arbitrary domains and
allows functions calculate values of affixes.

\subsection{Analytic Grammars}
\emph{Analytic Grammars} are used in \emph{Parsing} (\S
\ref{sec:parsers}). A few examples:

\begin{description}
\item[Top-Down Parsing Language] \hfill \\
Formal representation of \emph{Recursive Descent Parser}. Production
rules of the form
\[
    A \leftarrow \varepsilon
\]\[
    A \leftarrow f
\]\[
    A \leftarrow a
\]\[
    A \leftarrow BC/D
\]
\item[Parsing Expression Generator] \hfill \\
A more generalized Top-Down Parsing Language.
\item[Link Grammar] \hfill \\
Dependency Grammar with directionality between Symbols.
\end{description}

% --------------------------------------------------------------------
\section{Parsers} \label{sec:parsers}
% --------------------------------------------------------------------

A \emph{Parser} analyzes an Expression according to the rules of a Formal
Grammar, generating a \emph{Data Structure} describing the Syntax of
the input. An outline of the process follows.

\subsection{Lexical Analysis}
A Parser may be preceded by a \emph{Lexical Analyzer} which creates
\emph{Tokens} (Symbols) from an input Expression. Strings of Tokens
are referred to as Phrases. A Lexical Analyzer is a Parser itself and
usually the \emph{Lexical Grammar} is a Regular Language (other
methods are \emph{flags}, \emph{delimiters}, or \emph{dictionaries})
and the Tokens are parsed as a Context-free or \emph{Attribute Phrase
  Syntax}.

Prior to \emph{Scanning}, a \emph{Lexer} may perform its own
Tokenization.  The Scanning stage first recognizes the Token
strings as \emph{Lexemes}, usually achieved by a Finite State
Machine.

Lexemes are resolved into Tokens by an \emph{Evaluator} which assigns
values where needed-- this results in Tokens that are either a
\emph{Type-Value} pair, or just a \emph{Type}.

\subsection{Syntactic Analysis}
The Parser determines if and how the input can be derived from the
Start Symbol of the Grammar. Parsing can proceed in two directions:

\begin{description}
    \item[Top-down Parsing]
    starts with the highest level of the \emph{Parse Tree}. Proceeds greedily
    and may be \emph{Exponential} with \emph{Backtracking}.
    \item[Bottom-up Parsing]
    starts with the lowest level of the Parse Tree.
\end{description}

Further \emph{Semantic} Parsing may be performed after these steps. An
example of this would be the in the \emph{Compiler} of a
\emph{Programming Language}.

\subsection{Parser Generators}\label{subsec:parser_generator}

A \emph{Parser Generator} takes as a Grammar (for example a BNF
Grammar) and outputs the source code of a Parser for the Language
specified by the Grammar.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Automata Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% --------------------------------------------------------------------
\section{State Transition Systems} \label{sec:state_transition_system}
% --------------------------------------------------------------------
A \emph{State Transition System} can have an infinite number of
\emph{States} and \emph{Transitions}, represented as the pair
\[
    (S,\rightarrow)
\]
where $S$ is a set of States and $\rightarrow \subseteq S \times
S$. This is identical to an \emph{un-indexed Abstract Rewriting
  System}(\S \ref{sec:abstract_rewrite}).

\emph{Finite Automata} may be seen as State Transition Systems with an
initial State and a number of final \emph{Accept} states indicating
\emph{Word} (Expression) membership for a Language.

\emph{Labeled State Transition Systems} have an additional set of
\emph{Labels}, $\Lambda$
\[(S,\Lambda,\rightarrow)\]
and $\rightarrow \subseteq S \times \Lambda \times S$.

\emph{Action Programming Languages} add a set of \emph{Fluents}, $F$, and
\emph{Values}, $V$, and a function mapping $F \times S$ to $V$.

% --------------------------------------------------------------------
\section{Semiautomata}
A State Transition System may be formulated as a \emph{Semiautomata}
\[
    (Q,\Sigma,T)
\]
where $\Sigma$ is a non-empty \emph{input Symbols}, $Q$ is the set of
States, and $T$ is a \emph{transition function} $T:Q \times \Sigma
\rightarrow Q$.

A Semiautomaton induces a Monoid called the \emph{input Monoid}:
\[
    M(Q,\Sigma,T) = \{T_w | w \in \Sigma^*\}
\]

% --------------------------------------------------------------------
\section{Automata} \label{subsec:automata}
% --------------------------------------------------------------------

An \emph{Automaton} reads input strings, \emph{Words} (Expressions),
and either accepts or rejects depending on whether a Word is a member
of the Language recognized by that Automaton. By convention the
Vocabulary of Expressions will be re-cast as an Alphabet of Words,
$\Sigma$.

Automata may be arranged in a hierarchy according to increasing power:
\[
    DFA = NFA \subset DPDA-I \subset NPDA-I \subset LBA \subset DPDA-II =
\]\[
    = NPDA-II = DTM = NTM = PTM = MDTM
\]
where
\begin{itemize}
\item DFA = Deterministic Finite Automata
\item NFA = Non-deterministic Finite Automata
\item DPDA = Deterministic Push Down Automata with 1
  or 2 push-down stores
\item NPDA = Non-deterministic Push Down Automata
  with 1 or 2 push-down stores
\item LBA = Linear Bounded Automata
\item DTM = Deterministic Turing Machine
\item NTM = Non-deterministic Turing Machine
\item PTM = Probabilistic Turing Machine
\item MDTM = Multidimensional Turing Machine
\end{itemize}

\subsection{Finite Automata}
\emph{Finite Automata} are \emph{Finite State Machines} and take a
finite input string of Symbols and either accepts or rejects the
input depending on the final State of the computation. Finite
Automata are able to recognize Regular Languages(\S\ref{subsec:regular_language}).

\subsubsection{Deterministic Finite Automata}\label{subsec:dfa}
\emph{Deterministic Finite Automata} have the restriction that an
input Symbol has a transition function to a single State.
Deterministic Finite Automata recognize Regular
Languages(\S\ref{subsec:regular_language}).

Representation of a Deterministic Finite Automaton as a 5-tuple:
\[
    (Q,\Sigma,\delta,q_0,F)
\]
where
\begin{itemize}
\item $Q$ is a finite set of States
\item $\Sigma$ is the Alphabet
\item $\delta$ is the transition function $\delta: Q \times
  \Sigma \rightarrow Q$
\item $q_0 \in Q$ is the initial State
\item $F \subseteq Q$ is the set of final Accept States.
\end{itemize}

Running for a given input $w = a_1,a_2, \cdots , a_n \in \Sigma^*$
produces a sequence of States $q_0,q_1,q_2,\cdots , q_n$ where $q_i
\in Q$ such that $q_i = \delta (q_{i-1},a_i)$ and $w$ is accepted if
$q_n \in F$.

A recursive definition using \emph{composition} of transition
functions
\[
    \widehat{\delta}(q,\varepsilon) = q
\]\[
    \widehat{\delta}(q,wa) = \delta_a(\widehat{\delta}(q,w))
\]
where $w \in \Sigma^*$, $a \in \Sigma$ and $q \in Q$. Repeated
application describes the \emph{Transition Monoid} or
\emph{Transformation Semigroup}.

A kind of Deterministic Finite Automata that recognizes Local
Languages(\S\ref{subsec:k_testable}) is called a \emph{Local Automaton}.

\subsubsection{Nondeterministic Finite Automata}\label{subsec:ndfa}
\emph{Nondeterministic Finite Automata} are Finite State Machines that
may transition from one State to a number of different states, given
as an element of the powerset of $Q$, $\mathcal{P}(Q)$.

Representation of a Nondeterministic Finite Automaton as a
5-tuple:
\[
    (Q,\Sigma,\Delta,q_0,F)
\]
where
\begin{itemize}
\item $Q$ is a finite set of States
\item $\Sigma$ is the Alphabet
\item $\Delta$ is a \emph{transition relation} $\Delta: Q \times
  \Sigma \rightarrow \mathcal{P}(Q)$
\item $q_0 \in Q$ is the initial State
\item $F \subseteq Q$ is the set of final Accept States.
\end{itemize}

A Word, $w=a_1,a_2,\cdots,a_n$, is accepted when there exists a
sequence of States, $r_0,r_1,\cdots,r_n$ such that
\begin{enumerate}
\item $r_0 = q_0$
\item $r_{i+1} \in \Delta(r_i, a_{i+1})$, for $i = 0, \cdots, n-1$
\item $r_n \in F$
\end{enumerate}

A DFA may be seen as a NFA which restricts transitions to allow only
one State, and can be constructed from a NFA with $n$ States using
\emph{powerset construction}, requiring up to $2^n$ States. Both types
recognize the same Regular Languages(\S\ref{subsec:regular_language}).

\paragraph{NFA-$\varepsilon$} is a NFA that allows transitions
without consuming input Symbols. A transition that changes state
without consuming input is an $\varepsilon$ $move$. Each State $q$
defines an $\varepsilon$-\emph{closure}, $E(q)$, which is the set of
States that are reachable by $\varepsilon$ moves.

The Languages recognized by NFA-$\varepsilon$ are the same as NFA/DFA.

\subsection{Pushdown Automata}\label{subsec:pushdown_automata}
\emph{Pushdown Automata} add to Finite Automata a \emph{Stack} as a
parameter for choice of States and can recognize Context-free
Languages(\S\ref{subsec:context_free_language}).

Adding a second Stack makes a Pushdown Automata equal in power to a
Turing Machine.

Unlike Finite Automata, Deterministic PDA are not equivalent to
Nondeterministic PDA. The general representation for a PDA is
\[
    M = (Q, \Sigma, \Gamma, q_0, Z_0, F, \delta)
\]
where
\begin{itemize}
\item $Q$ is a finite set of States
\item $\Sigma$ is a finite set of input Symbols
\item $\Gamma$ is a finite set of Stack Symbols
\item $q_0 \in Q$ is the initial State
\item $Z_0 \in \Gamma$ is the initial Stack Symbol
\item $F \subseteq Q$ is the set of final Accept States
\item $\delta$ is the transition function $\delta: (Q \times (\Sigma
  \cup \{\varepsilon\}) \times \Gamma) \rightarrow \mathcal{P}(Q \times
  \Gamma^*)$
\end{itemize}

An element $(p,a,Z,q,\alpha)\in\delta$, with $M$ in State $p \in Q$,
input $a \in \Sigma \cup \{\varepsilon\}$, and top stack Symbol $Z \in
\Gamma$ results in the following:
\begin{enumerate}
\item read $a$
\item change state to $q$
\item pop $Z$
\item push $\alpha \in \Gamma^*$
\end{enumerate}

\subsubsection{Deterministic Pushdown Automata}\label{subsec:deterministic_pda}
\emph{Deterministic Pushdown Automata} have the restriction of only
one derivation per accepted input Word. This allows recognition of a
subset of Context-free Languages termed
Deterministic(\S\ref{subsec:deterministic_cfg}). Such Languages can be
parsed in linear time and Parsers for such Languages can be generated
automatically(\S\ref{subsec:parser_generator}).

A Pushdown Automata is Deterministic iff both
\begin{enumerate}
\item $\forall q \in Q, a \in \Sigma \cup {\varepsilon}, x \in
  \Gamma \vdash |\delta(q,a,x)| \leq 1$
\item $\forall q \in Q, x \in \Gamma \vdash |\delta(q,\varepsilon,x)|
  \neq 0 \Rightarrow \forall a \in \Sigma \vdash |\delta(q,a,x)|=0$
\end{enumerate}

\subsection{Linear Bounded Automata} \label{subsec:linear_bounded_automata}
\emph{Linear Bounded Automata} are Turing Machines restricted to an
input of finite length and are acceptors for Context-sensitive
Languages(\S\ref{subsec:context_sensitive}) which require that
Production rules do not increase the size of the Expression as a
result; therefore the size of the input is sufficient for calculation.

\subsection{Turing Machines}\label{subsec:turing_machine}
A Turing Machine operates on an infinite \emph{storage tape}, which
acts as the read input as well as write storage. Pushdown Automata
with 2 Stacks are equivalent to Turing Machines.

\subsubsection{Nondeterministic Turing Machines}
\emph{Nondeterministic Turing Machines} (\emph{NTM}s) can be defined
as
    \[
        M = (Q, \Sigma, q_0, \sqcup, A, \delta)
    \]
where
\begin{itemize}
\item $Q$ is a finite set of States
\item $\Sigma$ is the finite Alphabet
\item $q_0 \in Q$ is the initial State
\item $\sqcup \in \Sigma$ is the blank Symbol
\item $F \subseteq Q$ is the set of final Accept States
\item $\delta \subseteq (Q \setminus F \times \Sigma) \times (Q \times
  \Sigma \times \{L,R\})$ and $L$ and $R$ are left and right shift.
\end{itemize}

The operation of $M$ in State $q_i$ and current read input $a_j$ is a
transition function, $q_i a_j \rightarrow q_{i1} a_{j1} d_k$. Note
that for an NTM, $\delta$ is a relation and more than one function can
exist for each possible input/State combination. The result is to
write the new Symbol $a_{j1}$ in the current position and shift the
storage left or right as specified by $d_k$, afterwards assuming State
$q_{i1}$.

\subsubsection{Deterministic Turing Machines}
\emph{Deterministic Turing Machines} (\emph{DTM}s) have one possible
output transition per unique input/State combination, thus $\delta$ is
a \emph{partial function} rather than a \emph{relation}:
\[
    \delta : Q \setminus F \times \Sigma \rightarrow Q \times
    \Sigma \times {L,R}
\]
The computational power of DTMs and NTMs is equivalent (they can solve
the same problems) as NTMs include DTMs as a special case. An
equivalent accepting computation in a DTM is generally exponential to
the length of the shortest accepting computation of an NTM.

\subsubsection{Probabilistic Turing Machines}
A \emph{Probabilistic Turing Machine} adds to transitions a
probability distribution (or a tape with random Symbols). It is an
open question whether this is more powerful than a DTM
($\mathsf{BPP}=\mathsf{P}$ ?)  but it is useful in the definition of
\emph{interactive proof systems}. %FIXME ref

\subsubsection{Multidimensional Turing Machines}
\emph{Multidimensional Turing Machines} allow for tapes of varying
topologies. This requires additional shift directions (ie $\{L, R, U,
D\}$ for a 2-dimensional tape) but does not increase the computing
power; even an $\infty$-\emph{dimensional} Turing Machine can be
simulated by a DTM.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Symbolic Logic}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% --------------------------------------------------------------------
\section{Terms}\label{sec:terms}
% --------------------------------------------------------------------

\begin{description}
\item[Universe] class containing elements of entities (objects)
  considered in a particular Logical discourse, also called
  \emph{Domain of Discourse}
\item[Constant] a named object from the Domain
\item[Variable] a placeholder that ranges over the objects in the
  Domain
\item[Function] $n$-ary functions maps $n$-tuples of objects in the
  Domain to objects
\item[Term] an object of the Domain (Variables, Constants and Compound
  Statements)
\item[Formula] a mathematical Fact
\end{description}
\hfill \\
Inductive definition of \emph{Terms} in terms of \emph{Constants},
\emph{Variables}, and \emph{Functions}:

Given Terms, $T$, Variables, $V$, n-ary Functions, $F = F_0 \cup F_1
\cup F_2 \cup \cdots \cup F_n$, Constants, $C = F_0$:
\[
    V \subseteq T
\]\[
    C \subseteq T
\]\[
    \forall \tau_n=\{t_1,\cdots,t_n\} \in \mathcal{P}(T), f \in F_n
    \exists f(t_1,\cdots,t_n) \in T
\]

% --------------------------------------------------------------------
\section{Systems of Logic} \label{sec:formal_systems}
% --------------------------------------------------------------------

Symbols may be divided into \emph{Logical} and \emph{Non-Logical
  Symbols}: Logical Symbols ($\forall$, $\vee$, $\rightarrow$, $\neg$,
etc., and \emph{Variables} $x_0$, $x_1$, etc.) always have the same
meaning while Non-Logical Symbols (\emph{Predicates},
\emph{Functions}, and individual \emph{Constants}) only have meaning
under \emph{Interpretation} (\S \ref{sec:interpretation}). The set of
Non-Logical Symbols used in a particular discourse is called the
\emph{Signature} of the discourse.

\emph{Extra-logical Symbols} are those of a Metalanguage, such as the
symbol for \emph{Logical Consequence} (\emph{Entailment}), $\vdash$,
(read \emph{yields} or \emph{proves}) or Metavariables, $\varphi,
\psi, \ldots$.

A particular Formal System is required to be \emph{Consistent}; that
is the ability to derive only the affirmation or denial of a
particular statement, not both.

\subsection{Deductive Apparatus}
\label{subsec:deductive_apparatus}

A Formal Language (described by a Formal Grammar) in combination with
a \emph{Deductive Apparatus} gives rise to a \emph{System of
  Logic}. Here, Expressions of Symbols are usually referred to as
\emph{Forumulas}, and Expressions that belong to the Language are
called ``\emph{Well-formed Formulas}'' (\emph{WFF}).

The Deductive Apparatus is a set of zero or more \emph{Axioms} and one
or more \emph{Inference Rules}. A System of Logic is termed
\emph{Effective} (ie Recursively Definable) if the set of Axioms and
the set of Inference Rules are Decidable or Semi-decidable. The notion
of \emph{Theorems}, however, is not in general Effective
(\S\ref{subsec:formal_proof}).

\subsubsection{Axioms}

\emph{Axioms} are given as WFFs, the truth value of which are assumed
for the purpose of performing \emph{analysis} within a System of
Logic. An Axiom is properly an \emph{Inference Rule} with no
\emph{Premises}, only a given \emph{Conclusion}; that is a
\emph{Logical Assertion}(\S\ref{subsec:sequent_notation}).

Axioms may be divided into two kinds: \emph{Logical Axioms} of a
tautological sort, and \emph{Non-logical Axioms}, hereafter referred
to as \emph{Postulates}, that play the role of assumptions: defining
properties of the domain of the theory in question.

An \emph{Axiom Schema} is properly a template for Axioms in which one
or more \emph{Schematic Variables} (Metavariables, \S
\ref{sec:metalanguage}) appear, standing for a subformula in the
Object Language of the system. For a Language with infinitely many
WFF, an Axiom Schema describes a countably infinite number of
Axioms. A system without Schema is termed \emph{finitely axiomatized}.

\subsubsection{Inference Rules} \label{subsec:inference_rules}

An \emph{Inference Rule} is a \emph{transformation rule}: it is the
\emph{Logical Form} of the \emph{Deduction} of a \emph{Conclusion}
(also called an \emph{Idiomatic}) based on \emph{Premises}-- Premises
and Conclusions being WFF in the Formal Language of the system. Axioms
are special cases of Inference Rules which have no Premises, only a
universally held Conclusion. Axioms may be further differentiated from
Rules by saying that Rules are statements \emph{about} the system,
Axioms are statements \emph{in} the system. Inference Rules, like
Axioms, may be Schematic if they contain Metavariables.

Inference Rules may be viewed as functions that take Premises and
return a Conclusion. An alternative formulation for Inference Rules is
as a \emph{Deducibility Relation}, $\vdash$, that holds between zero
or more Premises and a Conclusion.

Taken individually, both Premises and Conclusions are
\emph{Propositions}. The Conclusion relies on the truth of the
Premises; if the Premises are left unsatisfied, then the derivation is
\emph{Hypothetical} and the Premises \emph{Hypotheses}. It can be said
that the Conclusion of a Deducibility Relation is reached by Syntactic
\emph{Logical Consequence}. For more information, see section on
\emph{Formal Proof} (\S\ref{subsec:formal_proof}).

Inference Rules may be identified as reduntant in two senses. An
\emph{Admissible Rule} is one which does not change the set of
\emph{Theorems} in a Formal System when it is added. A \emph{Derivable
  Rule} is a case of an Admissible Rule that has been \emph{Derived}
from existing rules.

\subsection{Zeroth-order - Propositional}\label{subsec:propositional}

\emph{Propositional Logic} (also called \emph{sentential} or
\emph{statement logic}) is represented by a Formal Language with WFF
consisting only of \emph{Operators} (\emph{logical connectives}) and
\emph{Primitive Symbols} representing \emph{Propositions}.

Propositions are WFF that are assigned a truth value. An \emph{Atomic
  Proposition} contains no Operators. A \emph{Composite Proposition}
is composed by recursive application of Operators to Propositions by a
corresponding \emph{Concatenation Rule} that assigns a new truth value
to the Composite string.

Primitive Symbols are usually divided into three different categories:
\begin{description}
\item[Propositional Constants] \hfill \\
Represent particular Propositions: $A$, $B$, $C$, $\ldots$
\item[Propositional Variables] \hfill \\
Range over set of all Atomic Propositions: $p$, $q$, $r$, $\ldots$
\item[Schematic Variables] \hfill \\
Metavariables; range over set of all propositions: $\varphi$, $\psi$,
$\chi$, $\ldots$
\end{description}

The Domain of a Propositional Calculus is \emph{Truth} and
\emph{Falsity}, so Variables are not necessarily \emph{Bound} or
\emph{Free} as in \emph{Predicate Logic}. In fact, a Propositional
Variable is equivalent to a \emph{Nullary Predicate} in \emph{First
  Order Logic}.

Formal definition of a \emph{Propositional Calculus}:
\[
    \mathcal{S} = (\mathbf{A},\mathbf{\Omega},\mathbf{Z},\mathbf{I})
\]
where
\begin{itemize}
\item $\mathbf{A}$ is a finite set of Proposition symbols ($p$, $q$,
  $r$, $\ldots$)
\item $\mathbf{\Omega}$ is a finite set of Operator symbols ($\neg$,
  $\wedge$, $\vee$, $\ldots$)
\item $\mathbf{Z}$ is a finite set of Inference Rules
\item $\mathbf{I}$ is a finite set of Axioms
\end{itemize}
$\mathcal{S}$ is then inductively defined as follows, where
$\mathbf{\Omega_j}$ is the partition of $\mathbf{\Omega}$ containing
Operators of arity $\mathbf{j}$:
\begin{enumerate}
\item Any element of $\mathbf{A}$ is a formula of $\mathcal{S}$
\item For formulas $p_1, p_2, \cdots, p_j$ and $f \in
  \mathbf{\Omega_j}$ then $f(p_1, p_2, \cdots, p_j)$ is a formula
\end{enumerate}
Propositional Logic is closed under truth-functional connectives, so
the above is sufficient to define all WFF: nothing else is a formula
of $\mathcal{S}$.

Formulas derived by the Axioms and Inference Rules of a Propositional
Logic are termed \emph{Theorems}. Allowing for Axiom Schema (an
infinite number of axioms) extends Propositional Logic; an example of
such a system is \emph{Skolem Arithmetic}\cite{skolem23}.

The set of WFF of a System, $\mathcal{S}$, may be defined inductively:
\begin{itemize}
\item Propositional Variables are WFF
\item If $\varphi$ is a WFF, then $\neg\varphi$ is a WFF
\item If $\varphi$ and $\psi$ are WFF and $\bullet$ is a binary Operator,
  then $\varphi \bullet \psi$ is a WFF.
\end{itemize}

\subsubsection{Argument Forms}

Inference Rules of a Propositional Logic define valid \emph{Argument
  Forms}. The simplest Argument Form that is both necessary (and given
a complete set of Axioms is sufficient to define all other Argument
Forms) is \emph{Modus Ponens}, shown here Schematicized:

$\textrm{1. }\varphi \rightarrow \psi$

$\textrm{2. }\varphi$

$\therefore\textrm{ }\psi$
\\
where lines one and two are Premises and line three is the Conclusion
(the symbol $\therefore$ is read as \emph{therefore}). This is written in
\emph{Sequent Notation}(\S\ref{subsec:sequent_notation}) as
\[(\varphi \rightarrow \psi), \varphi \vdash \psi\]
The Schematic representation of \emph{Modus Tollens}:

$\textrm{1. }\varphi \rightarrow \psi$

$\textrm{2. }\neg\psi$

$\therefore\textrm{ }\neg\varphi$

\subsubsection{Operators}

The minimal set of primitive Operators is the \emph{negation} symbol
($\neg$) plus a \emph{sole sufficient} Operator of either $\land$,
$\lor$ or $\rightarrow$. Choosing one of these Operators, the other
two, and any other Operator, can be defined in terms of it and
negation. It is also possible to construct functionally complete sets
of one element: $\mathbf{\Omega} = \{\uparrow\}$ or $\mathbf{\Omega} =
\{\downarrow\}$ ($\uparrow$ and $\downarrow$ being \emph{NAND} and
\emph{NOR}, respectively).
\\
Example simple Axiom system:

$\mathbf{\Omega} = \mathbf{\Omega_1} \cup \mathbf{\Omega_2}$

$\mathbf{\Omega_1} = \{\neg\}$

$\mathbf{\Omega_2} = \{\rightarrow\}$

$\mathbf{I} = \{ (p \rightarrow (q \rightarrow p)),$

$\qquad((p \rightarrow (q \rightarrow r)) \rightarrow
(( p \rightarrow q) \rightarrow (p \rightarrow r))),$

$\qquad(( \neg p \rightarrow \neg q ) \rightarrow (q \rightarrow p ))
\}$\\ with Modus Ponens as the sole inference rule (see Hilbert
Systems, \S\ref{subsec:hilbert_systems}).

In Propositional Logic, the Extra-logical Symbol for Entailment,
$\vdash$, and the Logical \emph{Implication Symbol}, $\rightarrow$,
coincide in that
\[(A \vdash B) \leftrightarrow (\vdash A \rightarrow B)\]
but the difference is that $\vdash$ describes a Deduction, that is a
relation between Sentences, and $\rightarrow$ is a Logical Connective
within a Formula.

Another possible system is a \emph{Natural Deduction
  System}\cite{jaskowski34} (\S \ref{subsec:natural_deduction})
which has no Axioms ($\mathbf{I}=\varnothing$) and ten Inference
Rules.

\subsection{First-order - Predicate}

Systems of \emph{First-order Predicate Logic} add \emph{Extensional
  Quantifiers} that may be applied to Variables, which may be Objects
of the Universe of discussion, or Relations or Functions. A
\emph{Theory} may be formed by a system of First-order Logic together
with a Domain of Discourse over which Variables may range, plus
finitely many Functions and \emph{Predicates} defined on that Domain,
and a recursive set of Axioms.

A Predicate in First-order Logic takes one or more Objects from the
Domain and returns either True or False. A Predicate taking no Objects
(a Nullary Predicate) is equivalent to a Proposition in Zeroth-order
Logic.

\emph{Higher-order Logic}(\S\ref{subsec:higher_order}) allows Predicates
to be applied to other Predicates or Functions, or Quantifiers may be
applied to Predicates or Functions. In First-order Logic, Predicates
are associated with Sets, in Higher-order Logic, with Sets of
Sets.
\\
The traditional Signature used in First-order Logic:
\begin{enumerate}
\item For $n \geq 0$, $n$-ary Predicate (also called Relation)
  Symbols: $p^{n}_0, p^{n}_1, p^{n}_2, p^{n}_2, p^{n}_3, \ldots$
\item For $n \geq 0$, $n$-ary Function Symbols: $f^{n}_0, f^{n}_1,
  f^{n}_2, f^{n}_2, f^{n}_3, \ldots$
\end{enumerate}
The contemporary Signature used:
\begin{enumerate}
\item Predicate Symbols denoted by uppercase letters $P$, $Q$, $R$,
  $\ldots$ with arity ($\geq 0$) specified by the \emph{Valence} of the
  parenthetical arguments, eg P(x), Q(x,y).
\item Function Symbols denoted by lowercase letters $f$, $g$, $h$,
  $\ldots$ with arity specified in the usual way.
\end{enumerate}
Here, Functions of Valence 0 are \emph{Constant Symbols} denoted by
letters $a$, $b$, $c$, $\ldots$.

\subsubsection{Properties}

First-order Logic may be used to devise Deductive Systems with
finite Domains that are \emph{Sound} and \emph{Complete}, but for
infinite Domains a system of Higher-order Logic is
required. First-order Logic is Semi-decidable(\S\ref{subsec:semidecidable}).

%FIXME ref Lowenheim-skolem thoerem
The \emph{L\"owenheim-Skolem theorem} implies that First-order Logic
is unable to characterize the concept of Countability (or
Uncountability).

The \emph{Compactness theorem} implies that if a Formula is derived
from a System of First-order Logic with an infinite set of Axioms,
then it can be derived from a finite number of those Axioms. This has
implications for the determination of \emph{Connected Components} of a
\emph{Directed Graph}. %FIXME ref Graph theory.

\subsubsection{Formation Rules}

The \emph{Formation Rules} for WFF in a System of First-order Logic
generally describe a Context-free Grammar with a infinite Alphabet and
many Start Symbols.

Terms are limited to those derived from Variables and a finite number
of $n$-ary Function applications, but not Expressions involving a
Predicate Symbol. See Section \ref{sec:terms} for a recursive
definition of Terms.

Definition of Atomic Formulas (no Logical Connectives or Quantifiers):
\begin{enumerate}
\item If $t_1$ and $t_2$ are Terms, then $t_1 = t_2$ is an Atomic Formula.
\item If $R$ is an $n$-ary Relation (Predicate), and $t_1,\ldots,t_n$
  are terms, then $R(t_1,\ldots,t_n)$ is an Atomic Formula.
\end{enumerate}

Definition of WFF as a finite number of applications of the following rules:
\begin{enumerate}
\item $\neg \phi$ is a WFF when $\phi$ is a WFF
\item $(\phi \bullet \psi)$ is a WFF when $\phi$ and $\psi$ are WFF
  and $\bullet$ is a Binary Connective
\item $\exists x \phi$ is a WFF when $x$ is a Variable and $\phi$ is a WFF
\item $\forall x \phi$ is a WFF when $x$ is a Variable and $\phi$ is a WFF
\end{enumerate}

\subsubsection{Quantification}

A Quantifier limits (\emph{Binds}) a Variable to a certain quantity of
members of the Domain, the two fundamental Quantifiers being
\emph{Universal} ($\forall$) and \emph{Existential} ($\exists$).

Variables are \emph{Free Variables} if they are not Quantified in any
Formula, and \emph{Bound Variables} when they are Quantified.
Inductive definition of \emph{Free} and \emph{Bound Variables}:
\begin{enumerate}
\item A Variable $x$ is Free in Atomic Formula $\varphi$ if $x$ occurs
  in $\varphi$ (there are no Bound Variables in Atomic Formulas)
\item A Variable is Free or Bound in $\varphi \bullet \psi$ if $x$ is
  Free or Bound in either $\varphi$ or $\psi$, where $\bullet$ is a
  Binary Connective
\item A Variable $x$ is Free in $\forall y \varphi$ iff $x$ is Free in
  $\varphi$ and $x$ is not $y$. Conversely $x$ is Bound in $\forall y
  \varphi$ if $x$ is $y$ or $x$ is Bound in $\varphi$.
\end{enumerate}

A Formula with no Free Variables in First-order Logic is a
\emph{First-order Sentence} (also called a \emph{Closed
  Formula}). First-order Sentences have well-defined Truth values.

\subsubsection{Inference Rules}

\paragraph{Universal Generalization}\label{subsec:universal_generalization} \hfill
\\
\[P(x) \vdash \forall x P(x)\]

\subsubsection{Equality Conventions}

\paragraph{First-order Logic with Equality}\hfill
\\ Including a primitive Logical Symbol for equality, $=$, interpreted
as the real equality relation between members of the Domain such that
``two'' given members are the same member. This adds the following
Axioms:

\begin{enumerate}
\item \textbf{Reflexivity}: $\forall x, x=x$
\item \textbf{Substitution for functions}: given a function, $f$,
  $\forall x \forall y, x = y \rightarrow f(\ldots,x,\ldots) =
  f(\ldots,y,\ldots)$
\item \textbf{Substitution for formulas (Leibniz's Law)}: given a
  formula $\varphi$ with Free occurrences of $x$, and $\varphi '$ with
  Free occurrences of $y$, $\forall x \forall y, x = y \rightarrow
  (\varphi \rightarrow \varphi ')$
\end{enumerate}

Defining a theory with a binary relation $A(x,y)$ that satisfies
Reflexivity and Leibniz's law is sufficient to derive any other
equality Theorems.

\paragraph{First-order Logic without Equality} \hfill
\\ An alternative convention is to consider the Equality Relation to
be a Non-logical Symbol, included as a part of the Signiature of a
particular Theory instead of as a Rule of Logic. This allows two
distinct individuals to be considered equal by an arbitraray
Equivalence Relation. If this convention is used, but no distinct
individuals, $a$ and $b$ satisfy $a=b$ then the interpretation is
termed a \emph{Normal Model} (that is equivalent to a First-order
Logic with Equality).


\subsubsection{Monadic First-order Logic}

\emph{Monadic First-order Logic}, also called \emph{Monadic Predicate
  Calculus} restricts First-order Logic to unary Relations and no
Function symbols. This weaker form of First-order Logic is fully
Decidable.

\subsubsection{Many-sorted First-order Logic}

\emph{Many-sorted First-order Logic} allows Variables to be Quantified
over different Domains, thus giving Variables different
\emph{Sorts}. With finitely many Sorts, Many-sorted First-order Logic
can be reduced to Single-sorted First-order Logic. This can be
accomplished by adding unary Predicates to a First-order Logic that
partition the Domain.

\subsubsection{Infinitary First-order Logic}

\emph{Infinitary Logic} allows Formulas of infinite length, through
either Conjunctons and Disjunctions, infinite-arity Relations and
Functions, or Quantification over infinitely many Variables.

\subsection{Higher-order - Plural}\label{subsec:higher_order}

\subsubsection{Second-order}

\emph{Second-order Logic} allows for Quantifiers to range over
Relations and Functions and thus \emph{Sorts} of Variables that range
over $k$-ary Relations and Functions. It is possible to leave out a
definition of Quantifiers for Functions since $k$-ary Functions can be
represented by $k+1$-ary Relations.\cite{shapiro00}

\subsubsection{Plural, Monadic Second-order Logic}

An alternative formulation of Second-order Logic is to allow Variables
to take on \emph{Plural} Values. It is equi-interpretable with
\emph{Monadic Second-order Logic}, which restricts Quantification to
Unary Relations (sets).

\subsection{Classical Logic}\label{subsec:classical_logic} \hfill
\\ \emph{Classical Logic} is the class of Propositional and
First-order Systems of Logic characterized by the following Inference
Rules:

\begin{description}

\item [Tertium non datur] (\emph{Law of excluded middle})
    \[\vdash(p \vee \neg p)\]

\item [Double Negation]
    \[p \vdash \neg\neg p\]

\item [Law of Non-contradiction]
    \[\vdash \neg(p \wedge \neg p)\]

\item [Ex falso quodlibet] (\emph{Principle of explosion},
  \emph{Principle of Psuedo-Scotus})
    \[\vdash 0 \rightarrow p\]

%FIXME finish properties and rules

\end{description}

\subsection{Modal (Intensional) Logic} \label{subsec:modal_logic}

\emph{Intensional Logic} adds to First-order Logic \emph{Sentential
  Functors} (\emph{Intensions}) that range over Terms. An Intension is
the \emph{Sense} in which a Logical Assertion is made, as opposed to
the \emph{Reference} to which the Assertion applies (\emph{ie
  Extensional Quantification}).

\emph{Modal Logic} extends Propositional and Predicate Logic to
include Operators expressing \emph{Modality}. Various meanings for
these Modal Operators include \emph{Alethic Modality}
(\emph{Necessity} and \emph{Possibility}), \emph{Temporal Modality}
(qualification in terms of time, eg \emph{always}, \emph{eventually},
\emph{until}), \emph{Deontic Modality} (\emph{Obligation} and
\emph{Permission}), and \emph{Doxastic Modality} (Modalities with
regards to \emph{Belief}).

An unary \emph{Primitive Modal Operator}, $\square$, defines a Dual
Operator, $\Diamond$, such that the following analogues of de Morgan's
laws hold:
    \[\Diamond P \leftrightarrow \neg \square \neg P\]
    \[\square P \leftrightarrow \neg \Diamond \neg P\]
Modal Logic with more than one Primitive Modal Operator, $\square _i,
i \in \{1, \ldots, n\}$ is \emph{Multimodal Logic}.

\subsubsection{Alethic Logic}

Most Systems of Alethic Logic are based on an extension of
Propositional Logic called $\mathbf{K}$ which has:

\begin{enumerate}
\item $\square$, unary operator for \emph{Necessity}.
\item $\mathbf{N}$, \emph{Necessitation Rule}: stating if $p$ is a
  Theorem, then $\square p$ is a Theorem.
\item $\mathbf{K}$, \emph{Distribution Axiom}: $\square(p \rightarrow
  q) \rightarrow (\square p \rightarrow \square q)$ (also called the
  \emph{Kripke schema})
\end{enumerate}

Adding further Axioms gives rise to a nested hierarchy of Systems of
\emph{Normal Modal Logic}:

\begin{itemize}
\item $K := \mathbf{K} + \mathbf{N}$
\item $T := K + \mathbf{T}$
\item $S4 := T + \mathbf{4}$
\item $S5 := S4 + \mathbf{5}$
\item $D := K + \mathbf{D}$
\end{itemize} \hfill \\
where

\begin{itemize}
\item $\Diamond$, unary operator for \emph{Possibly}
\item $\mathbf{T}$, \emph{Reflexivity Axiom}: $\square p \rightarrow p$
\item $\mathbf{4}$: $\square p \rightarrow \square \square p$
\item $\mathbf{B}$: $p \rightarrow \square \Diamond p$
\item $\mathbf{D}$: $\square p \rightarrow \Diamond p$
\item $\mathbf{5}$: $\Diamond p \rightarrow \square \Diamond p$
\end{itemize}

\subsubsection{Doxastic Logic}

\emph{Doxastic Logic} uses the unary Modal Operator, $\mathcal{B}$, to
denote \emph{Belief}. Example:
\[
    \mathcal{B} x
\]
has the meaning ``It is Believed that x is the case''. A set of
Beliefs is usually denoted
\[
    \mathbb{B}: \{ b_1, b_2, \ldots, b_n \}
\]

\subsubsection{Deontic Logic}

\emph{Standard Deontic Logic} ($\mathbf{SDL}$) adds the following
Axioms to Propositional Logic (\S\ref{subsec:propositional}):
    \[O(A \rightarrow B) \rightarrow (OA \rightarrow OB)\]
    \[PA \rightarrow \neg O \neg A\]
with Primitive Operators $O$ (\emph{Obligatory}) and $P$
(\emph{Permissible}). \emph{Forbidden} is defined as
    \[FA = O \neg A\]
or
    \[FA = \neg P A\]
Deontic Logic may be extended by Alethic Operators with the Axiom:
    \[OA \rightarrow \Diamond A\]
which has the meaning ``ought implies can''.

\subsubsection{Temporal Logic}

\paragraph{Tense Logic} \hfill \\

\emph{Tense Logic} is a 2-modal Logic that adds operators $[F]$ for
\emph{Future} and $[P]$ for \emph{Past} Modalities.

\paragraph{Linear Temporal Logic}

\paragraph{Computation Tree Logic}

\paragraph{Interval Temporal Logc}

\paragraph{Modal $\mu$-calculus}

\subsubsection{Dynamic Logic}

\emph{Dynamic Logic} adds Terms denoting \emph{Actions}:
\[[a]p\]
where after performing Action $a$ is necessitated that $p$ holds and
\[\langle a \rangle p\]
where after performing Action $a$ it is possible that $p$ holds.

\subsection{Intuitionistic Logic}\label{subsec:intuitionistic_logic}

\subsubsection{Minimal Logic}

\subsubsection{Combinatory Logic} \label{subsec:combinatory_logic}

\subsection{Substructural Logic}

\subsubsection{Relevance Logic}

\subsubsection{Linear Logic}

\paragraph{Non-commutative Logic}\label{subsec:noncommutative_logic}

\subsection{Ordinal Logic}

Alan Turing's PhD Thesis \cite{turing38}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Proof Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Metatheory} \label{sec:metatheory}

\emph{Proof Theory} is itself \emph{Metamathematical} in that it
studies the form of Logical Consequence within Logical Systems, and
therefore is expressed as \emph{Metatheory}.

A \emph{Judgement} is an inductively definable assertion in the
Metatheory of a Logical System. That is, one that includes
Extra-logical Symbols, namely that of Logical Consequence, $\vdash$,
and commas used in \emph{Sequents}
(\S\ref{subsec:sequent_notation}). In this way, Axioms are Judgements,
and a \emph{Formal Proof} expresses a Judgement with the Premises
being a sequence of Judgements and the Conclusion also a Judgement.

\subsection{Formal Proof} \label{subsec:formal_proof}

A Formal Proof is a \emph{Logical Derivation}: a finite
sequence of Well-formed Formulas of a Formal System that are either
Axioms of a Logical System or follow from the preceding Formulas by an
Inference Rule. The concluding Formula in the sequence is a
\emph{Theorem}.

For a Formal System, $\mathcal{S}$, of a set of Formulas, $\Gamma$,
there is a \emph{Syntactic Consequence}, $A$, if there is a
Formal Proof of $A$ from the set $\Gamma$:
\[
    \Gamma \vdash_{\mathcal{S}} A
\]
It will suffice for now to say that Syntactic Consequence as
differentiated from \emph{Material Consequence} should: % FIXME ref
                                % material consequence
\begin{enumerate}
\item Rely on the Logical Form (\S\ref{subsec:inference_rules}) of the
  Expressions
\item Be completely \emph{a priori}
\item Be \emph{Modal} (\S\ref{subsec:modal_logic})
\end{enumerate}
Another form of Logical Consequence, \emph{Semantic Consequence} will
be described under \emph{Model Theory} (Part \ref{sec:model_theory}).

Proof by Syntactic Consequence is a \emph{Deduction}; that is, the
production of a Theorem is said to be a \emph{Derivation}. Deduction
proper is the top-down, \emph{Reductive} process that starts with
general Axioms and Reduces to the specific Theorem that is being
proved. \emph{Mathematical Induction} is the bottom-up,
\emph{Implicative} process where a \emph{Base Case} is shown to extend
to the more general by means of Implication (the Inductive step). Note
that Mathematical Induction is not \emph{Inductive Reasoning} which is
an empirical or probabilistic Inference and not a form of Deduction.

\subsubsection{Sequent Notation}\label{subsec:sequent_notation}

A \emph{Sequent} is a specific kind of Judgement of the form
\[\Gamma \vdash \Sigma \]
where the \emph{Antecedent}, $\Gamma$, is a Conjunctive sequence of
Formula, and the \emph{Succedent}, $\Sigma$, is a Disjunctive sequence
of Formulas. Together, Antecedents and Succedents are
\emph{Cedents}. The Extra-logical Operators, $\vdash$, and $,$
(comma), are called \emph{Structural Operators}. A sequence of Cedents
may be called a \emph{Context}, but \emph{the} Context for a specific
Judgement is usually meant to be the Antecedent.

In a general \emph{Sequent Calculus} there may be any
number of Formulas on either side
\[
    A_1, \ldots, A_n \vdash B_1, \ldots, B_k
\]
is equivalent to
\[
    \vdash(A_1 \wedge \cdots \wedge A_n) \rightarrow (B_1 \vee \cdots \vee B_k)
\]
and the dual nature of Judgements and negation can be expressed by the
dual forms
\[
    \vdash \neg A_1 \vee \cdots \vee \neg A_n \vee B_1 \vee \cdots
    \vee B_k
\]
and
\[
    \vdash \neg(A_1 \wedge \cdots \wedge A_n \wedge \neg B_1 \wedge
    \cdots \wedge \neg B_k)
\]

A Sequent with no Succedent ($\Gamma \vdash$) is interpreted as
proving falsity which is inconsistent. A Sequent with no Antecedent
($\vdash \Sigma$) is a \emph{Logical Assertion}.

% --------------------------------------------------------------------
\section{Proof Calculi}
% --------------------------------------------------------------------

\emph{Proof Calculi} are families of Formal (Deductive) Systems
(\S\ref{sec:formal_systems}), specifying templates for forms of
\emph{Formal Inference} (Axioms and Inference Rules).

% --------------------------------------------------------------------
\subsection{Axiomatic Systems}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\subsubsection{Hilbert Systems} \label{subsec:hilbert_systems}
% --------------------------------------------------------------------

\emph{Hilbert Systems} are characterized by having a large number of
Axiom Schema and few Inference Rules-- just Modus Ponens for
Propositional Logics and Universal Generalization for Predicate
Logic. In a Hilbert System, Judgements and Formulas are not
differentiated.

% --------------------------------------------------------------------
\subsection{Structural Proof Theory}
% --------------------------------------------------------------------

\emph{Structural Proof Theory} studies Proof Calculi that support
\emph{Analytic Proof}; that is Proofs that are \emph{Cut-free} (they
do not use the \emph{Cut Rule}) or in \emph{Normal Form}.

\subsubsection{Natural Deduction}\label{subsec:natural_deduction} \hfill
\\
Systems of \emph{Natural Deduction}\cite{prawitz65}, contrasted with
Hilbert Systems, include many Inference Rules but few or no Axioms. A
Natural Deduction System allows Judgements with multiple Antecedents
and a single Succedent
\[
    A_1,\ldots,A_n \vdash B
\]
Inference Rules in Natural Deduction have the general notation
\[
    {J_1 \quad J_2 \quad \cdots \quad J_n
    \over J} name
\]
where the Rule with name $name$ has Premises of zero or more
Judgements $J_i$ and the Judgement $J$ is the Conclusion.

Inference Rules that introduce a Logical Connective in the Conclusion
are called \emph{Introduction Rules}. Example
\[
    {A\;\mathrm{true} \quad B\;\mathrm{true}
    \over (A \wedge B)\;\mathrm{true}} \wedge_I
\]
where $A$ and $B$ are Propositions.

Conversely, Inference Rules that remove Logical Connectives are
\emph{Elimination Rules}.
\[
    {A \wedge B\;\mathrm{true}
    \over A\;\mathrm{true}} \wedge_E
\]

\emph{Hypothetical Derivations} (reasoning from \emph{Assumptions})
are required for Implication Introduction or Disjunction Elimination.

\emph{Normal Form}

\subsubsection{Sequent Calculus}

\paragraph{$\mathbf{LJ}$} \hfill \\

Formalization of Intuitionistic Logic (\S\ref{subsec:intuitionistic_logic})

\paragraph{$\mathbf{LK}$} \hfill \\

Formalization of Classical Logic (\S\ref{subsec:classical_logic})

\subsection{Calculus of Structures}

\emph{Deep Inference}

Non-commutative Logic (\S\ref{subsec:noncommutative_logic})

\subsection{Analytic Tableau}

Theoretic

Problematic

% --------------------------------------------------------------------
Synthesis
% --------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Model Theory}\label{sec:model_theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Metalogic

Semantic Consequence of a Logic System

Tautology

Interpretation

% --------------------------------------------------------------------
\section{Algebraic Logic}
% --------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Formal Semantics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Material Consequence

Proof-theoretic Semantics

Logical Harmony

Semantic Tableau

% --------------------------------------------------------------------
\section{Interpretation}\label{sec:interpretation}
% --------------------------------------------------------------------
% --------------------------------------------------------------------
\section{Denotational Semantics}
% --------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Type Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Curry-Howard Correspondence

% --------------------------------------------------------------------
\section{$\lambda$-Calculus}
% --------------------------------------------------------------------

% --------------------------------------------------------------------
\section{Intuitionistic Type Theory}
% --------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Set Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% --------------------------------------------------------------------
\section{Order Theory}
% --------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Graph Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Category Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Complexity Theory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% --------------------------------------------------------------------
\section{Algorithms}
% --------------------------------------------------------------------

An \emph{Algorithm} may be formalized as a sequence of operations that
can be simulated by a Turing-complete system and any function
that is computable by Algorithm is a \emph{computable function}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Topology}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{9}

\bibitem{turing38}
    Alan Turing,
    \emph{Systems of Logic Based on Ordinals},
    Princeton,
    1938.

\bibitem{kozen97}
    Dexter C. Kozen,
    \emph{Automata and Computability},
    Springer,
    1997

\bibitem{aho69}
    Alfred V. Aho,
    \emph{Nested stack automata},
    Journal of the ACM,
    1969

\bibitem{villemonte02}
    \'Eric Villemonte de la Clergerie,
    \emph{Parsing mildly context-sensitive languages with thread automata},
    COLING '02 Proceedings,
    2002

\bibitem{vijayashanker88}
    K. Vijayashanker,
    \emph{A study of tree adjoining grammars},
    University of Pennsylvania,
    1988

\bibitem{schutzenberger65}
    Mercel-Paul Sch\"utzenberger,
    \emph{On finite monoids having only trivial subgroups},
    Information and Computation,
    1965

\bibitem{mcnaughton-papert71}
    Robert McNaughton, Seymour Papert,
    \emph{Counter-free Automata},
    MIT Press,
    1971

\bibitem{skolem23}
    Thoralf Skolem,
    \emph{The foundations of elementary arithmetic},
    1923,
    trans. Jean van Heijenoort,
    \emph{From Frege to G\"odel: A Source Book in Mathematical Logic, 1879-1931},
    Harvard Univ. Press,
    1967

\bibitem{jaskowski34}
    Stanislaw Ja\'skowski,
    \emph{On the Rules of Suppositions in Formal Logic},
    1934,
    ed. Storrs McCall,
    \emph{Polish logic 1920-39},
    Oxford,
    1967

\bibitem{shapiro00}
    S. Shapiro,
    \emph{Foundations without Foundationalism: A Case for Second-order
    Logic},
    Oxford University Press,
    2000

\bibitem{prawitz65}
    Dag Prawitz,
    \emph{Natural Deduction: A proof-theoretical study},
    Dover,
    1965

\end{thebibliography}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
